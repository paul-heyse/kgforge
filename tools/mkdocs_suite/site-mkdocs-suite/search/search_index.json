{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"KgFoundry MkDocs Suite","text":""},{"location":"#kgfoundry-mkdocs-suite","title":"KgFoundry MkDocs Suite","text":"<p>Welcome to the experimental MkDocs-driven documentation experience for KgFoundry. This site is generated independently from the primary Sphinx build so that new navigation patterns and auxiliary assets can evolve without putting pressure on the production pipeline.</p> <p>Use the navigation sidebar to explore architecture notes, API references, and dynamically generated module summaries powered by Griffe.</p>"},{"location":"api/","title":"Api","text":""},{"location":"api/#http-api","title":"HTTP API","text":""},{"location":"api/interfaces/","title":"Interface Catalog","text":""},{"location":"api/interfaces/#interface-catalog","title":"Interface Catalog","text":"<p>This catalog is generated from <code>_nav.json</code> sidecars and the shared interface registry.</p> Interface Type Module Owner Stability Spec Description Problem Details orchestration-cli cli orchestration @orchestration beta CLI Spec Primary Typer application for orchestration flows and indexing commands. \u2014 search-http http search_api @search-api experimental HTTP API FastAPI application exposing search operations via the public HTTP API. schema/examples/problem_details/search-missing-index.json, schema/examples/problem_details/search-gpu-unavailable.json"},{"location":"api/interfaces/#orchestration-cli","title":"orchestration-cli","text":"<ul> <li>Type: cli</li> <li>Module: orchestration</li> <li>Owner: @orchestration</li> <li>Stability: beta</li> <li>Description: Typer-powered orchestration command suite covering indexing flows, API bootstrapping, and end-to-end demonstrations. Each command maps to a generated OpenAPI operation consumed by the MkDocs suite.</li> </ul>"},{"location":"api/interfaces/#operations","title":"Operations","text":"<ul> <li><code>cli.index_bm25</code> \u2014 Build BM25 index from JSON/Parquet chunks.<ul> <li>Module docs: orchestration.cli</li> <li>Source: orchestration.cli</li> </ul> </li> <li>Tags: orchestration, index_bm25</li> <li>Handler: <code>orchestration.cli:index_bm25</code></li> <li>Problem Details: schema/examples/problem_details/tool-execution-error.json</li> <li>Code Samples:<ul> <li>(bash) <code>kgf index-bm25 data/chunks.parquet --backend lucene --index-dir ./_indices/bm25</code></li> </ul> </li> <li><code>cli.index_faiss</code> \u2014 Build FAISS index from dense vectors.<ul> <li>Module docs: orchestration.cli</li> <li>Source: orchestration.cli</li> </ul> </li> <li>Tags: orchestration, index_faiss</li> <li>Handler: <code>orchestration.cli:index_faiss</code></li> <li>Env: KGF_FAISS_RESOURCES</li> <li>Problem Details: schema/examples/problem_details/tool-execution-error.json, schema/examples/problem_details/faiss-index-build-timeout.json</li> <li>Code Samples:<ul> <li>(bash) <code>kgf index-faiss artifacts/vectors.json --factory 'OPQ64,IVF8192,PQ64' --metric ip</code></li> </ul> </li> <li><code>cli.api</code> \u2014 Launch FastAPI search service.<ul> <li>Module docs: orchestration.cli</li> <li>Source: orchestration.cli</li> </ul> </li> <li>Tags: orchestration, api</li> <li>Handler: <code>orchestration.cli:api</code></li> <li>Env: KGF_SEARCH_CONFIG</li> <li>Problem Details: schema/examples/problem_details/public-api-invalid-config.json</li> <li>Code Samples:<ul> <li>(bash) <code>kgf api --port 8080</code></li> </ul> </li> <li><code>cli.e2e</code> \u2014 Execute end-to-end orchestration demo.<ul> <li>Module docs: orchestration.cli</li> <li>Source: orchestration.cli</li> </ul> </li> <li>Tags: orchestration, e2e</li> <li>Handler: <code>orchestration.cli:e2e</code></li> <li>Env: KGF_PROFILE</li> <li>Problem Details: schema/examples/problem_details/public-api-invalid-config.json</li> <li>Code Samples:<ul> <li>(bash) <code>kgf e2e</code></li> </ul> </li> </ul>"},{"location":"api/interfaces/#search-http","title":"search-http","text":"<ul> <li>Type: http</li> <li>Module: search_api</li> <li>Owner: @search-api</li> <li>Stability: experimental</li> <li>Description: FastAPI service exposing search endpoints, aggregation helpers, and Problem Details responses.</li> </ul>"},{"location":"api/openapi-cli/","title":"CLI Specification","text":""},{"location":"api/openapi-cli/#cli-specification","title":"CLI Specification","text":""},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#architecture-overview","title":"Architecture Overview","text":"<p>This section is reserved for high-level system documentation. Populate the page with architecture narratives, diagrams, or operational guides as the MkDocs suite matures.</p>"},{"location":"cli/","title":"Cli","text":""},{"location":"cli/#command-reference","title":"Command Reference","text":""},{"location":"cli/#app","title":"app","text":"<p>kgfoundry orchestration CLI</p> <p>Usage:</p> <pre><code> [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <pre><code>  --install-completion  Install completion for the current shell.\n  --show-completion     Show completion for the current shell, to copy it or\n                        customize the installation.\n</code></pre>"},{"location":"cli/#api","title":"api","text":"<p>Start FastAPI search service.</p>"},{"location":"cli/#parameters","title":"Parameters","text":"<p>port : int, optional     Port to bind to. Defaults to 8080.</p>"},{"location":"cli/#raises","title":"Raises","text":"<p>typer.Exit     If uvicorn is not available or entry point is missing (exit code 1).</p> <p>Usage:</p> <pre><code> api [OPTIONS]\n</code></pre> <p>Options:</p> <pre><code>  --port INTEGER  \\[default: 8080]\n</code></pre>"},{"location":"cli/#e2e","title":"e2e","text":"<p>Execute end-to-end orchestration pipeline.</p> <p>This command runs the complete e2e flow using Prefect orchestration. Requires Prefect to be installed.</p>"},{"location":"cli/#raises_1","title":"Raises","text":"<p>typer.Exit     If Prefect is not installed (exit code 1).</p> <p>Usage:</p> <pre><code> e2e [OPTIONS]\n</code></pre>"},{"location":"cli/#index_bm25","title":"index_bm25","text":"<p>Usage:</p> <pre><code> index_bm25 [OPTIONS] CHUNKS_PARQUET\n</code></pre> <p>Options:</p> <pre><code>  CHUNKS_PARQUET    Path to Parquet/JSONL with chunks  \\[required]\n  --backend TEXT    lucene|pure  \\[default: lucene]\n  --index-dir TEXT  Output index directory  \\[default: ./_indices/bm25]\n</code></pre>"},{"location":"cli/#index_faiss","title":"index_faiss","text":"<p>Build FAISS index from dense vectors.</p> <p>This command builds a FAISS index from dense vector data with structured observability and comprehensive error handling. The operation is idempotent: if an index already exists at the output path, it will be rebuilt from scratch.</p>"},{"location":"cli/#parameters_1","title":"Parameters","text":"<p>dense_vectors : str     Path to JSON file containing vectors in skeleton format.     Expected format: list of {\"key\": \"id\", \"vector\": [float, ...]} objects. index_path : str, optional     Output path for the index file. Defaults to \"./_indices/faiss/shard_000.idx\". factory : str, optional     FAISS factory string (e.g., \"Flat\", \"OPQ64,IVF8192,PQ64\").     Defaults to \"Flat\" for testing; production uses \"OPQ64,IVF8192,PQ64\". metric : str, optional     Metric type: \"ip\" (inner product) or \"l2\" (L2 distance).     Defaults to \"ip\".</p>"},{"location":"cli/#notes","title":"Notes","text":"<ul> <li>Idempotency: Running twice with identical inputs rebuilds the index.</li> <li>Retries: No automatic retries. On failure, check logs and re-run.</li> <li>GPU Fallback: If GPU unavailable, CPU index is built automatically.</li> </ul>"},{"location":"cli/#notes_1","title":"Notes","text":"<p>Propagates :class:<code>typer.Exit</code> from :func:<code>run_index_faiss</code> when the index build fails.</p>"},{"location":"cli/#examples","title":"Examples","text":"<p>Build Flat CPU index for testing::</p> <pre><code>kgfoundry orchestration cli index_faiss vectors.json\n</code></pre> <p>Build quantized GPU index::</p> <pre><code>kgfoundry orchestration cli index_faiss vectors.json \\\\\n    --factory \"OPQ64,IVF8192,PQ64\"\n</code></pre> <p>Usage:</p> <pre><code> index_faiss [OPTIONS] DENSE_VECTORS\n</code></pre> <p>Options:</p> <pre><code>  DENSE_VECTORS      Path to dense vectors JSON (skeleton)  \\[required]\n  --index-path TEXT  Output index (CPU .idx)  \\[default:\n                     ./_indices/faiss/shard_000.idx]\n  --factory TEXT     FAISS factory string  \\[default: Flat]\n  --metric TEXT      Metric: 'ip' or 'l2'  \\[default: ip]\n</code></pre> <p>:::</p>"},{"location":"diagrams/","title":"Diagrams","text":""},{"location":"diagrams/#diagrams","title":"Diagrams","text":"<ul> <li>api</li> <li>app</li> <li>base</li> <li>bm25</li> <li>bm25_index</li> <li>calibration</li> <li>canonicalizer</li> <li>catalog</li> <li>cli</li> <li>client</li> <li>config</li> <li>docling</li> <li>download</li> <li>duckdb_helpers</li> <li>duckdb_registry</li> <li>embeddings_dense</li> <li>embeddings_sparse</li> <li>errors</li> <li>exceptions</li> <li>faiss_adapter</li> <li>faiss_gpu</li> <li>fastapi_helpers</li> <li>fixture_flow</li> <li>fixture_index</li> <li>flows</li> <li>fs</li> <li>fusion</li> <li>gpu</li> <li>harvester</li> <li>helper</li> <li>hybrid</li> <li>ids</li> <li>jsonschema_utils</li> <li>kg_builder</li> <li>kg_mock</li> <li>kgfoundry_common</li> <li>linker</li> <li>linking</li> <li>loader</li> <li>logging</li> <li>metrics</li> <li>migrate</li> <li>mock_kg</li> <li>models</li> <li>navmap_loader</li> <li>navmap_types</li> <li>neo4j_store</li> <li>numpy_typing</li> <li>observability</li> <li>ontology</li> <li>opentelemetry_types</li> <li>optional_deps</li> <li>orchestration</li> <li>parquet_io</li> <li>problem_details</li> <li>prometheus</li> <li>pydantic</li> <li>qwen3</li> <li>registry</li> <li>safe_pickle</li> <li>safe_pickle_v2</li> <li>schema_helpers</li> <li>schemas</li> <li>search_api</li> <li>search_client</li> <li>sequence_guards</li> <li>serialization</li> <li>service</li> <li>settings</li> <li>splade</li> <li>splade_index</li> <li>subprocess_utils</li> <li>types</li> <li>typing</li> <li>vector_types</li> <li>vectorstore_factory</li> <li>vectorstore_faiss</li> <li>vlm</li> </ul>"},{"location":"modules/","title":"Modules","text":""},{"location":"modules/#modules","title":"Modules","text":"<ul> <li>docling</li> <li>docling.canonicalizer</li> <li>docling.hybrid</li> <li>docling.vlm</li> <li>download</li> <li>download.cli</li> <li>download.harvester</li> <li>embeddings_dense</li> <li>embeddings_dense.base</li> <li>embeddings_dense.qwen3</li> <li>embeddings_sparse</li> <li>embeddings_sparse.base</li> <li>embeddings_sparse.bm25</li> <li>embeddings_sparse.splade</li> <li>kg_builder</li> <li>kg_builder.mock_kg</li> <li>kg_builder.neo4j_store</li> <li>kgfoundry_common</li> <li>kgfoundry_common.config</li> <li>kgfoundry_common.errors</li> <li>kgfoundry_common.errors.codes</li> <li>kgfoundry_common.errors.exceptions</li> <li>kgfoundry_common.errors.http</li> <li>kgfoundry_common.exceptions</li> <li>kgfoundry_common.fastapi_helpers</li> <li>kgfoundry_common.fs</li> <li>kgfoundry_common.gpu</li> <li>kgfoundry_common.ids</li> <li>kgfoundry_common.jsonschema_utils</li> <li>kgfoundry_common.logging</li> <li>kgfoundry_common.models</li> <li>kgfoundry_common.navmap_loader</li> <li>kgfoundry_common.navmap_types</li> <li>kgfoundry_common.numpy_typing</li> <li>kgfoundry_common.observability</li> <li>kgfoundry_common.opentelemetry_types</li> <li>kgfoundry_common.optional_deps</li> <li>kgfoundry_common.parquet_io</li> <li>kgfoundry_common.problem_details</li> <li>kgfoundry_common.prometheus</li> <li>kgfoundry_common.pydantic</li> <li>kgfoundry_common.safe_pickle_v2</li> <li>kgfoundry_common.schema_helpers</li> <li>kgfoundry_common.sequence_guards</li> <li>kgfoundry_common.serialization</li> <li>kgfoundry_common.settings</li> <li>kgfoundry_common.subprocess_utils</li> <li>kgfoundry_common.types</li> <li>kgfoundry_common.typing</li> <li>kgfoundry_common.vector_types</li> <li>linking</li> <li>linking.calibration</li> <li>linking.linker</li> <li>observability</li> <li>observability.metrics</li> <li>ontology</li> <li>ontology.catalog</li> <li>ontology.loader</li> <li>orchestration</li> <li>orchestration.cli</li> <li>orchestration.config</li> <li>orchestration.fixture_flow</li> <li>orchestration.flows</li> <li>orchestration.safe_pickle</li> <li>registry</li> <li>registry.api</li> <li>registry.duckdb_helpers</li> <li>registry.duckdb_registry</li> <li>registry.helper</li> <li>registry.migrate</li> <li>search_api</li> <li>search_api.app</li> <li>search_api.bm25_index</li> <li>search_api.faiss_adapter</li> <li>search_api.faiss_gpu</li> <li>search_api.fastapi_helpers</li> <li>search_api.fixture_index</li> <li>search_api.fusion</li> <li>search_api.kg_mock</li> <li>search_api.schemas</li> <li>search_api.service</li> <li>search_api.splade_index</li> <li>search_api.types</li> <li>search_api.vectorstore_factory</li> <li>search_client</li> <li>search_client.client</li> <li>vectorstore_faiss</li> <li>vectorstore_faiss.gpu</li> </ul>"},{"location":"modules/docling.canonicalizer/","title":"docling.canonicalizer","text":""},{"location":"modules/docling.canonicalizer/#doclingcanonicalizer","title":"docling.canonicalizer","text":"<p>String canonicalisation utilities for docling preprocessing</p> <p>:material-source-repository: View source</p>"},{"location":"modules/docling.canonicalizer/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"docling.canonicalizer__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatareunicodedatadocling.canonicalizer code <p>See the full diagram: docling.canonicalizer</p>"},{"location":"modules/docling.canonicalizer/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>docling.canonicalizer.canonicalize_text</li> </ul>"},{"location":"modules/docling.canonicalizer/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>re</code>, <code>unicodedata</code></p>"},{"location":"modules/docling.canonicalizer/#contents","title":"Contents","text":""},{"location":"modules/docling.canonicalizer/#doclingcanonicalizercanonicalize_text","title":"docling.canonicalizer.canonicalize_text","text":""},{"location":"modules/docling.canonicalizer/#docling.canonicalizer.canonicalize_text","title":"<code>docling.canonicalizer.canonicalize_text(blocks)</code>","text":"<p>Canonicalize text blocks by normalizing Unicode and whitespace.</p> <p>Normalizes Unicode characters (NFC), standardizes line endings, replaces bullet points and dashes with hyphens, removes control characters, and collapses whitespace. Returns a single joined string.</p> <p>Parameters:</p> Name Type Description Default <code>blocks</code> <code>list[str]</code> <p>List of text blocks to canonicalize.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Canonicalized text joined with newlines, with empty blocks filtered.</p> Source code in <code>src/docling/canonicalizer.py</code> <pre><code>def canonicalize_text(blocks: list[str]) -&gt; str:\n    \"\"\"Canonicalize text blocks by normalizing Unicode and whitespace.\n\n    Normalizes Unicode characters (NFC), standardizes line endings,\n    replaces bullet points and dashes with hyphens, removes control\n    characters, and collapses whitespace. Returns a single joined string.\n\n    Parameters\n    ----------\n    blocks : list[str]\n        List of text blocks to canonicalize.\n\n    Returns\n    -------\n    str\n        Canonicalized text joined with newlines, with empty blocks filtered.\n    \"\"\"\n\n    def norm(s: str) -&gt; str:\n        \"\"\"Compute norm.\n\n        Carry out the norm operation for the surrounding component. Generated documentation highlights how this helper collaborates with neighbouring utilities. Callers rely on the routine to remain stable across releases.\n\n        Parameters\n        ----------\n        s : str\n            Description for ``s``.\n\n        Returns\n        -------\n        str\n            Description of return value.\n\n        Examples\n        --------\n        &gt;&gt;&gt; from docling.canonicalizer import norm\n        &gt;&gt;&gt; result = norm(...)\n        &gt;&gt;&gt; result  # doctest: +ELLIPSIS\n        \"\"\"\n        s = unicodedata.normalize(\"NFC\", s)\n        s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n        s = re.sub(r\"[\\u2022\\u25E6\\u2013]\", \"-\", s)  # bullets/dashes\n        s = re.sub(r\"[\\x00-\\x1F]\", \" \", s)\n        return re.sub(r\"\\s+\", \" \", s).strip()\n\n    normed = [norm(b) for b in blocks if b.strip()]\n    return \"\\n\".join(normed)\n</code></pre>"},{"location":"modules/docling.hybrid/","title":"docling.hybrid","text":""},{"location":"modules/docling.hybrid/#doclinghybrid","title":"docling.hybrid","text":"<p>Hybrid docling pipeline combining layout and text cues</p> <p>:material-source-repository: View source</p>"},{"location":"modules/docling.hybrid/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class HybridChunker\n</code></pre>"},{"location":"modules/docling.hybrid/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"docling.hybrid__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatadocling.hybrid code <p>See the full diagram: docling.hybrid</p>"},{"location":"modules/docling.hybrid/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>docling.hybrid.HybridChunker</li> </ul>"},{"location":"modules/docling.hybrid/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p>"},{"location":"modules/docling.hybrid/#contents","title":"Contents","text":""},{"location":"modules/docling.hybrid/#doclinghybridhybridchunker","title":"docling.hybrid.HybridChunker","text":""},{"location":"modules/docling.hybrid/#docling.hybrid.HybridChunker","title":"<code>docling.hybrid.HybridChunker</code>","text":"<p>Placeholder class for hybrid docling chunking pipeline.</p> <p>This class serves as a placeholder for future hybrid chunking functionality that combines layout and text cues for document processing. Implementation details will be added later.</p> Source code in <code>src/docling/hybrid.py</code> <pre><code>class HybridChunker:\n    \"\"\"Placeholder class for hybrid docling chunking pipeline.\n\n    This class serves as a placeholder for future hybrid chunking functionality that combines layout\n    and text cues for document processing. Implementation details will be added later.\n    \"\"\"\n</code></pre>"},{"location":"modules/docling/","title":"docling","text":""},{"location":"modules/docling/#docling","title":"docling","text":"<p>Public surface for docling preprocessing utilities</p> <p>:material-source-repository: View source</p>"},{"location":"modules/docling/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"docling__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.navmap_types.NavMapdocling code <p>See the full diagram: docling</p>"},{"location":"modules/docling/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.navmap_types.NavMap</code></p>"},{"location":"modules/docling.vlm/","title":"docling.vlm","text":""},{"location":"modules/docling.vlm/#doclingvlm","title":"docling.vlm","text":"<p>Vision-language tagging helpers for docling</p> <p>:material-source-repository: View source</p>"},{"location":"modules/docling.vlm/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class GraniteDoclingVLM\n</code></pre>"},{"location":"modules/docling.vlm/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"docling.vlm__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatadocling.vlm code <p>See the full diagram: docling.vlm</p>"},{"location":"modules/docling.vlm/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>docling.vlm.GraniteDoclingVLM</li> </ul>"},{"location":"modules/docling.vlm/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p>"},{"location":"modules/docling.vlm/#contents","title":"Contents","text":""},{"location":"modules/docling.vlm/#doclingvlmgranitedoclingvlm","title":"docling.vlm.GraniteDoclingVLM","text":""},{"location":"modules/docling.vlm/#docling.vlm.GraniteDoclingVLM","title":"<code>docling.vlm.GraniteDoclingVLM</code>","text":"<p>Placeholder class for vision-language model tagging helpers.</p> <p>This class serves as a placeholder for future Granite vision-language model integration for docling document processing. Implementation details will be added later.</p> Source code in <code>src/docling/vlm.py</code> <pre><code>class GraniteDoclingVLM:\n    \"\"\"Placeholder class for vision-language model tagging helpers.\n\n    This class serves as a placeholder for future Granite vision-language model integration for\n    docling document processing. Implementation details will be added later.\n    \"\"\"\n</code></pre>"},{"location":"modules/download.cli/","title":"download.cli","text":""},{"location":"modules/download.cli/#downloadcli","title":"download.cli","text":"<p>Command-line entrypoints for bulk download orchestration</p> <p>:material-source-repository: View source</p>"},{"location":"modules/download.cli/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"download.cli__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatatyperdownload.cli code <p>See the full diagram: download.cli</p>"},{"location":"modules/download.cli/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>download.cli.harvest</li> </ul>"},{"location":"modules/download.cli/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>typer</code></p>"},{"location":"modules/download.cli/#contents","title":"Contents","text":""},{"location":"modules/download.cli/#downloadcliharvest","title":"download.cli.harvest","text":""},{"location":"modules/download.cli/#download.cli.harvest","title":"<code>download.cli.harvest(topic, years='&gt;=2018', max_works=20000)</code>","text":"<p>Harvest documents from OpenAlex matching the given criteria.</p> <p>Downloads research papers from OpenAlex filtered by topic and publication year. Currently implements a dry-run mode.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>str</code> <p>Topic query string for filtering papers.</p> required <code>years</code> <code>str</code> <p>Year filter expression (e.g., \"&gt;=2018\"). Defaults to \"&gt;=2018\".</p> <code>'&gt;=2018'</code> <code>max_works</code> <code>int</code> <p>Maximum number of works to harvest. Defaults to 20000.</p> <code>20000</code> Source code in <code>src/download/cli.py</code> <pre><code>def harvest(topic: str, years: str = \"&gt;=2018\", max_works: int = 20000) -&gt; None:\n    \"\"\"Harvest documents from OpenAlex matching the given criteria.\n\n    Downloads research papers from OpenAlex filtered by topic and\n    publication year. Currently implements a dry-run mode.\n\n    Parameters\n    ----------\n    topic : str\n        Topic query string for filtering papers.\n    years : str, optional\n        Year filter expression (e.g., \"&gt;=2018\"). Defaults to \"&gt;=2018\".\n    max_works : int, optional\n        Maximum number of works to harvest. Defaults to 20000.\n    \"\"\"\n    typer.echo(f\"[dry-run] would harvest topic={topic!r}, years={years}, max_works={max_works}\")\n</code></pre>"},{"location":"modules/download.harvester/","title":"download.harvester","text":""},{"location":"modules/download.harvester/#downloadharvester","title":"download.harvester","text":"<p>Utilities for harvesting open-access PDFs from OpenAlex.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/download.harvester/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class HarvesterConfig\n    class OpenAccessHarvester\n</code></pre>"},{"location":"modules/download.harvester/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"download.harvester__future__.annotationscollections.abc.Mappingcollections.abc.Sequencedataclasses.dataclasskgfoundry_common.errors.DownloadErrorkgfoundry_common.errors.UnsupportedMIMEErrorkgfoundry_common.models.Dockgfoundry_common.navmap_loader.load_nav_metadatapathlib.Pathrequeststimetyping.castdownload.harvester code <p>See the full diagram: download.harvester</p>"},{"location":"modules/download.harvester/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>download.harvester.HarvesterConfig</li> <li>download.harvester.OpenAccessHarvester</li> </ul>"},{"location":"modules/download.harvester/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Mapping</code>, <code>collections.abc.Sequence</code>, <code>dataclasses.dataclass</code>, <code>kgfoundry_common.errors.DownloadError</code>, <code>kgfoundry_common.errors.UnsupportedMIMEError</code>, <code>kgfoundry_common.models.Doc</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>pathlib.Path</code>, <code>requests</code>, <code>time</code>, <code>typing.cast</code></p>"},{"location":"modules/download.harvester/#contents","title":"Contents","text":""},{"location":"modules/download.harvester/#downloadharvesterharvesterconfig","title":"download.harvester.HarvesterConfig","text":""},{"location":"modules/download.harvester/#download.harvester.HarvesterConfig","title":"<code>download.harvester.HarvesterConfig</code>  <code>dataclass</code>","text":"<p>Configuration for OpenAccessHarvester.</p> <p>Provides configuration options for customizing API endpoints and output directory for the harvester. All fields have sensible defaults.</p> <p>Attributes:</p> Name Type Description <code>openalex_base</code> <code>str</code> <p>Base URL for the OpenAlex API. Defaults to \"https://api.openalex.org\".</p> <code>unpaywall_base</code> <code>str</code> <p>Base URL for the Unpaywall API. Defaults to \"https://api.unpaywall.org\".</p> <code>pdf_host_base</code> <code>str | None</code> <p>Optional base URL for a custom PDF hosting service. If provided, PDFs will be resolved using this host. Defaults to None.</p> <code>out_dir</code> <code>str</code> <p>Output directory path where downloaded PDFs will be saved. Defaults to \"/data/pdfs\".</p> Source code in <code>src/download/harvester.py</code> <pre><code>@dataclass(frozen=True)\nclass HarvesterConfig:\n    \"\"\"Configuration for OpenAccessHarvester.\n\n    Provides configuration options for customizing API endpoints and output\n    directory for the harvester. All fields have sensible defaults.\n\n    Attributes\n    ----------\n    openalex_base : str\n        Base URL for the OpenAlex API. Defaults to \"https://api.openalex.org\".\n    unpaywall_base : str\n        Base URL for the Unpaywall API. Defaults to \"https://api.unpaywall.org\".\n    pdf_host_base : str | None\n        Optional base URL for a custom PDF hosting service. If provided,\n        PDFs will be resolved using this host. Defaults to None.\n    out_dir : str\n        Output directory path where downloaded PDFs will be saved.\n        Defaults to \"/data/pdfs\".\n    \"\"\"\n\n    openalex_base: str = \"https://api.openalex.org\"\n    unpaywall_base: str = \"https://api.unpaywall.org\"\n    pdf_host_base: str | None = None\n    out_dir: str = \"/data/pdfs\"\n</code></pre>"},{"location":"modules/download.harvester/#downloadharvesteropenaccessharvester","title":"download.harvester.OpenAccessHarvester","text":""},{"location":"modules/download.harvester/#download.harvester.OpenAccessHarvester","title":"<code>download.harvester.OpenAccessHarvester</code>","text":"<p>Harvester for downloading open-access PDFs from OpenAlex.</p> <p>Provides functionality to search for academic works in OpenAlex, resolve PDF URLs through multiple sources (direct links, locations, Unpaywall, or custom PDF host), and download PDFs to local storage.</p> <p>Sets up HTTP session with proper headers and creates output directory if it doesn't exist.</p> <p>Parameters:</p> Name Type Description Default <code>user_agent</code> <code>str</code> <p>User agent string for HTTP requests (required by OpenAlex API).</p> required <code>contact_email</code> <code>str</code> <p>Contact email address for API requests (required by OpenAlex API).</p> required <code>config</code> <code>HarvesterConfig | None</code> <p>Optional configuration object. If None, uses default HarvesterConfig. Defaults to None.</p> <code>None</code> Source code in <code>src/download/harvester.py</code> <pre><code>class OpenAccessHarvester:\n    \"\"\"Harvester for downloading open-access PDFs from OpenAlex.\n\n    Provides functionality to search for academic works in OpenAlex, resolve\n    PDF URLs through multiple sources (direct links, locations, Unpaywall, or\n    custom PDF host), and download PDFs to local storage.\n\n    Sets up HTTP session with proper headers and creates output directory\n    if it doesn't exist.\n\n    Parameters\n    ----------\n    user_agent : str\n        User agent string for HTTP requests (required by OpenAlex API).\n    contact_email : str\n        Contact email address for API requests (required by OpenAlex API).\n    config : HarvesterConfig | None, optional\n        Optional configuration object. If None, uses default HarvesterConfig.\n        Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        user_agent: str,\n        contact_email: str,\n        config: HarvesterConfig | None = None,\n    ) -&gt; None:\n        cfg = config or HarvesterConfig()\n        self.ua = user_agent\n        self.email = contact_email\n        self.openalex = cfg.openalex_base.rstrip(\"/\")\n        self.unpaywall = cfg.unpaywall_base.rstrip(\"/\")\n        self.pdf_host = (cfg.pdf_host_base or \"\").rstrip(\"/\")\n        self.out_dir = cfg.out_dir\n        Path(self.out_dir).mkdir(parents=True, exist_ok=True)\n        self.session = requests.Session()\n        self.session.headers.update({\"User-Agent\": f\"{self.ua} ({self.email})\"})\n\n    def search(self, topic: str, years: str, max_works: int) -&gt; list[dict[str, object]]:\n        \"\"\"Search for works in OpenAlex matching the topic and year filter.\n\n        Queries the OpenAlex API for works matching the specified topic and\n        optional year filter. Returns up to max_works results as a list of\n        work dictionaries.\n\n        Parameters\n        ----------\n        topic : str\n            Topic query string (e.g., \"machine learning\").\n        years : str\n            Optional year filter string (e.g., \"publication_year:2020-2023\").\n            Empty string means no year filter.\n        max_works : int\n            Maximum number of works to return (capped at 200 per request).\n\n        Returns\n        -------\n        list[dict[str, object]]\n            List of work dictionaries from OpenAlex API. Each dictionary\n            contains work metadata (id, title, doi, locations, etc.).\n\n        Raises\n        ------\n        TypeError\n            If the response payload is not a mapping or contains invalid structure.\n        \"\"\"\n        url = f\"{self.openalex}/works\"\n        params: dict[str, str | int] = {\n            \"topic\": topic,\n            \"per_page\": min(200, max_works),\n            \"cursor\": \"*\",\n        }\n        if years:\n            params[\"filter\"] = years\n        response = self.session.get(url, params=params, timeout=30)\n        response.raise_for_status()\n        raw_payload: object = response.json()\n        if not isinstance(raw_payload, Mapping):\n            message = \"OpenAlex response payload must be a mapping\"\n            raise TypeError(message)\n        if not all(isinstance(key, str) for key in raw_payload):\n            message = \"OpenAlex payload keys must be strings\"\n            raise TypeError(message)\n        payload = cast(\"Mapping[str, object]\", raw_payload)\n        results_obj = payload.get(\"results\", [])\n        if not isinstance(results_obj, list):\n            message = \"OpenAlex response must contain a list of results\"\n            raise TypeError(message)\n        typed_results: list[dict[str, object]] = []\n        for entry in results_obj:\n            if not isinstance(entry, Mapping):\n                continue\n            if any(not isinstance(key, str) for key in entry):\n                continue\n            mapping_entry = cast(\"Mapping[str, object]\", entry)\n            typed_results.append(dict(mapping_entry))\n        return typed_results[:max_works]\n\n    def resolve_pdf(self, work: Mapping[str, object]) -&gt; str | None:\n        \"\"\"Resolve PDF URL for a work using multiple fallback strategies.\n\n        Attempts to find a PDF URL for the work by trying multiple sources:\n        1. Direct PDF URL from best_oa_location\n        2. PDF URL from locations array\n        3. Unpaywall API lookup (if DOI available)\n        4. Custom PDF host URL (if configured and DOI available)\n\n        Parameters\n        ----------\n        work : Mapping[str, object]\n            Work dictionary from OpenAlex API containing work metadata.\n\n        Returns\n        -------\n        str | None\n            PDF URL if found, None otherwise.\n        \"\"\"\n        direct = self._lookup_direct_pdf(work)\n        if direct:\n            return direct\n\n        from_locations = self._lookup_locations_pdf(work.get(\"locations\"))\n        if from_locations:\n            return from_locations\n\n        doi_obj = work.get(\"doi\")\n        if isinstance(doi_obj, str) and doi_obj:\n            unpaywall_url = self._resolve_unpaywall_pdf(doi_obj)\n            if unpaywall_url:\n                return unpaywall_url\n            host_url = self._host_pdf_url(doi_obj)\n            if host_url:\n                return host_url\n        return None\n\n    @staticmethod\n    def _lookup_direct_pdf(work: Mapping[str, object]) -&gt; str | None:\n        \"\"\"Look up PDF URL from work's best_oa_location field.\n\n        Checks the best_oa_location field in the work dictionary for a\n        direct PDF URL.\n\n        Parameters\n        ----------\n        work : Mapping[str, object]\n            Work dictionary from OpenAlex API.\n\n        Returns\n        -------\n        str | None\n            PDF URL from best_oa_location if found, None otherwise.\n        \"\"\"\n        best = work.get(\"best_oa_location\")\n        if isinstance(best, Mapping):\n            pdf_url = best.get(\"pdf_url\")\n            if isinstance(pdf_url, str) and pdf_url:\n                return pdf_url\n        return None\n\n    @staticmethod\n    def _lookup_locations_pdf(locations: object) -&gt; str | None:\n        \"\"\"Look up PDF URL from work's locations array.\n\n        Searches through the locations array for the first location with\n        a valid PDF URL.\n\n        Parameters\n        ----------\n        locations : object\n            Locations array from work dictionary. Can be a sequence of\n            location dictionaries or other types.\n\n        Returns\n        -------\n        str | None\n            PDF URL from locations array if found, None otherwise.\n        \"\"\"\n        if isinstance(locations, (str, bytes)):\n            return None\n        if not isinstance(locations, Sequence):\n            return None\n        for location in locations:\n            if isinstance(location, Mapping):\n                candidate = location.get(\"pdf_url\")\n                if isinstance(candidate, str) and candidate:\n                    return candidate\n        return None\n\n    def _resolve_unpaywall_pdf(self, doi: str) -&gt; str | None:\n        \"\"\"Resolve PDF URL using Unpaywall API.\n\n        Queries the Unpaywall API for the given DOI and returns the PDF URL\n        from the best open-access location if available.\n\n        Parameters\n        ----------\n        doi : str\n            Digital Object Identifier (DOI) of the work.\n\n        Returns\n        -------\n        str | None\n            PDF URL from Unpaywall if found, None otherwise.\n        \"\"\"\n        response = self.session.get(\n            f\"{self.unpaywall}/v2/{doi}\", params={\"email\": self.email}, timeout=15\n        )\n        if not response.ok:\n            return None\n        raw_payload: object = response.json()\n        if isinstance(raw_payload, Mapping):\n            payload = cast(\"Mapping[str, object]\", raw_payload)\n            best_location = payload.get(\"best_oa_location\")\n            if isinstance(best_location, Mapping):\n                url = best_location.get(\"url_for_pdf\")\n                if isinstance(url, str) and url:\n                    return url\n        return None\n\n    def _host_pdf_url(self, doi: str) -&gt; str | None:\n        \"\"\"Construct PDF URL from custom PDF host configuration.\n\n        Generates a PDF URL using the configured pdf_host_base and the DOI.\n        The DOI is sanitized by replacing slashes with underscores.\n\n        Parameters\n        ----------\n        doi : str\n            Digital Object Identifier (DOI) of the work.\n\n        Returns\n        -------\n        str | None\n            PDF URL from custom host if pdf_host_base is configured,\n            None otherwise.\n        \"\"\"\n        if not self.pdf_host:\n            return None\n        return f\"{self.pdf_host}/pdf/{doi.replace('/', '_')}.pdf\"\n\n    def download_pdf(self, url: str, target_path: str | Path) -&gt; Path:\n        \"\"\"Download a PDF file from URL to local path.\n\n        Downloads the PDF file from the given URL and saves it to the\n        specified target path. Validates that the response is a PDF-like\n        content type.\n\n        Parameters\n        ----------\n        url : str\n            URL of the PDF file to download.\n        target_path : str | Path\n            Local file path where the PDF will be saved.\n\n        Returns\n        -------\n        Path\n            Path object pointing to the downloaded file.\n\n        Raises\n        ------\n        DownloadError\n            If the HTTP request returns a non-200 status code.\n        UnsupportedMIMEError\n            If the response content type is not PDF-like.\n        \"\"\"\n        response = self.session.get(url, timeout=60)\n        if response.status_code != HTTP_OK:\n            message = f\"Bad status {response.status_code} for {url}\"\n            raise DownloadError(message)\n        content_type = response.headers.get(\"Content-Type\", \"application/pdf\")\n        if not content_type.startswith(\"application/\"):\n            message = f\"Not a PDF-like content type: {content_type}\"\n            raise UnsupportedMIMEError(message)\n        path_obj = Path(target_path)\n        with path_obj.open(\"wb\") as file_handle:\n            file_handle.write(response.content)\n        return path_obj\n\n    def run(self, topic: str, years: str, max_works: int) -&gt; list[Doc]:\n        \"\"\"Run the complete harvesting workflow.\n\n        Searches for works, resolves PDF URLs, downloads PDFs, and creates\n        Doc objects for each successfully downloaded document.\n\n        Parameters\n        ----------\n        topic : str\n            Topic query string (e.g., \"machine learning\").\n        years : str\n            Optional year filter string (e.g., \"publication_year:2020-2023\").\n            Empty string means no year filter.\n        max_works : int\n            Maximum number of works to process.\n\n        Returns\n        -------\n        list[Doc]\n            List of Doc objects for successfully downloaded PDFs.\n        \"\"\"\n        docs: list[Doc] = []\n        works = self.search(topic, years, max_works)\n        for work in works:\n            pdf_url = self.resolve_pdf(work)\n            if not pdf_url:\n                continue\n            raw_name = work.get(\"doi\") or work.get(\"id\") or str(int(time.time() * 1000))\n            filename = f\"{str(raw_name).replace('/', '_')}.pdf\"\n            destination = Path(self.out_dir) / filename\n            destination = self.download_pdf(pdf_url, destination)\n            doc = Doc(\n                id=f\"urn:doc:source:openalex:{work.get('id', 'unknown')}\",\n                openalex_id=work.get(\"id\"),\n                doi=work.get(\"doi\"),\n                title=work.get(\"title\", \"\"),\n                authors=[],\n                pub_date=None,\n                license=None,\n                language=\"en\",\n                pdf_uri=destination,\n                source=\"openalex\",\n                content_hash=None,\n            )\n            docs.append(doc)\n        return docs\n</code></pre>"},{"location":"modules/download.harvester/#download.harvester.OpenAccessHarvester.download_pdf","title":"<code>download_pdf(url, target_path)</code>","text":"<p>Download a PDF file from URL to local path.</p> <p>Downloads the PDF file from the given URL and saves it to the specified target path. Validates that the response is a PDF-like content type.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL of the PDF file to download.</p> required <code>target_path</code> <code>str | Path</code> <p>Local file path where the PDF will be saved.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path object pointing to the downloaded file.</p> <p>Raises:</p> Type Description <code>DownloadError</code> <p>If the HTTP request returns a non-200 status code.</p> <code>UnsupportedMIMEError</code> <p>If the response content type is not PDF-like.</p> Source code in <code>src/download/harvester.py</code> <pre><code>def download_pdf(self, url: str, target_path: str | Path) -&gt; Path:\n    \"\"\"Download a PDF file from URL to local path.\n\n    Downloads the PDF file from the given URL and saves it to the\n    specified target path. Validates that the response is a PDF-like\n    content type.\n\n    Parameters\n    ----------\n    url : str\n        URL of the PDF file to download.\n    target_path : str | Path\n        Local file path where the PDF will be saved.\n\n    Returns\n    -------\n    Path\n        Path object pointing to the downloaded file.\n\n    Raises\n    ------\n    DownloadError\n        If the HTTP request returns a non-200 status code.\n    UnsupportedMIMEError\n        If the response content type is not PDF-like.\n    \"\"\"\n    response = self.session.get(url, timeout=60)\n    if response.status_code != HTTP_OK:\n        message = f\"Bad status {response.status_code} for {url}\"\n        raise DownloadError(message)\n    content_type = response.headers.get(\"Content-Type\", \"application/pdf\")\n    if not content_type.startswith(\"application/\"):\n        message = f\"Not a PDF-like content type: {content_type}\"\n        raise UnsupportedMIMEError(message)\n    path_obj = Path(target_path)\n    with path_obj.open(\"wb\") as file_handle:\n        file_handle.write(response.content)\n    return path_obj\n</code></pre>"},{"location":"modules/download.harvester/#download.harvester.OpenAccessHarvester.resolve_pdf","title":"<code>resolve_pdf(work)</code>","text":"<p>Resolve PDF URL for a work using multiple fallback strategies.</p> <p>Attempts to find a PDF URL for the work by trying multiple sources: 1. Direct PDF URL from best_oa_location 2. PDF URL from locations array 3. Unpaywall API lookup (if DOI available) 4. Custom PDF host URL (if configured and DOI available)</p> <p>Parameters:</p> Name Type Description Default <code>work</code> <code>Mapping[str, object]</code> <p>Work dictionary from OpenAlex API containing work metadata.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>PDF URL if found, None otherwise.</p> Source code in <code>src/download/harvester.py</code> <pre><code>def resolve_pdf(self, work: Mapping[str, object]) -&gt; str | None:\n    \"\"\"Resolve PDF URL for a work using multiple fallback strategies.\n\n    Attempts to find a PDF URL for the work by trying multiple sources:\n    1. Direct PDF URL from best_oa_location\n    2. PDF URL from locations array\n    3. Unpaywall API lookup (if DOI available)\n    4. Custom PDF host URL (if configured and DOI available)\n\n    Parameters\n    ----------\n    work : Mapping[str, object]\n        Work dictionary from OpenAlex API containing work metadata.\n\n    Returns\n    -------\n    str | None\n        PDF URL if found, None otherwise.\n    \"\"\"\n    direct = self._lookup_direct_pdf(work)\n    if direct:\n        return direct\n\n    from_locations = self._lookup_locations_pdf(work.get(\"locations\"))\n    if from_locations:\n        return from_locations\n\n    doi_obj = work.get(\"doi\")\n    if isinstance(doi_obj, str) and doi_obj:\n        unpaywall_url = self._resolve_unpaywall_pdf(doi_obj)\n        if unpaywall_url:\n            return unpaywall_url\n        host_url = self._host_pdf_url(doi_obj)\n        if host_url:\n            return host_url\n    return None\n</code></pre>"},{"location":"modules/download.harvester/#download.harvester.OpenAccessHarvester.run","title":"<code>run(topic, years, max_works)</code>","text":"<p>Run the complete harvesting workflow.</p> <p>Searches for works, resolves PDF URLs, downloads PDFs, and creates Doc objects for each successfully downloaded document.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>str</code> <p>Topic query string (e.g., \"machine learning\").</p> required <code>years</code> <code>str</code> <p>Optional year filter string (e.g., \"publication_year:2020-2023\"). Empty string means no year filter.</p> required <code>max_works</code> <code>int</code> <p>Maximum number of works to process.</p> required <p>Returns:</p> Type Description <code>list[Doc]</code> <p>List of Doc objects for successfully downloaded PDFs.</p> Source code in <code>src/download/harvester.py</code> <pre><code>def run(self, topic: str, years: str, max_works: int) -&gt; list[Doc]:\n    \"\"\"Run the complete harvesting workflow.\n\n    Searches for works, resolves PDF URLs, downloads PDFs, and creates\n    Doc objects for each successfully downloaded document.\n\n    Parameters\n    ----------\n    topic : str\n        Topic query string (e.g., \"machine learning\").\n    years : str\n        Optional year filter string (e.g., \"publication_year:2020-2023\").\n        Empty string means no year filter.\n    max_works : int\n        Maximum number of works to process.\n\n    Returns\n    -------\n    list[Doc]\n        List of Doc objects for successfully downloaded PDFs.\n    \"\"\"\n    docs: list[Doc] = []\n    works = self.search(topic, years, max_works)\n    for work in works:\n        pdf_url = self.resolve_pdf(work)\n        if not pdf_url:\n            continue\n        raw_name = work.get(\"doi\") or work.get(\"id\") or str(int(time.time() * 1000))\n        filename = f\"{str(raw_name).replace('/', '_')}.pdf\"\n        destination = Path(self.out_dir) / filename\n        destination = self.download_pdf(pdf_url, destination)\n        doc = Doc(\n            id=f\"urn:doc:source:openalex:{work.get('id', 'unknown')}\",\n            openalex_id=work.get(\"id\"),\n            doi=work.get(\"doi\"),\n            title=work.get(\"title\", \"\"),\n            authors=[],\n            pub_date=None,\n            license=None,\n            language=\"en\",\n            pdf_uri=destination,\n            source=\"openalex\",\n            content_hash=None,\n        )\n        docs.append(doc)\n    return docs\n</code></pre>"},{"location":"modules/download.harvester/#download.harvester.OpenAccessHarvester.search","title":"<code>search(topic, years, max_works)</code>","text":"<p>Search for works in OpenAlex matching the topic and year filter.</p> <p>Queries the OpenAlex API for works matching the specified topic and optional year filter. Returns up to max_works results as a list of work dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>topic</code> <code>str</code> <p>Topic query string (e.g., \"machine learning\").</p> required <code>years</code> <code>str</code> <p>Optional year filter string (e.g., \"publication_year:2020-2023\"). Empty string means no year filter.</p> required <code>max_works</code> <code>int</code> <p>Maximum number of works to return (capped at 200 per request).</p> required <p>Returns:</p> Type Description <code>list[dict[str, object]]</code> <p>List of work dictionaries from OpenAlex API. Each dictionary contains work metadata (id, title, doi, locations, etc.).</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the response payload is not a mapping or contains invalid structure.</p> Source code in <code>src/download/harvester.py</code> <pre><code>def search(self, topic: str, years: str, max_works: int) -&gt; list[dict[str, object]]:\n    \"\"\"Search for works in OpenAlex matching the topic and year filter.\n\n    Queries the OpenAlex API for works matching the specified topic and\n    optional year filter. Returns up to max_works results as a list of\n    work dictionaries.\n\n    Parameters\n    ----------\n    topic : str\n        Topic query string (e.g., \"machine learning\").\n    years : str\n        Optional year filter string (e.g., \"publication_year:2020-2023\").\n        Empty string means no year filter.\n    max_works : int\n        Maximum number of works to return (capped at 200 per request).\n\n    Returns\n    -------\n    list[dict[str, object]]\n        List of work dictionaries from OpenAlex API. Each dictionary\n        contains work metadata (id, title, doi, locations, etc.).\n\n    Raises\n    ------\n    TypeError\n        If the response payload is not a mapping or contains invalid structure.\n    \"\"\"\n    url = f\"{self.openalex}/works\"\n    params: dict[str, str | int] = {\n        \"topic\": topic,\n        \"per_page\": min(200, max_works),\n        \"cursor\": \"*\",\n    }\n    if years:\n        params[\"filter\"] = years\n    response = self.session.get(url, params=params, timeout=30)\n    response.raise_for_status()\n    raw_payload: object = response.json()\n    if not isinstance(raw_payload, Mapping):\n        message = \"OpenAlex response payload must be a mapping\"\n        raise TypeError(message)\n    if not all(isinstance(key, str) for key in raw_payload):\n        message = \"OpenAlex payload keys must be strings\"\n        raise TypeError(message)\n    payload = cast(\"Mapping[str, object]\", raw_payload)\n    results_obj = payload.get(\"results\", [])\n    if not isinstance(results_obj, list):\n        message = \"OpenAlex response must contain a list of results\"\n        raise TypeError(message)\n    typed_results: list[dict[str, object]] = []\n    for entry in results_obj:\n        if not isinstance(entry, Mapping):\n            continue\n        if any(not isinstance(key, str) for key in entry):\n            continue\n        mapping_entry = cast(\"Mapping[str, object]\", entry)\n        typed_results.append(dict(mapping_entry))\n    return typed_results[:max_works]\n</code></pre>"},{"location":"modules/download/","title":"download","text":""},{"location":"modules/download/#download","title":"download","text":"<p>Public modules for the download and harvesting pipeline</p> <p>:material-source-repository: View source</p>"},{"location":"modules/download/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"download__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.navmap_types.NavMapdownload code <p>See the full diagram: download</p>"},{"location":"modules/download/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.navmap_types.NavMap</code></p>"},{"location":"modules/embeddings_dense.base/","title":"embeddings_dense.base","text":""},{"location":"modules/embeddings_dense.base/#embeddings_densebase","title":"embeddings_dense.base","text":"<p>Protocols describing dense embedding providers</p> <p>:material-source-repository: View source</p>"},{"location":"modules/embeddings_dense.base/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class DenseEmbeddingModel\n    class Protocol\n    Protocol &lt;|-- DenseEmbeddingModel\n</code></pre>"},{"location":"modules/embeddings_dense.base/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"embeddings_dense.base__future__.annotationscollections.abc.Sequencekgfoundry_common.navmap_loader.load_nav_metadatanumpynumpy.typing.NDArraytyping.Protocoltyping.TYPE_CHECKINGembeddings_dense.base code <p>See the full diagram: embeddings_dense.base</p>"},{"location":"modules/embeddings_dense.base/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>embeddings_dense.base.DenseEmbeddingModel</li> </ul>"},{"location":"modules/embeddings_dense.base/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Sequence</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>numpy</code>, <code>numpy.typing.NDArray</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code></p>"},{"location":"modules/embeddings_dense.base/#contents","title":"Contents","text":""},{"location":"modules/embeddings_dense.base/#embeddings_densebasedenseembeddingmodel","title":"embeddings_dense.base.DenseEmbeddingModel","text":"<p>Bases: Protocol</p>"},{"location":"modules/embeddings_dense.base/#embeddings_dense.base.DenseEmbeddingModel","title":"<code>embeddings_dense.base.DenseEmbeddingModel</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for dense embedding model implementations.</p> <p>Defines the interface for models that generate dense vector embeddings from text sequences. Implementations must provide an encode method that accepts a sequence of text strings and returns a NumPy array of float32 vectors.</p> Source code in <code>src/embeddings_dense/base.py</code> <pre><code>class DenseEmbeddingModel(Protocol):\n    \"\"\"Protocol for dense embedding model implementations.\n\n    Defines the interface for models that generate dense vector embeddings from text sequences.\n    Implementations must provide an encode method that accepts a sequence of text strings and\n    returns a NumPy array of float32 vectors.\n    \"\"\"\n\n    def encode(self, texts: Sequence[str]) -&gt; NDArray[np.float32]:\n        \"\"\"Encode text sequences into dense embedding vectors.\n\n        Converts a sequence of text strings into a NumPy array of dense\n        float32 vectors where each row corresponds to one input text.\n\n        Parameters\n        ----------\n        texts : Sequence[str]\n            Sequence of text strings to encode.\n\n        Returns\n        -------\n        NDArray[np.float32]\n            NumPy array of shape (len(texts), embedding_dim) containing\n            the dense embedding vectors.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/embeddings_dense.base/#embeddings_dense.base.DenseEmbeddingModel.encode","title":"<code>encode(texts)</code>","text":"<p>Encode text sequences into dense embedding vectors.</p> <p>Converts a sequence of text strings into a NumPy array of dense float32 vectors where each row corresponds to one input text.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <code>Sequence[str]</code> <p>Sequence of text strings to encode.</p> required <p>Returns:</p> Type Description <code>NDArray[float32]</code> <p>NumPy array of shape (len(texts), embedding_dim) containing the dense embedding vectors.</p> Source code in <code>src/embeddings_dense/base.py</code> <pre><code>def encode(self, texts: Sequence[str]) -&gt; NDArray[np.float32]:\n    \"\"\"Encode text sequences into dense embedding vectors.\n\n    Converts a sequence of text strings into a NumPy array of dense\n    float32 vectors where each row corresponds to one input text.\n\n    Parameters\n    ----------\n    texts : Sequence[str]\n        Sequence of text strings to encode.\n\n    Returns\n    -------\n    NDArray[np.float32]\n        NumPy array of shape (len(texts), embedding_dim) containing\n        the dense embedding vectors.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/embeddings_dense/","title":"embeddings_dense","text":""},{"location":"modules/embeddings_dense/#embeddings_dense","title":"embeddings_dense","text":"<p>Dense embedding adapters and protocols</p> <p>:material-source-repository: View source</p>"},{"location":"modules/embeddings_dense/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"embeddings_dense__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.navmap_types.NavMapembeddings_dense code <p>See the full diagram: embeddings_dense</p>"},{"location":"modules/embeddings_dense/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.navmap_types.NavMap</code></p>"},{"location":"modules/embeddings_dense.qwen3/","title":"embeddings_dense.qwen3","text":""},{"location":"modules/embeddings_dense.qwen3/#embeddings_denseqwen3","title":"embeddings_dense.qwen3","text":"<p>Qwen-3 dense embedding adapter</p> <p>:material-source-repository: View source</p>"},{"location":"modules/embeddings_dense.qwen3/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class Qwen3Embedder\n</code></pre>"},{"location":"modules/embeddings_dense.qwen3/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"embeddings_dense.qwen3__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadataembeddings_dense.qwen3 code <p>See the full diagram: embeddings_dense.qwen3</p>"},{"location":"modules/embeddings_dense.qwen3/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>embeddings_dense.qwen3.Qwen3Embedder</li> </ul>"},{"location":"modules/embeddings_dense.qwen3/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p>"},{"location":"modules/embeddings_dense.qwen3/#contents","title":"Contents","text":""},{"location":"modules/embeddings_dense.qwen3/#embeddings_denseqwen3qwen3embedder","title":"embeddings_dense.qwen3.Qwen3Embedder","text":""},{"location":"modules/embeddings_dense.qwen3/#embeddings_dense.qwen3.Qwen3Embedder","title":"<code>embeddings_dense.qwen3.Qwen3Embedder</code>","text":"<p>Placeholder class for Qwen-3 dense embedding adapter.</p> <p>This class serves as a placeholder for future Qwen-3 embedding model integration. Implementation details will be added later.</p> Source code in <code>src/embeddings_dense/qwen3.py</code> <pre><code>class Qwen3Embedder:\n    \"\"\"Placeholder class for Qwen-3 dense embedding adapter.\n\n    This class serves as a placeholder for future Qwen-3 embedding model integration. Implementation\n    details will be added later.\n    \"\"\"\n</code></pre>"},{"location":"modules/embeddings_sparse.base/","title":"embeddings_sparse.base","text":""},{"location":"modules/embeddings_sparse.base/#embeddings_sparsebase","title":"embeddings_sparse.base","text":"<p>Protocols for sparse embedding encoders and indices</p> <p>:material-source-repository: View source</p>"},{"location":"modules/embeddings_sparse.base/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class SparseEncoder\n    class Protocol\n    Protocol &lt;|-- SparseEncoder\n    class SparseIndex\n    Protocol &lt;|-- SparseIndex\n</code></pre>"},{"location":"modules/embeddings_sparse.base/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"embeddings_sparse.base__future__.annotationscollections.abc.Iterablecollections.abc.Mappingkgfoundry_common.navmap_loader.load_nav_metadatatyping.Protocoltyping.TYPE_CHECKINGembeddings_sparse.base code <p>See the full diagram: embeddings_sparse.base</p>"},{"location":"modules/embeddings_sparse.base/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>embeddings_sparse.base.SparseEncoder</li> <li>embeddings_sparse.base.SparseIndex</li> </ul>"},{"location":"modules/embeddings_sparse.base/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Iterable</code>, <code>collections.abc.Mapping</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code></p>"},{"location":"modules/embeddings_sparse.base/#contents","title":"Contents","text":""},{"location":"modules/embeddings_sparse.base/#embeddings_sparsebasesparseencoder","title":"embeddings_sparse.base.SparseEncoder","text":"<p>Bases: Protocol</p>"},{"location":"modules/embeddings_sparse.base/#embeddings_sparse.base.SparseEncoder","title":"<code>embeddings_sparse.base.SparseEncoder</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for sparse embedding encoders.</p> <p>Defines the interface for encoders that convert text into sparse embeddings. Sparse embeddings consist of token indices and weights, typically used for learned sparse retrieval (e.g., SPLADE).</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Encoder name or identifier.</p> Source code in <code>src/embeddings_sparse/base.py</code> <pre><code>class SparseEncoder(Protocol):\n    \"\"\"Protocol for sparse embedding encoders.\n\n    Defines the interface for encoders that convert text into sparse\n    embeddings. Sparse embeddings consist of token indices and weights,\n    typically used for learned sparse retrieval (e.g., SPLADE).\n\n    Attributes\n    ----------\n    name : str\n        Encoder name or identifier.\n    \"\"\"\n\n    name: str\n\n    def encode(self, texts: list[str]) -&gt; list[tuple[list[int], list[float]]]:\n        \"\"\"Encode texts into sparse embeddings.\n\n        Converts a list of text strings into sparse embeddings represented\n        as (token_indices, weights) tuples.\n\n        Parameters\n        ----------\n        texts : list[str]\n            List of text strings to encode.\n\n        Returns\n        -------\n        list[tuple[list[int], list[float]]]\n            List of sparse embeddings. Each tuple contains:\n            - token_indices: List of vocabulary token indices\n            - weights: List of weights corresponding to the token indices\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/embeddings_sparse.base/#embeddings_sparse.base.SparseEncoder.encode","title":"<code>encode(texts)</code>","text":"<p>Encode texts into sparse embeddings.</p> <p>Converts a list of text strings into sparse embeddings represented as (token_indices, weights) tuples.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <code>list[str]</code> <p>List of text strings to encode.</p> required <p>Returns:</p> Type Description <code>list[tuple[list[int], list[float]]]</code> <p>List of sparse embeddings. Each tuple contains: - token_indices: List of vocabulary token indices - weights: List of weights corresponding to the token indices</p> Source code in <code>src/embeddings_sparse/base.py</code> <pre><code>def encode(self, texts: list[str]) -&gt; list[tuple[list[int], list[float]]]:\n    \"\"\"Encode texts into sparse embeddings.\n\n    Converts a list of text strings into sparse embeddings represented\n    as (token_indices, weights) tuples.\n\n    Parameters\n    ----------\n    texts : list[str]\n        List of text strings to encode.\n\n    Returns\n    -------\n    list[tuple[list[int], list[float]]]\n        List of sparse embeddings. Each tuple contains:\n        - token_indices: List of vocabulary token indices\n        - weights: List of weights corresponding to the token indices\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/embeddings_sparse.base/#embeddings_sparsebasesparseindex","title":"embeddings_sparse.base.SparseIndex","text":"<p>Bases: Protocol</p>"},{"location":"modules/embeddings_sparse.base/#embeddings_sparse.base.SparseIndex","title":"<code>embeddings_sparse.base.SparseIndex</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for sparse embedding indexes.</p> <p>Defines the interface for indexes that store and search sparse embeddings. Used for sparse retrieval operations where documents are represented as sparse vectors (token indices with weights).</p> Source code in <code>src/embeddings_sparse/base.py</code> <pre><code>class SparseIndex(Protocol):\n    \"\"\"Protocol for sparse embedding indexes.\n\n    Defines the interface for indexes that store and search sparse embeddings. Used for sparse\n    retrieval operations where documents are represented as sparse vectors (token indices with\n    weights).\n    \"\"\"\n\n    def build(self, docs_iterable: Iterable[tuple[str, dict[str, str]]]) -&gt; None:\n        \"\"\"Build the index from documents.\n\n        Indexes documents from the provided iterable. Each document is\n        represented as a tuple of (doc_id, fields_dict) where fields_dict\n        contains field names mapped to text content.\n\n        Parameters\n        ----------\n        docs_iterable : Iterable[tuple[str, dict[str, str]]]\n            Iterable of document tuples. Each tuple contains:\n            - doc_id: Document identifier\n            - fields_dict: Dictionary mapping field names to text content\n        \"\"\"\n        ...\n\n    def search(\n        self, query: str, k: int, fields: Mapping[str, str] | None = None\n    ) -&gt; list[tuple[str, float]]:\n        \"\"\"Search the index for documents matching the query.\n\n        Performs sparse retrieval to find top-k documents matching the query.\n        Supports optional field boosting through the fields parameter.\n\n        Parameters\n        ----------\n        query : str\n            Search query text.\n        k : int\n            Number of top results to return.\n        fields : Mapping[str, str] | None, optional\n            Optional field boost weights. Maps field names to boost values.\n            If None, uses default field weights. Defaults to None.\n\n        Returns\n        -------\n        list[tuple[str, float]]\n            List of (doc_id, score) tuples sorted by score descending.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/embeddings_sparse.base/#embeddings_sparse.base.SparseIndex.build","title":"<code>build(docs_iterable)</code>","text":"<p>Build the index from documents.</p> <p>Indexes documents from the provided iterable. Each document is represented as a tuple of (doc_id, fields_dict) where fields_dict contains field names mapped to text content.</p> <p>Parameters:</p> Name Type Description Default <code>docs_iterable</code> <code>Iterable[tuple[str, dict[str, str]]]</code> <p>Iterable of document tuples. Each tuple contains: - doc_id: Document identifier - fields_dict: Dictionary mapping field names to text content</p> required Source code in <code>src/embeddings_sparse/base.py</code> <pre><code>def build(self, docs_iterable: Iterable[tuple[str, dict[str, str]]]) -&gt; None:\n    \"\"\"Build the index from documents.\n\n    Indexes documents from the provided iterable. Each document is\n    represented as a tuple of (doc_id, fields_dict) where fields_dict\n    contains field names mapped to text content.\n\n    Parameters\n    ----------\n    docs_iterable : Iterable[tuple[str, dict[str, str]]]\n        Iterable of document tuples. Each tuple contains:\n        - doc_id: Document identifier\n        - fields_dict: Dictionary mapping field names to text content\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/embeddings_sparse.base/#embeddings_sparse.base.SparseIndex.search","title":"<code>search(query, k, fields=None)</code>","text":"<p>Search the index for documents matching the query.</p> <p>Performs sparse retrieval to find top-k documents matching the query. Supports optional field boosting through the fields parameter.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query text.</p> required <code>k</code> <code>int</code> <p>Number of top results to return.</p> required <code>fields</code> <code>Mapping[str, str] | None</code> <p>Optional field boost weights. Maps field names to boost values. If None, uses default field weights. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[tuple[str, float]]</code> <p>List of (doc_id, score) tuples sorted by score descending.</p> Source code in <code>src/embeddings_sparse/base.py</code> <pre><code>def search(\n    self, query: str, k: int, fields: Mapping[str, str] | None = None\n) -&gt; list[tuple[str, float]]:\n    \"\"\"Search the index for documents matching the query.\n\n    Performs sparse retrieval to find top-k documents matching the query.\n    Supports optional field boosting through the fields parameter.\n\n    Parameters\n    ----------\n    query : str\n        Search query text.\n    k : int\n        Number of top results to return.\n    fields : Mapping[str, str] | None, optional\n        Optional field boost weights. Maps field names to boost values.\n        If None, uses default field weights. Defaults to None.\n\n    Returns\n    -------\n    list[tuple[str, float]]\n        List of (doc_id, score) tuples sorted by score descending.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/","title":"embeddings_sparse.bm25","text":""},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25","title":"embeddings_sparse.bm25","text":"<p>Pure Python and Lucene-backed BM25 adapters for sparse retrieval</p> <p>:material-source-repository: View source</p>"},{"location":"modules/embeddings_sparse.bm25/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class BM25Doc\n    class LuceneBM25\n    class LuceneHitProtocol\n    class Protocol\n    Protocol &lt;|-- LuceneHitProtocol\n    class LuceneIndexerFactory\n    Protocol &lt;|-- LuceneIndexerFactory\n    class LuceneIndexerProtocol\n    Protocol &lt;|-- LuceneIndexerProtocol\n    class LuceneSearcherFactory\n    Protocol &lt;|-- LuceneSearcherFactory\n    class LuceneSearcherProtocol\n    Protocol &lt;|-- LuceneSearcherProtocol\n    class PurePythonBM25\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"embeddings_sparse.bm25__future__.annotationscollections.abc.Iterablecollections.abc.Mappingcollections.abc.Sequencecollections.defaultdictdataclasses.dataclassdataclasses.fieldimportlib.import_modulekgfoundry_common.errors.DeserializationErrorkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.problem_details.JsonValuekgfoundry_common.safe_pickle_v2.UnsafeSerializationErrorkgfoundry_common.safe_pickle_v2.load_unsigned_legacykgfoundry_common.serialization.deserialize_jsonkgfoundry_common.serialization.serialize_jsonloggingmathpathlib.Pathrere.Patterntyping.Finaltyping.Protocoltyping.TYPE_CHECKINGtyping.castembeddings_sparse.bm25 code <p>See the full diagram: embeddings_sparse.bm25</p>"},{"location":"modules/embeddings_sparse.bm25/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>embeddings_sparse.bm25.BM25Doc</li> <li>embeddings_sparse.bm25.LuceneBM25</li> <li>embeddings_sparse.bm25.LuceneHitProtocol</li> <li>embeddings_sparse.bm25._default_int_dict</li> <li>embeddings_sparse.bm25._load_json_metadata</li> <li>embeddings_sparse.bm25._load_lucene_indexer_factory</li> </ul>"},{"location":"modules/embeddings_sparse.bm25/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Iterable</code>, <code>collections.abc.Mapping</code>, <code>collections.abc.Sequence</code>, <code>collections.defaultdict</code>, <code>dataclasses.dataclass</code>, <code>dataclasses.field</code>, <code>importlib.import_module</code>, <code>kgfoundry_common.errors.DeserializationError</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.problem_details.JsonValue</code>, <code>kgfoundry_common.safe_pickle_v2.UnsafeSerializationError</code>, <code>kgfoundry_common.safe_pickle_v2.load_unsigned_legacy</code>, <code>kgfoundry_common.serialization.deserialize_json</code>, <code>kgfoundry_common.serialization.serialize_json</code>, <code>logging</code>, <code>math</code>, <code>pathlib.Path</code>, <code>re</code>, <code>re.Pattern</code>, <code>typing.Final</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/embeddings_sparse.bm25/#contents","title":"Contents","text":""},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25bm25doc","title":"embeddings_sparse.bm25.BM25Doc","text":""},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.BM25Doc","title":"<code>embeddings_sparse.bm25.BM25Doc</code>  <code>dataclass</code>","text":"<p>Represent a document stored in the in-memory BM25 index.</p> <p>Stores document metadata, term frequencies, and field content for BM25 scoring. Used by both PurePythonBM25 and LuceneBM25 implementations.</p> <p>Attributes:</p> Name Type Description <code>doc_id</code> <code>str</code> <p>Unique document identifier.</p> <code>length</code> <code>int</code> <p>Total number of tokens in the document (sum of all term frequencies).</p> <code>fields</code> <code>dict[str, str]</code> <p>Document field content dictionary containing \"title\", \"section\", and \"body\" fields.</p> <code>term_freqs</code> <code>dict[str, int]</code> <p>Term frequency dictionary mapping token strings to their occurrence counts in this document. Defaults to empty dict.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>@dataclass\nclass BM25Doc:\n    \"\"\"Represent a document stored in the in-memory BM25 index.\n\n    Stores document metadata, term frequencies, and field content for BM25\n    scoring. Used by both PurePythonBM25 and LuceneBM25 implementations.\n\n    Attributes\n    ----------\n    doc_id : str\n        Unique document identifier.\n    length : int\n        Total number of tokens in the document (sum of all term frequencies).\n    fields : dict[str, str]\n        Document field content dictionary containing \"title\", \"section\", and\n        \"body\" fields.\n    term_freqs : dict[str, int]\n        Term frequency dictionary mapping token strings to their occurrence\n        counts in this document. Defaults to empty dict.\n    \"\"\"\n\n    doc_id: str\n    length: int\n    fields: dict[str, str]\n    term_freqs: dict[str, int] = field(default_factory=dict)\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25lucenebm25","title":"embeddings_sparse.bm25.LuceneBM25","text":""},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneBM25","title":"<code>embeddings_sparse.bm25.LuceneBM25</code>","text":"<p>Wrap Pyserini's Lucene BM25 indexer with project defaults.</p> <p>Provides a BM25 implementation backed by Apache Lucene via Pyserini. Suitable for large indexes that benefit from disk-backed storage and optimized search performance.</p> <p>Initializes the Lucene-backed BM25 adapter with index directory and scoring parameters.</p> <p>Parameters:</p> Name Type Description Default <code>index_dir</code> <code>str</code> <p>Path to the Lucene index directory on disk.</p> required <code>k1</code> <code>float</code> <p>BM25 term saturation parameter forwarded to Pyserini. Controls how quickly term frequency saturates. Higher values allow more influence from repeated terms. Defaults to 0.9.</p> <code>0.9</code> <code>b</code> <code>float</code> <p>BM25 document length normalization parameter. Controls the degree of length normalization. Values closer to 1.0 normalize more aggressively. Defaults to 0.4.</p> <code>0.4</code> <code>field_boosts</code> <code>Mapping[str, float] | None</code> <p>Optional mapping of field names to boost weights. Used when composing Lucene query strings with field-specific boosts. Normalized and merged with default boosts. Defaults to None (uses default boosts: title=2.0, section=1.2, body=1.0).</p> <code>None</code> Notes <p>Requires the optional <code>pyserini</code> dependency. Import errors propagate as :class:<code>RuntimeError</code> when helper factories are loaded. The searcher is lazy-initialized on first search call to avoid unnecessary index loading.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>class LuceneBM25:\n    \"\"\"Wrap Pyserini's Lucene BM25 indexer with project defaults.\n\n    Provides a BM25 implementation backed by Apache Lucene via Pyserini.\n    Suitable for large indexes that benefit from disk-backed storage and\n    optimized search performance.\n\n    Initializes the Lucene-backed BM25 adapter with index directory and scoring parameters.\n\n    Parameters\n    ----------\n    index_dir : str\n        Path to the Lucene index directory on disk.\n    k1 : float, optional\n        BM25 term saturation parameter forwarded to Pyserini. Controls how quickly\n        term frequency saturates. Higher values allow more influence from repeated terms.\n        Defaults to 0.9.\n    b : float, optional\n        BM25 document length normalization parameter. Controls the degree of length\n        normalization. Values closer to 1.0 normalize more aggressively.\n        Defaults to 0.4.\n    field_boosts : Mapping[str, float] | None, optional\n        Optional mapping of field names to boost weights. Used when composing\n        Lucene query strings with field-specific boosts. Normalized and merged with\n        default boosts. Defaults to None (uses default boosts: title=2.0, section=1.2, body=1.0).\n\n    Notes\n    -----\n    Requires the optional ``pyserini`` dependency. Import errors propagate as\n    :class:`RuntimeError` when helper factories are loaded. The searcher is\n    lazy-initialized on first search call to avoid unnecessary index loading.\n    \"\"\"\n\n    def __init__(\n        self,\n        index_dir: str,\n        k1: float = 0.9,\n        b: float = 0.4,\n        field_boosts: Mapping[str, float] | None = None,\n    ) -&gt; None:\n        self.index_dir = index_dir\n        self.k1 = k1\n        self.b = b\n        self.field_boosts = _normalize_field_boosts(field_boosts)\n        self._indexer_factory = _load_lucene_indexer_factory()\n        self._searcher_factory = _load_lucene_searcher_factory()\n        self._searcher: LuceneSearcherProtocol | None = None\n\n    def build(self, docs_iterable: Iterable[tuple[str, dict[str, str]]]) -&gt; None:\n        \"\"\"Stream documents into a Lucene index using Pyserini.\"\"\"\n        Path(self.index_dir).mkdir(parents=True, exist_ok=True)\n        indexer = self._indexer_factory(self.index_dir)\n        try:\n            for doc_id, fields in docs_iterable:\n                indexer.add_doc_dict(self._build_lucene_doc(doc_id, fields))\n        finally:\n            indexer.close()\n\n    def load(self) -&gt; None:\n        \"\"\"Ensure a Lucene searcher can be constructed for the configured index.\"\"\"\n        self._searcher = None\n        self._ensure_searcher()\n\n    def search(\n        self,\n        query: str,\n        k: int,\n        fields: Mapping[str, str] | None = None,\n    ) -&gt; list[tuple[str, float]]:\n        \"\"\"Execute a Lucene BM25 query using the configured searcher.\n\n        Parameters\n        ----------\n        query : str\n            Query string to search.\n        k : int\n            Number of top results to return.\n        fields : Mapping[str, str] | None, optional\n            Optional field mapping for query construction.\n\n        Returns\n        -------\n        list[tuple[str, float]]\n            List of (document_id, score) tuples.\n        \"\"\"\n        searcher = self._ensure_searcher()\n        query_string = self._compose_query(query, fields)\n        hits: Sequence[LuceneHitProtocol] = searcher.search(query_string, k)\n        return [(hit.docid, float(hit.score)) for hit in hits]\n\n    def _ensure_searcher(self) -&gt; LuceneSearcherProtocol:\n        if self._searcher is None:\n            searcher = self._searcher_factory(self.index_dir)\n            searcher.set_bm25(self.k1, self.b)\n            self._searcher = searcher\n        return self._searcher\n\n    def _build_lucene_doc(self, doc_id: str, fields: Mapping[str, str]) -&gt; dict[str, str]:\n        doc: dict[str, str] = {\"id\": doc_id, \"contents\": self._compose_contents(fields)}\n        for key, value in fields.items():\n            doc[key] = str(value)\n        return doc\n\n    @staticmethod\n    def _compose_contents(fields: Mapping[str, str]) -&gt; str:\n        ordered_fields = (\"title\", \"section\", \"body\")\n        parts = [str(fields.get(name, \"\")) for name in ordered_fields]\n        extras = [str(value) for key, value in fields.items() if key not in ordered_fields]\n        text_parts = [part for part in (*parts, *extras) if part]\n        return \" \".join(text_parts)\n\n    def _compose_query(self, query: str, fields: Mapping[str, str] | None) -&gt; str:\n        components: list[str] = []\n        if query:\n            components.append(query)\n        if fields:\n            for field_name, boost in self.field_boosts.items():\n                field_value = fields.get(field_name)\n                if field_value:\n                    components.append(f\"{field_name}:( {field_value} )^{boost}\")\n        return \" \".join(components) if components else query\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneBM25.build","title":"<code>build(docs_iterable)</code>","text":"<p>Stream documents into a Lucene index using Pyserini.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def build(self, docs_iterable: Iterable[tuple[str, dict[str, str]]]) -&gt; None:\n    \"\"\"Stream documents into a Lucene index using Pyserini.\"\"\"\n    Path(self.index_dir).mkdir(parents=True, exist_ok=True)\n    indexer = self._indexer_factory(self.index_dir)\n    try:\n        for doc_id, fields in docs_iterable:\n            indexer.add_doc_dict(self._build_lucene_doc(doc_id, fields))\n    finally:\n        indexer.close()\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneBM25.load","title":"<code>load()</code>","text":"<p>Ensure a Lucene searcher can be constructed for the configured index.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def load(self) -&gt; None:\n    \"\"\"Ensure a Lucene searcher can be constructed for the configured index.\"\"\"\n    self._searcher = None\n    self._ensure_searcher()\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneBM25.search","title":"<code>search(query, k, fields=None)</code>","text":"<p>Execute a Lucene BM25 query using the configured searcher.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Query string to search.</p> required <code>k</code> <code>int</code> <p>Number of top results to return.</p> required <code>fields</code> <code>Mapping[str, str] | None</code> <p>Optional field mapping for query construction.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[tuple[str, float]]</code> <p>List of (document_id, score) tuples.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def search(\n    self,\n    query: str,\n    k: int,\n    fields: Mapping[str, str] | None = None,\n) -&gt; list[tuple[str, float]]:\n    \"\"\"Execute a Lucene BM25 query using the configured searcher.\n\n    Parameters\n    ----------\n    query : str\n        Query string to search.\n    k : int\n        Number of top results to return.\n    fields : Mapping[str, str] | None, optional\n        Optional field mapping for query construction.\n\n    Returns\n    -------\n    list[tuple[str, float]]\n        List of (document_id, score) tuples.\n    \"\"\"\n    searcher = self._ensure_searcher()\n    query_string = self._compose_query(query, fields)\n    hits: Sequence[LuceneHitProtocol] = searcher.search(query_string, k)\n    return [(hit.docid, float(hit.score)) for hit in hits]\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25lucenehitprotocol","title":"embeddings_sparse.bm25.LuceneHitProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneHitProtocol","title":"<code>embeddings_sparse.bm25.LuceneHitProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol describing a single Lucene BM25 hit.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>class LuceneHitProtocol(Protocol):\n    \"\"\"Protocol describing a single Lucene BM25 hit.\"\"\"\n\n    docid: str\n    score: float\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25luceneindexerfactory","title":"embeddings_sparse.bm25.LuceneIndexerFactory","text":"<p>Bases: Protocol</p>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneIndexerFactory","title":"<code>embeddings_sparse.bm25.LuceneIndexerFactory</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Factory protocol for instantiating Lucene BM25 indexers.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>class LuceneIndexerFactory(Protocol):\n    \"\"\"Factory protocol for instantiating Lucene BM25 indexers.\"\"\"\n\n    def __call__(self, index_dir: str) -&gt; LuceneIndexerProtocol:\n        \"\"\"Create an indexer that writes into ``index_dir``.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneIndexerFactory.__call__","title":"<code>__call__(index_dir)</code>","text":"<p>Create an indexer that writes into <code>index_dir</code>.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def __call__(self, index_dir: str) -&gt; LuceneIndexerProtocol:\n    \"\"\"Create an indexer that writes into ``index_dir``.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25luceneindexerprotocol","title":"embeddings_sparse.bm25.LuceneIndexerProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneIndexerProtocol","title":"<code>embeddings_sparse.bm25.LuceneIndexerProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for Lucene index writers used by the BM25 adapters.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>class LuceneIndexerProtocol(Protocol):\n    \"\"\"Protocol for Lucene index writers used by the BM25 adapters.\"\"\"\n\n    def add_doc_dict(self, doc: Mapping[str, str]) -&gt; None:\n        \"\"\"Add a document mapping to the Lucene index.\"\"\"\n        ...\n\n    def close(self) -&gt; None:\n        \"\"\"Finalize the index writer and flush in-memory buffers.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneIndexerProtocol.add_doc_dict","title":"<code>add_doc_dict(doc)</code>","text":"<p>Add a document mapping to the Lucene index.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def add_doc_dict(self, doc: Mapping[str, str]) -&gt; None:\n    \"\"\"Add a document mapping to the Lucene index.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneIndexerProtocol.close","title":"<code>close()</code>","text":"<p>Finalize the index writer and flush in-memory buffers.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Finalize the index writer and flush in-memory buffers.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25lucenesearcherfactory","title":"embeddings_sparse.bm25.LuceneSearcherFactory","text":"<p>Bases: Protocol</p>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneSearcherFactory","title":"<code>embeddings_sparse.bm25.LuceneSearcherFactory</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Factory protocol for creating Lucene BM25 searchers.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>class LuceneSearcherFactory(Protocol):\n    \"\"\"Factory protocol for creating Lucene BM25 searchers.\"\"\"\n\n    def __call__(self, index_dir: str) -&gt; LuceneSearcherProtocol:\n        \"\"\"Return a searcher bound to ``index_dir``.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneSearcherFactory.__call__","title":"<code>__call__(index_dir)</code>","text":"<p>Return a searcher bound to <code>index_dir</code>.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def __call__(self, index_dir: str) -&gt; LuceneSearcherProtocol:\n    \"\"\"Return a searcher bound to ``index_dir``.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25lucenesearcherprotocol","title":"embeddings_sparse.bm25.LuceneSearcherProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneSearcherProtocol","title":"<code>embeddings_sparse.bm25.LuceneSearcherProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for Lucene searchers supporting BM25 configuration.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>class LuceneSearcherProtocol(Protocol):\n    \"\"\"Protocol for Lucene searchers supporting BM25 configuration.\"\"\"\n\n    def set_bm25(self, k1: float, b: float) -&gt; None:\n        \"\"\"Configure the BM25 parameters used by the underlying index.\"\"\"\n        ...\n\n    def search(self, query: str, k: int) -&gt; Sequence[LuceneHitProtocol]:\n        \"\"\"Return the top ``k`` hits for ``query`` using the active BM25 settings.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneSearcherProtocol.search","title":"<code>search(query, k)</code>","text":"<p>Return the top <code>k</code> hits for <code>query</code> using the active BM25 settings.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def search(self, query: str, k: int) -&gt; Sequence[LuceneHitProtocol]:\n    \"\"\"Return the top ``k`` hits for ``query`` using the active BM25 settings.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.LuceneSearcherProtocol.set_bm25","title":"<code>set_bm25(k1, b)</code>","text":"<p>Configure the BM25 parameters used by the underlying index.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def set_bm25(self, k1: float, b: float) -&gt; None:\n    \"\"\"Configure the BM25 parameters used by the underlying index.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25purepythonbm25","title":"embeddings_sparse.bm25.PurePythonBM25","text":""},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.PurePythonBM25","title":"<code>embeddings_sparse.bm25.PurePythonBM25</code>","text":"<p>Pure Python BM25 implementation backed by simple in-memory data structures.</p> <p>Implements BM25 ranking algorithm using Python dictionaries and lists without external dependencies. Suitable for small to medium-sized indexes that fit in memory.</p> <p>Sets up BM25 scoring parameters and initializes empty data structures for documents, postings, and document frequencies.</p> <p>Parameters:</p> Name Type Description Default <code>index_dir</code> <code>str</code> <p>Directory path where index metadata will be stored. Created if it doesn't exist.</p> required <code>k1</code> <code>float</code> <p>Term frequency saturation parameter. Controls how quickly term frequency saturates. Higher values allow more influence from repeated terms. Defaults to 0.9.</p> <code>0.9</code> <code>b</code> <code>float</code> <p>Document length normalization parameter. Controls the degree of length normalization. Values closer to 1.0 normalize more aggressively. Defaults to 0.4.</p> <code>0.4</code> <code>field_boosts</code> <code>Mapping[str, float] | None</code> <p>Optional mapping of field names to boost weights. Fields with higher boosts contribute more to relevance scores. Normalized and merged with default boosts. Defaults to None (uses default boosts: title=2.0, section=1.2, body=1.0).</p> <code>None</code> Notes <p>The implementation uses in-memory data structures and is suitable for indexes that fit in RAM. For larger indexes, consider using LuceneBM25 which uses Pyserini's disk-backed Lucene index.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>class PurePythonBM25:\n    \"\"\"Pure Python BM25 implementation backed by simple in-memory data structures.\n\n    Implements BM25 ranking algorithm using Python dictionaries and lists\n    without external dependencies. Suitable for small to medium-sized indexes\n    that fit in memory.\n\n    Sets up BM25 scoring parameters and initializes empty data structures\n    for documents, postings, and document frequencies.\n\n    Parameters\n    ----------\n    index_dir : str\n        Directory path where index metadata will be stored. Created if it\n        doesn't exist.\n    k1 : float, optional\n        Term frequency saturation parameter. Controls how quickly term frequency\n        saturates. Higher values allow more influence from repeated terms.\n        Defaults to 0.9.\n    b : float, optional\n        Document length normalization parameter. Controls the degree of length\n        normalization. Values closer to 1.0 normalize more aggressively.\n        Defaults to 0.4.\n    field_boosts : Mapping[str, float] | None, optional\n        Optional mapping of field names to boost weights. Fields with higher\n        boosts contribute more to relevance scores. Normalized and merged with\n        default boosts. Defaults to None (uses default boosts: title=2.0, section=1.2, body=1.0).\n\n    Notes\n    -----\n    The implementation uses in-memory data structures and is suitable for\n    indexes that fit in RAM. For larger indexes, consider using LuceneBM25\n    which uses Pyserini's disk-backed Lucene index.\n    \"\"\"\n\n    def __init__(\n        self,\n        index_dir: str,\n        k1: float = 0.9,\n        b: float = 0.4,\n        field_boosts: Mapping[str, float] | None = None,\n    ) -&gt; None:\n        self.index_dir = index_dir\n        self.k1 = k1\n        self.b = b\n        self.field_boosts = _normalize_field_boosts(field_boosts)\n        self.df: dict[str, int] = {}\n        self.postings: dict[str, dict[str, int]] = {}\n        self.docs: dict[str, BM25Doc] = {}\n        self.N = 0\n        self.avgdl = 0.0\n\n    @staticmethod\n    def _tokenize(text: str) -&gt; list[str]:\n        \"\"\"Tokenize text with a simple alphanumeric regex.\n\n        Extracts alphanumeric sequences (including underscores) from text and\n        converts them to lowercase for case-insensitive matching.\n\n        Parameters\n        ----------\n        text : str\n            Input text to tokenize. May be empty.\n\n        Returns\n        -------\n        list[str]\n            List of lowercase tokens extracted from the text. Empty list if\n            input contains no alphanumeric sequences.\n        \"\"\"\n        matches = cast(\"list[str]\", TOKEN_RE.findall(text))\n        return [token.lower() for token in matches]\n\n    def _create_doc(\n        self,\n        doc_id: str,\n        fields: Mapping[str, str],\n        df: defaultdict[str, int],\n        postings: defaultdict[str, defaultdict[str, int]],\n    ) -&gt; BM25Doc:\n        title = fields.get(\"title\", \"\")\n        section = fields.get(\"section\", \"\")\n        body = fields.get(\"body\", \"\")\n        text = \" \".join(part for part in (title, section, body) if part)\n        tokens = self._tokenize(text)\n        seen: set[str] = set()\n        term_freqs: defaultdict[str, int] = defaultdict(int)\n        for token in tokens:\n            term_freqs[token] += 1\n            postings[token][doc_id] += 1\n            if token not in seen:\n                df[token] += 1\n                seen.add(token)\n        return BM25Doc(\n            doc_id=doc_id,\n            length=len(tokens),\n            fields={\"title\": title, \"section\": section, \"body\": body},\n            term_freqs={term: int(count) for term, count in term_freqs.items()},\n        )\n\n    def build(self, docs_iterable: Iterable[tuple[str, dict[str, str]]]) -&gt; None:\n        \"\"\"Build postings and document statistics for the BM25 index.\n\n        Processes an iterable of documents, computes term frequencies and\n        document frequencies, and serializes the index metadata to disk with\n        schema validation.\n\n        Parameters\n        ----------\n        docs_iterable : Iterable[tuple[str, dict[str, str]]]\n            Iterable of (doc_id, fields) tuples. Each fields dictionary should\n            contain \"title\", \"section\", and \"body\" keys with string values.\n\n        Notes\n        -----\n        This method clears any existing index state and rebuilds from scratch.\n        After processing all documents, it computes average document length\n        and writes metadata to `pure_bm25.json` in the index directory with\n        schema validation and checksum verification.\n        \"\"\"\n        Path(self.index_dir).mkdir(parents=True, exist_ok=True)\n        df: defaultdict[str, int] = defaultdict(int)\n        postings: defaultdict[str, defaultdict[str, int]] = defaultdict(_default_int_dict)\n        docs: dict[str, BM25Doc] = {}\n        lengths: list[int] = []\n        for doc_id, fields in docs_iterable:\n            doc = self._create_doc(doc_id, fields, df, postings)\n            docs[doc_id] = doc\n            lengths.append(doc.length)\n        self.N = len(docs)\n        self.avgdl = (sum(lengths) / self.N) if self.N else 0.0\n        self.df = dict(df)\n        self.postings = {term: dict(term_postings) for term, term_postings in postings.items()}\n        self.docs = docs\n        metadata_path = Path(self.index_dir) / \"pure_bm25.json\"\n        serialize_json(self._metadata_payload(), _BM25_SCHEMA_PATH, metadata_path)\n\n    def load(self) -&gt; None:\n        \"\"\"Load an existing BM25 index from disk.\n\n        Performs schema validation and checksum verification.\n        \"\"\"\n        payload = self._read_metadata()\n        self._initialize_from_payload(payload)\n\n    def _metadata_payload(self) -&gt; dict[str, JsonValue]:\n        docs_data: list[JsonValue] = [\n            {\n                \"chunk_id\": doc_id,\n                \"doc_id\": doc_id,\n                \"title\": doc.fields.get(\"title\", \"\"),\n                \"section\": doc.fields.get(\"section\", \"\"),\n                \"body\": doc.fields.get(\"body\", \"\"),\n                \"tf\": {term: int(freq) for term, freq in doc.term_freqs.items()},\n                \"dl\": float(doc.length),\n            }\n            for doc_id, doc in self.docs.items()\n        ]\n        payload: dict[str, JsonValue] = {\n            \"k1\": float(self.k1),\n            \"b\": float(self.b),\n            \"field_boosts\": {\n                field_name: float(weight) for field_name, weight in self.field_boosts.items()\n            },\n            \"df\": {term: int(count) for term, count in self.df.items()},\n            \"postings\": {\n                term: {doc_id: int(freq) for doc_id, freq in posting.items()}\n                for term, posting in self.postings.items()\n            },\n            \"docs\": docs_data,\n            \"N\": int(self.N),\n            \"avgdl\": float(self.avgdl),\n        }\n        return payload\n\n    def _read_metadata(self) -&gt; dict[str, JsonValue]:\n        metadata_path = Path(self.index_dir) / \"pure_bm25.json\"\n        legacy_path = Path(self.index_dir) / \"pure_bm25.pkl\"\n\n        if metadata_path.exists():\n            try:\n                return _load_json_metadata(metadata_path, _BM25_SCHEMA_PATH)\n            except DeserializationError as exc:\n                logger.warning(\"Failed to load JSON index, trying legacy pickle: %s\", exc)\n                if legacy_path.exists():\n                    return self._load_legacy_payload(legacy_path)\n                raise\n\n        if legacy_path.exists():\n            payload = self._load_legacy_payload(legacy_path)\n            logger.warning(\"Loaded legacy pickle index. Consider migrating to JSON format.\")\n            return payload\n\n        msg = f\"Index metadata not found at {metadata_path} or {legacy_path}\"\n        raise FileNotFoundError(msg)\n\n    @staticmethod\n    def _load_legacy_payload(legacy_path: Path) -&gt; dict[str, JsonValue]:\n        with legacy_path.open(\"rb\") as handle:\n            try:\n                payload = load_unsigned_legacy(handle)\n            except UnsafeSerializationError as legacy_exc:\n                msg = f\"Legacy pickle data failed allow-list validation: {legacy_exc}\"\n                raise DeserializationError(msg) from legacy_exc\n        if not isinstance(payload, dict):\n            msg = f\"Invalid pickle data format: expected dict, got {type(payload)}\"\n            raise DeserializationError(msg)\n        return cast(\"dict[str, JsonValue]\", payload)\n\n    def _initialize_from_payload(self, data: Mapping[str, JsonValue]) -&gt; None:\n        self._apply_scalar_metadata(data)\n        self.docs = self._build_docs_from_metadata(data)\n        postings_val = data.get(\"postings\", {})\n        self.postings = (\n            cast(\"dict[str, dict[str, int]]\", postings_val)\n            if isinstance(postings_val, dict)\n            else {}\n        )\n\n    def _apply_scalar_metadata(self, data: Mapping[str, JsonValue]) -&gt; None:\n        k1_val = data.get(\"k1\", 0.9)\n        b_val = data.get(\"b\", 0.4)\n        self.k1 = float(k1_val) if isinstance(k1_val, (int, float)) else 0.9\n        self.b = float(b_val) if isinstance(b_val, (int, float)) else 0.4\n        field_boosts_val = data.get(\"field_boosts\", _DEFAULT_FIELD_BOOSTS)\n        if isinstance(field_boosts_val, Mapping):\n            self.field_boosts = _normalize_field_boosts(\n                cast(\"Mapping[str, float]\", field_boosts_val)\n            )\n        else:\n            self.field_boosts = dict(_DEFAULT_FIELD_BOOSTS)\n        df_val = data.get(\"df\", {})\n        self.df = cast(\"dict[str, int]\", df_val) if isinstance(df_val, dict) else {}\n        n_val = data.get(\"N\", 0)\n        avgdl_val = data.get(\"avgdl\", 0.0)\n        self.N = int(n_val) if isinstance(n_val, (int, float)) else 0\n        self.avgdl = float(avgdl_val) if isinstance(avgdl_val, (int, float)) else 0.0\n\n    @staticmethod\n    def _build_docs_from_metadata(data: Mapping[str, JsonValue]) -&gt; dict[str, BM25Doc]:\n        docs_data_raw = data.get(\"docs\", [])\n        if isinstance(docs_data_raw, list) and docs_data_raw:\n            docs: dict[str, BM25Doc] = {}\n            for doc_value in docs_data_raw:\n                if not isinstance(doc_value, dict):\n                    continue\n                doc_id_raw = doc_value.get(\"doc_id\") or doc_value.get(\"chunk_id\")\n                doc_id = str(doc_id_raw) if doc_id_raw is not None else \"\"\n                if not doc_id:\n                    continue\n                length_val = doc_value.get(\"dl\", doc_value.get(\"length\", 0))\n                length = int(length_val) if isinstance(length_val, (int, float)) else 0\n                title = str(doc_value.get(\"title\", \"\"))\n                section = str(doc_value.get(\"section\", \"\"))\n                body = str(doc_value.get(\"body\", \"\"))\n                tf_raw = doc_value.get(\"tf\", doc_value.get(\"term_freqs\", {}))\n                tf_map = (\n                    {\n                        str(term): int(freq)\n                        for term, freq in cast(\"dict[object, object]\", tf_raw).items()\n                        if isinstance(term, str) and isinstance(freq, (int, float))\n                    }\n                    if isinstance(tf_raw, dict)\n                    else {}\n                )\n                docs[doc_id] = BM25Doc(\n                    doc_id=doc_id,\n                    length=length,\n                    fields={\"title\": title, \"section\": section, \"body\": body},\n                    term_freqs=tf_map,\n                )\n            return docs\n\n        docs_val = data.get(\"docs\", {})\n        if isinstance(docs_val, dict):\n            return cast(\"dict[str, BM25Doc]\", docs_val)\n        return {}\n\n    def _idf(self, term: str) -&gt; float:\n        \"\"\"Compute the inverse document frequency for a given term.\n\n        Calculates IDF using the BM25 formula: log((N - df + 0.5) / (df + 0.5) + 1.0)\n        where N is the total number of documents and df is the document frequency.\n\n        Parameters\n        ----------\n        term : str\n            Token string to compute IDF for.\n\n        Returns\n        -------\n        float\n            IDF score for the term. Returns 0.0 if the term does not appear\n            in any document or if the index is empty.\n\n        Notes\n        -----\n        Uses the standard BM25 IDF formula with smoothing to avoid division by\n        zero. The 0.5 smoothing factor prevents negative IDF values for terms\n        appearing in all documents.\n        \"\"\"\n        n_t = self.df.get(term, 0)\n        if n_t == 0:\n            return 0.0\n        # BM25 idf variant\n        return math.log((self.N - n_t + 0.5) / (n_t + 0.5) + 1.0)\n\n    def search(\n        self,\n        query: str,\n        k: int,\n        fields: Mapping[str, str] | None = None,\n    ) -&gt; list[tuple[str, float]]:\n        \"\"\"Score documents stored in the in-memory BM25 index.\n\n        Tokenizes the query (and optional field values), computes BM25 relevance\n        scores for all documents, and returns the top-k results sorted by score\n        in descending order.\n\n        Parameters\n        ----------\n        query : str\n            Search query string to tokenize and match against documents.\n        k : int\n            Maximum number of results to return.\n        fields : Mapping[str, str] | None, optional\n            Optional field mapping for query expansion. If provided, field\n            values are tokenized and added to the query tokens. Defaults to None.\n\n        Returns\n        -------\n        list[tuple[str, float]]\n            List of (doc_id, score) tuples sorted by score descending. Only\n            includes documents with score &gt; 0.0. Returns empty list if index is\n            empty or no documents match.\n\n        Notes\n        -----\n        BM25 scoring combines term frequency (TF), inverse document frequency\n        (IDF), and document length normalization. The implementation uses naive\n        field weighting where terms from different fields contribute equally\n        to the final score.\n        \"\"\"\n        # naive field weighting at score aggregation (title/section/body contributions)\n        tokens = self._tokenize(query)\n        if fields:\n            for text in fields.values():\n                tokens.extend(self._tokenize(text))\n        scores: defaultdict[str, float] = defaultdict(float)\n        for term in tokens:\n            idf = self._idf(term)\n            postings = self.postings.get(term)\n            if not postings:\n                continue\n            for doc_id, tf in postings.items():\n                doc = self.docs[doc_id]\n                dl = doc.length or 1\n                denom = tf + self.k1 * (1 - self.b + self.b * (dl / self.avgdl))\n                contrib = idf * ((tf * (self.k1 + 1)) / (denom))\n                scores[doc_id] += contrib\n        ranked_scores: list[tuple[str, float]] = [\n            (doc_id, score) for doc_id, score in scores.items()\n        ]\n        ranked_scores.sort(key=_score_value, reverse=True)\n        return ranked_scores[:k]\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.PurePythonBM25.build","title":"<code>build(docs_iterable)</code>","text":"<p>Build postings and document statistics for the BM25 index.</p> <p>Processes an iterable of documents, computes term frequencies and document frequencies, and serializes the index metadata to disk with schema validation.</p> <p>Parameters:</p> Name Type Description Default <code>docs_iterable</code> <code>Iterable[tuple[str, dict[str, str]]]</code> <p>Iterable of (doc_id, fields) tuples. Each fields dictionary should contain \"title\", \"section\", and \"body\" keys with string values.</p> required Notes <p>This method clears any existing index state and rebuilds from scratch. After processing all documents, it computes average document length and writes metadata to <code>pure_bm25.json</code> in the index directory with schema validation and checksum verification.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def build(self, docs_iterable: Iterable[tuple[str, dict[str, str]]]) -&gt; None:\n    \"\"\"Build postings and document statistics for the BM25 index.\n\n    Processes an iterable of documents, computes term frequencies and\n    document frequencies, and serializes the index metadata to disk with\n    schema validation.\n\n    Parameters\n    ----------\n    docs_iterable : Iterable[tuple[str, dict[str, str]]]\n        Iterable of (doc_id, fields) tuples. Each fields dictionary should\n        contain \"title\", \"section\", and \"body\" keys with string values.\n\n    Notes\n    -----\n    This method clears any existing index state and rebuilds from scratch.\n    After processing all documents, it computes average document length\n    and writes metadata to `pure_bm25.json` in the index directory with\n    schema validation and checksum verification.\n    \"\"\"\n    Path(self.index_dir).mkdir(parents=True, exist_ok=True)\n    df: defaultdict[str, int] = defaultdict(int)\n    postings: defaultdict[str, defaultdict[str, int]] = defaultdict(_default_int_dict)\n    docs: dict[str, BM25Doc] = {}\n    lengths: list[int] = []\n    for doc_id, fields in docs_iterable:\n        doc = self._create_doc(doc_id, fields, df, postings)\n        docs[doc_id] = doc\n        lengths.append(doc.length)\n    self.N = len(docs)\n    self.avgdl = (sum(lengths) / self.N) if self.N else 0.0\n    self.df = dict(df)\n    self.postings = {term: dict(term_postings) for term, term_postings in postings.items()}\n    self.docs = docs\n    metadata_path = Path(self.index_dir) / \"pure_bm25.json\"\n    serialize_json(self._metadata_payload(), _BM25_SCHEMA_PATH, metadata_path)\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.PurePythonBM25.load","title":"<code>load()</code>","text":"<p>Load an existing BM25 index from disk.</p> <p>Performs schema validation and checksum verification.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def load(self) -&gt; None:\n    \"\"\"Load an existing BM25 index from disk.\n\n    Performs schema validation and checksum verification.\n    \"\"\"\n    payload = self._read_metadata()\n    self._initialize_from_payload(payload)\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.PurePythonBM25.search","title":"<code>search(query, k, fields=None)</code>","text":"<p>Score documents stored in the in-memory BM25 index.</p> <p>Tokenizes the query (and optional field values), computes BM25 relevance scores for all documents, and returns the top-k results sorted by score in descending order.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query string to tokenize and match against documents.</p> required <code>k</code> <code>int</code> <p>Maximum number of results to return.</p> required <code>fields</code> <code>Mapping[str, str] | None</code> <p>Optional field mapping for query expansion. If provided, field values are tokenized and added to the query tokens. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[tuple[str, float]]</code> <p>List of (doc_id, score) tuples sorted by score descending. Only includes documents with score &gt; 0.0. Returns empty list if index is empty or no documents match.</p> Notes <p>BM25 scoring combines term frequency (TF), inverse document frequency (IDF), and document length normalization. The implementation uses naive field weighting where terms from different fields contribute equally to the final score.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def search(\n    self,\n    query: str,\n    k: int,\n    fields: Mapping[str, str] | None = None,\n) -&gt; list[tuple[str, float]]:\n    \"\"\"Score documents stored in the in-memory BM25 index.\n\n    Tokenizes the query (and optional field values), computes BM25 relevance\n    scores for all documents, and returns the top-k results sorted by score\n    in descending order.\n\n    Parameters\n    ----------\n    query : str\n        Search query string to tokenize and match against documents.\n    k : int\n        Maximum number of results to return.\n    fields : Mapping[str, str] | None, optional\n        Optional field mapping for query expansion. If provided, field\n        values are tokenized and added to the query tokens. Defaults to None.\n\n    Returns\n    -------\n    list[tuple[str, float]]\n        List of (doc_id, score) tuples sorted by score descending. Only\n        includes documents with score &gt; 0.0. Returns empty list if index is\n        empty or no documents match.\n\n    Notes\n    -----\n    BM25 scoring combines term frequency (TF), inverse document frequency\n    (IDF), and document length normalization. The implementation uses naive\n    field weighting where terms from different fields contribute equally\n    to the final score.\n    \"\"\"\n    # naive field weighting at score aggregation (title/section/body contributions)\n    tokens = self._tokenize(query)\n    if fields:\n        for text in fields.values():\n            tokens.extend(self._tokenize(text))\n    scores: defaultdict[str, float] = defaultdict(float)\n    for term in tokens:\n        idf = self._idf(term)\n        postings = self.postings.get(term)\n        if not postings:\n            continue\n        for doc_id, tf in postings.items():\n            doc = self.docs[doc_id]\n            dl = doc.length or 1\n            denom = tf + self.k1 * (1 - self.b + self.b * (dl / self.avgdl))\n            contrib = idf * ((tf * (self.k1 + 1)) / (denom))\n            scores[doc_id] += contrib\n    ranked_scores: list[tuple[str, float]] = [\n        (doc_id, score) for doc_id, score in scores.items()\n    ]\n    ranked_scores.sort(key=_score_value, reverse=True)\n    return ranked_scores[:k]\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25_default_int_dict","title":"embeddings_sparse.bm25._default_int_dict","text":""},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25._default_int_dict","title":"<code>embeddings_sparse.bm25._default_int_dict()</code>","text":"Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def _default_int_dict() -&gt; defaultdict[str, int]:\n    return defaultdict(int)\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25_load_json_metadata","title":"embeddings_sparse.bm25._load_json_metadata","text":""},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25._load_json_metadata","title":"<code>embeddings_sparse.bm25._load_json_metadata(metadata_path, schema_path)</code>","text":"Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def _load_json_metadata(metadata_path: Path, schema_path: Path) -&gt; dict[str, JsonValue]:\n    data_raw = deserialize_json(metadata_path, schema_path)\n    if not isinstance(data_raw, dict):\n        msg = f\"Invalid index data format: expected dict, got {type(data_raw)}\"\n        raise DeserializationError(msg)\n    return cast(\"dict[str, JsonValue]\", data_raw)\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25_load_lucene_indexer_factory","title":"embeddings_sparse.bm25._load_lucene_indexer_factory","text":""},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25._load_lucene_indexer_factory","title":"<code>embeddings_sparse.bm25._load_lucene_indexer_factory()</code>","text":"Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def _load_lucene_indexer_factory() -&gt; LuceneIndexerFactory:\n    try:\n        module = import_module(\"pyserini.index.lucene\")\n    except Exception as exc:  # pragma: no cover - depends on optional dependency\n        msg = \"pyserini.index.lucene module is unavailable\"\n        raise RuntimeError(msg) from exc\n    candidate_callable = cast(\n        \"LuceneIndexerFactory | None\",\n        getattr(module, \"LuceneIndexer\", None),\n    )\n    if candidate_callable is None:  # pragma: no cover - defensive branch\n        msg = \"pyserini index module is missing 'LuceneIndexer'\"\n        raise TypeError(msg)\n    return candidate_callable\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25_load_lucene_searcher_factory","title":"embeddings_sparse.bm25._load_lucene_searcher_factory","text":""},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25._load_lucene_searcher_factory","title":"<code>embeddings_sparse.bm25._load_lucene_searcher_factory()</code>","text":"Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def _load_lucene_searcher_factory() -&gt; LuceneSearcherFactory:\n    try:\n        module = import_module(\"pyserini.search.lucene\")\n    except Exception as exc:  # pragma: no cover - depends on optional dependency\n        msg = \"pyserini.search.lucene module is unavailable\"\n        raise RuntimeError(msg) from exc\n    candidate_callable = cast(\n        \"LuceneSearcherFactory | None\",\n        getattr(module, \"LuceneSearcher\", None),\n    )\n    if candidate_callable is None:  # pragma: no cover - defensive branch\n        msg = \"pyserini search module is missing 'LuceneSearcher'\"\n        raise TypeError(msg)\n    return candidate_callable\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25_normalize_field_boosts","title":"embeddings_sparse.bm25._normalize_field_boosts","text":""},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25._normalize_field_boosts","title":"<code>embeddings_sparse.bm25._normalize_field_boosts(boosts)</code>","text":"Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def _normalize_field_boosts(boosts: Mapping[str, float] | None) -&gt; dict[str, float]:\n    if boosts is None:\n        return dict(_DEFAULT_FIELD_BOOSTS)\n    normalized: dict[str, float] = {}\n    for field_name, value in boosts.items():\n        normalized[str(field_name)] = float(value)\n    return normalized\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25_score_value","title":"embeddings_sparse.bm25._score_value","text":""},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25._score_value","title":"<code>embeddings_sparse.bm25._score_value(item)</code>","text":"Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def _score_value(item: tuple[str, float]) -&gt; float:\n    return item[1]\n</code></pre>"},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparsebm25get_bm25","title":"embeddings_sparse.bm25.get_bm25","text":""},{"location":"modules/embeddings_sparse.bm25/#embeddings_sparse.bm25.get_bm25","title":"<code>embeddings_sparse.bm25.get_bm25(backend, index_dir, *, k1=0.9, b=0.4, load_existing=True)</code>","text":"<p>Return a BM25 index implementation for the requested backend.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>str</code> <p>Backend name (\"pure\" or \"lucene\").</p> required <code>index_dir</code> <code>str</code> <p>Directory path for the index.</p> required <code>k1</code> <code>float</code> <p>BM25 k1 parameter (default: 0.9).</p> <code>0.9</code> <code>b</code> <code>float</code> <p>BM25 b parameter (default: 0.4).</p> <code>0.4</code> <code>load_existing</code> <code>bool</code> <p>Whether to load existing index if available (default: True).</p> <code>True</code> <p>Returns:</p> Type Description <code>PurePythonBM25 | LuceneBM25</code> <p>BM25 index instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If backend is not one of the supported values.</p> Source code in <code>src/embeddings_sparse/bm25.py</code> <pre><code>def get_bm25(\n    backend: str,\n    index_dir: str,\n    *,\n    k1: float = 0.9,\n    b: float = 0.4,\n    load_existing: bool = True,\n) -&gt; PurePythonBM25 | LuceneBM25:\n    \"\"\"Return a BM25 index implementation for the requested backend.\n\n    Parameters\n    ----------\n    backend : str\n        Backend name (\"pure\" or \"lucene\").\n    index_dir : str\n        Directory path for the index.\n    k1 : float, optional\n        BM25 k1 parameter (default: 0.9).\n    b : float, optional\n        BM25 b parameter (default: 0.4).\n    load_existing : bool, optional\n        Whether to load existing index if available (default: True).\n\n    Returns\n    -------\n    PurePythonBM25 | LuceneBM25\n        BM25 index instance.\n\n    Raises\n    ------\n    ValueError\n        If backend is not one of the supported values.\n    \"\"\"\n    normalized_backend = backend.strip().lower()\n    if normalized_backend == \"pure\":\n        index: PurePythonBM25 | LuceneBM25 = PurePythonBM25(\n            index_dir=index_dir,\n            k1=k1,\n            b=b,\n        )\n    elif normalized_backend == \"lucene\":\n        index = LuceneBM25(\n            index_dir=index_dir,\n            k1=k1,\n            b=b,\n        )\n    else:\n        msg = f\"Unsupported BM25 backend '{backend}'\"\n        raise ValueError(msg)\n\n    if load_existing:\n        index.load()\n\n    return index\n</code></pre>"},{"location":"modules/embeddings_sparse/","title":"embeddings_sparse","text":""},{"location":"modules/embeddings_sparse/#embeddings_sparse","title":"embeddings_sparse","text":"<p>Sparse embedding adapters and indices</p> <p>:material-source-repository: View source</p>"},{"location":"modules/embeddings_sparse/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"embeddings_sparse__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.navmap_types.NavMapembeddings_sparse code <p>See the full diagram: embeddings_sparse</p>"},{"location":"modules/embeddings_sparse/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.navmap_types.NavMap</code></p>"},{"location":"modules/embeddings_sparse.splade/","title":"embeddings_sparse.splade","text":""},{"location":"modules/embeddings_sparse.splade/#embeddings_sparsesplade","title":"embeddings_sparse.splade","text":"<p>SPLADE sparse embedding helpers</p> <p>:material-source-repository: View source</p>"},{"location":"modules/embeddings_sparse.splade/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class ImpactHitProtocol\n    class Protocol\n    Protocol &lt;|-- ImpactHitProtocol\n    class LuceneImpactIndex\n    class LuceneImpactSearcherFactory\n    Protocol &lt;|-- LuceneImpactSearcherFactory\n    class LuceneImpactSearcherProtocol\n    Protocol &lt;|-- LuceneImpactSearcherProtocol\n    class PureImpactIndex\n    class SPLADEv3Encoder\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"embeddings_sparse.splade__future__.annotationsbase64binasciicollections.Countercollections.abc.Iterablecollections.abc.Sequencecollections.defaultdictimportlibkgfoundry_common.config.load_configkgfoundry_common.errors.DeserializationErrorkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.problem_details.JsonValuekgfoundry_common.safe_pickle_v2.SignedPickleWrapperkgfoundry_common.safe_pickle_v2.UnsafeSerializationErrorkgfoundry_common.safe_pickle_v2.load_unsigned_legacykgfoundry_common.serialization.deserialize_jsonkgfoundry_common.serialization.serialize_jsonloggingmathpathlib.Pathrere.Patterntypes.ModuleTypetyping.BinaryIOtyping.Protocoltyping.TYPE_CHECKINGtyping.castembeddings_sparse.splade code <p>See the full diagram: embeddings_sparse.splade</p>"},{"location":"modules/embeddings_sparse.splade/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>embeddings_sparse.splade.ImpactHitProtocol</li> <li>embeddings_sparse.splade.LuceneImpactIndex</li> <li>embeddings_sparse.splade.LuceneImpactSearcherFactory</li> <li>embeddings_sparse.splade._decode_signing_key</li> <li>embeddings_sparse.splade._default_float_dict</li> <li>embeddings_sparse.splade._load_legacy_metadata</li> </ul>"},{"location":"modules/embeddings_sparse.splade/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>base64</code>, <code>binascii</code>, <code>collections.Counter</code>, <code>collections.abc.Iterable</code>, <code>collections.abc.Sequence</code>, <code>collections.defaultdict</code>, <code>importlib</code>, <code>kgfoundry_common.config.load_config</code>, <code>kgfoundry_common.errors.DeserializationError</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.problem_details.JsonValue</code>, <code>kgfoundry_common.safe_pickle_v2.SignedPickleWrapper</code>, <code>kgfoundry_common.safe_pickle_v2.UnsafeSerializationError</code>, <code>kgfoundry_common.safe_pickle_v2.load_unsigned_legacy</code>, <code>kgfoundry_common.serialization.deserialize_json</code>, <code>kgfoundry_common.serialization.serialize_json</code>, <code>logging</code>, <code>math</code>, <code>pathlib.Path</code>, <code>re</code>, <code>re.Pattern</code>, <code>types.ModuleType</code>, <code>typing.BinaryIO</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/embeddings_sparse.splade/#contents","title":"Contents","text":""},{"location":"modules/embeddings_sparse.splade/#embeddings_sparsespladeimpacthitprotocol","title":"embeddings_sparse.splade.ImpactHitProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.ImpactHitProtocol","title":"<code>embeddings_sparse.splade.ImpactHitProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol describing the minimal SPLADE impact hit payload.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>class ImpactHitProtocol(Protocol):\n    \"\"\"Protocol describing the minimal SPLADE impact hit payload.\"\"\"\n\n    docid: str\n    score: float\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparsespladeluceneimpactindex","title":"embeddings_sparse.splade.LuceneImpactIndex","text":""},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.LuceneImpactIndex","title":"<code>embeddings_sparse.splade.LuceneImpactIndex</code>","text":"<p>Lucene-backed SPLADE impact index implementation.</p> <p>Provides SPLADE sparse retrieval using Apache Lucene via Pyserini's impact search. Suitable for large indexes that benefit from disk-backed storage and optimized search performance.</p> <p>Initializes the Lucene impact index with an index directory and optional query encoder.</p> <p>Parameters:</p> Name Type Description Default <code>index_dir</code> <code>str</code> <p>Directory path where the Lucene impact index is stored. Must exist and contain a valid Lucene index.</p> required <code>query_encoder</code> <code>str</code> <p>Hugging Face model identifier for query encoding. Defaults to \"naver/splade-v3-distilbert\".</p> <code>'naver/splade-v3-distilbert'</code> Notes <p>Requires the optional <code>pyserini</code> dependency. Import errors propagate as :class:<code>RuntimeError</code> when helper factories are loaded. The searcher is lazy-initialized on first search call to avoid unnecessary index loading.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>class LuceneImpactIndex:\n    \"\"\"Lucene-backed SPLADE impact index implementation.\n\n    Provides SPLADE sparse retrieval using Apache Lucene via Pyserini's impact\n    search. Suitable for large indexes that benefit from disk-backed storage\n    and optimized search performance.\n\n    Initializes the Lucene impact index with an index directory and optional query encoder.\n\n    Parameters\n    ----------\n    index_dir : str\n        Directory path where the Lucene impact index is stored. Must exist\n        and contain a valid Lucene index.\n    query_encoder : str, optional\n        Hugging Face model identifier for query encoding. Defaults to\n        \"naver/splade-v3-distilbert\".\n\n    Notes\n    -----\n    Requires the optional ``pyserini`` dependency. Import errors propagate as\n    :class:`RuntimeError` when helper factories are loaded. The searcher is\n    lazy-initialized on first search call to avoid unnecessary index loading.\n    \"\"\"\n\n    def __init__(self, index_dir: str, query_encoder: str = \"naver/splade-v3-distilbert\") -&gt; None:\n        self.index_dir = index_dir\n        self.query_encoder = query_encoder\n        self._searcher: LuceneImpactSearcherProtocol | None = None\n\n    def _ensure(self) -&gt; None:\n        \"\"\"Initialise the Lucene impact searcher if Pyserini is available.\n\n        Raises\n        ------\n        RuntimeError\n            If the Pyserini Lucene search implementation is unavailable.\n        \"\"\"\n        if self._searcher is not None:\n            return\n        try:\n            lucene_search_module: ModuleType = importlib.import_module(\"pyserini.search.lucene\")\n            lucene_impact_searcher_cls = cast(\n                \"LuceneImpactSearcherFactory\",\n                lucene_search_module.LuceneImpactSearcher,\n            )\n        except (ImportError, AttributeError) as exc:  # pragma: no cover - optional dependency\n            message = \"Pyserini not available for SPLADE impact search\"\n            logger.exception(\"Failed to import LuceneImpactSearcher\")\n            raise RuntimeError(message) from exc\n        searcher = lucene_impact_searcher_cls(self.index_dir, query_encoder=self.query_encoder)\n        self._searcher = searcher\n\n    def ensure_available(self) -&gt; None:\n        \"\"\"Ensure the Lucene searcher is initialized and ready for queries.\n\n        Notes\n        -----\n        Propagates :class:`RuntimeError` when Pyserini is not available for\n        SPLADE impact search.\n        \"\"\"\n        self._ensure()\n\n    def search(self, query: str, k: int) -&gt; list[tuple[str, float]]:\n        \"\"\"Search Lucene impact index and return top-k results.\n\n        Executes a SPLADE impact search using the configured Lucene searcher\n        and returns the top-k results sorted by impact score.\n\n        Parameters\n        ----------\n        query : str\n            Search query string to encode and search.\n        k : int\n            Maximum number of results to return.\n\n        Returns\n        -------\n        list[tuple[str, float]]\n            List of (doc_id, score) tuples sorted by score descending. Contains\n            up to k results.\n\n        Raises\n        ------\n        RuntimeError\n            If Lucene searcher is not initialized or Pyserini is not available.\n            This can occur if ensure_available() has not been called or if\n            Pyserini modules are missing.\n        \"\"\"\n        self._ensure()\n        if self._searcher is None:\n            message = \"Lucene impact searcher not initialized\"\n            raise RuntimeError(message)\n        hits = self._searcher.search(query, k)\n        return [(str(hit.docid), float(hit.score)) for hit in hits]\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.LuceneImpactIndex.ensure_available","title":"<code>ensure_available()</code>","text":"<p>Ensure the Lucene searcher is initialized and ready for queries.</p> Notes <p>Propagates :class:<code>RuntimeError</code> when Pyserini is not available for SPLADE impact search.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>def ensure_available(self) -&gt; None:\n    \"\"\"Ensure the Lucene searcher is initialized and ready for queries.\n\n    Notes\n    -----\n    Propagates :class:`RuntimeError` when Pyserini is not available for\n    SPLADE impact search.\n    \"\"\"\n    self._ensure()\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.LuceneImpactIndex.search","title":"<code>search(query, k)</code>","text":"<p>Search Lucene impact index and return top-k results.</p> <p>Executes a SPLADE impact search using the configured Lucene searcher and returns the top-k results sorted by impact score.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query string to encode and search.</p> required <code>k</code> <code>int</code> <p>Maximum number of results to return.</p> required <p>Returns:</p> Type Description <code>list[tuple[str, float]]</code> <p>List of (doc_id, score) tuples sorted by score descending. Contains up to k results.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If Lucene searcher is not initialized or Pyserini is not available. This can occur if ensure_available() has not been called or if Pyserini modules are missing.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>def search(self, query: str, k: int) -&gt; list[tuple[str, float]]:\n    \"\"\"Search Lucene impact index and return top-k results.\n\n    Executes a SPLADE impact search using the configured Lucene searcher\n    and returns the top-k results sorted by impact score.\n\n    Parameters\n    ----------\n    query : str\n        Search query string to encode and search.\n    k : int\n        Maximum number of results to return.\n\n    Returns\n    -------\n    list[tuple[str, float]]\n        List of (doc_id, score) tuples sorted by score descending. Contains\n        up to k results.\n\n    Raises\n    ------\n    RuntimeError\n        If Lucene searcher is not initialized or Pyserini is not available.\n        This can occur if ensure_available() has not been called or if\n        Pyserini modules are missing.\n    \"\"\"\n    self._ensure()\n    if self._searcher is None:\n        message = \"Lucene impact searcher not initialized\"\n        raise RuntimeError(message)\n    hits = self._searcher.search(query, k)\n    return [(str(hit.docid), float(hit.score)) for hit in hits]\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparsespladeluceneimpactsearcherfactory","title":"embeddings_sparse.splade.LuceneImpactSearcherFactory","text":"<p>Bases: Protocol</p>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.LuceneImpactSearcherFactory","title":"<code>embeddings_sparse.splade.LuceneImpactSearcherFactory</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Factory protocol for constructing Lucene SPLADE searchers.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>class LuceneImpactSearcherFactory(Protocol):\n    \"\"\"Factory protocol for constructing Lucene SPLADE searchers.\"\"\"\n\n    def __call__(\n        self, index_dir: str, *, query_encoder: str | None = None\n    ) -&gt; LuceneImpactSearcherProtocol:\n        \"\"\"Build a searcher for ``index_dir`` using an optional query encoder.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.LuceneImpactSearcherFactory.__call__","title":"<code>__call__(index_dir, *, query_encoder=None)</code>","text":"<p>Build a searcher for <code>index_dir</code> using an optional query encoder.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>def __call__(\n    self, index_dir: str, *, query_encoder: str | None = None\n) -&gt; LuceneImpactSearcherProtocol:\n    \"\"\"Build a searcher for ``index_dir`` using an optional query encoder.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparsespladeluceneimpactsearcherprotocol","title":"embeddings_sparse.splade.LuceneImpactSearcherProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.LuceneImpactSearcherProtocol","title":"<code>embeddings_sparse.splade.LuceneImpactSearcherProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for Lucene-backed SPLADE searchers.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>class LuceneImpactSearcherProtocol(Protocol):\n    \"\"\"Protocol for Lucene-backed SPLADE searchers.\"\"\"\n\n    def search(self, query: str, k: int) -&gt; Sequence[ImpactHitProtocol]:\n        \"\"\"Return the top ``k`` SPLADE impact hits for ``query``.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.LuceneImpactSearcherProtocol.search","title":"<code>search(query, k)</code>","text":"<p>Return the top <code>k</code> SPLADE impact hits for <code>query</code>.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>def search(self, query: str, k: int) -&gt; Sequence[ImpactHitProtocol]:\n    \"\"\"Return the top ``k`` SPLADE impact hits for ``query``.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparsespladepureimpactindex","title":"embeddings_sparse.splade.PureImpactIndex","text":""},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.PureImpactIndex","title":"<code>embeddings_sparse.splade.PureImpactIndex</code>","text":"<p>Pure Python SPLADE impact index implementation.</p> <p>Implements SPLADE (Sparse Lexical and Expansion) sparse retrieval using Python dictionaries and lists. Suitable for small to medium-sized indexes that fit in memory.</p> <p>Initializes the SPLADE impact index with an index directory.</p> <p>Parameters:</p> Name Type Description Default <code>index_dir</code> <code>str</code> <p>Directory path where index metadata will be stored. Created if it doesn't exist.</p> required Notes <p>The implementation uses in-memory data structures and is suitable for indexes that fit in RAM. For larger indexes, consider using LuceneImpactIndex which uses Pyserini's disk-backed Lucene impact search.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>class PureImpactIndex:\n    \"\"\"Pure Python SPLADE impact index implementation.\n\n    Implements SPLADE (Sparse Lexical and Expansion) sparse retrieval using\n    Python dictionaries and lists. Suitable for small to medium-sized indexes\n    that fit in memory.\n\n    Initializes the SPLADE impact index with an index directory.\n\n    Parameters\n    ----------\n    index_dir : str\n        Directory path where index metadata will be stored. Created if it\n        doesn't exist.\n\n    Notes\n    -----\n    The implementation uses in-memory data structures and is suitable for\n    indexes that fit in RAM. For larger indexes, consider using LuceneImpactIndex\n    which uses Pyserini's disk-backed Lucene impact search.\n    \"\"\"\n\n    def __init__(self, index_dir: str) -&gt; None:\n        self.index_dir = index_dir\n        self.df: dict[str, int] = {}\n        self.N = 0\n        self.postings: dict[str, dict[str, float]] = {}\n\n    @staticmethod\n    def _tokenize(text: str) -&gt; list[str]:\n        \"\"\"Tokenize text with a simple alphanumeric regex.\n\n        Extracts alphanumeric sequences (including underscores) from text and\n        converts them to lowercase for case-insensitive matching.\n\n        Parameters\n        ----------\n        text : str\n            Input text to tokenize. May be empty.\n\n        Returns\n        -------\n        list[str]\n            List of lowercase tokens extracted from the text. Empty list if\n            input contains no alphanumeric sequences.\n        \"\"\"\n        matches = cast(\"list[str]\", TOKEN_RE.findall(text))\n        return [token.lower() for token in matches]\n\n    def build(self, docs_iterable: Iterable[tuple[str, dict[str, str]]]) -&gt; None:\n        \"\"\"Build SPLADE impact index from document iterable.\n\n        Processes an iterable of documents, computes term frequencies with\n        log1p normalization, applies IDF scoring, and serializes the index\n        metadata to disk with schema validation.\n\n        Parameters\n        ----------\n        docs_iterable : Iterable[tuple[str, dict[str, str]]]\n            Iterable of (doc_id, fields) tuples. Each fields dictionary should\n            contain \"title\", \"section\", and \"body\" keys with string values.\n\n        Notes\n        -----\n        This method clears any existing index state and rebuilds from scratch.\n        Term frequencies are normalized using log1p, then combined with IDF\n        scores. The final metadata is written to `impact.json` in the index\n        directory with schema validation and checksum verification.\n        \"\"\"\n        Path(self.index_dir).mkdir(parents=True, exist_ok=True)\n        df: defaultdict[str, int] = defaultdict(int)\n        postings: defaultdict[str, defaultdict[str, float]] = defaultdict(_default_float_dict)\n        doc_count = 0\n        for doc_id, fields in docs_iterable:\n            text = \" \".join(\n                [fields.get(\"title\", \"\"), fields.get(\"section\", \"\"), fields.get(\"body\", \"\")]\n            )\n            tokens = self._tokenize(text)\n            doc_count += 1\n            counts = Counter(tokens)\n            for token, term_freq in counts.items():\n                df[token] += 1\n                postings[token][doc_id] = math.log1p(term_freq)\n        self.N = doc_count\n        self.df = dict(df)\n        self.postings = {\n            token: {\n                doc: weight * math.log((doc_count - df[token] + 0.5) / (df[token] + 0.5) + 1.0)\n                for doc, weight in docs.items()\n            }\n            for token, docs in postings.items()\n        }\n        # persist using secure JSON serialization with schema validation\n        metadata_path = Path(self.index_dir) / \"impact.json\"\n        schema_path = (\n            Path(__file__).parent.parent.parent / \"schema\" / \"models\" / \"splade_metadata.v1.json\"\n        )\n        payload = {\"df\": self.df, \"N\": self.N, \"postings\": self.postings}\n        serialize_json(payload, schema_path, metadata_path)\n\n    def load(self) -&gt; None:\n        \"\"\"Load SPLADE index metadata from disk with schema validation and checksum verification.\n\n        Deserializes index metadata from JSON, verifying checksum and validating\n        against the schema. Falls back to legacy pickle format for backward\n        compatibility if JSON loading fails.\n\n        Raises\n        ------\n        DeserializationError\n            If deserialization, schema validation, or checksum verification fails.\n        FileNotFoundError\n            If metadata or schema file is missing (and no legacy pickle exists).\n\n        Notes\n        -----\n        The method first attempts to load from `impact.json`. If that fails and\n        `impact.pkl` exists, it falls back to legacy pickle format with\n        allow-list validation. Legacy pickle loading supports both signed and\n        unsigned formats.\n        \"\"\"\n        metadata_path = Path(self.index_dir) / \"impact.json\"\n        schema_path = (\n            Path(__file__).parent.parent.parent / \"schema\" / \"models\" / \"splade_metadata.v1.json\"\n        )\n        legacy_path = Path(self.index_dir) / \"impact.pkl\"\n\n        if metadata_path.exists():\n            try:\n                data_raw = deserialize_json(metadata_path, schema_path)\n            except DeserializationError:\n                logger.warning(\n                    \"Failed to load JSON index, trying legacy pickle\",\n                    extra={\"metadata_path\": str(metadata_path), \"legacy_path\": str(legacy_path)},\n                )\n                if legacy_path.exists():\n                    data_dict = _load_legacy_metadata(legacy_path)\n                else:\n                    raise\n            else:\n                if not isinstance(data_raw, dict):\n                    msg = f\"Invalid index data format: expected dict, got {type(data_raw)}\"\n                    raise DeserializationError(msg)\n                data_dict = cast(\"dict[str, JsonValue]\", data_raw)\n        elif legacy_path.exists():\n            data_dict = _load_legacy_metadata(legacy_path)\n            logger.warning(\"Loaded legacy pickle index. Consider migrating to JSON format.\")\n        else:\n            msg = f\"Index metadata not found at {metadata_path} or {legacy_path}\"\n            raise FileNotFoundError(msg)\n\n        # Extract values with type narrowing\n        df_val: JsonValue = data_dict.get(\"df\", {})\n        n_val: JsonValue = data_dict.get(\"N\", 0)\n        postings_val: JsonValue = data_dict.get(\"postings\", {})\n\n        # Type narrowing and conversion\n        self.df = cast(\"dict[str, int]\", df_val) if isinstance(df_val, dict) else {}\n        self.N = int(n_val) if isinstance(n_val, (int, float)) else 0\n        # postings is dict[str, dict[str, float]] - need to convert nested dict values\n        if isinstance(postings_val, dict):\n            # Convert nested dict values from JsonValue to dict[str, float]\n            postings_converted: dict[str, dict[str, float]] = {}\n            for term, term_postings in postings_val.items():\n                if isinstance(term_postings, dict):\n                    # Convert inner dict values to float\n                    term_postings_float: dict[str, float] = {\n                        str(doc_id): float(weight) if isinstance(weight, (int, float)) else 0.0\n                        for doc_id, weight in term_postings.items()\n                    }\n                    postings_converted[str(term)] = term_postings_float\n            self.postings = postings_converted\n        else:\n            self.postings = {}\n\n    def search(self, query: str, k: int) -&gt; list[tuple[str, float]]:\n        \"\"\"Search SPLADE impact index and return top-k results.\n\n        Tokenizes the query, computes impact scores by summing term weights\n        from postings, and returns the top-k results sorted by score in\n        descending order.\n\n        Parameters\n        ----------\n        query : str\n            Search query string to tokenize and match against documents.\n        k : int\n            Maximum number of results to return.\n\n        Returns\n        -------\n        list[tuple[str, float]]\n            List of (doc_id, score) tuples sorted by score descending. Only\n            includes documents with score &gt; 0.0. Returns empty list if index is\n            empty or no documents match.\n\n        Notes\n        -----\n        SPLADE impact scoring sums term weights (combining log1p(TF) and IDF)\n        for each query token. Documents with higher scores are more relevant\n        to the query.\n        \"\"\"\n        tokens = self._tokenize(query)\n        scores: defaultdict[str, float] = defaultdict(float)\n        for token in tokens:\n            postings = self.postings.get(token)\n            if not postings:\n                continue\n            for doc_id, weight in postings.items():\n                scores[doc_id] += weight\n        ranked_scores: list[tuple[str, float]] = [\n            (doc_id, score) for doc_id, score in scores.items()\n        ]\n        ranked_scores.sort(key=_score_value, reverse=True)\n        return ranked_scores[:k]\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.PureImpactIndex.build","title":"<code>build(docs_iterable)</code>","text":"<p>Build SPLADE impact index from document iterable.</p> <p>Processes an iterable of documents, computes term frequencies with log1p normalization, applies IDF scoring, and serializes the index metadata to disk with schema validation.</p> <p>Parameters:</p> Name Type Description Default <code>docs_iterable</code> <code>Iterable[tuple[str, dict[str, str]]]</code> <p>Iterable of (doc_id, fields) tuples. Each fields dictionary should contain \"title\", \"section\", and \"body\" keys with string values.</p> required Notes <p>This method clears any existing index state and rebuilds from scratch. Term frequencies are normalized using log1p, then combined with IDF scores. The final metadata is written to <code>impact.json</code> in the index directory with schema validation and checksum verification.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>def build(self, docs_iterable: Iterable[tuple[str, dict[str, str]]]) -&gt; None:\n    \"\"\"Build SPLADE impact index from document iterable.\n\n    Processes an iterable of documents, computes term frequencies with\n    log1p normalization, applies IDF scoring, and serializes the index\n    metadata to disk with schema validation.\n\n    Parameters\n    ----------\n    docs_iterable : Iterable[tuple[str, dict[str, str]]]\n        Iterable of (doc_id, fields) tuples. Each fields dictionary should\n        contain \"title\", \"section\", and \"body\" keys with string values.\n\n    Notes\n    -----\n    This method clears any existing index state and rebuilds from scratch.\n    Term frequencies are normalized using log1p, then combined with IDF\n    scores. The final metadata is written to `impact.json` in the index\n    directory with schema validation and checksum verification.\n    \"\"\"\n    Path(self.index_dir).mkdir(parents=True, exist_ok=True)\n    df: defaultdict[str, int] = defaultdict(int)\n    postings: defaultdict[str, defaultdict[str, float]] = defaultdict(_default_float_dict)\n    doc_count = 0\n    for doc_id, fields in docs_iterable:\n        text = \" \".join(\n            [fields.get(\"title\", \"\"), fields.get(\"section\", \"\"), fields.get(\"body\", \"\")]\n        )\n        tokens = self._tokenize(text)\n        doc_count += 1\n        counts = Counter(tokens)\n        for token, term_freq in counts.items():\n            df[token] += 1\n            postings[token][doc_id] = math.log1p(term_freq)\n    self.N = doc_count\n    self.df = dict(df)\n    self.postings = {\n        token: {\n            doc: weight * math.log((doc_count - df[token] + 0.5) / (df[token] + 0.5) + 1.0)\n            for doc, weight in docs.items()\n        }\n        for token, docs in postings.items()\n    }\n    # persist using secure JSON serialization with schema validation\n    metadata_path = Path(self.index_dir) / \"impact.json\"\n    schema_path = (\n        Path(__file__).parent.parent.parent / \"schema\" / \"models\" / \"splade_metadata.v1.json\"\n    )\n    payload = {\"df\": self.df, \"N\": self.N, \"postings\": self.postings}\n    serialize_json(payload, schema_path, metadata_path)\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.PureImpactIndex.load","title":"<code>load()</code>","text":"<p>Load SPLADE index metadata from disk with schema validation and checksum verification.</p> <p>Deserializes index metadata from JSON, verifying checksum and validating against the schema. Falls back to legacy pickle format for backward compatibility if JSON loading fails.</p> <p>Raises:</p> Type Description <code>DeserializationError</code> <p>If deserialization, schema validation, or checksum verification fails.</p> <code>FileNotFoundError</code> <p>If metadata or schema file is missing (and no legacy pickle exists).</p> Notes <p>The method first attempts to load from <code>impact.json</code>. If that fails and <code>impact.pkl</code> exists, it falls back to legacy pickle format with allow-list validation. Legacy pickle loading supports both signed and unsigned formats.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>def load(self) -&gt; None:\n    \"\"\"Load SPLADE index metadata from disk with schema validation and checksum verification.\n\n    Deserializes index metadata from JSON, verifying checksum and validating\n    against the schema. Falls back to legacy pickle format for backward\n    compatibility if JSON loading fails.\n\n    Raises\n    ------\n    DeserializationError\n        If deserialization, schema validation, or checksum verification fails.\n    FileNotFoundError\n        If metadata or schema file is missing (and no legacy pickle exists).\n\n    Notes\n    -----\n    The method first attempts to load from `impact.json`. If that fails and\n    `impact.pkl` exists, it falls back to legacy pickle format with\n    allow-list validation. Legacy pickle loading supports both signed and\n    unsigned formats.\n    \"\"\"\n    metadata_path = Path(self.index_dir) / \"impact.json\"\n    schema_path = (\n        Path(__file__).parent.parent.parent / \"schema\" / \"models\" / \"splade_metadata.v1.json\"\n    )\n    legacy_path = Path(self.index_dir) / \"impact.pkl\"\n\n    if metadata_path.exists():\n        try:\n            data_raw = deserialize_json(metadata_path, schema_path)\n        except DeserializationError:\n            logger.warning(\n                \"Failed to load JSON index, trying legacy pickle\",\n                extra={\"metadata_path\": str(metadata_path), \"legacy_path\": str(legacy_path)},\n            )\n            if legacy_path.exists():\n                data_dict = _load_legacy_metadata(legacy_path)\n            else:\n                raise\n        else:\n            if not isinstance(data_raw, dict):\n                msg = f\"Invalid index data format: expected dict, got {type(data_raw)}\"\n                raise DeserializationError(msg)\n            data_dict = cast(\"dict[str, JsonValue]\", data_raw)\n    elif legacy_path.exists():\n        data_dict = _load_legacy_metadata(legacy_path)\n        logger.warning(\"Loaded legacy pickle index. Consider migrating to JSON format.\")\n    else:\n        msg = f\"Index metadata not found at {metadata_path} or {legacy_path}\"\n        raise FileNotFoundError(msg)\n\n    # Extract values with type narrowing\n    df_val: JsonValue = data_dict.get(\"df\", {})\n    n_val: JsonValue = data_dict.get(\"N\", 0)\n    postings_val: JsonValue = data_dict.get(\"postings\", {})\n\n    # Type narrowing and conversion\n    self.df = cast(\"dict[str, int]\", df_val) if isinstance(df_val, dict) else {}\n    self.N = int(n_val) if isinstance(n_val, (int, float)) else 0\n    # postings is dict[str, dict[str, float]] - need to convert nested dict values\n    if isinstance(postings_val, dict):\n        # Convert nested dict values from JsonValue to dict[str, float]\n        postings_converted: dict[str, dict[str, float]] = {}\n        for term, term_postings in postings_val.items():\n            if isinstance(term_postings, dict):\n                # Convert inner dict values to float\n                term_postings_float: dict[str, float] = {\n                    str(doc_id): float(weight) if isinstance(weight, (int, float)) else 0.0\n                    for doc_id, weight in term_postings.items()\n                }\n                postings_converted[str(term)] = term_postings_float\n        self.postings = postings_converted\n    else:\n        self.postings = {}\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.PureImpactIndex.search","title":"<code>search(query, k)</code>","text":"<p>Search SPLADE impact index and return top-k results.</p> <p>Tokenizes the query, computes impact scores by summing term weights from postings, and returns the top-k results sorted by score in descending order.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query string to tokenize and match against documents.</p> required <code>k</code> <code>int</code> <p>Maximum number of results to return.</p> required <p>Returns:</p> Type Description <code>list[tuple[str, float]]</code> <p>List of (doc_id, score) tuples sorted by score descending. Only includes documents with score &gt; 0.0. Returns empty list if index is empty or no documents match.</p> Notes <p>SPLADE impact scoring sums term weights (combining log1p(TF) and IDF) for each query token. Documents with higher scores are more relevant to the query.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>def search(self, query: str, k: int) -&gt; list[tuple[str, float]]:\n    \"\"\"Search SPLADE impact index and return top-k results.\n\n    Tokenizes the query, computes impact scores by summing term weights\n    from postings, and returns the top-k results sorted by score in\n    descending order.\n\n    Parameters\n    ----------\n    query : str\n        Search query string to tokenize and match against documents.\n    k : int\n        Maximum number of results to return.\n\n    Returns\n    -------\n    list[tuple[str, float]]\n        List of (doc_id, score) tuples sorted by score descending. Only\n        includes documents with score &gt; 0.0. Returns empty list if index is\n        empty or no documents match.\n\n    Notes\n    -----\n    SPLADE impact scoring sums term weights (combining log1p(TF) and IDF)\n    for each query token. Documents with higher scores are more relevant\n    to the query.\n    \"\"\"\n    tokens = self._tokenize(query)\n    scores: defaultdict[str, float] = defaultdict(float)\n    for token in tokens:\n        postings = self.postings.get(token)\n        if not postings:\n            continue\n        for doc_id, weight in postings.items():\n            scores[doc_id] += weight\n    ranked_scores: list[tuple[str, float]] = [\n        (doc_id, score) for doc_id, score in scores.items()\n    ]\n    ranked_scores.sort(key=_score_value, reverse=True)\n    return ranked_scores[:k]\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparsespladespladev3encoder","title":"embeddings_sparse.splade.SPLADEv3Encoder","text":""},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.SPLADEv3Encoder","title":"<code>embeddings_sparse.splade.SPLADEv3Encoder</code>","text":"<p>SPLADE-v3 encoder for generating sparse embeddings.</p> <p>Provides an interface for encoding text into SPLADE sparse embeddings. Currently a skeleton implementation that raises NotImplementedError.</p> <p>Initializes the SPLADE-v3 encoder with model configuration and device settings.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>Hugging Face model identifier for the SPLADE encoder. Defaults to \"naver/splade-v3-distilbert\".</p> <code>'naver/splade-v3-distilbert'</code> <code>device</code> <code>str</code> <p>Device to run inference on (\"cuda\" or \"cpu\"). Defaults to \"cuda\".</p> <code>'cuda'</code> <code>topk</code> <code>int</code> <p>Number of top-k vocabulary tokens to retain in sparse representation. Defaults to 256.</p> <code>256</code> <code>max_seq_len</code> <code>int</code> <p>Maximum sequence length for tokenization. Defaults to 512.</p> <code>512</code> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Encoder name identifier (\"SPLADE-v3-distilbert\").</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>The encode method is not implemented in the skeleton. Use LuceneImpactIndex for SPLADE-based retrieval instead.</p> Notes <p>This is a placeholder implementation. For production use, consider using LuceneImpactIndex which integrates with Pyserini's Lucene impact search.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>class SPLADEv3Encoder:\n    \"\"\"SPLADE-v3 encoder for generating sparse embeddings.\n\n    Provides an interface for encoding text into SPLADE sparse embeddings.\n    Currently a skeleton implementation that raises NotImplementedError.\n\n    Initializes the SPLADE-v3 encoder with model configuration and device settings.\n\n    Parameters\n    ----------\n    model_id : str, optional\n        Hugging Face model identifier for the SPLADE encoder. Defaults to\n        \"naver/splade-v3-distilbert\".\n    device : str, optional\n        Device to run inference on (\"cuda\" or \"cpu\"). Defaults to \"cuda\".\n    topk : int, optional\n        Number of top-k vocabulary tokens to retain in sparse representation.\n        Defaults to 256.\n    max_seq_len : int, optional\n        Maximum sequence length for tokenization. Defaults to 512.\n\n    Attributes\n    ----------\n    name : str\n        Encoder name identifier (\"SPLADE-v3-distilbert\").\n\n    Raises\n    ------\n    NotImplementedError\n        The encode method is not implemented in the skeleton. Use LuceneImpactIndex\n        for SPLADE-based retrieval instead.\n\n    Notes\n    -----\n    This is a placeholder implementation. For production use, consider using\n    LuceneImpactIndex which integrates with Pyserini's Lucene impact search.\n    \"\"\"\n\n    name = \"SPLADE-v3-distilbert\"\n\n    def __init__(\n        self,\n        model_id: str = \"naver/splade-v3-distilbert\",\n        device: str = \"cuda\",\n        topk: int = 256,\n        max_seq_len: int = 512,\n    ) -&gt; None:\n        self.model_id = model_id\n        self.device = device\n        self.topk = topk\n        self.max_seq_len = max_seq_len\n\n    def encode(self, texts: list[str]) -&gt; list[tuple[list[int], list[float]]]:\n        \"\"\"Encode texts into SPLADE sparse embeddings.\n\n        This method is not implemented in the skeleton implementation. Use\n        LuceneImpactIndex for SPLADE-based retrieval instead.\n\n        Parameters\n        ----------\n        texts : list[str]\n            List of text strings to encode.\n\n        Returns\n        -------\n        list[tuple[list[int], list[float]]]\n            List of (token_ids, weights) tuples, one per input text.\n\n        Raises\n        ------\n        NotImplementedError\n            This function is not implemented in the skeleton. Use LuceneImpactIndex\n            instead.\n\n        Notes\n        -----\n        Use the Lucene impact index variant if available for production SPLADE\n        encoding and retrieval.\n        \"\"\"\n        message = (\n            \"SPLADE encoding is not implemented in the skeleton. Use the Lucene \"\n            \"impact index variant if available. \"\n            f\"Requested device={self.device!r} with {len(texts)} texts.\"\n        )\n        raise NotImplementedError(message)\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.SPLADEv3Encoder.encode","title":"<code>encode(texts)</code>","text":"<p>Encode texts into SPLADE sparse embeddings.</p> <p>This method is not implemented in the skeleton implementation. Use LuceneImpactIndex for SPLADE-based retrieval instead.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <code>list[str]</code> <p>List of text strings to encode.</p> required <p>Returns:</p> Type Description <code>list[tuple[list[int], list[float]]]</code> <p>List of (token_ids, weights) tuples, one per input text.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This function is not implemented in the skeleton. Use LuceneImpactIndex instead.</p> Notes <p>Use the Lucene impact index variant if available for production SPLADE encoding and retrieval.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>def encode(self, texts: list[str]) -&gt; list[tuple[list[int], list[float]]]:\n    \"\"\"Encode texts into SPLADE sparse embeddings.\n\n    This method is not implemented in the skeleton implementation. Use\n    LuceneImpactIndex for SPLADE-based retrieval instead.\n\n    Parameters\n    ----------\n    texts : list[str]\n        List of text strings to encode.\n\n    Returns\n    -------\n    list[tuple[list[int], list[float]]]\n        List of (token_ids, weights) tuples, one per input text.\n\n    Raises\n    ------\n    NotImplementedError\n        This function is not implemented in the skeleton. Use LuceneImpactIndex\n        instead.\n\n    Notes\n    -----\n    Use the Lucene impact index variant if available for production SPLADE\n    encoding and retrieval.\n    \"\"\"\n    message = (\n        \"SPLADE encoding is not implemented in the skeleton. Use the Lucene \"\n        \"impact index variant if available. \"\n        f\"Requested device={self.device!r} with {len(texts)} texts.\"\n    )\n    raise NotImplementedError(message)\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparsesplade_decode_signing_key","title":"embeddings_sparse.splade._decode_signing_key","text":""},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade._decode_signing_key","title":"<code>embeddings_sparse.splade._decode_signing_key()</code>","text":"<p>Decode the configured signing key, returning <code>None</code> if unavailable.</p> <p>Returns:</p> Type Description <code>bytes | None</code> <p>Decoded signing key, or None if unavailable.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>def _decode_signing_key() -&gt; bytes | None:\n    \"\"\"Decode the configured signing key, returning ``None`` if unavailable.\n\n    Returns\n    -------\n    bytes | None\n        Decoded signing key, or None if unavailable.\n    \"\"\"\n    try:\n        settings = load_config()\n    except ValueError as exc:\n        logger.warning(\"Configuration invalid; proceeding without signing key\", exc_info=exc)\n        return None\n\n    encoded_key = settings.signing_key\n    if encoded_key is None:\n        return None\n\n    try:\n        return base64.b64decode(encoded_key)\n    except binascii.Error as exc:\n        logger.warning(\n            \"Signing key is not valid base64; ignoring secure pickle signature\", exc_info=exc\n        )\n        return None\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparsesplade_default_float_dict","title":"embeddings_sparse.splade._default_float_dict","text":""},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade._default_float_dict","title":"<code>embeddings_sparse.splade._default_float_dict()</code>","text":"<p>Return a defaultdict that produces <code>float</code> zeros for missing keys.</p> <p>Returns:</p> Type Description <code>defaultdict[str, float]</code> <p>Defaultdict with float factory.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>def _default_float_dict() -&gt; defaultdict[str, float]:\n    \"\"\"Return a defaultdict that produces ``float`` zeros for missing keys.\n\n    Returns\n    -------\n    defaultdict[str, float]\n        Defaultdict with float factory.\n    \"\"\"\n    return defaultdict(float)\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparsesplade_load_legacy_metadata","title":"embeddings_sparse.splade._load_legacy_metadata","text":""},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade._load_legacy_metadata","title":"<code>embeddings_sparse.splade._load_legacy_metadata(legacy_path)</code>","text":"<p>Load SPLADE legacy pickle metadata using signed or unsigned safe loader.</p> <p>Parameters:</p> Name Type Description Default <code>legacy_path</code> <code>Path</code> <p>Path to the legacy pickle file.</p> required <p>Returns:</p> Type Description <code>dict[str, JsonValue]</code> <p>Deserialized metadata dictionary.</p> <p>Raises:</p> Type Description <code>DeserializationError</code> <p>If deserialization fails or payload is invalid.</p> Notes <p>Wraps :class:<code>OSError</code> raised during file access as :class:<code>DeserializationError</code> with additional context.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>def _load_legacy_metadata(legacy_path: Path) -&gt; dict[str, JsonValue]:\n    \"\"\"Load SPLADE legacy pickle metadata using signed or unsigned safe loader.\n\n    Parameters\n    ----------\n    legacy_path : Path\n        Path to the legacy pickle file.\n\n    Returns\n    -------\n    dict[str, JsonValue]\n        Deserialized metadata dictionary.\n\n    Raises\n    ------\n    DeserializationError\n        If deserialization fails or payload is invalid.\n\n    Notes\n    -----\n    Wraps :class:`OSError` raised during file access as\n    :class:`DeserializationError` with additional context.\n    \"\"\"\n    signing_key = _decode_signing_key()\n    try:\n        with legacy_path.open(\"rb\") as handle:\n            if signing_key:\n                wrapper = SignedPickleWrapper(signing_key)\n                try:\n                    payload_obj = wrapper.load(handle)\n                except UnsafeSerializationError:\n                    logger.warning(\n                        \"Signed pickle validation failed for legacy SPLADE index; falling back to unsigned loader\",\n                        extra={\"legacy_path\": str(legacy_path)},\n                    )\n                    handle.seek(0)\n                    payload = _load_unsigned_payload(handle, legacy_path)\n                else:\n                    if not isinstance(payload_obj, dict):\n                        msg = (\n                            f\"Invalid signed legacy payload: expected dict, got {type(payload_obj)}\"\n                        )\n                        raise DeserializationError(msg)\n                    payload = cast(\"dict[str, JsonValue]\", payload_obj)\n            else:\n                logger.warning(\n                    \"Missing signing key; using unsigned legacy pickle loader\",\n                    extra={\"legacy_path\": str(legacy_path)},\n                )\n                payload = _load_unsigned_payload(handle, legacy_path)\n    except OSError as exc:\n        msg = f\"Failed to read legacy SPLADE index at {legacy_path}: {exc}\"\n        raise DeserializationError(msg) from exc\n\n    return payload\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparsesplade_load_unsigned_payload","title":"embeddings_sparse.splade._load_unsigned_payload","text":""},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade._load_unsigned_payload","title":"<code>embeddings_sparse.splade._load_unsigned_payload(handle, legacy_path)</code>","text":"<p>Load legacy pickle payload with allow-list enforcement.</p> <p>Parameters:</p> Name Type Description Default <code>handle</code> <code>BinaryIO</code> <p>Binary file handle to read from.</p> required <code>legacy_path</code> <code>Path</code> <p>Path to the legacy pickle file.</p> required <p>Returns:</p> Type Description <code>dict[str, JsonValue]</code> <p>Deserialized payload dictionary.</p> <p>Raises:</p> Type Description <code>DeserializationError</code> <p>If deserialization fails or payload is invalid.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>def _load_unsigned_payload(handle: BinaryIO, legacy_path: Path) -&gt; dict[str, JsonValue]:\n    \"\"\"Load legacy pickle payload with allow-list enforcement.\n\n    Parameters\n    ----------\n    handle : BinaryIO\n        Binary file handle to read from.\n    legacy_path : Path\n        Path to the legacy pickle file.\n\n    Returns\n    -------\n    dict[str, JsonValue]\n        Deserialized payload dictionary.\n\n    Raises\n    ------\n    DeserializationError\n        If deserialization fails or payload is invalid.\n    \"\"\"\n    try:\n        payload_obj = load_unsigned_legacy(handle)\n    except UnsafeSerializationError as exc:\n        msg = f\"Legacy pickle at {legacy_path} failed safety validation\"\n        raise DeserializationError(msg) from exc\n\n    if not isinstance(payload_obj, dict):\n        msg = f\"Invalid legacy pickle payload: expected dict, got {type(payload_obj)}\"\n        raise DeserializationError(msg)\n\n    return cast(\"dict[str, JsonValue]\", payload_obj)\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparsesplade_score_value","title":"embeddings_sparse.splade._score_value","text":""},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade._score_value","title":"<code>embeddings_sparse.splade._score_value(item)</code>","text":"<p>Extract the score component from a Lucene impact result tuple.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>tuple[str, float]</code> <p>Impact result tuple.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Score value.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>def _score_value(item: tuple[str, float]) -&gt; float:\n    \"\"\"Extract the score component from a Lucene impact result tuple.\n\n    Parameters\n    ----------\n    item : tuple[str, float]\n        Impact result tuple.\n\n    Returns\n    -------\n    float\n        Score value.\n    \"\"\"\n    return item[1]\n</code></pre>"},{"location":"modules/embeddings_sparse.splade/#embeddings_sparsespladeget_splade","title":"embeddings_sparse.splade.get_splade","text":""},{"location":"modules/embeddings_sparse.splade/#embeddings_sparse.splade.get_splade","title":"<code>embeddings_sparse.splade.get_splade(backend, index_dir, query_encoder='naver/splade-v3-distilbert')</code>","text":"<p>Return a SPLADE index implementation for the requested backend.</p> <p>Factory function that creates either a PureImpactIndex or LuceneImpactIndex based on the backend parameter. Attempts to use Lucene backend if requested, falling back to PureImpactIndex if Lucene is unavailable.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>str</code> <p>Backend name (\"pure\" or \"lucene\"). Case-insensitive.</p> required <code>index_dir</code> <code>str</code> <p>Directory path for the index. Must exist and contain valid index data.</p> required <code>query_encoder</code> <code>str</code> <p>Hugging Face model identifier for query encoding (used only for Lucene backend). Defaults to \"naver/splade-v3-distilbert\".</p> <code>'naver/splade-v3-distilbert'</code> <p>Returns:</p> Type Description <code>PureImpactIndex | LuceneImpactIndex</code> <p>SPLADE index instance. Returns PureImpactIndex if Lucene backend is requested but unavailable.</p> Notes <p>If \"lucene\" backend is requested but Pyserini is not available, the function logs a warning and falls back to PureImpactIndex. This allows graceful degradation when optional dependencies are missing.</p> Source code in <code>src/embeddings_sparse/splade.py</code> <pre><code>def get_splade(\n    backend: str,\n    index_dir: str,\n    query_encoder: str = \"naver/splade-v3-distilbert\",\n) -&gt; PureImpactIndex | LuceneImpactIndex:\n    \"\"\"Return a SPLADE index implementation for the requested backend.\n\n    Factory function that creates either a PureImpactIndex or LuceneImpactIndex\n    based on the backend parameter. Attempts to use Lucene backend if requested,\n    falling back to PureImpactIndex if Lucene is unavailable.\n\n    Parameters\n    ----------\n    backend : str\n        Backend name (\"pure\" or \"lucene\"). Case-insensitive.\n    index_dir : str\n        Directory path for the index. Must exist and contain valid index data.\n    query_encoder : str, optional\n        Hugging Face model identifier for query encoding (used only for Lucene\n        backend). Defaults to \"naver/splade-v3-distilbert\".\n\n    Returns\n    -------\n    PureImpactIndex | LuceneImpactIndex\n        SPLADE index instance. Returns PureImpactIndex if Lucene backend is\n        requested but unavailable.\n\n    Notes\n    -----\n    If \"lucene\" backend is requested but Pyserini is not available, the function\n    logs a warning and falls back to PureImpactIndex. This allows graceful\n    degradation when optional dependencies are missing.\n    \"\"\"\n    if backend == \"lucene\":\n        lucene_index = LuceneImpactIndex(index_dir=index_dir, query_encoder=query_encoder)\n        try:\n            lucene_index.ensure_available()\n        except RuntimeError as exc:\n            logger.warning(\n                \"Lucene backend unavailable, falling back to PureImpactIndex\",\n                extra={\"index_dir\": index_dir, \"query_encoder\": query_encoder},\n                exc_info=exc,\n            )\n        else:\n            return lucene_index\n    return PureImpactIndex(index_dir)\n</code></pre>"},{"location":"modules/kg_builder/","title":"kg_builder","text":""},{"location":"modules/kg_builder/#kg_builder","title":"kg_builder","text":"<p>Knowledge graph builder components and interfaces</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kg_builder/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kg_builder__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.navmap_types.NavMapkg_builder code <p>See the full diagram: kg_builder</p>"},{"location":"modules/kg_builder/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.navmap_types.NavMap</code></p>"},{"location":"modules/kg_builder.mock_kg/","title":"kg_builder.mock_kg","text":""},{"location":"modules/kg_builder.mock_kg/#kg_buildermock_kg","title":"kg_builder.mock_kg","text":"<p>Helpers for the MockKG in-memory knowledge graph</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kg_builder.mock_kg/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class MockKG\n</code></pre>"},{"location":"modules/kg_builder.mock_kg/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kg_builder.mock_kg__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakg_builder.mock_kg code <p>See the full diagram: kg_builder.mock_kg</p>"},{"location":"modules/kg_builder.mock_kg/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kg_builder.mock_kg.MockKG</li> </ul>"},{"location":"modules/kg_builder.mock_kg/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p>"},{"location":"modules/kg_builder.mock_kg/#contents","title":"Contents","text":""},{"location":"modules/kg_builder.mock_kg/#kg_buildermock_kgmockkg","title":"kg_builder.mock_kg.MockKG","text":""},{"location":"modules/kg_builder.mock_kg/#kg_builder.mock_kg.MockKG","title":"<code>kg_builder.mock_kg.MockKG</code>","text":"<p>In-memory knowledge graph for testing and development.</p> <p>Provides a simple dictionary-based implementation of a knowledge graph with concept mentions and edges for use in tests and fixtures.</p> <p>Creates empty mappings for chunk-to-concepts and concept neighbors.</p> Source code in <code>src/kg_builder/mock_kg.py</code> <pre><code>class MockKG:\n    \"\"\"In-memory knowledge graph for testing and development.\n\n    Provides a simple dictionary-based implementation of a knowledge graph with concept mentions and\n    edges for use in tests and fixtures.\n\n    Creates empty mappings for chunk-to-concepts and concept neighbors.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self.chunk2concepts: dict[str, set[str]] = {}\n        self.neighbors: dict[str, set[str]] = {}\n\n    def add_mention(self, chunk_id: str, concept_id: str) -&gt; None:\n        \"\"\"Record a concept mention in a chunk.\n\n        Associates a concept with a chunk, creating the mapping if needed.\n\n        Parameters\n        ----------\n        chunk_id : str\n            Chunk identifier.\n        concept_id : str\n            Concept identifier.\n        \"\"\"\n        self.chunk2concepts.setdefault(chunk_id, set()).add(concept_id)\n\n    def add_edge(self, a: str, b: str) -&gt; None:\n        \"\"\"Add a bidirectional edge between two concepts.\n\n        Creates an undirected edge between concepts, adding both to each\n        other's neighbor sets.\n\n        Parameters\n        ----------\n        a : str\n            First concept identifier.\n        b : str\n            Second concept identifier.\n        \"\"\"\n        self.neighbors.setdefault(a, set()).add(b)\n        self.neighbors.setdefault(b, set()).add(a)\n\n    def linked_concepts(self, chunk_id: str) -&gt; list[str]:\n        \"\"\"Return concepts linked to a chunk.\n\n        Returns all concepts that have been mentioned in the given chunk,\n        sorted alphabetically.\n\n        Parameters\n        ----------\n        chunk_id : str\n            Chunk identifier.\n\n        Returns\n        -------\n        list[str]\n            Sorted list of concept IDs linked to the chunk.\n        \"\"\"\n        return sorted(self.chunk2concepts.get(chunk_id, set()))\n\n    def one_hop(self, concept_id: str) -&gt; list[str]:\n        \"\"\"Return one-hop neighbors of a concept.\n\n        Returns all concepts directly connected to the given concept via\n        edges, sorted alphabetically.\n\n        Parameters\n        ----------\n        concept_id : str\n            Concept identifier.\n\n        Returns\n        -------\n        list[str]\n            Sorted list of neighbor concept IDs.\n        \"\"\"\n        return sorted(self.neighbors.get(concept_id, set()))\n</code></pre>"},{"location":"modules/kg_builder.mock_kg/#kg_builder.mock_kg.MockKG.add_edge","title":"<code>add_edge(a, b)</code>","text":"<p>Add a bidirectional edge between two concepts.</p> <p>Creates an undirected edge between concepts, adding both to each other's neighbor sets.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>str</code> <p>First concept identifier.</p> required <code>b</code> <code>str</code> <p>Second concept identifier.</p> required Source code in <code>src/kg_builder/mock_kg.py</code> <pre><code>def add_edge(self, a: str, b: str) -&gt; None:\n    \"\"\"Add a bidirectional edge between two concepts.\n\n    Creates an undirected edge between concepts, adding both to each\n    other's neighbor sets.\n\n    Parameters\n    ----------\n    a : str\n        First concept identifier.\n    b : str\n        Second concept identifier.\n    \"\"\"\n    self.neighbors.setdefault(a, set()).add(b)\n    self.neighbors.setdefault(b, set()).add(a)\n</code></pre>"},{"location":"modules/kg_builder.mock_kg/#kg_builder.mock_kg.MockKG.add_mention","title":"<code>add_mention(chunk_id, concept_id)</code>","text":"<p>Record a concept mention in a chunk.</p> <p>Associates a concept with a chunk, creating the mapping if needed.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_id</code> <code>str</code> <p>Chunk identifier.</p> required <code>concept_id</code> <code>str</code> <p>Concept identifier.</p> required Source code in <code>src/kg_builder/mock_kg.py</code> <pre><code>def add_mention(self, chunk_id: str, concept_id: str) -&gt; None:\n    \"\"\"Record a concept mention in a chunk.\n\n    Associates a concept with a chunk, creating the mapping if needed.\n\n    Parameters\n    ----------\n    chunk_id : str\n        Chunk identifier.\n    concept_id : str\n        Concept identifier.\n    \"\"\"\n    self.chunk2concepts.setdefault(chunk_id, set()).add(concept_id)\n</code></pre>"},{"location":"modules/kg_builder.mock_kg/#kg_builder.mock_kg.MockKG.linked_concepts","title":"<code>linked_concepts(chunk_id)</code>","text":"<p>Return concepts linked to a chunk.</p> <p>Returns all concepts that have been mentioned in the given chunk, sorted alphabetically.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_id</code> <code>str</code> <p>Chunk identifier.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>Sorted list of concept IDs linked to the chunk.</p> Source code in <code>src/kg_builder/mock_kg.py</code> <pre><code>def linked_concepts(self, chunk_id: str) -&gt; list[str]:\n    \"\"\"Return concepts linked to a chunk.\n\n    Returns all concepts that have been mentioned in the given chunk,\n    sorted alphabetically.\n\n    Parameters\n    ----------\n    chunk_id : str\n        Chunk identifier.\n\n    Returns\n    -------\n    list[str]\n        Sorted list of concept IDs linked to the chunk.\n    \"\"\"\n    return sorted(self.chunk2concepts.get(chunk_id, set()))\n</code></pre>"},{"location":"modules/kg_builder.mock_kg/#kg_builder.mock_kg.MockKG.one_hop","title":"<code>one_hop(concept_id)</code>","text":"<p>Return one-hop neighbors of a concept.</p> <p>Returns all concepts directly connected to the given concept via edges, sorted alphabetically.</p> <p>Parameters:</p> Name Type Description Default <code>concept_id</code> <code>str</code> <p>Concept identifier.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>Sorted list of neighbor concept IDs.</p> Source code in <code>src/kg_builder/mock_kg.py</code> <pre><code>def one_hop(self, concept_id: str) -&gt; list[str]:\n    \"\"\"Return one-hop neighbors of a concept.\n\n    Returns all concepts directly connected to the given concept via\n    edges, sorted alphabetically.\n\n    Parameters\n    ----------\n    concept_id : str\n        Concept identifier.\n\n    Returns\n    -------\n    list[str]\n        Sorted list of neighbor concept IDs.\n    \"\"\"\n    return sorted(self.neighbors.get(concept_id, set()))\n</code></pre>"},{"location":"modules/kg_builder.neo4j_store/","title":"kg_builder.neo4j_store","text":""},{"location":"modules/kg_builder.neo4j_store/#kg_builderneo4j_store","title":"kg_builder.neo4j_store","text":"<p>Placeholder interface for a Neo4j-backed store</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kg_builder.neo4j_store/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class Neo4jStore\n</code></pre>"},{"location":"modules/kg_builder.neo4j_store/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kg_builder.neo4j_store__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakg_builder.neo4j_store code <p>See the full diagram: kg_builder.neo4j_store</p>"},{"location":"modules/kg_builder.neo4j_store/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kg_builder.neo4j_store.Neo4jStore</li> </ul>"},{"location":"modules/kg_builder.neo4j_store/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p>"},{"location":"modules/kg_builder.neo4j_store/#contents","title":"Contents","text":""},{"location":"modules/kg_builder.neo4j_store/#kg_builderneo4j_storeneo4jstore","title":"kg_builder.neo4j_store.Neo4jStore","text":""},{"location":"modules/kg_builder.neo4j_store/#kg_builder.neo4j_store.Neo4jStore","title":"<code>kg_builder.neo4j_store.Neo4jStore</code>","text":"<p>Placeholder interface for a Neo4j-backed knowledge graph store.</p> <p>This class serves as a placeholder for future Neo4j integration for storing knowledge graph data. Implementation details will be added later.</p> Source code in <code>src/kg_builder/neo4j_store.py</code> <pre><code>class Neo4jStore:\n    \"\"\"Placeholder interface for a Neo4j-backed knowledge graph store.\n\n    This class serves as a placeholder for future Neo4j integration for storing knowledge graph\n    data. Implementation details will be added later.\n    \"\"\"\n</code></pre>"},{"location":"modules/kgfoundry_common.config/","title":"kgfoundry_common.config","text":""},{"location":"modules/kgfoundry_common.config/#kgfoundry_commonconfig","title":"kgfoundry_common.config","text":"<p>Typed configuration management via pydantic_settings</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.config/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class AppSettings\n    class BaseSettings\n    BaseSettings &lt;|-- AppSettings\n    class ModelValidateOptions\n    class TypedDict\n    TypedDict &lt;|-- ModelValidateOptions\n</code></pre>"},{"location":"modules/kgfoundry_common.config/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.config__future__.annotationsbase64collections.abc.Mappingcollections.abc.Sequencefunctoolsfunctools.lru_cachekgfoundry_common.logging.get_loggerkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.types.JsonPrimitivekgfoundry_common.types.JsonValuepydantic.AliasChoicespydantic.Fieldpydantic.ValidationErrorpydantic.field_validatorpydantic_settings.BaseSettingstyping.Finaltyping.Literaltyping.Selftyping.TYPE_CHECKINGtyping.TypedDicttyping.castkgfoundry_common.config code <p>See the full diagram: kgfoundry_common.config</p>"},{"location":"modules/kgfoundry_common.config/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.config.AppSettings</li> <li>kgfoundry_common.config.ModelValidateOptions</li> <li>kgfoundry_common.config._format_validation_error</li> <li>kgfoundry_common.config._load_config_impl</li> <li>kgfoundry_common.config.load_config</li> </ul>"},{"location":"modules/kgfoundry_common.config/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>base64</code>, <code>collections.abc.Mapping</code>, <code>collections.abc.Sequence</code>, <code>functools</code>, <code>functools.lru_cache</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.types.JsonPrimitive</code>, <code>kgfoundry_common.types.JsonValue</code>, <code>pydantic.AliasChoices</code>, <code>pydantic.Field</code>, <code>pydantic.ValidationError</code>, <code>pydantic.field_validator</code>, <code>pydantic_settings.BaseSettings</code>, <code>typing.Final</code>, <code>typing.Literal</code>, <code>typing.Self</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.TypedDict</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.config/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.config/#kgfoundry_commonconfigappsettings","title":"kgfoundry_common.config.AppSettings","text":"<p>Bases: BaseSettings</p>"},{"location":"modules/kgfoundry_common.config/#kgfoundry_common.config.AppSettings","title":"<code>kgfoundry_common.config.AppSettings</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Application settings with environment variable support.</p> <p>This class uses pydantic_settings to load and validate configuration from environment variables. All fields are immutable (frozen=True) and self-documenting via Field descriptions.</p> <p>Security fields (HMAC signing key, subprocess/network timeouts) are optional but recommended. When provided, they enforce strict validation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import os\n&gt;&gt;&gt; # Set environment variable\n&gt;&gt;&gt; os.environ[\"LOG_LEVEL\"] = \"DEBUG\"\n&gt;&gt;&gt; settings = AppSettings()\n&gt;&gt;&gt; settings.log_level\n'DEBUG'\n</code></pre> <pre><code>&gt;&gt;&gt; # Validate invalid log level\n&gt;&gt;&gt; os.environ[\"LOG_LEVEL\"] = \"INVALID\"\n&gt;&gt;&gt; try:\n...     AppSettings()\n... except Exception:\n...     print(\"Validation failed for invalid log level\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Security configuration with timeouts\n&gt;&gt;&gt; os.environ[\"SUBPROCESS_TIMEOUT\"] = \"300\"\n&gt;&gt;&gt; os.environ[\"REQUEST_TIMEOUT\"] = \"30\"\n&gt;&gt;&gt; settings = AppSettings()\n</code></pre> Source code in <code>src/kgfoundry_common/config.py</code> <pre><code>class AppSettings(BaseSettings):\n    \"\"\"Application settings with environment variable support.\n\n    This class uses pydantic_settings to load and validate configuration\n    from environment variables. All fields are immutable (frozen=True) and\n    self-documenting via Field descriptions.\n\n    Security fields (HMAC signing key, subprocess/network timeouts) are\n    optional but recommended. When provided, they enforce strict validation.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import os\n    &gt;&gt;&gt; # Set environment variable\n    &gt;&gt;&gt; os.environ[\"LOG_LEVEL\"] = \"DEBUG\"\n    &gt;&gt;&gt; settings = AppSettings()\n    &gt;&gt;&gt; settings.log_level\n    'DEBUG'\n\n    &gt;&gt;&gt; # Validate invalid log level\n    &gt;&gt;&gt; os.environ[\"LOG_LEVEL\"] = \"INVALID\"\n    &gt;&gt;&gt; try:\n    ...     AppSettings()  # doctest: +SKIP\n    ... except Exception:\n    ...     print(\"Validation failed for invalid log level\")\n\n    &gt;&gt;&gt; # Security configuration with timeouts\n    &gt;&gt;&gt; os.environ[\"SUBPROCESS_TIMEOUT\"] = \"300\"\n    &gt;&gt;&gt; os.environ[\"REQUEST_TIMEOUT\"] = \"30\"\n    &gt;&gt;&gt; settings = AppSettings()  # doctest: +SKIP\n    \"\"\"\n\n    log_level: str = Field(\n        default=\"INFO\",\n        description=\"Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\",\n        validation_alias=AliasChoices(\"LOG_LEVEL\", \"log_level\"),\n    )\n\n    log_format: str = Field(\n        default=\"json\",\n        description=\"Logging format ('json' or 'text')\",\n        validation_alias=AliasChoices(\"LOG_FORMAT\", \"log_format\"),\n    )\n\n    signing_key: str | None = Field(\n        default=None,\n        description=\"HMAC signing key for secure pickle (base64-encoded, \u226532 bytes recommended)\",\n        validation_alias=AliasChoices(\"SIGNING_KEY\", \"signing_key\"),\n    )\n\n    subprocess_timeout: int = Field(\n        default=300,\n        description=\"Default timeout for subprocess operations in seconds\",\n        validation_alias=AliasChoices(\"SUBPROCESS_TIMEOUT\", \"subprocess_timeout\"),\n        ge=1,\n        le=3600,\n    )\n\n    request_timeout: int = Field(\n        default=30,\n        description=\"Default timeout for network requests in seconds\",\n        validation_alias=AliasChoices(\"REQUEST_TIMEOUT\", \"request_timeout\"),\n        ge=1,\n        le=3600,\n    )\n\n    model_config = {\"frozen\": True, \"case_sensitive\": False, \"populate_by_name\": True}\n\n    @classmethod\n    def model_validate(  # noqa: PLR0913\n        cls,\n        obj: object,\n        *,\n        strict: bool | None = None,\n        extra: Literal[\"allow\", \"ignore\", \"forbid\"] | None = None,\n        from_attributes: bool | None = None,\n        context: Mapping[str, object] | None = None,\n        by_alias: bool | None = None,\n        by_name: bool | None = None,\n    ) -&gt; Self:\n        \"\"\"Validate ``obj`` returning ``cls`` while normalising pydantic errors.\n\n        This method overrides the parent signature to normalize ValidationError\n        exceptions. The many parameters are required to match the parent API,\n        but internal logic is encapsulated in helper functions.\n\n        Note: PLR0913 suppression is required here because this method must match\n        the parent class signature from pydantic, which has 7 parameters total.\n        The actual validation logic is delegated to ``_validate_with_options``\n        which has only 2 parameters, reducing complexity.\n\n        Parameters\n        ----------\n        obj : object\n            Object to validate.\n        strict : bool | None\n            Whether to use strict mode validation.\n        extra : str | None\n            Extra field handling mode.\n        from_attributes : bool | None\n            Whether to validate from attributes.\n        context : Mapping[str, object] | None\n            Validation context.\n        by_alias : bool | None\n            Whether to use aliases.\n        by_name : bool | None\n            Whether to use names.\n\n        Returns\n        -------\n        Self\n            Validated instance.\n        \"\"\"\n        return cls._validate_with_options(\n            obj,\n            ModelValidateOptions(\n                strict=strict,\n                extra=extra,\n                from_attributes=from_attributes,\n                context=context,\n                by_alias=by_alias,\n                by_name=by_name,\n            ),\n        )\n\n    @classmethod\n    def _validate_with_options(cls, obj: object, options: ModelValidateOptions) -&gt; Self:\n        \"\"\"Encapsulate validation logic with reduced parameter count.\n\n        Parameters\n        ----------\n        obj : object\n            Object to validate.\n        options : ModelValidateOptions\n            Validation options dictionary.\n\n        Returns\n        -------\n        Self\n            Validated instance.\n\n        Raises\n        ------\n        ValueError\n            If validation fails with normalized error message.\n        \"\"\"\n        try:\n            return super().model_validate(\n                obj,\n                strict=options.get(\"strict\"),\n                extra=options.get(\"extra\"),\n                from_attributes=options.get(\"from_attributes\"),\n                context=options.get(\"context\"),\n                by_alias=options.get(\"by_alias\"),\n                by_name=options.get(\"by_name\"),\n            )\n        except ValidationError as exc:\n            message = _format_validation_error(exc)\n            raise ValueError(message) from exc\n\n    @field_validator(\"log_level\")\n    @classmethod\n    def validate_log_level(cls, value: str) -&gt; str:\n        \"\"\"Validate log level is one of the standard levels.\n\n        Parameters\n        ----------\n        value : str\n            Log level to validate.\n\n        Returns\n        -------\n        str\n            Validated log level (uppercase).\n\n        Raises\n        ------\n        ValueError\n            If log level is not valid.\n        \"\"\"\n        valid_levels = {\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"}\n        level_upper = value.upper()\n        if level_upper not in valid_levels:\n            msg = f\"Invalid log level: {value}. Must be one of {valid_levels}\"\n            raise ValueError(msg)\n        return level_upper\n\n    @field_validator(\"log_format\")\n    @classmethod\n    def validate_log_format(cls, value: str) -&gt; str:\n        \"\"\"Validate log format is one of the supported formats.\n\n        Parameters\n        ----------\n        value : str\n            Log format to validate.\n\n        Returns\n        -------\n        str\n            Validated log format (lowercase).\n\n        Raises\n        ------\n        ValueError\n            If log format is not supported.\n        \"\"\"\n        valid_formats = {\"json\", \"text\"}\n        format_lower = value.lower()\n        if format_lower not in valid_formats:\n            msg = f\"Invalid log format: {value}. Must be one of {valid_formats}\"\n            raise ValueError(msg)\n        return format_lower\n\n    @field_validator(\"signing_key\")\n    @classmethod\n    def validate_signing_key(cls, value: str | None) -&gt; str | None:\n        \"\"\"Validate signing key is properly formatted and sufficiently long.\n\n        Parameters\n        ----------\n        value : str | None\n            Base64-encoded signing key.\n\n        Returns\n        -------\n        str | None\n            Validated signing key (unchanged if valid).\n\n        Raises\n        ------\n        ValueError\n            If key is invalid, not base64-decodable, or too short.\n        \"\"\"\n        if value is None:\n            return None\n\n        if not value.strip():\n            msg = \"Signing key cannot be empty\"\n            raise ValueError(msg)\n\n        try:\n            decoded_key = base64.b64decode(value)\n        except Exception as exc:\n            msg = f\"Signing key must be valid base64: {exc}\"\n            raise ValueError(msg) from exc\n\n        if len(decoded_key) &lt; _MIN_SIGNING_KEY_BYTES:\n            msg = f\"Signing key must be \u2265{_MIN_SIGNING_KEY_BYTES} bytes when decoded (got {len(decoded_key)})\"\n            raise ValueError(msg)\n\n        return value\n\n    @classmethod\n    def from_dict(\n        cls,\n        values: Mapping[str, object] | None = None,\n        *,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; Self:\n        \"\"\"Construct ``AppSettings`` from a mapping of overrides.\n\n        This helper accepts a dictionary of configuration values\u2014mirroring the\n        structure provided by environment variables\u2014and returns a fully validated\n        ``AppSettings`` instance. It ensures keys are strings, preserves the\n        original mapping order, and routes validation errors through the same\n        normalization logic as ``model_validate`` so callers receive user-facing\n        messages.\n\n        Parameters\n        ----------\n        values : Mapping[str, object] | None, optional\n            Mapping of configuration overrides. Keys must be strings that match\n            the canonical field names used by ``AppSettings``. Defaults to an\n            empty mapping when ``None`` is supplied.\n        context : Mapping[str, object] | None, optional\n            Optional Pydantic context forwarded to ``model_validate``.\n\n        Returns\n        -------\n        AppSettings\n            Validated configuration settings.\n\n        Raises\n        ------\n        TypeError\n            If any key in ``values`` is not a string.\n\n        Notes\n        -----\n        Propagates :class:`ValueError` from ``pydantic`` when validation fails;\n        error messages mirror ``AppSettings`` field validators.\n        \"\"\"\n        normalized: dict[str, object] = {}\n\n        if values is not None:\n            mapping_values = cast(\"Mapping[object, object]\", values)\n            for key_obj, value in mapping_values.items():\n                if not isinstance(key_obj, str):\n                    message = (\n                        \"AppSettings.from_dict requires string keys; \"\n                        f\"received key of type {type(key_obj).__name__}\"\n                    )\n                    raise TypeError(message)\n                normalized[key_obj] = value\n\n        return cls.model_validate(normalized, context=context)\n</code></pre>"},{"location":"modules/kgfoundry_common.config/#kgfoundry_common.config.AppSettings.from_dict","title":"<code>from_dict(values=None, *, context=None)</code>  <code>classmethod</code>","text":"<p>Construct <code>AppSettings</code> from a mapping of overrides.</p> <p>This helper accepts a dictionary of configuration values\u2014mirroring the structure provided by environment variables\u2014and returns a fully validated <code>AppSettings</code> instance. It ensures keys are strings, preserves the original mapping order, and routes validation errors through the same normalization logic as <code>model_validate</code> so callers receive user-facing messages.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>Mapping[str, object] | None</code> <p>Mapping of configuration overrides. Keys must be strings that match the canonical field names used by <code>AppSettings</code>. Defaults to an empty mapping when <code>None</code> is supplied.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Optional Pydantic context forwarded to <code>model_validate</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>AppSettings</code> <p>Validated configuration settings.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If any key in <code>values</code> is not a string.</p> Notes <p>Propagates :class:<code>ValueError</code> from <code>pydantic</code> when validation fails; error messages mirror <code>AppSettings</code> field validators.</p> Source code in <code>src/kgfoundry_common/config.py</code> <pre><code>@classmethod\ndef from_dict(\n    cls,\n    values: Mapping[str, object] | None = None,\n    *,\n    context: Mapping[str, object] | None = None,\n) -&gt; Self:\n    \"\"\"Construct ``AppSettings`` from a mapping of overrides.\n\n    This helper accepts a dictionary of configuration values\u2014mirroring the\n    structure provided by environment variables\u2014and returns a fully validated\n    ``AppSettings`` instance. It ensures keys are strings, preserves the\n    original mapping order, and routes validation errors through the same\n    normalization logic as ``model_validate`` so callers receive user-facing\n    messages.\n\n    Parameters\n    ----------\n    values : Mapping[str, object] | None, optional\n        Mapping of configuration overrides. Keys must be strings that match\n        the canonical field names used by ``AppSettings``. Defaults to an\n        empty mapping when ``None`` is supplied.\n    context : Mapping[str, object] | None, optional\n        Optional Pydantic context forwarded to ``model_validate``.\n\n    Returns\n    -------\n    AppSettings\n        Validated configuration settings.\n\n    Raises\n    ------\n    TypeError\n        If any key in ``values`` is not a string.\n\n    Notes\n    -----\n    Propagates :class:`ValueError` from ``pydantic`` when validation fails;\n    error messages mirror ``AppSettings`` field validators.\n    \"\"\"\n    normalized: dict[str, object] = {}\n\n    if values is not None:\n        mapping_values = cast(\"Mapping[object, object]\", values)\n        for key_obj, value in mapping_values.items():\n            if not isinstance(key_obj, str):\n                message = (\n                    \"AppSettings.from_dict requires string keys; \"\n                    f\"received key of type {type(key_obj).__name__}\"\n                )\n                raise TypeError(message)\n            normalized[key_obj] = value\n\n    return cls.model_validate(normalized, context=context)\n</code></pre>"},{"location":"modules/kgfoundry_common.config/#kgfoundry_common.config.AppSettings.model_validate","title":"<code>model_validate(obj, *, strict=None, extra=None, from_attributes=None, context=None, by_alias=None, by_name=None)</code>  <code>classmethod</code>","text":"<p>Validate <code>obj</code> returning <code>cls</code> while normalising pydantic errors.</p> <p>This method overrides the parent signature to normalize ValidationError exceptions. The many parameters are required to match the parent API, but internal logic is encapsulated in helper functions.</p> <p>Note: PLR0913 suppression is required here because this method must match the parent class signature from pydantic, which has 7 parameters total. The actual validation logic is delegated to <code>_validate_with_options</code> which has only 2 parameters, reducing complexity.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>Object to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to use strict mode validation.</p> <code>None</code> <code>extra</code> <code>str | None</code> <p>Extra field handling mode.</p> <code>None</code> <code>from_attributes</code> <code>bool | None</code> <p>Whether to validate from attributes.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Validation context.</p> <code>None</code> <code>by_alias</code> <code>bool | None</code> <p>Whether to use aliases.</p> <code>None</code> <code>by_name</code> <code>bool | None</code> <p>Whether to use names.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>Validated instance.</p> Source code in <code>src/kgfoundry_common/config.py</code> <pre><code>@classmethod\ndef model_validate(  # noqa: PLR0913\n    cls,\n    obj: object,\n    *,\n    strict: bool | None = None,\n    extra: Literal[\"allow\", \"ignore\", \"forbid\"] | None = None,\n    from_attributes: bool | None = None,\n    context: Mapping[str, object] | None = None,\n    by_alias: bool | None = None,\n    by_name: bool | None = None,\n) -&gt; Self:\n    \"\"\"Validate ``obj`` returning ``cls`` while normalising pydantic errors.\n\n    This method overrides the parent signature to normalize ValidationError\n    exceptions. The many parameters are required to match the parent API,\n    but internal logic is encapsulated in helper functions.\n\n    Note: PLR0913 suppression is required here because this method must match\n    the parent class signature from pydantic, which has 7 parameters total.\n    The actual validation logic is delegated to ``_validate_with_options``\n    which has only 2 parameters, reducing complexity.\n\n    Parameters\n    ----------\n    obj : object\n        Object to validate.\n    strict : bool | None\n        Whether to use strict mode validation.\n    extra : str | None\n        Extra field handling mode.\n    from_attributes : bool | None\n        Whether to validate from attributes.\n    context : Mapping[str, object] | None\n        Validation context.\n    by_alias : bool | None\n        Whether to use aliases.\n    by_name : bool | None\n        Whether to use names.\n\n    Returns\n    -------\n    Self\n        Validated instance.\n    \"\"\"\n    return cls._validate_with_options(\n        obj,\n        ModelValidateOptions(\n            strict=strict,\n            extra=extra,\n            from_attributes=from_attributes,\n            context=context,\n            by_alias=by_alias,\n            by_name=by_name,\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.config/#kgfoundry_common.config.AppSettings.validate_log_format","title":"<code>validate_log_format(value)</code>  <code>classmethod</code>","text":"<p>Validate log format is one of the supported formats.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>Log format to validate.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Validated log format (lowercase).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If log format is not supported.</p> Source code in <code>src/kgfoundry_common/config.py</code> <pre><code>@field_validator(\"log_format\")\n@classmethod\ndef validate_log_format(cls, value: str) -&gt; str:\n    \"\"\"Validate log format is one of the supported formats.\n\n    Parameters\n    ----------\n    value : str\n        Log format to validate.\n\n    Returns\n    -------\n    str\n        Validated log format (lowercase).\n\n    Raises\n    ------\n    ValueError\n        If log format is not supported.\n    \"\"\"\n    valid_formats = {\"json\", \"text\"}\n    format_lower = value.lower()\n    if format_lower not in valid_formats:\n        msg = f\"Invalid log format: {value}. Must be one of {valid_formats}\"\n        raise ValueError(msg)\n    return format_lower\n</code></pre>"},{"location":"modules/kgfoundry_common.config/#kgfoundry_common.config.AppSettings.validate_log_level","title":"<code>validate_log_level(value)</code>  <code>classmethod</code>","text":"<p>Validate log level is one of the standard levels.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>Log level to validate.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Validated log level (uppercase).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If log level is not valid.</p> Source code in <code>src/kgfoundry_common/config.py</code> <pre><code>@field_validator(\"log_level\")\n@classmethod\ndef validate_log_level(cls, value: str) -&gt; str:\n    \"\"\"Validate log level is one of the standard levels.\n\n    Parameters\n    ----------\n    value : str\n        Log level to validate.\n\n    Returns\n    -------\n    str\n        Validated log level (uppercase).\n\n    Raises\n    ------\n    ValueError\n        If log level is not valid.\n    \"\"\"\n    valid_levels = {\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"}\n    level_upper = value.upper()\n    if level_upper not in valid_levels:\n        msg = f\"Invalid log level: {value}. Must be one of {valid_levels}\"\n        raise ValueError(msg)\n    return level_upper\n</code></pre>"},{"location":"modules/kgfoundry_common.config/#kgfoundry_common.config.AppSettings.validate_signing_key","title":"<code>validate_signing_key(value)</code>  <code>classmethod</code>","text":"<p>Validate signing key is properly formatted and sufficiently long.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str | None</code> <p>Base64-encoded signing key.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Validated signing key (unchanged if valid).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If key is invalid, not base64-decodable, or too short.</p> Source code in <code>src/kgfoundry_common/config.py</code> <pre><code>@field_validator(\"signing_key\")\n@classmethod\ndef validate_signing_key(cls, value: str | None) -&gt; str | None:\n    \"\"\"Validate signing key is properly formatted and sufficiently long.\n\n    Parameters\n    ----------\n    value : str | None\n        Base64-encoded signing key.\n\n    Returns\n    -------\n    str | None\n        Validated signing key (unchanged if valid).\n\n    Raises\n    ------\n    ValueError\n        If key is invalid, not base64-decodable, or too short.\n    \"\"\"\n    if value is None:\n        return None\n\n    if not value.strip():\n        msg = \"Signing key cannot be empty\"\n        raise ValueError(msg)\n\n    try:\n        decoded_key = base64.b64decode(value)\n    except Exception as exc:\n        msg = f\"Signing key must be valid base64: {exc}\"\n        raise ValueError(msg) from exc\n\n    if len(decoded_key) &lt; _MIN_SIGNING_KEY_BYTES:\n        msg = f\"Signing key must be \u2265{_MIN_SIGNING_KEY_BYTES} bytes when decoded (got {len(decoded_key)})\"\n        raise ValueError(msg)\n\n    return value\n</code></pre>"},{"location":"modules/kgfoundry_common.config/#kgfoundry_commonconfigmodelvalidateoptions","title":"kgfoundry_common.config.ModelValidateOptions","text":"<p>Bases: TypedDict</p>"},{"location":"modules/kgfoundry_common.config/#kgfoundry_common.config.ModelValidateOptions","title":"<code>kgfoundry_common.config.ModelValidateOptions</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Options for model validation, encapsulating multiple parameters.</p> <p>This TypedDict groups validation parameters to reduce argument count in model_validate while maintaining compatibility with parent signature.</p> Source code in <code>src/kgfoundry_common/config.py</code> <pre><code>class ModelValidateOptions(TypedDict, total=False):\n    \"\"\"Options for model validation, encapsulating multiple parameters.\n\n    This TypedDict groups validation parameters to reduce argument count in model_validate while\n    maintaining compatibility with parent signature.\n    \"\"\"\n\n    strict: bool | None\n    extra: Literal[\"allow\", \"ignore\", \"forbid\"] | None\n    from_attributes: bool | None\n    context: Mapping[str, object] | None\n    by_alias: bool | None\n    by_name: bool | None\n</code></pre>"},{"location":"modules/kgfoundry_common.config/#kgfoundry_commonconfig_format_validation_error","title":"kgfoundry_common.config._format_validation_error","text":""},{"location":"modules/kgfoundry_common.config/#kgfoundry_common.config._format_validation_error","title":"<code>kgfoundry_common.config._format_validation_error(exc)</code>","text":"<p>Return the most helpful message from a pydantic <code>ValidationError</code>.</p> <p>Parameters:</p> Name Type Description Default <code>exc</code> <code>ValidationError</code> <p>Validation error to format.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Most helpful error message from the validation error.</p> Source code in <code>src/kgfoundry_common/config.py</code> <pre><code>def _format_validation_error(exc: ValidationError) -&gt; str:\n    \"\"\"Return the most helpful message from a pydantic ``ValidationError``.\n\n    Parameters\n    ----------\n    exc : ValidationError\n        Validation error to format.\n\n    Returns\n    -------\n    str\n        Most helpful error message from the validation error.\n    \"\"\"\n    errors_raw = cast(\"Sequence[Mapping[str, object]]\", exc.errors())\n    if errors_raw:\n        primary = errors_raw[0]\n        msg_obj = primary.get(\"msg\")\n        if isinstance(msg_obj, str) and msg_obj:\n            return msg_obj\n    return str(exc)\n</code></pre>"},{"location":"modules/kgfoundry_common.config/#kgfoundry_commonconfig_load_config_impl","title":"kgfoundry_common.config._load_config_impl","text":""},{"location":"modules/kgfoundry_common.config/#kgfoundry_common.config._load_config_impl","title":"<code>kgfoundry_common.config._load_config_impl()</code>","text":"<p>Load and validate application configuration from environment.</p> <p>Returns:</p> Type Description <code>AppSettings</code> <p>Validated application settings.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If configuration validation fails.</p> Source code in <code>src/kgfoundry_common/config.py</code> <pre><code>def _load_config_impl() -&gt; AppSettings:\n    \"\"\"Load and validate application configuration from environment.\n\n    Returns\n    -------\n    AppSettings\n        Validated application settings.\n\n    Raises\n    ------\n    ValueError\n        If configuration validation fails.\n    \"\"\"\n    try:\n        settings = AppSettings()\n        logger.log_success(\n            \"Configuration loaded\",\n            operation=\"config.load\",\n            extra={\n                \"log_level\": settings.log_level,\n                \"log_format\": settings.log_format,\n                \"signing_key_present\": settings.signing_key is not None,\n                \"subprocess_timeout\": settings.subprocess_timeout,\n                \"request_timeout\": settings.request_timeout,\n            },\n        )\n    except ValueError as exc:\n        logger.log_failure(\n            \"Configuration validation failed\",\n            exception=exc,\n            operation=\"config.load\",\n        )\n        raise\n    else:\n        return settings\n</code></pre>"},{"location":"modules/kgfoundry_common.config/#kgfoundry_commonconfigload_config","title":"kgfoundry_common.config.load_config","text":""},{"location":"modules/kgfoundry_common.config/#kgfoundry_common.config.load_config","title":"<code>kgfoundry_common.config.load_config(*, reload=False)</code>","text":"<p>Load application configuration from environment variables.</p> <p>This function caches the configuration to avoid repeated environment variable parsing. Pass reload=True to force a fresh load.</p> <p>Parameters:</p> Name Type Description Default <code>reload</code> <code>bool</code> <p>If True, clears the cache and reloads configuration from environment. Defaults to <code>False</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>AppSettings</code> <p>Validated application settings.</p> Notes <p>Propagates :class:<code>ValueError</code> from <code>pydantic</code> when configuration validation fails (for example, due to an invalid log level).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; settings = load_config()\n&gt;&gt;&gt; settings.log_level\n'INFO'\n</code></pre> <pre><code>&gt;&gt;&gt; # Reload configuration\n&gt;&gt;&gt; settings = load_config(reload=True)\n</code></pre> Source code in <code>src/kgfoundry_common/config.py</code> <pre><code>def load_config(*, reload: bool = False) -&gt; AppSettings:\n    \"\"\"Load application configuration from environment variables.\n\n    This function caches the configuration to avoid repeated environment\n    variable parsing. Pass reload=True to force a fresh load.\n\n    Parameters\n    ----------\n    reload : bool, optional\n        If True, clears the cache and reloads configuration from environment.\n        Defaults to ``False``.\n\n    Returns\n    -------\n    AppSettings\n        Validated application settings.\n\n    Notes\n    -----\n    Propagates :class:`ValueError` from ``pydantic`` when configuration\n    validation fails (for example, due to an invalid log level).\n\n    Examples\n    --------\n    &gt;&gt;&gt; settings = load_config()\n    &gt;&gt;&gt; settings.log_level  # doctest: +SKIP\n    'INFO'\n\n    &gt;&gt;&gt; # Reload configuration\n    &gt;&gt;&gt; settings = load_config(reload=True)  # doctest: +SKIP\n    \"\"\"\n    if reload:\n        _load_config_cached.cache_clear()\n\n    return _load_config_cached()\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.codes/","title":"kgfoundry_common.errors.codes","text":""},{"location":"modules/kgfoundry_common.errors.codes/#kgfoundry_commonerrorscodes","title":"kgfoundry_common.errors.codes","text":"<p>Error code registry and type URIs for Problem Details.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.errors.codes/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class ErrorCode\n    class StrEnum\n    StrEnum &lt;|-- ErrorCode\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.codes/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.errors.codes__future__.annotationsenum.StrEnumkgfoundry_common.navmap_loader.load_nav_metadatatyping.Finalkgfoundry_common.errors.codes code <p>See the full diagram: kgfoundry_common.errors.codes</p>"},{"location":"modules/kgfoundry_common.errors.codes/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.errors.codes.ErrorCode</li> <li>kgfoundry_common.errors.codes.get_type_uri</li> </ul>"},{"location":"modules/kgfoundry_common.errors.codes/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>enum.StrEnum</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>typing.Final</code></p>"},{"location":"modules/kgfoundry_common.errors.codes/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.errors.codes/#kgfoundry_commonerrorscodeserrorcode","title":"kgfoundry_common.errors.codes.ErrorCode","text":"<p>Bases: StrEnum</p>"},{"location":"modules/kgfoundry_common.errors.codes/#kgfoundry_common.errors.codes.ErrorCode","title":"<code>kgfoundry_common.errors.codes.ErrorCode</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Stable error codes for kgfoundry exceptions.</p> <p>Enumeration of error codes used in RFC 9457 Problem Details responses. Codes follow kebab-case naming and remain stable across releases to ensure backward compatibility.</p> <p>Error codes are organized by category: - 1xx: Download &amp; Ingestion - 2xx: Document Processing - 3xx: Embedding &amp; Indexing - 4xx: Search &amp; Retrieval - 5xx: Configuration &amp; Runtime - 6xx: Knowledge Graph &amp; Ontology - 7xx: Serialization &amp; Persistence</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; code = ErrorCode.DOWNLOAD_FAILED\n&gt;&gt;&gt; assert code == \"download-failed\"\n&gt;&gt;&gt; assert isinstance(code, ErrorCode)\n</code></pre> Source code in <code>src/kgfoundry_common/errors/codes.py</code> <pre><code>class ErrorCode(StrEnum):\n    \"\"\"Stable error codes for kgfoundry exceptions.\n\n    Enumeration of error codes used in RFC 9457 Problem Details responses.\n    Codes follow kebab-case naming and remain stable across releases to ensure\n    backward compatibility.\n\n    Error codes are organized by category:\n    - 1xx: Download &amp; Ingestion\n    - 2xx: Document Processing\n    - 3xx: Embedding &amp; Indexing\n    - 4xx: Search &amp; Retrieval\n    - 5xx: Configuration &amp; Runtime\n    - 6xx: Knowledge Graph &amp; Ontology\n    - 7xx: Serialization &amp; Persistence\n\n    Examples\n    --------\n    &gt;&gt;&gt; code = ErrorCode.DOWNLOAD_FAILED\n    &gt;&gt;&gt; assert code == \"download-failed\"\n    &gt;&gt;&gt; assert isinstance(code, ErrorCode)\n    \"\"\"\n\n    # Download &amp; Ingestion (1xx)\n    DOWNLOAD_FAILED = \"download-failed\"\n    UNSUPPORTED_MIME = \"unsupported-mime\"\n    INVALID_INPUT = \"invalid-input\"\n\n    # Document Processing (2xx)\n    DOCLING_ERROR = \"docling-error\"\n    OCR_TIMEOUT = \"ocr-timeout\"\n    CHUNKING_ERROR = \"chunking-error\"\n\n    # Embedding &amp; Indexing (3xx)\n    EMBEDDING_ERROR = \"embedding-error\"\n    INDEX_BUILD_ERROR = \"index-build-error\"\n    SPLADE_OOM = \"splade-oom\"\n    RETRY_EXHAUSTED = \"retry-exhausted\"\n\n    # Search &amp; Retrieval (4xx)\n    SEARCH_INDEX_MISSING = \"search-index-missing\"\n    SEARCH_QUERY_INVALID = \"search-query-invalid\"\n    SEARCH_TIMEOUT = \"search-timeout\"\n    VECTOR_SEARCH_ERROR = \"vector-search-error\"\n    AGENT_CATALOG_SEARCH_ERROR = \"agent-catalog-search-error\"\n    CATALOG_LOAD_ERROR = \"catalog-load-error\"\n    SYMBOL_ATTACHMENT_ERROR = \"symbol-attachment-error\"\n\n    # Configuration &amp; Runtime (5xx)\n    CONFIGURATION_ERROR = \"configuration-error\"\n    RUNTIME_ERROR = \"runtime-error\"\n    RESOURCE_UNAVAILABLE = \"resource-unavailable\"\n    SESSION_ERROR = \"session-error\"\n\n    # Knowledge Graph &amp; Ontology (6xx)\n    ONTOLOGY_PARSE_ERROR = \"ontology-parse-error\"\n    LINKER_CALIBRATION_ERROR = \"linker-calibration-error\"\n    NEO4J_ERROR = \"neo4j-error\"\n\n    # Serialization &amp; Persistence (7xx)\n    SERIALIZATION_ERROR = \"serialization-error\"\n    DESERIALIZATION_ERROR = \"deserialization-error\"\n    SCHEMA_VALIDATION_ERROR = \"schema-validation-error\"\n    REGISTRY_ERROR = \"registry-error\"\n    ARTIFACT_MODEL_ERROR = \"artifact-model-error\"\n    ARTIFACT_VALIDATION_ERROR = \"artifact-validation-error\"\n    ARTIFACT_SERIALIZATION_ERROR = \"artifact-serialization-error\"\n    ARTIFACT_DESERIALIZATION_ERROR = \"artifact-deserialization-error\"\n    ARTIFACT_DEPENDENCY_ERROR = \"artifact-dependency-error\"\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return the code value as a string.\n\n        Returns\n        -------\n        str\n            The error code value (e.g., \"download-failed\").\n        \"\"\"\n        return self.value\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.codes/#kgfoundry_common.errors.codes.ErrorCode.__str__","title":"<code>__str__()</code>","text":"<p>Return the code value as a string.</p> <p>Returns:</p> Type Description <code>str</code> <p>The error code value (e.g., \"download-failed\").</p> Source code in <code>src/kgfoundry_common/errors/codes.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return the code value as a string.\n\n    Returns\n    -------\n    str\n        The error code value (e.g., \"download-failed\").\n    \"\"\"\n    return self.value\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.codes/#kgfoundry_commonerrorscodesget_type_uri","title":"kgfoundry_common.errors.codes.get_type_uri","text":""},{"location":"modules/kgfoundry_common.errors.codes/#kgfoundry_common.errors.codes.get_type_uri","title":"<code>kgfoundry_common.errors.codes.get_type_uri(code)</code>","text":"<p>Get the RFC 9457 type URI for an error code.</p> <p>Constructs a complete type URI by combining BASE_TYPE_URI with the error code value. Type URIs are used in Problem Details responses to uniquely identify error types.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>ErrorCode</code> <p>Error code enum value.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Complete type URI (e.g., \"https://kgfoundry.dev/problems/download-failed\").</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_type_uri(ErrorCode.DOWNLOAD_FAILED)\n'https://kgfoundry.dev/problems/download-failed'\n</code></pre> Source code in <code>src/kgfoundry_common/errors/codes.py</code> <pre><code>def get_type_uri(code: ErrorCode) -&gt; str:\n    \"\"\"Get the RFC 9457 type URI for an error code.\n\n    Constructs a complete type URI by combining BASE_TYPE_URI with the\n    error code value. Type URIs are used in Problem Details responses\n    to uniquely identify error types.\n\n    Parameters\n    ----------\n    code : ErrorCode\n        Error code enum value.\n\n    Returns\n    -------\n    str\n        Complete type URI (e.g., \"https://kgfoundry.dev/problems/download-failed\").\n\n    Examples\n    --------\n    &gt;&gt;&gt; get_type_uri(ErrorCode.DOWNLOAD_FAILED)\n    'https://kgfoundry.dev/problems/download-failed'\n    \"\"\"\n    return f\"{BASE_TYPE_URI}/{code.value}\"\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/","title":"kgfoundry_common.errors.exceptions","text":""},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptions","title":"kgfoundry_common.errors.exceptions","text":"<p>Typed exception hierarchy with Problem Details support.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class AgentCatalogSearchError\n    class KgFoundryError\n    KgFoundryError &lt;|-- AgentCatalogSearchError\n    class ArtifactDependencyError\n    KgFoundryError &lt;|-- ArtifactDependencyError\n    class ArtifactDeserializationError\n    KgFoundryError &lt;|-- ArtifactDeserializationError\n    class ArtifactModelError\n    KgFoundryError &lt;|-- ArtifactModelError\n    class ArtifactSerializationError\n    KgFoundryError &lt;|-- ArtifactSerializationError\n    class ArtifactValidationError\n    KgFoundryError &lt;|-- ArtifactValidationError\n    class CatalogLoadError\n    KgFoundryError &lt;|-- CatalogLoadError\n    class CatalogSessionError\n    KgFoundryError &lt;|-- CatalogSessionError\n    class ChunkingError\n    KgFoundryError &lt;|-- ChunkingError\n    class ConfigurationError\n    KgFoundryError &lt;|-- ConfigurationError\n    class DeserializationError\n    KgFoundryError &lt;|-- DeserializationError\n    class DoclingError\n    KgFoundryError &lt;|-- DoclingError\n    class DownloadError\n    KgFoundryError &lt;|-- DownloadError\n    class EmbeddingError\n    KgFoundryError &lt;|-- EmbeddingError\n    class IndexBuildError\n    KgFoundryError &lt;|-- IndexBuildError\n    class KgFoundryError_1\n    class Exception\n    Exception &lt;|-- KgFoundryError_1\n    class KgFoundryErrorConfig\n    class LinkerCalibrationError\n    KgFoundryError &lt;|-- LinkerCalibrationError\n    class Neo4jError\n    KgFoundryError &lt;|-- Neo4jError\n    class OCRTimeoutError\n    KgFoundryError &lt;|-- OCRTimeoutError\n    class OntologyParseError\n    KgFoundryError &lt;|-- OntologyParseError\n    class RegistryError\n    KgFoundryError &lt;|-- RegistryError\n    class RetryExhaustedError\n    KgFoundryError &lt;|-- RetryExhaustedError\n    class SchemaValidationError\n    KgFoundryError &lt;|-- SchemaValidationError\n    class SerializationError\n    KgFoundryError &lt;|-- SerializationError\n    class SettingsError\n    KgFoundryError &lt;|-- SettingsError\n    class SpladeOOMError\n    KgFoundryError &lt;|-- SpladeOOMError\n    class SymbolAttachmentError\n    KgFoundryError &lt;|-- SymbolAttachmentError\n    class UnsupportedMIMEError\n    KgFoundryError &lt;|-- UnsupportedMIMEError\n    class VectorSearchError\n    KgFoundryError &lt;|-- VectorSearchError\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.errors.exceptions__future__.annotationscollections.abc.Mappingdataclasses.dataclasskgfoundry_common.errors.codes.ErrorCodekgfoundry_common.errors.codes.get_type_urikgfoundry_common.logging.get_loggerkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.problem_details.JsonValuekgfoundry_common.problem_details.ProblemDetailskgfoundry_common.problem_details.build_problem_detailsloggingtyping.TYPE_CHECKINGtyping.castkgfoundry_common.errors.exceptions code <p>See the full diagram: kgfoundry_common.errors.exceptions</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.errors.exceptions.AgentCatalogSearchError</li> <li>kgfoundry_common.errors.exceptions.ArtifactDependencyError</li> <li>kgfoundry_common.errors.exceptions.ArtifactDeserializationError</li> <li>kgfoundry_common.errors.exceptions._coerce_error_config</li> </ul>"},{"location":"modules/kgfoundry_common.errors.exceptions/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Mapping</code>, <code>dataclasses.dataclass</code>, <code>kgfoundry_common.errors.codes.ErrorCode</code>, <code>kgfoundry_common.errors.codes.get_type_uri</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.problem_details.JsonValue</code>, <code>kgfoundry_common.problem_details.ProblemDetails</code>, <code>kgfoundry_common.problem_details.build_problem_details</code>, <code>logging</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsagentcatalogsearcherror","title":"kgfoundry_common.errors.exceptions.AgentCatalogSearchError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.AgentCatalogSearchError","title":"<code>kgfoundry_common.errors.exceptions.AgentCatalogSearchError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during agent catalog search operations.</p> <p>Raised when agent catalog search operations fail. Uses error code AGENT_CATALOG_SEARCH_ERROR and HTTP status 503 (Service Unavailable).</p> <p>Creates an AgentCatalogSearchError with AGENT_CATALOG_SEARCH_ERROR error code and HTTP status 503.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the catalog search failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the catalog search failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise AgentCatalogSearchError(\n...     \"Catalog search failed\", cause=RuntimeError(\"Index not loaded\")\n... )\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class AgentCatalogSearchError(KgFoundryError):\n    \"\"\"Error during agent catalog search operations.\n\n    Raised when agent catalog search operations fail. Uses error code\n    AGENT_CATALOG_SEARCH_ERROR and HTTP status 503 (Service Unavailable).\n\n    Creates an AgentCatalogSearchError with AGENT_CATALOG_SEARCH_ERROR error\n    code and HTTP status 503.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the catalog search failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the catalog search failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise AgentCatalogSearchError(\n    ...     \"Catalog search failed\", cause=RuntimeError(\"Index not loaded\")\n    ... )\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.AGENT_CATALOG_SEARCH_ERROR,\n            http_status=503,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.AgentCatalogSearchError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.AgentCatalogSearchError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsartifactdependencyerror","title":"kgfoundry_common.errors.exceptions.ArtifactDependencyError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactDependencyError","title":"<code>kgfoundry_common.errors.exceptions.ArtifactDependencyError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during artifact dependency resolution.</p> <p>Raised when artifact dependency resolution fails. Uses error code ARTIFACT_DEPENDENCY_ERROR and HTTP status 500 (Internal Server Error).</p> <p>Creates an ArtifactDependencyError with ARTIFACT_DEPENDENCY_ERROR error code and HTTP status 500.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the dependency resolution failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the dependency resolution failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise ArtifactDependencyError(\n...     \"Failed to resolve artifact dependency\", cause=ImportError(\"Module not found\")\n... )\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class ArtifactDependencyError(KgFoundryError):\n    \"\"\"Error during artifact dependency resolution.\n\n    Raised when artifact dependency resolution fails. Uses error code\n    ARTIFACT_DEPENDENCY_ERROR and HTTP status 500 (Internal Server Error).\n\n    Creates an ArtifactDependencyError with ARTIFACT_DEPENDENCY_ERROR error\n    code and HTTP status 500.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the dependency resolution failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the dependency resolution failure.\n        Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise ArtifactDependencyError(\n    ...     \"Failed to resolve artifact dependency\", cause=ImportError(\"Module not found\")\n    ... )\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.ARTIFACT_DEPENDENCY_ERROR,\n            http_status=500,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactDependencyError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactDependencyError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsartifactdeserializationerror","title":"kgfoundry_common.errors.exceptions.ArtifactDeserializationError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactDeserializationError","title":"<code>kgfoundry_common.errors.exceptions.ArtifactDeserializationError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during artifact deserialization.</p> <p>Raised when artifact deserialization fails. Uses error code ARTIFACT_DESERIALIZATION_ERROR and HTTP status 500 (Internal Server Error).</p> <p>Creates an ArtifactDeserializationError with ARTIFACT_DESERIALIZATION_ERROR error code and HTTP status 500.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the deserialization failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the deserialization failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise ArtifactDeserializationError(\n...     \"Failed to deserialize artifact\", cause=json.JSONDecodeError(\"Invalid JSON\")\n... )\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class ArtifactDeserializationError(KgFoundryError):\n    \"\"\"Error during artifact deserialization.\n\n    Raised when artifact deserialization fails. Uses error code\n    ARTIFACT_DESERIALIZATION_ERROR and HTTP status 500 (Internal Server Error).\n\n    Creates an ArtifactDeserializationError with ARTIFACT_DESERIALIZATION_ERROR\n    error code and HTTP status 500.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the deserialization failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the deserialization failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise ArtifactDeserializationError(\n    ...     \"Failed to deserialize artifact\", cause=json.JSONDecodeError(\"Invalid JSON\")\n    ... )\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.ARTIFACT_DESERIALIZATION_ERROR,\n            http_status=500,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactDeserializationError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactDeserializationError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsartifactmodelerror","title":"kgfoundry_common.errors.exceptions.ArtifactModelError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactModelError","title":"<code>kgfoundry_common.errors.exceptions.ArtifactModelError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during artifact model loading or validation.</p> <p>Raised when artifact model loading or validation fails. Uses error code ARTIFACT_MODEL_ERROR and HTTP status 500 (Internal Server Error).</p> <p>Creates an ArtifactModelError with ARTIFACT_MODEL_ERROR error code and HTTP status 500.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the model loading failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the model loading failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise ArtifactModelError(\n...     \"Failed to load artifact model\", cause=FileNotFoundError(\"Model file missing\")\n... )\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class ArtifactModelError(KgFoundryError):\n    \"\"\"Error during artifact model loading or validation.\n\n    Raised when artifact model loading or validation fails. Uses error code\n    ARTIFACT_MODEL_ERROR and HTTP status 500 (Internal Server Error).\n\n    Creates an ArtifactModelError with ARTIFACT_MODEL_ERROR error code\n    and HTTP status 500.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the model loading failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the model loading failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise ArtifactModelError(\n    ...     \"Failed to load artifact model\", cause=FileNotFoundError(\"Model file missing\")\n    ... )\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.ARTIFACT_MODEL_ERROR,\n            http_status=500,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactModelError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactModelError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsartifactserializationerror","title":"kgfoundry_common.errors.exceptions.ArtifactSerializationError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactSerializationError","title":"<code>kgfoundry_common.errors.exceptions.ArtifactSerializationError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during artifact serialization.</p> <p>Raised when artifact serialization fails. Uses error code ARTIFACT_SERIALIZATION_ERROR and HTTP status 500 (Internal Server Error).</p> <p>Creates an ArtifactSerializationError with ARTIFACT_SERIALIZATION_ERROR error code and HTTP status 500.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the serialization failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the serialization failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise ArtifactSerializationError(\n...     \"Failed to serialize artifact\", cause=json.JSONDecodeError(\"Invalid JSON\")\n... )\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class ArtifactSerializationError(KgFoundryError):\n    \"\"\"Error during artifact serialization.\n\n    Raised when artifact serialization fails. Uses error code\n    ARTIFACT_SERIALIZATION_ERROR and HTTP status 500 (Internal Server Error).\n\n    Creates an ArtifactSerializationError with ARTIFACT_SERIALIZATION_ERROR\n    error code and HTTP status 500.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the serialization failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the serialization failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise ArtifactSerializationError(\n    ...     \"Failed to serialize artifact\", cause=json.JSONDecodeError(\"Invalid JSON\")\n    ... )\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.ARTIFACT_SERIALIZATION_ERROR,\n            http_status=500,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactSerializationError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactSerializationError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsartifactvalidationerror","title":"kgfoundry_common.errors.exceptions.ArtifactValidationError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactValidationError","title":"<code>kgfoundry_common.errors.exceptions.ArtifactValidationError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during artifact validation.</p> <p>Raised when artifact validation fails. Uses error code ARTIFACT_VALIDATION_ERROR and HTTP status 422 (Unprocessable Entity).</p> <p>Creates an ArtifactValidationError with ARTIFACT_VALIDATION_ERROR error code and HTTP status 422.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the validation failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the validation failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise ArtifactValidationError(\n...     \"Artifact validation failed\", cause=json.JSONDecodeError(\"Invalid JSON\")\n... )\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class ArtifactValidationError(KgFoundryError):\n    \"\"\"Error during artifact validation.\n\n    Raised when artifact validation fails. Uses error code ARTIFACT_VALIDATION_ERROR\n    and HTTP status 422 (Unprocessable Entity).\n\n    Creates an ArtifactValidationError with ARTIFACT_VALIDATION_ERROR error\n    code and HTTP status 422.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the validation failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the validation failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise ArtifactValidationError(\n    ...     \"Artifact validation failed\", cause=json.JSONDecodeError(\"Invalid JSON\")\n    ... )\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.ARTIFACT_VALIDATION_ERROR,\n            http_status=422,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactValidationError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ArtifactValidationError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionscatalogloaderror","title":"kgfoundry_common.errors.exceptions.CatalogLoadError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.CatalogLoadError","title":"<code>kgfoundry_common.errors.exceptions.CatalogLoadError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during catalog payload loading or parsing.</p> <p>Raised when catalog payload loading or parsing fails. Uses error code CATALOG_LOAD_ERROR and HTTP status 422 (Unprocessable Entity).</p> <p>Creates a CatalogLoadError with CATALOG_LOAD_ERROR error code and HTTP status 422.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the catalog load failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the catalog load failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise CatalogLoadError(\n...     \"Failed to parse catalog JSON\", cause=json.JSONDecodeError(\"Invalid JSON\")\n... )\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class CatalogLoadError(KgFoundryError):\n    \"\"\"Error during catalog payload loading or parsing.\n\n    Raised when catalog payload loading or parsing fails. Uses error code\n    CATALOG_LOAD_ERROR and HTTP status 422 (Unprocessable Entity).\n\n    Creates a CatalogLoadError with CATALOG_LOAD_ERROR error code and HTTP status 422.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the catalog load failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the catalog load failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise CatalogLoadError(\n    ...     \"Failed to parse catalog JSON\", cause=json.JSONDecodeError(\"Invalid JSON\")\n    ... )\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.CATALOG_LOAD_ERROR,\n            http_status=422,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.CatalogLoadError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.CatalogLoadError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionscatalogsessionerror","title":"kgfoundry_common.errors.exceptions.CatalogSessionError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.CatalogSessionError","title":"<code>kgfoundry_common.errors.exceptions.CatalogSessionError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during catalog session operations (JSON-RPC, subprocess).</p> <p>Raised when catalog session operations fail (e.g., JSON-RPC or subprocess spawning). Uses error code SESSION_ERROR and HTTP status 500 (Internal Server Error).</p> <p>Creates a CatalogSessionError with SESSION_ERROR error code and HTTP status 500.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the session operation failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the session failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise CatalogSessionError(\"Session spawn failed\", cause=OSError(\"Command not found\"))\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class CatalogSessionError(KgFoundryError):\n    \"\"\"Error during catalog session operations (JSON-RPC, subprocess).\n\n    Raised when catalog session operations fail (e.g., JSON-RPC or subprocess\n    spawning). Uses error code SESSION_ERROR and HTTP status 500 (Internal Server Error).\n\n    Creates a CatalogSessionError with SESSION_ERROR error code and HTTP status 500.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the session operation failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the session failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise CatalogSessionError(\"Session spawn failed\", cause=OSError(\"Command not found\"))\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.SESSION_ERROR,\n            http_status=500,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.CatalogSessionError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.CatalogSessionError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionschunkingerror","title":"kgfoundry_common.errors.exceptions.ChunkingError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ChunkingError","title":"<code>kgfoundry_common.errors.exceptions.ChunkingError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during text chunking operations.</p> <p>Raised when text chunking operations fail. Uses error code CHUNKING_ERROR and HTTP status 422 (Unprocessable Entity).</p> <p>Creates a ChunkingError with CHUNKING_ERROR error code and HTTP status 422.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the chunking failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the chunking failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise ChunkingError(\"Failed to chunk document\", cause=ValueError(\"Empty text\"))\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class ChunkingError(KgFoundryError):\n    \"\"\"Error during text chunking operations.\n\n    Raised when text chunking operations fail. Uses error code CHUNKING_ERROR\n    and HTTP status 422 (Unprocessable Entity).\n\n    Creates a ChunkingError with CHUNKING_ERROR error code and HTTP status 422.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the chunking failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the chunking failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise ChunkingError(\"Failed to chunk document\", cause=ValueError(\"Empty text\"))\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.CHUNKING_ERROR,\n            http_status=422,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ChunkingError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ChunkingError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsconfigurationerror","title":"kgfoundry_common.errors.exceptions.ConfigurationError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ConfigurationError","title":"<code>kgfoundry_common.errors.exceptions.ConfigurationError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during configuration validation or loading.</p> <p>Raised when configuration validation or loading fails. Uses error code CONFIGURATION_ERROR and HTTP status 500 (Internal Server Error) with CRITICAL log level.</p> <p>Creates a ConfigurationError with CONFIGURATION_ERROR error code, HTTP status 500, and CRITICAL log level.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the configuration failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the configuration failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise ConfigurationError(\"Missing required env var: KGFOUNDRY_API_KEY\")\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class ConfigurationError(KgFoundryError):\n    \"\"\"Error during configuration validation or loading.\n\n    Raised when configuration validation or loading fails. Uses error code\n    CONFIGURATION_ERROR and HTTP status 500 (Internal Server Error) with\n    CRITICAL log level.\n\n    Creates a ConfigurationError with CONFIGURATION_ERROR error code,\n    HTTP status 500, and CRITICAL log level.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the configuration failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the configuration failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise ConfigurationError(\"Missing required env var: KGFOUNDRY_API_KEY\")\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.CONFIGURATION_ERROR,\n            http_status=500,\n            log_level=logging.CRITICAL,\n            cause=cause,\n            context=context,\n        )\n\n    @classmethod\n    def with_details(\n        cls,\n        *,\n        field: str,\n        issue: str,\n        hint: str | None = None,\n    ) -&gt; ConfigurationError:\n        \"\"\"Create a ConfigurationError with structured validation details.\n\n        Parameters\n        ----------\n        field : str\n            Name of the configuration field that failed validation.\n        issue : str\n            Description of the validation issue (e.g., \"Must be &gt; 0\", \"Invalid format\").\n        hint : str | None, optional\n            Optional hint for resolving the issue (e.g., \"Use ISO 8601 format\").\n            Defaults to ``None``.\n\n        Returns\n        -------\n        ConfigurationError\n            New instance with details captured in context.\n\n        Examples\n        --------\n        &gt;&gt;&gt; error = ConfigurationError.with_details(\n        ...     field=\"timeout_seconds\",\n        ...     issue=\"Must be &gt; 0\",\n        ...     hint=\"Provide a positive integer\",\n        ... )\n        &gt;&gt;&gt; assert \"timeout_seconds\" in str(error.context)\n        \"\"\"\n        details: dict[str, object] = {\n            \"field\": field,\n            \"issue\": issue,\n        }\n        if hint is not None:\n            details[\"hint\"] = hint\n\n        message = f\"Configuration validation failed for field '{field}': {issue}\"\n        return cls(message, context=details)\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ConfigurationError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ConfigurationError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.ConfigurationError.with_details","title":"<code>with_details(*, field, issue, hint=None)</code>  <code>classmethod</code>","text":"<p>Create a ConfigurationError with structured validation details.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>str</code> <p>Name of the configuration field that failed validation.</p> required <code>issue</code> <code>str</code> <p>Description of the validation issue (e.g., \"Must be &gt; 0\", \"Invalid format\").</p> required <code>hint</code> <code>str | None</code> <p>Optional hint for resolving the issue (e.g., \"Use ISO 8601 format\"). Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>ConfigurationError</code> <p>New instance with details captured in context.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = ConfigurationError.with_details(\n...     field=\"timeout_seconds\",\n...     issue=\"Must be &gt; 0\",\n...     hint=\"Provide a positive integer\",\n... )\n&gt;&gt;&gt; assert \"timeout_seconds\" in str(error.context)\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>@classmethod\ndef with_details(\n    cls,\n    *,\n    field: str,\n    issue: str,\n    hint: str | None = None,\n) -&gt; ConfigurationError:\n    \"\"\"Create a ConfigurationError with structured validation details.\n\n    Parameters\n    ----------\n    field : str\n        Name of the configuration field that failed validation.\n    issue : str\n        Description of the validation issue (e.g., \"Must be &gt; 0\", \"Invalid format\").\n    hint : str | None, optional\n        Optional hint for resolving the issue (e.g., \"Use ISO 8601 format\").\n        Defaults to ``None``.\n\n    Returns\n    -------\n    ConfigurationError\n        New instance with details captured in context.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = ConfigurationError.with_details(\n    ...     field=\"timeout_seconds\",\n    ...     issue=\"Must be &gt; 0\",\n    ...     hint=\"Provide a positive integer\",\n    ... )\n    &gt;&gt;&gt; assert \"timeout_seconds\" in str(error.context)\n    \"\"\"\n    details: dict[str, object] = {\n        \"field\": field,\n        \"issue\": issue,\n    }\n    if hint is not None:\n        details[\"hint\"] = hint\n\n    message = f\"Configuration validation failed for field '{field}': {issue}\"\n    return cls(message, context=details)\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsdeserializationerror","title":"kgfoundry_common.errors.exceptions.DeserializationError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.DeserializationError","title":"<code>kgfoundry_common.errors.exceptions.DeserializationError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during JSON deserialization, schema validation, or checksum verification.</p> <p>Raised when JSON deserialization, schema validation, or checksum verification fails. Uses error code DESERIALIZATION_ERROR and HTTP status 500 (Internal Server Error).</p> <p>Creates a DeserializationError with DESERIALIZATION_ERROR error code and HTTP status 500.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the deserialization failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the deserialization failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise DeserializationError(\"Checksum mismatch\", cause=ValueError(\"Corrupted data\"))\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class DeserializationError(KgFoundryError):\n    \"\"\"Error during JSON deserialization, schema validation, or checksum verification.\n\n    Raised when JSON deserialization, schema validation, or checksum verification\n    fails. Uses error code DESERIALIZATION_ERROR and HTTP status 500 (Internal Server Error).\n\n    Creates a DeserializationError with DESERIALIZATION_ERROR error code\n    and HTTP status 500.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the deserialization failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the deserialization failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise DeserializationError(\"Checksum mismatch\", cause=ValueError(\"Corrupted data\"))\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.DESERIALIZATION_ERROR,\n            http_status=500,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.DeserializationError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.DeserializationError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsdoclingerror","title":"kgfoundry_common.errors.exceptions.DoclingError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.DoclingError","title":"<code>kgfoundry_common.errors.exceptions.DoclingError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during document processing with Docling.</p> <p>Raised when document processing operations fail in Docling. Uses error code DOCLING_ERROR and HTTP status 422 (Unprocessable Entity).</p> <p>Creates a DoclingError with DOCLING_ERROR error code and HTTP status 422.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the processing failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the processing failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise DoclingError(\"Failed to parse document\", cause=ValueError(\"Invalid format\"))\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class DoclingError(KgFoundryError):\n    \"\"\"Error during document processing with Docling.\n\n    Raised when document processing operations fail in Docling. Uses error\n    code DOCLING_ERROR and HTTP status 422 (Unprocessable Entity).\n\n    Creates a DoclingError with DOCLING_ERROR error code and HTTP status 422.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the processing failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the processing failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise DoclingError(\"Failed to parse document\", cause=ValueError(\"Invalid format\"))\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.DOCLING_ERROR,\n            http_status=422,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.DoclingError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.DoclingError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsdownloaderror","title":"kgfoundry_common.errors.exceptions.DownloadError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.DownloadError","title":"<code>kgfoundry_common.errors.exceptions.DownloadError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during download or resource fetch operations.</p> <p>Raised when download or resource fetch operations fail. Uses error code DOWNLOAD_FAILED and HTTP status 503 (Service Unavailable).</p> <p>Creates a DownloadError with DOWNLOAD_FAILED error code and HTTP status 503.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the download failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the download failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise DownloadError(\"Failed to download PDF\", cause=IOError(\"Connection refused\"))\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class DownloadError(KgFoundryError):\n    \"\"\"Error during download or resource fetch operations.\n\n    Raised when download or resource fetch operations fail. Uses error code\n    DOWNLOAD_FAILED and HTTP status 503 (Service Unavailable).\n\n    Creates a DownloadError with DOWNLOAD_FAILED error code and HTTP status 503.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the download failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the download failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise DownloadError(\"Failed to download PDF\", cause=IOError(\"Connection refused\"))\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.DOWNLOAD_FAILED,\n            http_status=503,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.DownloadError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.DownloadError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsembeddingerror","title":"kgfoundry_common.errors.exceptions.EmbeddingError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.EmbeddingError","title":"<code>kgfoundry_common.errors.exceptions.EmbeddingError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during embedding generation.</p> <p>Raised when embedding generation operations fail. Uses error code EMBEDDING_ERROR and HTTP status 503 (Service Unavailable).</p> <p>Creates an EmbeddingError with EMBEDDING_ERROR error code and HTTP status 503.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the embedding failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the embedding failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise EmbeddingError(\"Failed to generate embeddings\", cause=RuntimeError(\"GPU unavailable\"))\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class EmbeddingError(KgFoundryError):\n    \"\"\"Error during embedding generation.\n\n    Raised when embedding generation operations fail. Uses error code\n    EMBEDDING_ERROR and HTTP status 503 (Service Unavailable).\n\n    Creates an EmbeddingError with EMBEDDING_ERROR error code and HTTP status 503.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the embedding failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the embedding failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise EmbeddingError(\"Failed to generate embeddings\", cause=RuntimeError(\"GPU unavailable\"))\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.EMBEDDING_ERROR,\n            http_status=503,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.EmbeddingError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.EmbeddingError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsindexbuilderror","title":"kgfoundry_common.errors.exceptions.IndexBuildError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.IndexBuildError","title":"<code>kgfoundry_common.errors.exceptions.IndexBuildError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during index construction.</p> <p>Raised when index construction operations fail (e.g., FAISS index build). Uses error code INDEX_BUILD_ERROR and HTTP status 500 (Internal Server Error).</p> <p>Creates an IndexBuildError with INDEX_BUILD_ERROR error code and HTTP status 500.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the index build failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the build failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise IndexBuildError(\"Failed to build FAISS index\", cause=IOError(\"Disk full\"))\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class IndexBuildError(KgFoundryError):\n    \"\"\"Error during index construction.\n\n    Raised when index construction operations fail (e.g., FAISS index build).\n    Uses error code INDEX_BUILD_ERROR and HTTP status 500 (Internal Server Error).\n\n    Creates an IndexBuildError with INDEX_BUILD_ERROR error code and HTTP status 500.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the index build failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the build failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise IndexBuildError(\"Failed to build FAISS index\", cause=IOError(\"Disk full\"))\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.INDEX_BUILD_ERROR,\n            http_status=500,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.IndexBuildError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.IndexBuildError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionskgfoundryerror","title":"kgfoundry_common.errors.exceptions.KgFoundryError","text":"<p>Bases: Exception</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.KgFoundryError","title":"<code>kgfoundry_common.errors.exceptions.KgFoundryError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for all kgfoundry errors.</p> <p>Provides structured fields (code, http_status, log_level) and RFC 9457 Problem Details mapping. All kgfoundry exceptions inherit from this base class and can be converted to Problem Details JSON for HTTP responses.</p> <p>Creates a new KgFoundryError instance with the provided message and configuration. Resolves configuration from either the config parameter or legacy keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message.</p> required <code>config</code> <code>KgFoundryErrorConfig | None</code> <p>Structured configuration for the error including code, http_status, log_level, cause and context. When omitted, these fields fall back to sensible defaults. Defaults to None.</p> <code>None</code> <code>**legacy_kwargs</code> <code>object</code> <p>Backwards-compatible keyword arguments mirroring the fields of KgFoundryErrorConfig. Cannot be combined with config.</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.errors import KgFoundryError, ErrorCode\n&gt;&gt;&gt; error = KgFoundryError(\"Operation failed\", code=ErrorCode.RUNTIME_ERROR)\n&gt;&gt;&gt; assert error.code == ErrorCode.RUNTIME_ERROR\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/operation\")\n&gt;&gt;&gt; assert details[\"status\"] == 500\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class KgFoundryError(Exception):\n    \"\"\"Base exception for all kgfoundry errors.\n\n    Provides structured fields (code, http_status, log_level) and RFC 9457\n    Problem Details mapping. All kgfoundry exceptions inherit from this\n    base class and can be converted to Problem Details JSON for HTTP responses.\n\n    Creates a new KgFoundryError instance with the provided message\n    and configuration. Resolves configuration from either the config\n    parameter or legacy keyword arguments.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message.\n    config : KgFoundryErrorConfig | None, optional\n        Structured configuration for the error including code, http_status,\n        log_level, cause and context. When omitted, these fields fall back\n        to sensible defaults. Defaults to None.\n    **legacy_kwargs : object\n        Backwards-compatible keyword arguments mirroring the fields of\n        KgFoundryErrorConfig. Cannot be combined with config.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.errors import KgFoundryError, ErrorCode\n    &gt;&gt;&gt; error = KgFoundryError(\"Operation failed\", code=ErrorCode.RUNTIME_ERROR)\n    &gt;&gt;&gt; assert error.code == ErrorCode.RUNTIME_ERROR\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/operation\")\n    &gt;&gt;&gt; assert details[\"status\"] == 500\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        *,\n        config: KgFoundryErrorConfig | None = None,\n        **legacy_kwargs: object,\n    ) -&gt; None:\n        resolved_config = _coerce_error_config(config, dict(legacy_kwargs))\n        self.message = message\n        self.code = resolved_config.code\n        self.http_status = resolved_config.http_status\n        self.log_level = resolved_config.log_level\n        self.context = dict(resolved_config.context) if resolved_config.context else {}\n        if resolved_config.cause is not None:\n            self.__cause__ = resolved_config.cause\n\n    def to_problem_details(\n        self,\n        instance: str | None = None,\n        title: str | None = None,\n    ) -&gt; ProblemDetails:\n        \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n        Converts the exception to a Problem Details JSON structure suitable\n        for HTTP error responses. Includes type URI, title, status, detail,\n        instance, code, and optional context extensions.\n\n        Parameters\n        ----------\n        instance : str | None, optional\n            URI identifying the specific occurrence. Defaults to None.\n        title : str | None, optional\n            Short summary. Defaults to the exception class name.\n            Defaults to None.\n\n        Returns\n        -------\n        ProblemDetails\n            Problem Details object with type, title, status, detail, code,\n            instance, and optional errors fields.\n\n        Examples\n        --------\n        &gt;&gt;&gt; error = KgFoundryError(\n        ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n        ... )\n        &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n        &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n        &gt;&gt;&gt; assert details[\"status\"] == 404\n        &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n        \"\"\"\n        return build_problem_details(\n            problem_type=get_type_uri(self.code),\n            title=title or self.__class__.__name__,\n            status=self.http_status,\n            detail=self.message,\n            instance=instance or \"urn:kgfoundry:error\",\n            code=self.code.value,\n            extensions=cast(\n                \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n            ),\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return formatted error string.\n\n        Returns a string representation of the error including the class\n        name, error code, and message. If a cause exception is present,\n        includes information about the cause.\n\n        Returns\n        -------\n        str\n            Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n        \"\"\"\n        base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n        if self.__cause__:\n            base += f\" (caused by: {type(self.__cause__).__name__})\"\n        return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.KgFoundryError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.KgFoundryError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionskgfoundryerrorconfig","title":"kgfoundry_common.errors.exceptions.KgFoundryErrorConfig","text":""},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.KgFoundryErrorConfig","title":"<code>kgfoundry_common.errors.exceptions.KgFoundryErrorConfig</code>  <code>dataclass</code>","text":"<p>Configuration options used when instantiating :class:<code>KgFoundryError</code>.</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>@dataclass(slots=True)\n# [nav:anchor KgFoundryErrorConfig]\nclass KgFoundryErrorConfig:\n    \"\"\"Configuration options used when instantiating :class:`KgFoundryError`.\"\"\"\n\n    code: ErrorCode = ErrorCode.RUNTIME_ERROR\n    http_status: int = 500\n    log_level: int = logging.ERROR\n    cause: Exception | None = None\n    context: Mapping[str, object] | None = None\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionslinkercalibrationerror","title":"kgfoundry_common.errors.exceptions.LinkerCalibrationError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.LinkerCalibrationError","title":"<code>kgfoundry_common.errors.exceptions.LinkerCalibrationError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during linker calibration.</p> <p>Raised when linker calibration operations fail. Uses error code LINKER_CALIBRATION_ERROR and HTTP status 500 (Internal Server Error).</p> <p>Creates a LinkerCalibrationError with LINKER_CALIBRATION_ERROR error code and HTTP status 500.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the calibration failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the calibration failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise LinkerCalibrationError(\"Calibration failed\", cause=ValueError(\"Invalid parameters\"))\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class LinkerCalibrationError(KgFoundryError):\n    \"\"\"Error during linker calibration.\n\n    Raised when linker calibration operations fail. Uses error code\n    LINKER_CALIBRATION_ERROR and HTTP status 500 (Internal Server Error).\n\n    Creates a LinkerCalibrationError with LINKER_CALIBRATION_ERROR error\n    code and HTTP status 500.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the calibration failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the calibration failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise LinkerCalibrationError(\"Calibration failed\", cause=ValueError(\"Invalid parameters\"))\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.LINKER_CALIBRATION_ERROR,\n            http_status=500,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.LinkerCalibrationError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.LinkerCalibrationError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsneo4jerror","title":"kgfoundry_common.errors.exceptions.Neo4jError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.Neo4jError","title":"<code>kgfoundry_common.errors.exceptions.Neo4jError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during Neo4j operations.</p> <p>Raised when Neo4j database operations fail. Uses error code NEO4J_ERROR and HTTP status 503 (Service Unavailable).</p> <p>Creates a Neo4jError with NEO4J_ERROR error code and HTTP status 503.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the Neo4j operation failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the Neo4j failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise Neo4jError(\"Neo4j query failed\", cause=ConnectionError(\"Database unreachable\"))\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class Neo4jError(KgFoundryError):\n    \"\"\"Error during Neo4j operations.\n\n    Raised when Neo4j database operations fail. Uses error code NEO4J_ERROR\n    and HTTP status 503 (Service Unavailable).\n\n    Creates a Neo4jError with NEO4J_ERROR error code and HTTP status 503.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the Neo4j operation failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the Neo4j failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise Neo4jError(\"Neo4j query failed\", cause=ConnectionError(\"Database unreachable\"))\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.NEO4J_ERROR,\n            http_status=503,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.Neo4jError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.Neo4jError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsocrtimeouterror","title":"kgfoundry_common.errors.exceptions.OCRTimeoutError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.OCRTimeoutError","title":"<code>kgfoundry_common.errors.exceptions.OCRTimeoutError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error when OCR operation times out.</p> <p>Raised when OCR (Optical Character Recognition) operations exceed their timeout limit. Uses error code OCR_TIMEOUT and HTTP status 504 (Gateway Timeout).</p> <p>Creates an OCRTimeoutError with OCR_TIMEOUT error code and HTTP status 504.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the timeout.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the timeout. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise OCRTimeoutError(\"OCR timed out after 30s\")\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class OCRTimeoutError(KgFoundryError):\n    \"\"\"Error when OCR operation times out.\n\n    Raised when OCR (Optical Character Recognition) operations exceed their\n    timeout limit. Uses error code OCR_TIMEOUT and HTTP status 504 (Gateway Timeout).\n\n    Creates an OCRTimeoutError with OCR_TIMEOUT error code and HTTP status 504.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the timeout.\n    cause : Exception | None, optional\n        Underlying exception that caused the timeout. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise OCRTimeoutError(\"OCR timed out after 30s\")\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.OCR_TIMEOUT,\n            http_status=504,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.OCRTimeoutError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.OCRTimeoutError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsontologyparseerror","title":"kgfoundry_common.errors.exceptions.OntologyParseError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.OntologyParseError","title":"<code>kgfoundry_common.errors.exceptions.OntologyParseError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during ontology parsing.</p> <p>Raised when ontology parsing operations fail (e.g., OWL file parsing). Uses error code ONTOLOGY_PARSE_ERROR and HTTP status 422 (Unprocessable Entity).</p> <p>Creates an OntologyParseError with ONTOLOGY_PARSE_ERROR error code and HTTP status 422.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the parsing failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the parsing failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise OntologyParseError(\"Failed to parse OWL file\", cause=XMLSyntaxError(\"Invalid XML\"))\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class OntologyParseError(KgFoundryError):\n    \"\"\"Error during ontology parsing.\n\n    Raised when ontology parsing operations fail (e.g., OWL file parsing).\n    Uses error code ONTOLOGY_PARSE_ERROR and HTTP status 422 (Unprocessable Entity).\n\n    Creates an OntologyParseError with ONTOLOGY_PARSE_ERROR error code\n    and HTTP status 422.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the parsing failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the parsing failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise OntologyParseError(\"Failed to parse OWL file\", cause=XMLSyntaxError(\"Invalid XML\"))\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.ONTOLOGY_PARSE_ERROR,\n            http_status=422,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.OntologyParseError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.OntologyParseError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsregistryerror","title":"kgfoundry_common.errors.exceptions.RegistryError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.RegistryError","title":"<code>kgfoundry_common.errors.exceptions.RegistryError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Errors raised during registry or DuckDB operations.</p> <p>Raised when registry or DuckDB database operations fail. Uses error code REGISTRY_ERROR and HTTP status 500 (Internal Server Error).</p> <p>Creates a RegistryError with REGISTRY_ERROR error code and HTTP status 500.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the registry operation failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the registry failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise RegistryError(\"Failed to write to registry\")\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class RegistryError(KgFoundryError):\n    \"\"\"Errors raised during registry or DuckDB operations.\n\n    Raised when registry or DuckDB database operations fail. Uses error code\n    REGISTRY_ERROR and HTTP status 500 (Internal Server Error).\n\n    Creates a RegistryError with REGISTRY_ERROR error code and HTTP status 500.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the registry operation failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the registry failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise RegistryError(\"Failed to write to registry\")\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        *,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.REGISTRY_ERROR,\n            http_status=500,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.RegistryError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.RegistryError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsretryexhaustederror","title":"kgfoundry_common.errors.exceptions.RetryExhaustedError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.RetryExhaustedError","title":"<code>kgfoundry_common.errors.exceptions.RetryExhaustedError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Raised when retry logic exhausts all attempts.</p> <p>This exception indicates that a retryable operation has exhausted all retry attempts and should surface Problem Details with retry guidance information. Uses error code RETRY_EXHAUSTED and HTTP status 503.</p> <p>Creates a RetryExhaustedError with RETRY_EXHAUSTED error code and HTTP status 503. Stores retry metadata for Problem Details conversion.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the retry exhaustion.</p> required <code>operation</code> <code>str | None</code> <p>Name of the operation that failed. Defaults to None.</p> <code>None</code> <code>attempts</code> <code>int | None</code> <p>Number of retry attempts that were made. Defaults to None.</p> <code>None</code> <code>last_error</code> <code>Exception | None</code> <p>The last exception that occurred before retries were exhausted. Defaults to None.</p> <code>None</code> <code>retry_after_seconds</code> <code>int | None</code> <p>Suggested retry delay in seconds. Defaults to None.</p> <code>None</code> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class RetryExhaustedError(KgFoundryError):\n    \"\"\"Raised when retry logic exhausts all attempts.\n\n    This exception indicates that a retryable operation has exhausted all\n    retry attempts and should surface Problem Details with retry guidance\n    information. Uses error code RETRY_EXHAUSTED and HTTP status 503.\n\n    Creates a RetryExhaustedError with RETRY_EXHAUSTED error code and\n    HTTP status 503. Stores retry metadata for Problem Details conversion.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the retry exhaustion.\n    operation : str | None, optional\n        Name of the operation that failed. Defaults to None.\n    attempts : int | None, optional\n        Number of retry attempts that were made. Defaults to None.\n    last_error : Exception | None, optional\n        The last exception that occurred before retries were exhausted.\n        Defaults to None.\n    retry_after_seconds : int | None, optional\n        Suggested retry delay in seconds. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        *,\n        operation: str | None = None,\n        attempts: int | None = None,\n        last_error: Exception | None = None,\n        retry_after_seconds: int | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.RETRY_EXHAUSTED,\n            http_status=503,\n            log_level=logging.ERROR,\n        )\n        self.operation = operation\n        self.attempts = attempts\n        self.last_error = last_error\n        self.retry_after_seconds = retry_after_seconds\n\n    def to_problem_details(\n        self,\n        instance: str | None = None,\n        title: str | None = None,\n    ) -&gt; ProblemDetails:\n        \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n        Converts the exception to a Problem Details JSON structure including\n        retry metadata (operation, attempts, retry_after_seconds) in extensions.\n\n        Parameters\n        ----------\n        instance : str | None, optional\n            Instance URI for the specific error occurrence. Defaults to None.\n        title : str | None, optional\n            Short summary. Defaults to the exception class name.\n            Defaults to None.\n\n        Returns\n        -------\n        ProblemDetails\n            Problem Details JSON structure with retry metadata in extensions.\n        \"\"\"\n        extensions: dict[str, object] = {}\n        if self.operation:\n            extensions[\"operation\"] = self.operation\n        if self.attempts is not None:\n            extensions[\"attempts\"] = self.attempts\n        if self.retry_after_seconds is not None:\n            extensions[\"retry_after_seconds\"] = self.retry_after_seconds\n\n        return build_problem_details(\n            problem_type=get_type_uri(self.code),\n            title=title or self.__class__.__name__,\n            status=self.http_status,\n            detail=self.message,\n            instance=instance or \"urn:kgfoundry:error\",\n            code=self.code.value,\n            extensions=cast(\"Mapping[str, JsonValue] | None\", extensions if extensions else None),\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.RetryExhaustedError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.RetryExhaustedError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure including retry metadata (operation, attempts, retry_after_seconds) in extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>Instance URI for the specific error occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details JSON structure with retry metadata in extensions.</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure including\n    retry metadata (operation, attempts, retry_after_seconds) in extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        Instance URI for the specific error occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details JSON structure with retry metadata in extensions.\n    \"\"\"\n    extensions: dict[str, object] = {}\n    if self.operation:\n        extensions[\"operation\"] = self.operation\n    if self.attempts is not None:\n        extensions[\"attempts\"] = self.attempts\n    if self.retry_after_seconds is not None:\n        extensions[\"retry_after_seconds\"] = self.retry_after_seconds\n\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\"Mapping[str, JsonValue] | None\", extensions if extensions else None),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsschemavalidationerror","title":"kgfoundry_common.errors.exceptions.SchemaValidationError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SchemaValidationError","title":"<code>kgfoundry_common.errors.exceptions.SchemaValidationError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error raised when schema validation fails.</p> <p>Raised when schema validation fails. Includes structured validation error details. Uses error code SCHEMA_VALIDATION_ERROR and HTTP status 422 (Unprocessable Entity).</p> <p>Creates a SchemaValidationError with SCHEMA_VALIDATION_ERROR error code and HTTP status 422. Merges validation errors into context if provided.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the validation failure.</p> required <code>errors</code> <code>list[str] | None</code> <p>List of validation error messages with path and constraint details. Defaults to None.</p> <code>None</code> <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the validation failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise SchemaValidationError(\"Invalid schema\", errors=[\"Missing field: name\"])\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class SchemaValidationError(KgFoundryError):\n    \"\"\"Error raised when schema validation fails.\n\n    Raised when schema validation fails. Includes structured validation error\n    details. Uses error code SCHEMA_VALIDATION_ERROR and HTTP status 422\n    (Unprocessable Entity).\n\n    Creates a SchemaValidationError with SCHEMA_VALIDATION_ERROR error\n    code and HTTP status 422. Merges validation errors into context if provided.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the validation failure.\n    errors : list[str] | None, optional\n        List of validation error messages with path and constraint details.\n        Defaults to None.\n    cause : Exception | None, optional\n        Underlying exception that caused the validation failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise SchemaValidationError(\"Invalid schema\", errors=[\"Missing field: name\"])\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        *,\n        errors: list[str] | None = None,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        combined_context: dict[str, object] = dict(context or {})\n        if errors:\n            combined_context.setdefault(\"validation_errors\", list(errors))\n        super().__init__(\n            message,\n            code=ErrorCode.SCHEMA_VALIDATION_ERROR,\n            http_status=422,\n            cause=cause,\n            context=combined_context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SchemaValidationError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SchemaValidationError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsserializationerror","title":"kgfoundry_common.errors.exceptions.SerializationError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SerializationError","title":"<code>kgfoundry_common.errors.exceptions.SerializationError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during JSON serialization or schema validation.</p> <p>Raised when JSON serialization or schema validation fails. Uses error code SERIALIZATION_ERROR and HTTP status 500 (Internal Server Error).</p> <p>Creates a SerializationError with SERIALIZATION_ERROR error code and HTTP status 500.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the serialization failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the serialization failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise SerializationError(\"Schema validation failed\", cause=ValueError(\"Invalid type\"))\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class SerializationError(KgFoundryError):\n    \"\"\"Error during JSON serialization or schema validation.\n\n    Raised when JSON serialization or schema validation fails. Uses error\n    code SERIALIZATION_ERROR and HTTP status 500 (Internal Server Error).\n\n    Creates a SerializationError with SERIALIZATION_ERROR error code\n    and HTTP status 500.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the serialization failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the serialization failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise SerializationError(\"Schema validation failed\", cause=ValueError(\"Invalid type\"))\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.SERIALIZATION_ERROR,\n            http_status=500,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SerializationError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SerializationError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionssettingserror","title":"kgfoundry_common.errors.exceptions.SettingsError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SettingsError","title":"<code>kgfoundry_common.errors.exceptions.SettingsError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error raised when runtime settings validation fails.</p> <p>Raised when runtime settings validation fails. Similar to ConfigurationError but includes structured validation error details. Uses error code CONFIGURATION_ERROR and HTTP status 500.</p> <p>Creates a SettingsError with CONFIGURATION_ERROR error code and HTTP status 500. Merges validation errors into context if provided.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the settings validation failure.</p> required <code>errors</code> <code>list[dict[str, object]] | None</code> <p>List of validation error dictionaries with field/issue details. Defaults to None.</p> <code>None</code> <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the validation failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class SettingsError(KgFoundryError):\n    \"\"\"Error raised when runtime settings validation fails.\n\n    Raised when runtime settings validation fails. Similar to ConfigurationError\n    but includes structured validation error details. Uses error code\n    CONFIGURATION_ERROR and HTTP status 500.\n\n    Creates a SettingsError with CONFIGURATION_ERROR error code and\n    HTTP status 500. Merges validation errors into context if provided.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the settings validation failure.\n    errors : list[dict[str, object]] | None, optional\n        List of validation error dictionaries with field/issue details.\n        Defaults to None.\n    cause : Exception | None, optional\n        Underlying exception that caused the validation failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        *,\n        errors: list[dict[str, object]] | None = None,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        combined_context: dict[str, object] = dict(context or {})\n        if errors:\n            combined_context.setdefault(\n                \"validation_errors\",\n                [dict(error) for error in errors],\n            )\n        super().__init__(\n            message,\n            code=ErrorCode.CONFIGURATION_ERROR,\n            http_status=500,\n            cause=cause,\n            context=combined_context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SettingsError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SettingsError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsspladeoomerror","title":"kgfoundry_common.errors.exceptions.SpladeOOMError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SpladeOOMError","title":"<code>kgfoundry_common.errors.exceptions.SpladeOOMError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error when SPLADE operation runs out of memory.</p> <p>Raised when SPLADE (Sparse Lexical and Expansion) operations exceed available memory. Uses error code SPLADE_OOM and HTTP status 507 (Insufficient Storage).</p> <p>Creates a SpladeOOMError with SPLADE_OOM error code and HTTP status 507.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the out-of-memory condition.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the OOM. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise SpladeOOMError(\"SPLADE OOM during inference\")\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class SpladeOOMError(KgFoundryError):\n    \"\"\"Error when SPLADE operation runs out of memory.\n\n    Raised when SPLADE (Sparse Lexical and Expansion) operations exceed\n    available memory. Uses error code SPLADE_OOM and HTTP status 507\n    (Insufficient Storage).\n\n    Creates a SpladeOOMError with SPLADE_OOM error code and HTTP status 507.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the out-of-memory condition.\n    cause : Exception | None, optional\n        Underlying exception that caused the OOM. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise SpladeOOMError(\"SPLADE OOM during inference\")\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.SPLADE_OOM,\n            http_status=507,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SpladeOOMError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SpladeOOMError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionssymbolattachmenterror","title":"kgfoundry_common.errors.exceptions.SymbolAttachmentError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SymbolAttachmentError","title":"<code>kgfoundry_common.errors.exceptions.SymbolAttachmentError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during symbol attachment to modules in catalog.</p> <p>Raised when symbol attachment to modules in the catalog fails. Uses error code SYMBOL_ATTACHMENT_ERROR and HTTP status 500 (Internal Server Error).</p> <p>Creates a SymbolAttachmentError with SYMBOL_ATTACHMENT_ERROR error code and HTTP status 500.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the symbol attachment failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the attachment failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise SymbolAttachmentError(\n...     \"Failed to attach symbols to module\", cause=sqlite3.DatabaseError(\"Database error\")\n... )\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class SymbolAttachmentError(KgFoundryError):\n    \"\"\"Error during symbol attachment to modules in catalog.\n\n    Raised when symbol attachment to modules in the catalog fails. Uses error\n    code SYMBOL_ATTACHMENT_ERROR and HTTP status 500 (Internal Server Error).\n\n    Creates a SymbolAttachmentError with SYMBOL_ATTACHMENT_ERROR error\n    code and HTTP status 500.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the symbol attachment failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the attachment failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise SymbolAttachmentError(\n    ...     \"Failed to attach symbols to module\", cause=sqlite3.DatabaseError(\"Database error\")\n    ... )\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.SYMBOL_ATTACHMENT_ERROR,\n            http_status=500,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SymbolAttachmentError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.SymbolAttachmentError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsunsupportedmimeerror","title":"kgfoundry_common.errors.exceptions.UnsupportedMIMEError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.UnsupportedMIMEError","title":"<code>kgfoundry_common.errors.exceptions.UnsupportedMIMEError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error for unsupported MIME types.</p> <p>Raised when a file or resource has an unsupported MIME type. Uses error code UNSUPPORTED_MIME and HTTP status 415 (Unsupported Media Type).</p> <p>Creates an UnsupportedMIMEError with UNSUPPORTED_MIME error code and HTTP status 415.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the unsupported MIME type.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the error. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise UnsupportedMIMEError(\"application/x-unknown is not supported\")\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class UnsupportedMIMEError(KgFoundryError):\n    \"\"\"Error for unsupported MIME types.\n\n    Raised when a file or resource has an unsupported MIME type. Uses error\n    code UNSUPPORTED_MIME and HTTP status 415 (Unsupported Media Type).\n\n    Creates an UnsupportedMIMEError with UNSUPPORTED_MIME error code\n    and HTTP status 415.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the unsupported MIME type.\n    cause : Exception | None, optional\n        Underlying exception that caused the error. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise UnsupportedMIMEError(\"application/x-unknown is not supported\")\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.UNSUPPORTED_MIME,\n            http_status=415,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.UnsupportedMIMEError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.UnsupportedMIMEError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptionsvectorsearcherror","title":"kgfoundry_common.errors.exceptions.VectorSearchError","text":"<p>Bases: KgFoundryError</p>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.VectorSearchError","title":"<code>kgfoundry_common.errors.exceptions.VectorSearchError</code>","text":"<p>               Bases: <code>KgFoundryError</code></p> <p>Error during vector search operations.</p> <p>Raised when vector search operations fail. Uses error code VECTOR_SEARCH_ERROR and HTTP status 503 (Service Unavailable).</p> <p>Creates a VectorSearchError with VECTOR_SEARCH_ERROR error code and HTTP status 503.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the search failure.</p> required <code>cause</code> <code>Exception | None</code> <p>Underlying exception that caused the search failure. Defaults to None.</p> <code>None</code> <code>context</code> <code>Mapping[str, object] | None</code> <p>Additional context dictionary for error details. Defaults to None.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise VectorSearchError(\"Search failed\", cause=RuntimeError(\"Index not loaded\"))\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>class VectorSearchError(KgFoundryError):\n    \"\"\"Error during vector search operations.\n\n    Raised when vector search operations fail. Uses error code VECTOR_SEARCH_ERROR\n    and HTTP status 503 (Service Unavailable).\n\n    Creates a VectorSearchError with VECTOR_SEARCH_ERROR error code and HTTP status 503.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the search failure.\n    cause : Exception | None, optional\n        Underlying exception that caused the search failure. Defaults to None.\n    context : Mapping[str, object] | None, optional\n        Additional context dictionary for error details. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise VectorSearchError(\"Search failed\", cause=RuntimeError(\"Index not loaded\"))\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        cause: Exception | None = None,\n        context: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        super().__init__(\n            message,\n            code=ErrorCode.VECTOR_SEARCH_ERROR,\n            http_status=503,\n            cause=cause,\n            context=context,\n        )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.VectorSearchError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions.VectorSearchError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_commonerrorsexceptions_coerce_error_config","title":"kgfoundry_common.errors.exceptions._coerce_error_config","text":""},{"location":"modules/kgfoundry_common.errors.exceptions/#kgfoundry_common.errors.exceptions._coerce_error_config","title":"<code>kgfoundry_common.errors.exceptions._coerce_error_config(config, legacy_kwargs)</code>","text":"Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def _coerce_error_config(\n    config: KgFoundryErrorConfig | None,\n    legacy_kwargs: dict[str, object],\n) -&gt; KgFoundryErrorConfig:\n    if config is not None:\n        if legacy_kwargs:\n            unexpected = \", \".join(sorted(legacy_kwargs))\n            message = (\n                f\"KgFoundryError received both 'config' and legacy keyword arguments: {unexpected}\"\n            )\n            raise TypeError(message)\n        return config\n\n    unexpected_keys = set(legacy_kwargs) - set(_KNOWN_CONFIG_KEYS)\n    if unexpected_keys:\n        unexpected = \", \".join(sorted(unexpected_keys))\n        message = f\"KgFoundryError got unexpected keyword arguments: {unexpected}\"\n        raise TypeError(message)\n\n    code = legacy_kwargs.get(\"code\", ErrorCode.RUNTIME_ERROR)\n    http_status = legacy_kwargs.get(\"http_status\", 500)\n    log_level = legacy_kwargs.get(\"log_level\", logging.ERROR)\n    cause = legacy_kwargs.get(\"cause\")\n    context = legacy_kwargs.get(\"context\")\n\n    context_mapping: Mapping[str, object] | None\n    if context is None:\n        context_mapping = None\n    elif isinstance(context, Mapping):\n        context_mapping = context\n    else:\n        message = \"context must be a mapping when provided\"\n        raise TypeError(message)\n\n    if not isinstance(code, ErrorCode):\n        message = \"code must be an instance of ErrorCode\"\n        raise TypeError(message)\n    if not isinstance(http_status, int):\n        message = \"http_status must be an int\"\n        raise TypeError(message)\n    if not isinstance(log_level, int):\n        message = \"log_level must be an int\"\n        raise TypeError(message)\n    if cause is not None and not isinstance(cause, Exception):\n        message = \"cause must be an Exception when provided\"\n        raise TypeError(message)\n\n    return KgFoundryErrorConfig(\n        code=code,\n        http_status=http_status,\n        log_level=log_level,\n        cause=cause,\n        context=context_mapping,\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.http/","title":"kgfoundry_common.errors.http","text":""},{"location":"modules/kgfoundry_common.errors.http/#kgfoundry_commonerrorshttp","title":"kgfoundry_common.errors.http","text":"<p>HTTP adapters for Problem Details exception handling.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.errors.http/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.errors.http__future__.annotationsasynciofastapi.FastAPIfastapi.Requestfastapi.responses.JSONResponsekgfoundry_common.errors.exceptions.KgFoundryErrorkgfoundry_common.fastapi_helpers.typed_exception_handlerkgfoundry_common.logging.get_loggerkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.problem_details.ProblemDetailstyping.TYPE_CHECKINGkgfoundry_common.errors.http code <p>See the full diagram: kgfoundry_common.errors.http</p>"},{"location":"modules/kgfoundry_common.errors.http/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.errors.http.problem_details_response</li> <li>kgfoundry_common.errors.http.register_problem_details_handler</li> </ul>"},{"location":"modules/kgfoundry_common.errors.http/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>asyncio</code>, <code>fastapi.FastAPI</code>, <code>fastapi.Request</code>, <code>fastapi.responses.JSONResponse</code>, <code>kgfoundry_common.errors.exceptions.KgFoundryError</code>, <code>kgfoundry_common.fastapi_helpers.typed_exception_handler</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.problem_details.ProblemDetails</code>, <code>typing.TYPE_CHECKING</code></p>"},{"location":"modules/kgfoundry_common.errors.http/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.errors.http/#kgfoundry_commonerrorshttpproblem_details_response","title":"kgfoundry_common.errors.http.problem_details_response","text":""},{"location":"modules/kgfoundry_common.errors.http/#kgfoundry_common.errors.http.problem_details_response","title":"<code>kgfoundry_common.errors.http.problem_details_response(error, request=None)</code>","text":"<p>Convert KgFoundryError to RFC 9457 Problem Details JSONResponse.</p> <p>Converts a KgFoundryError exception into a FastAPI JSONResponse conforming to RFC 9457 Problem Details format, including appropriate HTTP status code and content type headers.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>KgFoundryError</code> <p>Exception to convert to Problem Details response.</p> required <code>request</code> <code>Request | None</code> <p>FastAPI request object for generating instance URI. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>JSONResponse</code> <p>Problem Details JSON response with appropriate status code and Content-Type header.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.errors import DownloadError\n&gt;&gt;&gt; from kgfoundry_common.errors.http import problem_details_response\n&gt;&gt;&gt; error = DownloadError(\"Download failed\")\n&gt;&gt;&gt; response = problem_details_response(error)\n&gt;&gt;&gt; assert response.status_code == 503\n&gt;&gt;&gt; assert \"type\" in response.body.decode()\n</code></pre> Source code in <code>src/kgfoundry_common/errors/http.py</code> <pre><code>def problem_details_response(\n    error: KgFoundryError,\n    request: Request | None = None,\n) -&gt; JSONResponse:\n    \"\"\"Convert KgFoundryError to RFC 9457 Problem Details JSONResponse.\n\n    Converts a KgFoundryError exception into a FastAPI JSONResponse\n    conforming to RFC 9457 Problem Details format, including appropriate\n    HTTP status code and content type headers.\n\n    Parameters\n    ----------\n    error : KgFoundryError\n        Exception to convert to Problem Details response.\n    request : Request | None, optional\n        FastAPI request object for generating instance URI. Defaults to None.\n\n    Returns\n    -------\n    JSONResponse\n        Problem Details JSON response with appropriate status code and\n        Content-Type header.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.errors import DownloadError\n    &gt;&gt;&gt; from kgfoundry_common.errors.http import problem_details_response\n    &gt;&gt;&gt; error = DownloadError(\"Download failed\")\n    &gt;&gt;&gt; response = problem_details_response(error)\n    &gt;&gt;&gt; assert response.status_code == 503\n    &gt;&gt;&gt; assert \"type\" in response.body.decode()\n    \"\"\"\n    instance = None\n    if request:\n        instance = str(request.url.path)\n        if request.url.query:\n            instance += f\"?{request.url.query}\"\n\n    details: ProblemDetails = error.to_problem_details(instance=instance)\n\n    # Log the error at appropriate level\n    logger.log(error.log_level, \"Error: %s\", error.message, exc_info=error.__cause__)\n\n    return JSONResponse(\n        status_code=error.http_status,\n        content=details,\n        headers={\n            \"Content-Type\": \"application/problem+json\",\n        },\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors.http/#kgfoundry_commonerrorshttpregister_problem_details_handler","title":"kgfoundry_common.errors.http.register_problem_details_handler","text":""},{"location":"modules/kgfoundry_common.errors.http/#kgfoundry_common.errors.http.register_problem_details_handler","title":"<code>kgfoundry_common.errors.http.register_problem_details_handler(app)</code>","text":"<p>Register FastAPI exception handler for KgFoundryError.</p> Source code in <code>src/kgfoundry_common/errors/http.py</code> <pre><code>def register_problem_details_handler(app: FastAPI) -&gt; None:\n    \"\"\"Register FastAPI exception handler for KgFoundryError.\"\"\"\n\n    async def _handler(request: Request, exc: KgFoundryError) -&gt; JSONResponse:\n        return await asyncio.to_thread(problem_details_response, exc, request)\n\n    typed_exception_handler(\n        app,\n        KgFoundryError,\n        _handler,\n        name=\"kgfoundry_error_handler\",\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/","title":"kgfoundry_common.errors","text":""},{"location":"modules/kgfoundry_common.errors/#kgfoundry_commonerrors","title":"kgfoundry_common.errors","text":"<p>Exception hierarchy and Problem Details support</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.errors/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class ExceptionHandlerProtocol\n    class Protocol\n    Protocol &lt;|-- ExceptionHandlerProtocol\n    class FastAPIProtocol\n    Protocol &lt;|-- FastAPIProtocol\n    class JSONResponseProtocol\n    Protocol &lt;|-- JSONResponseProtocol\n    class ProblemDetailsResponse\n    Protocol &lt;|-- ProblemDetailsResponse\n    class RegisterProblemDetailsHandler\n    Protocol &lt;|-- RegisterProblemDetailsHandler\n    class RequestProtocol\n    Protocol &lt;|-- RequestProtocol\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.errors__future__.annotationskgfoundry_common.errors.codes.BASE_TYPE_URIkgfoundry_common.errors.codes.ErrorCodekgfoundry_common.errors.codes.get_type_urikgfoundry_common.errors.exceptions.AgentCatalogSearchErrorkgfoundry_common.errors.exceptions.ArtifactDependencyErrorkgfoundry_common.errors.exceptions.ArtifactDeserializationErrorkgfoundry_common.errors.exceptions.ArtifactModelErrorkgfoundry_common.errors.exceptions.ArtifactSerializationErrorkgfoundry_common.errors.exceptions.ArtifactValidationErrorkgfoundry_common.errors.exceptions.CatalogLoadErrorkgfoundry_common.errors.exceptions.CatalogSessionErrorkgfoundry_common.errors.exceptions.ChunkingErrorkgfoundry_common.errors.exceptions.ConfigurationErrorkgfoundry_common.errors.exceptions.DeserializationErrorkgfoundry_common.errors.exceptions.DoclingErrorkgfoundry_common.errors.exceptions.DownloadErrorkgfoundry_common.errors.exceptions.EmbeddingErrorkgfoundry_common.errors.exceptions.IndexBuildErrorkgfoundry_common.errors.exceptions.KgFoundryErrorkgfoundry_common.errors.exceptions.LinkerCalibrationErrorkgfoundry_common.errors.exceptions.Neo4jErrorkgfoundry_common.errors.exceptions.OCRTimeoutErrorkgfoundry_common.errors.exceptions.OntologyParseErrorkgfoundry_common.errors.exceptions.RegistryErrorkgfoundry_common.errors.exceptions.RetryExhaustedErrorkgfoundry_common.errors.exceptions.SchemaValidationErrorkgfoundry_common.errors.exceptions.SerializationErrorkgfoundry_common.errors.exceptions.SettingsErrorkgfoundry_common.errors.exceptions.SpladeOOMErrorkgfoundry_common.errors.exceptions.SymbolAttachmentErrorkgfoundry_common.errors.exceptions.UnsupportedMIMEErrorkgfoundry_common.errors.exceptions.VectorSearchErrorkgfoundry_common.errors.http.problem_details_responsekgfoundry_common.errors.http.register_problem_details_handlerkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.navmap_types.NavMaptyping.NoReturntyping.Protocoltyping.castkgfoundry_common.errors code <p>See the full diagram: kgfoundry_common.errors</p>"},{"location":"modules/kgfoundry_common.errors/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.errors.ExceptionHandlerProtocol</li> <li>kgfoundry_common.errors.FastAPIProtocol</li> <li>kgfoundry_common.errors.JSONResponseProtocol</li> <li>kgfoundry_common.errors._missing_problem_details_response</li> <li>kgfoundry_common.errors._missing_register_problem_details_handler</li> <li>kgfoundry_common.errors._protocol_stub</li> </ul>"},{"location":"modules/kgfoundry_common.errors/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.errors.codes.BASE_TYPE_URI</code>, <code>kgfoundry_common.errors.codes.ErrorCode</code>, <code>kgfoundry_common.errors.codes.get_type_uri</code>, <code>kgfoundry_common.errors.exceptions.AgentCatalogSearchError</code>, <code>kgfoundry_common.errors.exceptions.ArtifactDependencyError</code>, <code>kgfoundry_common.errors.exceptions.ArtifactDeserializationError</code>, <code>kgfoundry_common.errors.exceptions.ArtifactModelError</code>, <code>kgfoundry_common.errors.exceptions.ArtifactSerializationError</code>, <code>kgfoundry_common.errors.exceptions.ArtifactValidationError</code>, <code>kgfoundry_common.errors.exceptions.CatalogLoadError</code>, <code>kgfoundry_common.errors.exceptions.CatalogSessionError</code>, <code>kgfoundry_common.errors.exceptions.ChunkingError</code>, <code>kgfoundry_common.errors.exceptions.ConfigurationError</code>, <code>kgfoundry_common.errors.exceptions.DeserializationError</code>, <code>kgfoundry_common.errors.exceptions.DoclingError</code>, <code>kgfoundry_common.errors.exceptions.DownloadError</code>, <code>kgfoundry_common.errors.exceptions.EmbeddingError</code>, <code>kgfoundry_common.errors.exceptions.IndexBuildError</code>, <code>kgfoundry_common.errors.exceptions.KgFoundryError</code>, <code>kgfoundry_common.errors.exceptions.LinkerCalibrationError</code>, <code>kgfoundry_common.errors.exceptions.Neo4jError</code>, <code>kgfoundry_common.errors.exceptions.OCRTimeoutError</code>, <code>kgfoundry_common.errors.exceptions.OntologyParseError</code>, <code>kgfoundry_common.errors.exceptions.RegistryError</code>, <code>kgfoundry_common.errors.exceptions.RetryExhaustedError</code>, <code>kgfoundry_common.errors.exceptions.SchemaValidationError</code>, <code>kgfoundry_common.errors.exceptions.SerializationError</code>, <code>kgfoundry_common.errors.exceptions.SettingsError</code>, <code>kgfoundry_common.errors.exceptions.SpladeOOMError</code>, <code>kgfoundry_common.errors.exceptions.SymbolAttachmentError</code>, <code>kgfoundry_common.errors.exceptions.UnsupportedMIMEError</code>, <code>kgfoundry_common.errors.exceptions.VectorSearchError</code>, <code>kgfoundry_common.errors.http.problem_details_response</code>, <code>kgfoundry_common.errors.http.register_problem_details_handler</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.navmap_types.NavMap</code>, <code>typing.NoReturn</code>, <code>typing.Protocol</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.errors/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.errors/#kgfoundry_commonerrorsexceptionhandlerprotocol","title":"kgfoundry_common.errors.ExceptionHandlerProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors.ExceptionHandlerProtocol","title":"<code>kgfoundry_common.errors.ExceptionHandlerProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Structural type for FastAPI exception handlers.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>class ExceptionHandlerProtocol(Protocol):\n    \"\"\"Structural type for FastAPI exception handlers.\"\"\"\n\n    def __call__(self, *args: object, **kwargs: object) -&gt; object:\n        \"\"\"Process an exception raised within the FastAPI request lifecycle.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors.ExceptionHandlerProtocol.__call__","title":"<code>__call__(*args, **kwargs)</code>","text":"<p>Process an exception raised within the FastAPI request lifecycle.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>def __call__(self, *args: object, **kwargs: object) -&gt; object:\n    \"\"\"Process an exception raised within the FastAPI request lifecycle.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_commonerrorsfastapiprotocol","title":"kgfoundry_common.errors.FastAPIProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors.FastAPIProtocol","title":"<code>kgfoundry_common.errors.FastAPIProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Structural type for FastAPI application instances.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>class FastAPIProtocol(Protocol):\n    \"\"\"Structural type for FastAPI application instances.\"\"\"\n\n    def add_exception_handler(\n        self,\n        exception_class: type[BaseException],\n        handler: ExceptionHandlerProtocol,\n        *,\n        name: str | None = None,\n    ) -&gt; None:\n        \"\"\"Register an exception handler.\"\"\"\n        _protocol_stub(\"add_exception_handler\", self, exception_class, handler, name=name)\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors.FastAPIProtocol.add_exception_handler","title":"<code>add_exception_handler(exception_class, handler, *, name=None)</code>","text":"<p>Register an exception handler.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>def add_exception_handler(\n    self,\n    exception_class: type[BaseException],\n    handler: ExceptionHandlerProtocol,\n    *,\n    name: str | None = None,\n) -&gt; None:\n    \"\"\"Register an exception handler.\"\"\"\n    _protocol_stub(\"add_exception_handler\", self, exception_class, handler, name=name)\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_commonerrorsjsonresponseprotocol","title":"kgfoundry_common.errors.JSONResponseProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors.JSONResponseProtocol","title":"<code>kgfoundry_common.errors.JSONResponseProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Structural type for FastAPI's JSONResponse.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>class JSONResponseProtocol(Protocol):\n    \"\"\"Structural type for FastAPI's JSONResponse.\"\"\"\n\n    status_code: int\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_commonerrorsproblemdetailsresponse","title":"kgfoundry_common.errors.ProblemDetailsResponse","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors.ProblemDetailsResponse","title":"<code>kgfoundry_common.errors.ProblemDetailsResponse</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Callable protocol for Problem Details response helpers.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>class ProblemDetailsResponse(Protocol):\n    \"\"\"Callable protocol for Problem Details response helpers.\"\"\"\n\n    def __call__(\n        self,\n        error: KgFoundryError,\n        request: RequestProtocol | None = None,\n    ) -&gt; JSONResponseProtocol:\n        \"\"\"Convert a KgFoundryError into a JSON-response payload.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors.ProblemDetailsResponse.__call__","title":"<code>__call__(error, request=None)</code>","text":"<p>Convert a KgFoundryError into a JSON-response payload.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>def __call__(\n    self,\n    error: KgFoundryError,\n    request: RequestProtocol | None = None,\n) -&gt; JSONResponseProtocol:\n    \"\"\"Convert a KgFoundryError into a JSON-response payload.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_commonerrorsregisterproblemdetailshandler","title":"kgfoundry_common.errors.RegisterProblemDetailsHandler","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors.RegisterProblemDetailsHandler","title":"<code>kgfoundry_common.errors.RegisterProblemDetailsHandler</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Callable protocol for registering Problem Details handlers.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>class RegisterProblemDetailsHandler(Protocol):\n    \"\"\"Callable protocol for registering Problem Details handlers.\"\"\"\n\n    def __call__(self, app: FastAPIProtocol) -&gt; None:\n        \"\"\"Attach the Problem Details handler to a FastAPI-like application.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors.RegisterProblemDetailsHandler.__call__","title":"<code>__call__(app)</code>","text":"<p>Attach the Problem Details handler to a FastAPI-like application.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>def __call__(self, app: FastAPIProtocol) -&gt; None:\n    \"\"\"Attach the Problem Details handler to a FastAPI-like application.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_commonerrorsrequestprotocol","title":"kgfoundry_common.errors.RequestProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors.RequestProtocol","title":"<code>kgfoundry_common.errors.RequestProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Structural type for FastAPI's Request object.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>class RequestProtocol(Protocol):\n    \"\"\"Structural type for FastAPI's Request object.\"\"\"\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_commonerrors_missing_problem_details_response","title":"kgfoundry_common.errors._missing_problem_details_response","text":""},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors._missing_problem_details_response","title":"<code>kgfoundry_common.errors._missing_problem_details_response(error, request=None)</code>","text":"<p>Raise an informative error when FastAPI dependencies are missing.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>KgFoundryError</code> <p>Error instance (ignored).</p> required <code>request</code> <code>RequestProtocol | None</code> <p>Request instance (ignored).</p> <code>None</code> <p>Returns:</p> Type Description <code>JSONResponseProtocol</code> <p>Never returns; always raises RuntimeError.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>Always raised to indicate missing FastAPI dependency.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>def _missing_problem_details_response(\n    error: KgFoundryError,\n    request: RequestProtocol | None = None,\n) -&gt; JSONResponseProtocol:\n    \"\"\"Raise an informative error when FastAPI dependencies are missing.\n\n    Parameters\n    ----------\n    error : KgFoundryError\n        Error instance (ignored).\n    request : RequestProtocol | None, optional\n        Request instance (ignored).\n\n    Returns\n    -------\n    JSONResponseProtocol\n        Never returns; always raises RuntimeError.\n\n    Raises\n    ------\n    RuntimeError\n        Always raised to indicate missing FastAPI dependency.\n    \"\"\"\n    del error, request\n    message = (\n        \"FastAPI support is not installed. Install kgfoundry[api] to enable \"\n        \"problem details response helpers.\"\n    )\n    raise RuntimeError(message)\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_commonerrors_missing_register_problem_details_handler","title":"kgfoundry_common.errors._missing_register_problem_details_handler","text":""},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors._missing_register_problem_details_handler","title":"<code>kgfoundry_common.errors._missing_register_problem_details_handler(app)</code>","text":"<p>Raise an informative error when FastAPI dependencies are missing.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <code>FastAPIProtocol</code> <p>FastAPI app instance (ignored).</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>Always raised to indicate missing FastAPI dependency.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>def _missing_register_problem_details_handler(app: FastAPIProtocol) -&gt; None:\n    \"\"\"Raise an informative error when FastAPI dependencies are missing.\n\n    Parameters\n    ----------\n    app : FastAPIProtocol\n        FastAPI app instance (ignored).\n\n    Raises\n    ------\n    RuntimeError\n        Always raised to indicate missing FastAPI dependency.\n    \"\"\"\n    del app\n    message = (\n        \"FastAPI support is not installed. Install kgfoundry[api] to enable \"\n        \"Problem Details handlers.\"\n    )\n    raise RuntimeError(message)\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_commonerrors_protocol_stub","title":"kgfoundry_common.errors._protocol_stub","text":""},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors._protocol_stub","title":"<code>kgfoundry_common.errors._protocol_stub(method, *args, **kwargs)</code>","text":"<p>Raise <code>NotImplementedError</code> when a structural protocol leaks to runtime.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>def _protocol_stub(method: str, *args: object, **kwargs: object) -&gt; NoReturn:\n    \"\"\"Raise ``NotImplementedError`` when a structural protocol leaks to runtime.\"\"\"\n    message = (\n        f\"FastAPI protocol method '{method}' must be implemented by the concrete app. \"\n        f\"Received args={args!r}, kwargs={kwargs!r}.\"\n    )\n    raise NotImplementedError(message)\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_commonerrorsproblem_details_response","title":"kgfoundry_common.errors.problem_details_response","text":""},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors.problem_details_response","title":"<code>kgfoundry_common.errors.problem_details_response(error, request=None)</code>","text":"<p>Convert <code>KgFoundryError</code> to a Problem Details response.</p> <p>This wrapper preserves the optional FastAPI dependency while exposing a typed interface that accepts the structural <code>RequestProtocol</code> defined in this module. When FastAPI support is installed, the helper delegates to the implementation in <code>kgfoundry_common.errors.http</code>. Otherwise it raises an informative <code>RuntimeError</code> describing the missing optional dependency.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>KgFoundryError</code> <p>Error instance to convert.</p> required <code>request</code> <code>RequestProtocol | None</code> <p>Optional request instance for context.</p> <code>None</code> <p>Returns:</p> Type Description <code>JSONResponseProtocol</code> <p>Problem Details HTTP response.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>def problem_details_response(\n    error: KgFoundryError,\n    request: RequestProtocol | None = None,\n) -&gt; JSONResponseProtocol:\n    \"\"\"Convert ``KgFoundryError`` to a Problem Details response.\n\n    This wrapper preserves the optional FastAPI dependency while exposing a\n    typed interface that accepts the structural ``RequestProtocol`` defined in\n    this module. When FastAPI support is installed, the helper delegates to the\n    implementation in ``kgfoundry_common.errors.http``. Otherwise it raises an\n    informative ``RuntimeError`` describing the missing optional dependency.\n\n    Parameters\n    ----------\n    error : KgFoundryError\n        Error instance to convert.\n    request : RequestProtocol | None, optional\n        Optional request instance for context.\n\n    Returns\n    -------\n    JSONResponseProtocol\n        Problem Details HTTP response.\n    \"\"\"\n    return _problem_details_response(error, request)\n</code></pre>"},{"location":"modules/kgfoundry_common.errors/#kgfoundry_commonerrorsregister_problem_details_handler","title":"kgfoundry_common.errors.register_problem_details_handler","text":""},{"location":"modules/kgfoundry_common.errors/#kgfoundry_common.errors.register_problem_details_handler","title":"<code>kgfoundry_common.errors.register_problem_details_handler(app)</code>","text":"<p>Register the KgFoundry Problem Details handler on a FastAPI app.</p> Source code in <code>src/kgfoundry_common/errors/__init__.py</code> <pre><code>def register_problem_details_handler(app: FastAPIProtocol) -&gt; None:\n    \"\"\"Register the KgFoundry Problem Details handler on a FastAPI app.\"\"\"\n    _register_problem_details_handler(app)\n</code></pre>"},{"location":"modules/kgfoundry_common.exceptions/","title":"kgfoundry_common.exceptions","text":""},{"location":"modules/kgfoundry_common.exceptions/#kgfoundry_commonexceptions","title":"kgfoundry_common.exceptions","text":"<p>Legacy exception aliases maintained for backwards compatibility</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.exceptions/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.exceptions__future__.annotationskgfoundry_common.errors.DownloadErrorkgfoundry_common.errors.UnsupportedMIMEErrorkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.exceptions code <p>See the full diagram: kgfoundry_common.exceptions</p>"},{"location":"modules/kgfoundry_common.exceptions/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.errors.DownloadError</code>, <code>kgfoundry_common.errors.UnsupportedMIMEError</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p>"},{"location":"modules/kgfoundry_common.fastapi_helpers/","title":"kgfoundry_common.fastapi_helpers","text":""},{"location":"modules/kgfoundry_common.fastapi_helpers/#kgfoundry_commonfastapi_helpers","title":"kgfoundry_common.fastapi_helpers","text":"<p>Typed FastAPI helper utilities with structured logging and timeouts.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.fastapi_helpers/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.fastapi_helpers__future__.annotationsasynciocollections.abc.Callablefastapi.Dependsfastapi.FastAPIfastapi.Requestfastapi.params.Dependskgfoundry_common.logging.get_correlation_idkgfoundry_common.logging.get_loggerkgfoundry_common.logging.with_fieldskgfoundry_common.navmap_loader.load_nav_metadatastarlette.middleware.base.BaseHTTPMiddlewarestarlette.requests.Requeststarlette.responses.Responsestarlette.types.ASGIApptimetypingtyping.TYPE_CHECKINGtyping.castkgfoundry_common.fastapi_helpers code <p>See the full diagram: kgfoundry_common.fastapi_helpers</p>"},{"location":"modules/kgfoundry_common.fastapi_helpers/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.fastapi_helpers._await_with_timeout</li> <li>kgfoundry_common.fastapi_helpers.typed_dependency</li> <li>kgfoundry_common.fastapi_helpers.typed_exception_handler</li> </ul>"},{"location":"modules/kgfoundry_common.fastapi_helpers/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>asyncio</code>, <code>collections.abc.Callable</code>, <code>fastapi.Depends</code>, <code>fastapi.FastAPI</code>, <code>fastapi.Request</code>, <code>fastapi.params.Depends</code>, <code>kgfoundry_common.logging.get_correlation_id</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>kgfoundry_common.logging.with_fields</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>starlette.middleware.base.BaseHTTPMiddleware</code>, <code>starlette.requests.Request</code>, <code>starlette.responses.Response</code>, <code>starlette.types.ASGIApp</code>, <code>time</code>, <code>typing</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.fastapi_helpers/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.fastapi_helpers/#kgfoundry_commonfastapi_helpers_await_with_timeout","title":"kgfoundry_common.fastapi_helpers._await_with_timeout","text":""},{"location":"modules/kgfoundry_common.fastapi_helpers/#kgfoundry_common.fastapi_helpers._await_with_timeout","title":"<code>kgfoundry_common.fastapi_helpers._await_with_timeout(coro, timeout_seconds)</code>  <code>async</code>","text":"<p>Await <code>coro</code> while respecting <code>timeout_seconds</code> when provided.</p> <p>Parameters:</p> Name Type Description Default <code>coro</code> <code>Awaitable[T]</code> <p>Coroutine to await.</p> required <code>timeout_seconds</code> <code>float | None</code> <p>Timeout in seconds, or None for no timeout.</p> required <p>Returns:</p> Type Description <code>T</code> <p>Result of the coroutine.</p> Source code in <code>src/kgfoundry_common/fastapi_helpers.py</code> <pre><code>async def _await_with_timeout[T](coro: t.Awaitable[T], timeout_seconds: float | None) -&gt; T:\n    \"\"\"Await ``coro`` while respecting ``timeout_seconds`` when provided.\n\n    Parameters\n    ----------\n    coro : Awaitable[T]\n        Coroutine to await.\n    timeout_seconds : float | None\n        Timeout in seconds, or None for no timeout.\n\n    Returns\n    -------\n    T\n        Result of the coroutine.\n    \"\"\"\n    if timeout_seconds is None:\n        return await coro\n    return await asyncio.wait_for(coro, timeout_seconds)\n</code></pre>"},{"location":"modules/kgfoundry_common.fastapi_helpers/#kgfoundry_commonfastapi_helperstyped_dependency","title":"kgfoundry_common.fastapi_helpers.typed_dependency","text":""},{"location":"modules/kgfoundry_common.fastapi_helpers/#kgfoundry_common.fastapi_helpers.typed_dependency","title":"<code>kgfoundry_common.fastapi_helpers.typed_dependency(dependency, *, name, timeout=DEFAULT_TIMEOUT_SECONDS)</code>","text":"<p>Return a dependency marker suitable for <code>Annotated</code> parameters.</p> <p>The wrapped dependency records structured logs, includes any correlation ID stored in :mod:<code>kgfoundry_common.logging</code>, and enforces <code>timeout</code>.</p> <p>Parameters:</p> Name Type Description Default <code>dependency</code> <code>Callable[P, Awaitable[T]]</code> <p>Dependency function to wrap.</p> required <code>name</code> <code>str</code> <p>Operation name for logging.</p> required <code>timeout</code> <code>float | None</code> <p>Timeout in seconds. Defaults to DEFAULT_TIMEOUT_SECONDS.</p> <code>DEFAULT_TIMEOUT_SECONDS</code> <p>Returns:</p> Type Description <code>object</code> <p>Dependency marker for use in Annotated parameters.</p> Source code in <code>src/kgfoundry_common/fastapi_helpers.py</code> <pre><code>def typed_dependency[**P, T](\n    dependency: Callable[P, t.Awaitable[T]],\n    *,\n    name: str,\n    timeout: float | None = DEFAULT_TIMEOUT_SECONDS,\n) -&gt; object:\n    \"\"\"Return a dependency marker suitable for ``Annotated`` parameters.\n\n    The wrapped dependency records structured logs, includes any correlation ID\n    stored in :mod:`kgfoundry_common.logging`, and enforces ``timeout``.\n\n    Parameters\n    ----------\n    dependency : Callable[P, Awaitable[T]]\n        Dependency function to wrap.\n    name : str\n        Operation name for logging.\n    timeout : float | None, optional\n        Timeout in seconds. Defaults to DEFAULT_TIMEOUT_SECONDS.\n\n    Returns\n    -------\n    object\n        Dependency marker for use in Annotated parameters.\n    \"\"\"\n\n    async def _instrumented(*args: P.args, **kwargs: P.kwargs) -&gt; T:\n        \"\"\"Invoke ``dependency`` with logging, metrics, and timeout enforcement.\n\n        Parameters\n        ----------\n        *args : P.args\n            Positional arguments for the dependency.\n        **kwargs : P.kwargs\n            Keyword arguments for the dependency.\n\n        Returns\n        -------\n        T\n            Result from the dependency function.\n        \"\"\"\n        correlation_id = get_correlation_id()\n        with with_fields(logger, operation=name, correlation_id=correlation_id) as log:\n            start = time.perf_counter()\n            log.info(\"dependency.start\", extra={\"status\": \"started\"})\n            try:\n                result = await _await_with_timeout(\n                    dependency(*args, **kwargs),\n                    timeout_seconds=timeout,\n                )\n            except Exception:  # pragma: no cover - propagated to caller\n                duration_ms = (time.perf_counter() - start) * 1000.0\n                log.exception(\n                    \"dependency.error\",\n                    extra={\"status\": \"error\", \"duration_ms\": duration_ms},\n                )\n                raise\n            duration_ms = (time.perf_counter() - start) * 1000.0\n            log.info(\n                \"dependency.success\",\n                extra={\"status\": \"success\", \"duration_ms\": duration_ms},\n            )\n            return result\n\n    marker: DependsMarker = Depends(_instrumented)\n    return cast(\"object\", marker)\n</code></pre>"},{"location":"modules/kgfoundry_common.fastapi_helpers/#kgfoundry_commonfastapi_helperstyped_exception_handler","title":"kgfoundry_common.fastapi_helpers.typed_exception_handler","text":""},{"location":"modules/kgfoundry_common.fastapi_helpers/#kgfoundry_common.fastapi_helpers.typed_exception_handler","title":"<code>kgfoundry_common.fastapi_helpers.typed_exception_handler(app, exception_type, handler, *, name, timeout=DEFAULT_TIMEOUT_SECONDS)</code>","text":"<p>Register <code>handler</code> for <code>exception_type</code> with logging and timeouts.</p> Source code in <code>src/kgfoundry_common/fastapi_helpers.py</code> <pre><code>def typed_exception_handler[E: Exception](\n    app: FastAPI,\n    exception_type: type[E],\n    handler: Callable[[Request, E], t.Awaitable[Response]],\n    *,\n    name: str,\n    timeout: float | None = DEFAULT_TIMEOUT_SECONDS,\n) -&gt; None:\n    \"\"\"Register ``handler`` for ``exception_type`` with logging and timeouts.\"\"\"\n\n    async def _wrapped(request: Request, exc: E) -&gt; Response:\n        \"\"\"Execute ``handler`` while recording structured timing metadata.\n\n        Parameters\n        ----------\n        request : Request\n            HTTP request object.\n        exc : E\n            Exception instance.\n\n        Returns\n        -------\n        Response\n            Response from the exception handler.\n        \"\"\"\n        correlation_id = get_correlation_id()\n        with with_fields(logger, operation=name, correlation_id=correlation_id) as log:\n            start = time.perf_counter()\n            exception_name = cast(\n                \"str\",\n                getattr(exception_type, \"__name__\", exception_type.__class__.__name__),\n            )\n            log.info(\n                \"exception_handler.start\",\n                extra={\"status\": \"started\", \"exception_type\": exception_name},\n            )\n            try:\n                result = await _await_with_timeout(\n                    handler(request, exc),\n                    timeout_seconds=timeout,\n                )\n            except Exception:  # pragma: no cover - FastAPI surfaces this\n                duration_ms = (time.perf_counter() - start) * 1000.0\n                log.exception(\n                    \"exception_handler.error\",\n                    extra={\"status\": \"error\", \"duration_ms\": duration_ms},\n                )\n                raise\n            duration_ms = (time.perf_counter() - start) * 1000.0\n            log.info(\n                \"exception_handler.success\",\n                extra={\"status\": \"success\", \"duration_ms\": duration_ms},\n            )\n            return result\n\n    handler_callable = cast(\"Callable[[Request, Exception], t.Awaitable[Response]]\", _wrapped)\n    app.add_exception_handler(exception_type, handler_callable)\n</code></pre>"},{"location":"modules/kgfoundry_common.fastapi_helpers/#kgfoundry_commonfastapi_helperstyped_middleware","title":"kgfoundry_common.fastapi_helpers.typed_middleware","text":""},{"location":"modules/kgfoundry_common.fastapi_helpers/#kgfoundry_common.fastapi_helpers.typed_middleware","title":"<code>kgfoundry_common.fastapi_helpers.typed_middleware(app, middleware_class, *factory_args, name, timeout=DEFAULT_TIMEOUT_SECONDS, **options)</code>","text":"<p>Register <code>middleware_class</code> with instrumentation and timeouts.</p> Source code in <code>src/kgfoundry_common/fastapi_helpers.py</code> <pre><code>def typed_middleware(\n    app: FastAPI,\n    middleware_class: MiddlewareFactory,\n    *factory_args: object,\n    name: str,\n    timeout: float | None = DEFAULT_TIMEOUT_SECONDS,\n    **options: object,\n) -&gt; None:\n    \"\"\"Register ``middleware_class`` with instrumentation and timeouts.\"\"\"\n\n    class _InstrumentedMiddleware(BaseHTTPMiddleware):\n        \"\"\"Middleware wrapper that adds logging, metrics, and timeout controls.\"\"\"\n\n        def __init__(self, app: ASGIApp) -&gt; None:\n            \"\"\"Instantiate the wrapped middleware and record configuration.\"\"\"\n            self._delegate = middleware_class(app, *factory_args, **options)\n            super().__init__(app)\n\n        async def dispatch(\n            self,\n            request: StarletteRequest,\n            call_next: Callable[[StarletteRequest], t.Awaitable[Response]],\n        ) -&gt; Response:\n            \"\"\"Process ``request`` while capturing timing and error metrics.\n\n            Parameters\n            ----------\n            request : StarletteRequest\n                HTTP request to process.\n            call_next : Callable[[StarletteRequest], Awaitable[Response]]\n                Next middleware/handler in the chain.\n\n            Returns\n            -------\n            Response\n                HTTP response.\n            \"\"\"\n            correlation_id = get_correlation_id()\n            with with_fields(logger, operation=name, correlation_id=correlation_id) as log:\n                start = time.perf_counter()\n                log.info(\"middleware.start\", extra={\"status\": \"started\"})\n                try:\n                    response = await _await_with_timeout(\n                        self._delegate.dispatch(request, call_next),\n                        timeout_seconds=timeout,\n                    )\n                except Exception:  # pragma: no cover - propagated to caller\n                    duration_ms = (time.perf_counter() - start) * 1000.0\n                    log.exception(\n                        \"middleware.error\",\n                        extra={\"status\": \"error\", \"duration_ms\": duration_ms},\n                    )\n                    raise\n\n                duration_ms = (time.perf_counter() - start) * 1000.0\n                log.info(\n                    \"middleware.success\",\n                    extra={\"status\": \"success\", \"duration_ms\": duration_ms},\n                )\n                return response\n\n    name_attr: object = getattr(middleware_class, \"__name__\", None)\n    original_name = name_attr if isinstance(name_attr, str) else middleware_class.__class__.__name__\n    _InstrumentedMiddleware.__name__ = original_name\n    app.add_middleware(_InstrumentedMiddleware)\n</code></pre>"},{"location":"modules/kgfoundry_common.fs/","title":"kgfoundry_common.fs","text":""},{"location":"modules/kgfoundry_common.fs/#kgfoundry_commonfs","title":"kgfoundry_common.fs","text":"<p>Shared utilities and data structures used across KgFoundry services and tools.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.fs/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.fs__future__.annotationskgfoundry_common.logging.get_loggerpathlib.Pathsystempfiletyping.Literalkgfoundry_common.fs code <p>See the full diagram: kgfoundry_common.fs</p>"},{"location":"modules/kgfoundry_common.fs/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.fs.atomic_write</li> <li>kgfoundry_common.fs.ensure_dir</li> <li>kgfoundry_common.fs.read_text</li> </ul>"},{"location":"modules/kgfoundry_common.fs/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>pathlib.Path</code>, <code>sys</code>, <code>tempfile</code>, <code>typing.Literal</code></p>"},{"location":"modules/kgfoundry_common.fs/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.fs/#kgfoundry_commonfsatomic_write","title":"kgfoundry_common.fs.atomic_write","text":""},{"location":"modules/kgfoundry_common.fs/#kgfoundry_common.fs.atomic_write","title":"<code>kgfoundry_common.fs.atomic_write(path, data, mode='text')</code>","text":"<p>Write data atomically using a temporary file and rename.</p> <p>Writes data to a file using an atomic operation: first writes to a temporary file in the same directory, then renames it to the final path. This ensures that the final file is either completely written or not present, preventing partial writes in case of crashes.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Final file path to write. Parent directories will be created if needed.</p> required <code>data</code> <code>str | bytes</code> <p>Content to write. Must be str for text mode or bytes for binary mode.</p> required <code>mode</code> <code>Literal['text', 'binary']</code> <p>Write mode. Use \"text\" for string data (UTF-8 encoding) or \"binary\" for bytes data. Defaults to \"text\".</p> <code>'text'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If mode is \"text\" but data is bytes, or mode is \"binary\" but data is str.</p> Notes <p>Filesystem errors raised by :func:<code>ensure_dir</code>, :func:<code>tempfile.NamedTemporaryFile</code>, or :meth:<code>pathlib.Path.replace</code> propagate to the caller.</p> Notes <p>The atomic operation ensures that concurrent readers never see a partially written file. The temporary file is created in the same directory as the final path to ensure the rename operation succeeds (requires same filesystem).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; atomic_write(Path(\"/tmp/atomic.txt\"), \"safe content\")\n&gt;&gt;&gt; read_text(Path(\"/tmp/atomic.txt\"))\n'safe content'\n</code></pre> Source code in <code>src/kgfoundry_common/fs.py</code> <pre><code>def atomic_write(\n    path: Path,\n    data: str | bytes,\n    mode: Literal[\"text\", \"binary\"] = \"text\",\n) -&gt; None:\n    \"\"\"Write data atomically using a temporary file and rename.\n\n    Writes data to a file using an atomic operation: first writes to a temporary\n    file in the same directory, then renames it to the final path. This ensures\n    that the final file is either completely written or not present, preventing\n    partial writes in case of crashes.\n\n    Parameters\n    ----------\n    path : Path\n        Final file path to write. Parent directories will be created if needed.\n    data : str | bytes\n        Content to write. Must be str for text mode or bytes for binary mode.\n    mode : Literal['text', 'binary'], optional\n        Write mode. Use \"text\" for string data (UTF-8 encoding) or \"binary\"\n        for bytes data. Defaults to \"text\".\n\n    Raises\n    ------\n    ValueError\n        If mode is \"text\" but data is bytes, or mode is \"binary\" but data is str.\n\n    Notes\n    -----\n    Filesystem errors raised by :func:`ensure_dir`, :func:`tempfile.NamedTemporaryFile`,\n    or :meth:`pathlib.Path.replace` propagate to the caller.\n\n    Notes\n    -----\n    The atomic operation ensures that concurrent readers never see a partially\n    written file. The temporary file is created in the same directory as the\n    final path to ensure the rename operation succeeds (requires same filesystem).\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; atomic_write(Path(\"/tmp/atomic.txt\"), \"safe content\")\n    &gt;&gt;&gt; read_text(Path(\"/tmp/atomic.txt\"))\n    'safe content'\n    \"\"\"\n    ensure_dir(path.parent, exist_ok=True)\n    tmp_path: Path | None = None\n    try:\n        dir_arg = str(path.parent) if path.parent else None\n        if mode == \"text\":\n            if not isinstance(data, str):\n                msg = \"text mode requires str data\"\n                raise ValueError(msg)\n            with tempfile.NamedTemporaryFile(\n                mode=\"w\",\n                dir=dir_arg,\n                delete=False,\n                encoding=\"utf-8\",\n            ) as temp_file:\n                tmp_path = Path(temp_file.name)\n                temp_file.write(data)\n                temp_file.flush()\n        else:\n            if not isinstance(data, bytes):\n                msg = \"binary mode requires bytes data\"\n                raise ValueError(msg)\n            with tempfile.NamedTemporaryFile(\n                mode=\"wb\",\n                dir=dir_arg,\n                delete=False,\n            ) as temp_file:\n                tmp_path = Path(temp_file.name)\n                temp_file.write(data)\n                temp_file.flush()\n        if tmp_path is not None:\n            tmp_path.replace(path)\n    finally:\n        if tmp_path is not None and sys.exc_info()[0] is not None:\n            tmp_path.unlink(missing_ok=True)\n</code></pre>"},{"location":"modules/kgfoundry_common.fs/#kgfoundry_commonfsensure_dir","title":"kgfoundry_common.fs.ensure_dir","text":""},{"location":"modules/kgfoundry_common.fs/#kgfoundry_common.fs.ensure_dir","title":"<code>kgfoundry_common.fs.ensure_dir(path, *, exist_ok=True)</code>","text":"<p>Create directory if it does not exist, including parent directories.</p> <p>Creates the specified directory path and all intermediate parent directories if they do not exist. Uses pathlib's mkdir with parents=True for atomic directory creation.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Directory path to create. May be absolute or relative.</p> required <code>exist_ok</code> <code>bool</code> <p>If True, do not raise an exception if the directory already exists. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Path</code> <p>The created or existing directory path (same as input).</p> Notes <p>This call delegates to :meth:<code>pathlib.Path.mkdir</code>. Filesystem-level errors such as <code>PermissionError</code> or <code>FileExistsError</code> propagate unchanged.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; ensure_dir(Path(\"/tmp/data/subdir\"))\nPath('/tmp/data/subdir')\n</code></pre> Source code in <code>src/kgfoundry_common/fs.py</code> <pre><code>def ensure_dir(path: Path, *, exist_ok: bool = True) -&gt; Path:\n    \"\"\"Create directory if it does not exist, including parent directories.\n\n    Creates the specified directory path and all intermediate parent directories\n    if they do not exist. Uses pathlib's mkdir with parents=True for atomic\n    directory creation.\n\n    Parameters\n    ----------\n    path : Path\n        Directory path to create. May be absolute or relative.\n    exist_ok : bool, optional\n        If True, do not raise an exception if the directory already exists.\n        Defaults to True.\n\n    Returns\n    -------\n    Path\n        The created or existing directory path (same as input).\n\n    Notes\n    -----\n    This call delegates to :meth:`pathlib.Path.mkdir`. Filesystem-level errors\n    such as ``PermissionError`` or ``FileExistsError`` propagate unchanged.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; ensure_dir(Path(\"/tmp/data/subdir\"))\n    Path('/tmp/data/subdir')\n    \"\"\"\n    path.mkdir(parents=True, exist_ok=exist_ok)\n    return path\n</code></pre>"},{"location":"modules/kgfoundry_common.fs/#kgfoundry_commonfsread_text","title":"kgfoundry_common.fs.read_text","text":""},{"location":"modules/kgfoundry_common.fs/#kgfoundry_common.fs.read_text","title":"<code>kgfoundry_common.fs.read_text(path, encoding='utf-8')</code>","text":"<p>Read text file contents with explicit encoding.</p> <p>Reads a text file and returns its contents as a string. Uses the specified encoding to decode bytes. This is a convenience wrapper around pathlib.Path.read_text().</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>File path to read. Must exist and be readable.</p> required <code>encoding</code> <code>str</code> <p>Text encoding to use for decoding bytes. Defaults to \"utf-8\".</p> <code>'utf-8'</code> <p>Returns:</p> Type Description <code>str</code> <p>File contents as a decoded string.</p> Notes <p>This helper delegates to :meth:<code>pathlib.Path.read_text</code>, so filesystem errors such as <code>FileNotFoundError</code> or <code>PermissionError</code> will surface unchanged.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; write_text(Path(\"/tmp/test.txt\"), \"hello\")\n&gt;&gt;&gt; read_text(Path(\"/tmp/test.txt\"))\n'hello'\n</code></pre> Source code in <code>src/kgfoundry_common/fs.py</code> <pre><code>def read_text(path: Path, encoding: str = \"utf-8\") -&gt; str:\n    \"\"\"Read text file contents with explicit encoding.\n\n    Reads a text file and returns its contents as a string. Uses the specified\n    encoding to decode bytes. This is a convenience wrapper around\n    pathlib.Path.read_text().\n\n    Parameters\n    ----------\n    path : Path\n        File path to read. Must exist and be readable.\n    encoding : str, optional\n        Text encoding to use for decoding bytes. Defaults to \"utf-8\".\n\n    Returns\n    -------\n    str\n        File contents as a decoded string.\n\n    Notes\n    -----\n    This helper delegates to :meth:`pathlib.Path.read_text`, so filesystem\n    errors such as ``FileNotFoundError`` or ``PermissionError`` will surface\n    unchanged.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; write_text(Path(\"/tmp/test.txt\"), \"hello\")\n    &gt;&gt;&gt; read_text(Path(\"/tmp/test.txt\"))\n    'hello'\n    \"\"\"\n    return path.read_text(encoding=encoding)\n</code></pre>"},{"location":"modules/kgfoundry_common.fs/#kgfoundry_commonfssafe_join","title":"kgfoundry_common.fs.safe_join","text":""},{"location":"modules/kgfoundry_common.fs/#kgfoundry_common.fs.safe_join","title":"<code>kgfoundry_common.fs.safe_join(base, *parts)</code>","text":"<p>Join path components safely, preventing directory traversal.</p> <p>Joins path components relative to a base directory and validates that the resolved path does not escape the base directory. This prevents path traversal attacks by ensuring all resolved paths are within the base.</p> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>Path</code> <p>Base directory path. Must be absolute to enable validation.</p> required <code>*parts</code> <code>str | Path</code> <p>Relative path components to join. These are joined relative to base.</p> <code>()</code> <p>Returns:</p> Type Description <code>Path</code> <p>Resolved absolute path that is guaranteed to be within the base directory.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If base is not absolute or if the resolved path escapes the base directory (path traversal attempt).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; base = Path(\"/safe/base\")\n&gt;&gt;&gt; safe_join(base, \"file.txt\")\nPath('/safe/base/file.txt')\n&gt;&gt;&gt; safe_join(base, \"..\", \"etc\", \"passwd\")\nValueError: Path escapes base directory\n</code></pre> Source code in <code>src/kgfoundry_common/fs.py</code> <pre><code>def safe_join(base: Path, *parts: str | Path) -&gt; Path:\n    \"\"\"Join path components safely, preventing directory traversal.\n\n    Joins path components relative to a base directory and validates that the\n    resolved path does not escape the base directory. This prevents path\n    traversal attacks by ensuring all resolved paths are within the base.\n\n    Parameters\n    ----------\n    base : Path\n        Base directory path. Must be absolute to enable validation.\n    *parts : str | Path\n        Relative path components to join. These are joined relative to base.\n\n    Returns\n    -------\n    Path\n        Resolved absolute path that is guaranteed to be within the base\n        directory.\n\n    Raises\n    ------\n    ValueError\n        If base is not absolute or if the resolved path escapes the base\n        directory (path traversal attempt).\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; base = Path(\"/safe/base\")\n    &gt;&gt;&gt; safe_join(base, \"file.txt\")\n    Path('/safe/base/file.txt')\n    &gt;&gt;&gt; safe_join(base, \"..\", \"etc\", \"passwd\")  # doctest: +SKIP\n    ValueError: Path escapes base directory\n    \"\"\"\n    if not base.is_absolute():\n        msg = f\"Base path must be absolute: {base}\"\n        raise ValueError(msg)\n    resolved = (base / Path(*parts)).resolve()\n    try:\n        resolved.relative_to(base.resolve())\n    except ValueError as exc:\n        msg = f\"Path escapes base directory: {resolved}\"\n        raise ValueError(msg) from exc\n    return resolved\n</code></pre>"},{"location":"modules/kgfoundry_common.fs/#kgfoundry_commonfswrite_text","title":"kgfoundry_common.fs.write_text","text":""},{"location":"modules/kgfoundry_common.fs/#kgfoundry_common.fs.write_text","title":"<code>kgfoundry_common.fs.write_text(path, data, encoding='utf-8')</code>","text":"<p>Write text data to a file, creating parent directories if needed.</p> <p>Writes text content to a file, encoding it using the specified encoding. Creates parent directories if they do not exist. Uses pathlib's write_text for atomic file operations.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>File path to write. Parent directories will be created if needed.</p> required <code>data</code> <code>str</code> <p>Text content to write. Will be encoded using the specified encoding.</p> required <code>encoding</code> <code>str</code> <p>Text encoding to use for encoding the string to bytes. Defaults to \"utf-8\".</p> <code>'utf-8'</code> Notes <p>Exceptions raised by :func:<code>ensure_dir</code> or :meth:<code>pathlib.Path.write_text</code> (for example <code>OSError</code> or <code>PermissionError</code>) propagate to callers.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; write_text(Path(\"/tmp/output.txt\"), \"content\")\n&gt;&gt;&gt; read_text(Path(\"/tmp/output.txt\"))\n'content'\n</code></pre> Source code in <code>src/kgfoundry_common/fs.py</code> <pre><code>def write_text(path: Path, data: str, encoding: str = \"utf-8\") -&gt; None:\n    \"\"\"Write text data to a file, creating parent directories if needed.\n\n    Writes text content to a file, encoding it using the specified encoding.\n    Creates parent directories if they do not exist. Uses pathlib's write_text\n    for atomic file operations.\n\n    Parameters\n    ----------\n    path : Path\n        File path to write. Parent directories will be created if needed.\n    data : str\n        Text content to write. Will be encoded using the specified encoding.\n    encoding : str, optional\n        Text encoding to use for encoding the string to bytes. Defaults to \"utf-8\".\n\n    Notes\n    -----\n    Exceptions raised by :func:`ensure_dir` or :meth:`pathlib.Path.write_text`\n    (for example ``OSError`` or ``PermissionError``) propagate to callers.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; write_text(Path(\"/tmp/output.txt\"), \"content\")\n    &gt;&gt;&gt; read_text(Path(\"/tmp/output.txt\"))\n    'content'\n    \"\"\"\n    ensure_dir(path.parent, exist_ok=True)\n    path.write_text(data, encoding=encoding)\n</code></pre>"},{"location":"modules/kgfoundry_common.gpu/","title":"kgfoundry_common.gpu","text":""},{"location":"modules/kgfoundry_common.gpu/#kgfoundry_commongpu","title":"kgfoundry_common.gpu","text":"<p>Shared utilities and data structures used across KgFoundry services and tools.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.gpu/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.gpu__future__.annotationscollections.abc.Callablecollections.abc.Iterableimportlibostypes.ModuleTypetyping.TYPE_CHECKINGtyping.castkgfoundry_common.gpu code <p>See the full diagram: kgfoundry_common.gpu</p>"},{"location":"modules/kgfoundry_common.gpu/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.gpu._modules_available</li> <li>kgfoundry_common.gpu.has_gpu_stack</li> </ul>"},{"location":"modules/kgfoundry_common.gpu/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Callable</code>, <code>collections.abc.Iterable</code>, <code>importlib</code>, <code>os</code>, <code>types.ModuleType</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.gpu/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.gpu/#kgfoundry_commongpu_modules_available","title":"kgfoundry_common.gpu._modules_available","text":""},{"location":"modules/kgfoundry_common.gpu/#kgfoundry_common.gpu._modules_available","title":"<code>kgfoundry_common.gpu._modules_available(modules)</code>","text":"<p>Check if all specified modules can be imported.</p> <p>Verifies that each module in the iterable can be resolved by Python's import system.</p> <p>Parameters:</p> Name Type Description Default <code>modules</code> <code>Iterable[str]</code> <p>Iterable of module names to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if all modules are available, False otherwise.</p> Source code in <code>src/kgfoundry_common/gpu.py</code> <pre><code>def _modules_available(modules: Iterable[str]) -&gt; bool:\n    \"\"\"Check if all specified modules can be imported.\n\n    Verifies that each module in the iterable can be resolved\n    by Python's import system.\n\n    Parameters\n    ----------\n    modules : Iterable[str]\n        Iterable of module names to check.\n\n    Returns\n    -------\n    bool\n        True if all modules are available, False otherwise.\n    \"\"\"\n    return all(importlib.util.find_spec(module) is not None for module in modules)\n</code></pre>"},{"location":"modules/kgfoundry_common.gpu/#kgfoundry_commongpuhas_gpu_stack","title":"kgfoundry_common.gpu.has_gpu_stack","text":""},{"location":"modules/kgfoundry_common.gpu/#kgfoundry_common.gpu.has_gpu_stack","title":"<code>kgfoundry_common.gpu.has_gpu_stack(*, allow_without_cuda_env='ALLOW_GPU_TESTS_WITHOUT_CUDA')</code>","text":"<p>Check if the optional GPU stack is available and CUDA is usable.</p> <p>Verifies that all core GPU modules can be imported and that CUDA is available via PyTorch. Can be overridden by an environment variable for testing on CPU-only hosts.</p> <p>Parameters:</p> Name Type Description Default <code>allow_without_cuda_env</code> <code>str</code> <p>Environment variable name that, when set to \"1\", permits returning True even when CUDA is unavailable. Defaults to \"ALLOW_GPU_TESTS_WITHOUT_CUDA\".</p> <code>'ALLOW_GPU_TESTS_WITHOUT_CUDA'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True when the GPU stack is available or the override environment variable is set, False otherwise.</p> Source code in <code>src/kgfoundry_common/gpu.py</code> <pre><code>def has_gpu_stack(*, allow_without_cuda_env: str = \"ALLOW_GPU_TESTS_WITHOUT_CUDA\") -&gt; bool:\n    \"\"\"Check if the optional GPU stack is available and CUDA is usable.\n\n    Verifies that all core GPU modules can be imported and that CUDA\n    is available via PyTorch. Can be overridden by an environment variable\n    for testing on CPU-only hosts.\n\n    Parameters\n    ----------\n    allow_without_cuda_env : str, optional\n        Environment variable name that, when set to \"1\", permits returning\n        True even when CUDA is unavailable. Defaults to\n        \"ALLOW_GPU_TESTS_WITHOUT_CUDA\".\n\n    Returns\n    -------\n    bool\n        True when the GPU stack is available or the override environment\n        variable is set, False otherwise.\n    \"\"\"\n    if not _modules_available(GPU_CORE_MODULES):\n        return False\n    if os.getenv(allow_without_cuda_env) == \"1\":\n        return True\n    try:\n        torch_module = importlib.import_module(\"torch\")\n    except ImportError:  # pragma: no cover - import guard\n        return False\n    cuda_module: object = getattr(torch_module, \"cuda\", None)\n    if not isinstance(cuda_module, ModuleType):\n        return False\n    is_available_attr: object = getattr(cuda_module, \"is_available\", None)\n    if not callable(is_available_attr):\n        return False\n    is_available = cast(\"Callable[[], bool]\", is_available_attr)\n    return bool(is_available())\n</code></pre>"},{"location":"modules/kgfoundry_common.ids/","title":"kgfoundry_common.ids","text":""},{"location":"modules/kgfoundry_common.ids/#kgfoundry_commonids","title":"kgfoundry_common.ids","text":"<p>Helpers for generating deterministic URNs</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.ids/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.ids__future__.annotationsbase64hashlibkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.ids code <p>See the full diagram: kgfoundry_common.ids</p>"},{"location":"modules/kgfoundry_common.ids/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.ids.urn_chunk</li> <li>kgfoundry_common.ids.urn_doc_from_text</li> </ul>"},{"location":"modules/kgfoundry_common.ids/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>base64</code>, <code>hashlib</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p>"},{"location":"modules/kgfoundry_common.ids/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.ids/#kgfoundry_commonidsurn_chunk","title":"kgfoundry_common.ids.urn_chunk","text":""},{"location":"modules/kgfoundry_common.ids/#kgfoundry_common.ids.urn_chunk","title":"<code>kgfoundry_common.ids.urn_chunk(doc_hash, start, end)</code>","text":"<p>Generate a URN for a chunk referencing a document.</p> <p>Creates a URN identifier for a text chunk by extracting the hash from the document URN and appending the start and end positions.</p> <p>Parameters:</p> Name Type Description Default <code>doc_hash</code> <code>str</code> <p>Document URN hash (e.g., \"urn:doc:sha256:{hash}\").</p> required <code>start</code> <code>int</code> <p>Start character position of the chunk.</p> required <code>end</code> <code>int</code> <p>End character position of the chunk.</p> required <p>Returns:</p> Type Description <code>str</code> <p>URN string in format \"urn:chunk:{hash}:{start}-{end}\".</p> Source code in <code>src/kgfoundry_common/ids.py</code> <pre><code>def urn_chunk(doc_hash: str, start: int, end: int) -&gt; str:\n    \"\"\"Generate a URN for a chunk referencing a document.\n\n    Creates a URN identifier for a text chunk by extracting the hash\n    from the document URN and appending the start and end positions.\n\n    Parameters\n    ----------\n    doc_hash : str\n        Document URN hash (e.g., \"urn:doc:sha256:{hash}\").\n    start : int\n        Start character position of the chunk.\n    end : int\n        End character position of the chunk.\n\n    Returns\n    -------\n    str\n        URN string in format \"urn:chunk:{hash}:{start}-{end}\".\n    \"\"\"\n    return f\"urn:chunk:{doc_hash.rsplit(':', maxsplit=1)[-1]}:{start}-{end}\"\n</code></pre>"},{"location":"modules/kgfoundry_common.ids/#kgfoundry_commonidsurn_doc_from_text","title":"kgfoundry_common.ids.urn_doc_from_text","text":""},{"location":"modules/kgfoundry_common.ids/#kgfoundry_common.ids.urn_doc_from_text","title":"<code>kgfoundry_common.ids.urn_doc_from_text(text)</code>","text":"<p>Generate a deterministic URN for a document from its text content.</p> <p>Creates a SHA256-based URN identifier for a document by hashing its text content and encoding the hash in base32.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Document text content to hash.</p> required <p>Returns:</p> Type Description <code>str</code> <p>URN string in format \"urn:doc:sha256:{base32_hash}\".</p> Source code in <code>src/kgfoundry_common/ids.py</code> <pre><code>def urn_doc_from_text(text: str) -&gt; str:\n    \"\"\"Generate a deterministic URN for a document from its text content.\n\n    Creates a SHA256-based URN identifier for a document by hashing\n    its text content and encoding the hash in base32.\n\n    Parameters\n    ----------\n    text : str\n        Document text content to hash.\n\n    Returns\n    -------\n    str\n        URN string in format \"urn:doc:sha256:{base32_hash}\".\n    \"\"\"\n    h = hashlib.sha256(text.encode(\"utf-8\")).digest()[:16]\n    b32 = base64.b32encode(h).decode(\"ascii\").strip(\"=\").lower()\n    return f\"urn:doc:sha256:{b32}\"\n</code></pre>"},{"location":"modules/kgfoundry_common.jsonschema_utils/","title":"kgfoundry_common.jsonschema_utils","text":""},{"location":"modules/kgfoundry_common.jsonschema_utils/#kgfoundry_commonjsonschema_utils","title":"kgfoundry_common.jsonschema_utils","text":"<p>Typed facades for jsonschema usage across the codebase.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.jsonschema_utils/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class Draft202012ValidatorProtocol\n    class Protocol\n    Protocol &lt;|-- Draft202012ValidatorProtocol\n    class ValidationErrorProtocol\n    Protocol &lt;|-- ValidationErrorProtocol\n</code></pre>"},{"location":"modules/kgfoundry_common.jsonschema_utils/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.jsonschema_utils__future__.annotationscollections.abc.Iterablecollections.abc.Mappingcollections.abc.Sequencejsonschema.exceptions.SchemaErrorjsonschema.exceptions.ValidationErrorjsonschema.validatejsonschema.validators.Draft202012Validatorkgfoundry_common.navmap_loader.load_nav_metadatatyping.Protocoltyping.TYPE_CHECKINGtyping.castkgfoundry_common.jsonschema_utils code <p>See the full diagram: kgfoundry_common.jsonschema_utils</p>"},{"location":"modules/kgfoundry_common.jsonschema_utils/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.jsonschema_utils.Draft202012ValidatorProtocol</li> <li>kgfoundry_common.jsonschema_utils.ValidationErrorProtocol</li> <li>kgfoundry_common.jsonschema_utils.create_draft202012_validator</li> <li>kgfoundry_common.jsonschema_utils.validate</li> </ul>"},{"location":"modules/kgfoundry_common.jsonschema_utils/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Iterable</code>, <code>collections.abc.Mapping</code>, <code>collections.abc.Sequence</code>, <code>jsonschema.exceptions.SchemaError</code>, <code>jsonschema.exceptions.ValidationError</code>, <code>jsonschema.validate</code>, <code>jsonschema.validators.Draft202012Validator</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.jsonschema_utils/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.jsonschema_utils/#kgfoundry_commonjsonschema_utilsdraft202012validatorprotocol","title":"kgfoundry_common.jsonschema_utils.Draft202012ValidatorProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.jsonschema_utils/#kgfoundry_common.jsonschema_utils.Draft202012ValidatorProtocol","title":"<code>kgfoundry_common.jsonschema_utils.Draft202012ValidatorProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Typed facade for :class:<code>jsonschema.validators.Draft202012Validator</code>.</p> Source code in <code>src/kgfoundry_common/jsonschema_utils.py</code> <pre><code>class Draft202012ValidatorProtocol(Protocol):\n    \"\"\"Typed facade for :class:`jsonschema.validators.Draft202012Validator`.\"\"\"\n\n    def __init__(self, schema: Mapping[str, object], *args: object, **kwargs: object) -&gt; None:\n        \"\"\"Initialize the validator with ``schema``.\"\"\"\n        ...\n\n    @classmethod\n    def check_schema(cls, schema: Mapping[str, object]) -&gt; None:\n        \"\"\"Validate that ``schema`` conforms to the Draft 2020-12 meta-schema.\"\"\"\n        ...\n\n    def iter_errors(self, instance: object) -&gt; Iterable[ValidationErrorProtocol]:\n        \"\"\"Yield validation errors for ``instance`` without raising.\"\"\"\n        ...\n\n    def validate(self, instance: object) -&gt; None:\n        \"\"\"Validate ``instance`` against the configured schema.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.jsonschema_utils/#kgfoundry_common.jsonschema_utils.Draft202012ValidatorProtocol.__init__","title":"<code>__init__(schema, *args, **kwargs)</code>","text":"<p>Initialize the validator with <code>schema</code>.</p> Source code in <code>src/kgfoundry_common/jsonschema_utils.py</code> <pre><code>def __init__(self, schema: Mapping[str, object], *args: object, **kwargs: object) -&gt; None:\n    \"\"\"Initialize the validator with ``schema``.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.jsonschema_utils/#kgfoundry_common.jsonschema_utils.Draft202012ValidatorProtocol.check_schema","title":"<code>check_schema(schema)</code>  <code>classmethod</code>","text":"<p>Validate that <code>schema</code> conforms to the Draft 2020-12 meta-schema.</p> Source code in <code>src/kgfoundry_common/jsonschema_utils.py</code> <pre><code>@classmethod\ndef check_schema(cls, schema: Mapping[str, object]) -&gt; None:\n    \"\"\"Validate that ``schema`` conforms to the Draft 2020-12 meta-schema.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.jsonschema_utils/#kgfoundry_common.jsonschema_utils.Draft202012ValidatorProtocol.iter_errors","title":"<code>iter_errors(instance)</code>","text":"<p>Yield validation errors for <code>instance</code> without raising.</p> Source code in <code>src/kgfoundry_common/jsonschema_utils.py</code> <pre><code>def iter_errors(self, instance: object) -&gt; Iterable[ValidationErrorProtocol]:\n    \"\"\"Yield validation errors for ``instance`` without raising.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.jsonschema_utils/#kgfoundry_common.jsonschema_utils.Draft202012ValidatorProtocol.validate","title":"<code>validate(instance)</code>","text":"<p>Validate <code>instance</code> against the configured schema.</p> Source code in <code>src/kgfoundry_common/jsonschema_utils.py</code> <pre><code>def validate(self, instance: object) -&gt; None:\n    \"\"\"Validate ``instance`` against the configured schema.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.jsonschema_utils/#kgfoundry_commonjsonschema_utilsvalidationerrorprotocol","title":"kgfoundry_common.jsonschema_utils.ValidationErrorProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.jsonschema_utils/#kgfoundry_common.jsonschema_utils.ValidationErrorProtocol","title":"<code>kgfoundry_common.jsonschema_utils.ValidationErrorProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Typed view over <code>jsonschema.exceptions.ValidationError</code> instances.</p> Source code in <code>src/kgfoundry_common/jsonschema_utils.py</code> <pre><code>class ValidationErrorProtocol(Protocol):\n    \"\"\"Typed view over ``jsonschema.exceptions.ValidationError`` instances.\"\"\"\n\n    message: str\n    absolute_path: Sequence[object]\n    path: Sequence[object]\n</code></pre>"},{"location":"modules/kgfoundry_common.jsonschema_utils/#kgfoundry_commonjsonschema_utilscreate_draft202012_validator","title":"kgfoundry_common.jsonschema_utils.create_draft202012_validator","text":""},{"location":"modules/kgfoundry_common.jsonschema_utils/#kgfoundry_common.jsonschema_utils.create_draft202012_validator","title":"<code>kgfoundry_common.jsonschema_utils.create_draft202012_validator(schema)</code>","text":"<p>Return a typed Draft 2020-12 validator for <code>schema</code>.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>Mapping[str, object]</code> <p>JSON Schema to validate against.</p> required <p>Returns:</p> Type Description <code>Draft202012ValidatorProtocol</code> <p>Typed validator instance.</p> Source code in <code>src/kgfoundry_common/jsonschema_utils.py</code> <pre><code>def create_draft202012_validator(\n    schema: Mapping[str, object],\n) -&gt; Draft202012ValidatorProtocol:\n    \"\"\"Return a typed Draft 2020-12 validator for ``schema``.\n\n    Parameters\n    ----------\n    schema : Mapping[str, object]\n        JSON Schema to validate against.\n\n    Returns\n    -------\n    Draft202012ValidatorProtocol\n        Typed validator instance.\n    \"\"\"\n    concrete_schema = {str(key): value for key, value in schema.items()}\n    instance = _Draft202012Validator(concrete_schema)\n    return cast(\"Draft202012ValidatorProtocol\", instance)\n</code></pre>"},{"location":"modules/kgfoundry_common.jsonschema_utils/#kgfoundry_commonjsonschema_utilsvalidate","title":"kgfoundry_common.jsonschema_utils.validate","text":""},{"location":"modules/kgfoundry_common.jsonschema_utils/#kgfoundry_common.jsonschema_utils.validate","title":"<code>kgfoundry_common.jsonschema_utils.validate(instance, schema)</code>","text":"<p>Validate <code>instance</code> against <code>schema</code> using jsonschema.</p> Source code in <code>src/kgfoundry_common/jsonschema_utils.py</code> <pre><code>def validate(instance: object, schema: Mapping[str, object]) -&gt; None:\n    \"\"\"Validate ``instance`` against ``schema`` using jsonschema.\"\"\"\n    _jsonschema_validate(instance=instance, schema=schema)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/","title":"kgfoundry_common.logging","text":""},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonlogging","title":"kgfoundry_common.logging","text":"<p>Structured logging helpers with correlation IDs and observability</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.logging/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class CorrelationContext\n    class JsonFormatter\n    class Formatter\n    Formatter &lt;|-- JsonFormatter\n    class LogContextExtra\n    class LoggerAdapter\n    class _LoggerAdapterBase\n    _LoggerAdapterBase &lt;|-- LoggerAdapter\n    class LoggingCache\n    class Protocol\n    Protocol &lt;|-- LoggingCache\n    class _DefaultLoggingCache\n    class _LoggerAdapterBase_1\n    class _WithFieldsContext\n    class AbstractContextManager\n    AbstractContextManager &lt;|-- _WithFieldsContext\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.logging__future__.annotationscollections.abc.Mappingcontextlib.AbstractContextManagercontextvarsdataclasses.dataclassdataclasses.replacejsonkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.types.JsonValueloggingsystimetypes.TracebackTypetyping.Anytyping.Protocoltyping.Selftyping.TYPE_CHECKINGtyping.casttyping.runtime_checkablekgfoundry_common.logging code <p>See the full diagram: kgfoundry_common.logging</p>"},{"location":"modules/kgfoundry_common.logging/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.logging.CorrelationContext</li> <li>kgfoundry_common.logging.JsonFormatter</li> <li>kgfoundry_common.logging.LogContextExtra</li> <li>kgfoundry_common.logging.get_correlation_id</li> <li>kgfoundry_common.logging.get_logger</li> <li>kgfoundry_common.logging.get_logging_cache</li> </ul>"},{"location":"modules/kgfoundry_common.logging/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Mapping</code>, <code>contextlib.AbstractContextManager</code>, <code>contextvars</code>, <code>dataclasses.dataclass</code>, <code>dataclasses.replace</code>, <code>json</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.types.JsonValue</code>, <code>logging</code>, <code>sys</code>, <code>time</code>, <code>types.TracebackType</code>, <code>typing.Any</code>, <code>typing.Protocol</code>, <code>typing.Self</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code>, <code>typing.runtime_checkable</code></p>"},{"location":"modules/kgfoundry_common.logging/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonloggingcorrelationcontext","title":"kgfoundry_common.logging.CorrelationContext","text":""},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.CorrelationContext","title":"<code>kgfoundry_common.logging.CorrelationContext</code>","text":"<p>Context manager for correlation ID propagation using contextvars.</p> <p>Manages correlation ID context using <code>contextvars.ContextVar</code>, ensuring IDs propagate correctly through async tasks and thread pools without cross-contamination between concurrent requests. Automatically restores the previous correlation ID when the context exits.</p> <p>Parameters:</p> Name Type Description Default <code>correlation_id</code> <code>str | None</code> <p>Correlation ID to set in context. This ID will be automatically injected into all log entries within the context. Set to None to clear the correlation ID.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.logging import CorrelationContext, get_logger\n&gt;&gt;&gt; logger = get_logger(__name__)\n&gt;&gt;&gt; with CorrelationContext(correlation_id=\"req-123\"):\n...     logger.info(\"Request started\")  # correlation_id=\"req-123\" auto-injected\n&gt;&gt;&gt; # Correlation ID is automatically cleared when context exits\n</code></pre> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>class CorrelationContext:\n    \"\"\"Context manager for correlation ID propagation using contextvars.\n\n    Manages correlation ID context using `contextvars.ContextVar`, ensuring\n    IDs propagate correctly through async tasks and thread pools without\n    cross-contamination between concurrent requests. Automatically restores\n    the previous correlation ID when the context exits.\n\n    Parameters\n    ----------\n    correlation_id : str | None\n        Correlation ID to set in context. This ID will be automatically\n        injected into all log entries within the context. Set to None to\n        clear the correlation ID.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.logging import CorrelationContext, get_logger\n    &gt;&gt;&gt; logger = get_logger(__name__)\n    &gt;&gt;&gt; with CorrelationContext(correlation_id=\"req-123\"):\n    ...     logger.info(\"Request started\")  # correlation_id=\"req-123\" auto-injected\n    &gt;&gt;&gt; # Correlation ID is automatically cleared when context exits\n    \"\"\"\n\n    def __init__(self, correlation_id: str | None) -&gt; None:\n        \"\"\"Initialize correlation context.\n\n        Parameters\n        ----------\n        correlation_id : str | NoneType\n            Correlation ID to set in context (or None to clear).\n        \"\"\"\n        self.correlation_id = correlation_id\n        self._token: contextvars.Token[str | None] | None = None\n\n    def __enter__(self) -&gt; Self:\n        \"\"\"Enter correlation context and set correlation ID.\n\n        Returns\n        -------\n        CorrelationContext\n            Self for use as context manager.\n        \"\"\"\n        self._token = _correlation_id.set(self.correlation_id)\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: TracebackType | None,\n    ) -&gt; None:\n        \"\"\"Exit correlation context and restore previous correlation ID.\n\n        Parameters\n        ----------\n        exc_type : type[BaseException] | None\n            Exception type (if any).\n        exc_val : BaseException | None\n            Exception value (if any).\n        exc_tb : object\n            Exception traceback (if any).\n        \"\"\"\n        if self._token is not None:\n            _correlation_id.reset(self._token)\n        del exc_type, exc_val, exc_tb\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.CorrelationContext.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter correlation context and set correlation ID.</p> <p>Returns:</p> Type Description <code>CorrelationContext</code> <p>Self for use as context manager.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def __enter__(self) -&gt; Self:\n    \"\"\"Enter correlation context and set correlation ID.\n\n    Returns\n    -------\n    CorrelationContext\n        Self for use as context manager.\n    \"\"\"\n    self._token = _correlation_id.set(self.correlation_id)\n    return self\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.CorrelationContext.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Exit correlation context and restore previous correlation ID.</p> <p>Parameters:</p> Name Type Description Default <code>exc_type</code> <code>type[BaseException] | None</code> <p>Exception type (if any).</p> required <code>exc_val</code> <code>BaseException | None</code> <p>Exception value (if any).</p> required <code>exc_tb</code> <code>object</code> <p>Exception traceback (if any).</p> required Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def __exit__(\n    self,\n    exc_type: type[BaseException] | None,\n    exc_val: BaseException | None,\n    exc_tb: TracebackType | None,\n) -&gt; None:\n    \"\"\"Exit correlation context and restore previous correlation ID.\n\n    Parameters\n    ----------\n    exc_type : type[BaseException] | None\n        Exception type (if any).\n    exc_val : BaseException | None\n        Exception value (if any).\n    exc_tb : object\n        Exception traceback (if any).\n    \"\"\"\n    if self._token is not None:\n        _correlation_id.reset(self._token)\n    del exc_type, exc_val, exc_tb\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.CorrelationContext.__init__","title":"<code>__init__(correlation_id)</code>","text":"<p>Initialize correlation context.</p> <p>Parameters:</p> Name Type Description Default <code>correlation_id</code> <code>str | NoneType</code> <p>Correlation ID to set in context (or None to clear).</p> required Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def __init__(self, correlation_id: str | None) -&gt; None:\n    \"\"\"Initialize correlation context.\n\n    Parameters\n    ----------\n    correlation_id : str | NoneType\n        Correlation ID to set in context (or None to clear).\n    \"\"\"\n    self.correlation_id = correlation_id\n    self._token: contextvars.Token[str | None] | None = None\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonloggingjsonformatter","title":"kgfoundry_common.logging.JsonFormatter","text":"<p>Bases: logging.Formatter</p>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.JsonFormatter","title":"<code>kgfoundry_common.logging.JsonFormatter</code>","text":"<p>               Bases: <code>Formatter</code></p> <p>JSON formatter for structured logging.</p> <p>Formats log records as JSON with timestamp, level, name, message, and structured fields (correlation_id, operation, status, duration_ms). Automatically extracts correlation_id from contextvars if not present in the log record.</p> <p>Parameters:</p> Name Type Description Default <code>fmt</code> <code>str | None</code> <p>Format string (ignored for JSON formatting). Defaults to None.</p> required <code>datefmt</code> <code>str | None</code> <p>Date format string (ignored for JSON formatting). Defaults to None.</p> required <code>style</code> <code>str</code> <p>Format style (\"%\", \"{\", or \"$\"). Defaults to \"%\".</p> required <code>validate</code> <code>bool</code> <p>Whether to validate format string. Defaults to True.</p> required <code>defaults</code> <code>dict[str, object] | None</code> <p>Default values for format string. Defaults to None.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import logging\n&gt;&gt;&gt; handler = logging.StreamHandler()\n&gt;&gt;&gt; handler.setFormatter(JsonFormatter())\n&gt;&gt;&gt; logger = logging.getLogger(\"test\")\n&gt;&gt;&gt; logger.addHandler(handler)\n&gt;&gt;&gt; logger.info(\"Test message\", extra={\"operation\": \"test\", \"status\": \"success\"})\n</code></pre> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>class JsonFormatter(logging.Formatter):\n    \"\"\"JSON formatter for structured logging.\n\n    Formats log records as JSON with timestamp, level, name, message,\n    and structured fields (correlation_id, operation, status, duration_ms).\n    Automatically extracts correlation_id from contextvars if not present\n    in the log record.\n\n    Parameters\n    ----------\n    fmt : str | None, optional\n        Format string (ignored for JSON formatting). Defaults to None.\n    datefmt : str | None, optional\n        Date format string (ignored for JSON formatting). Defaults to None.\n    style : str, optional\n        Format style (\"%\", \"{\", or \"$\"). Defaults to \"%\".\n    validate : bool, optional\n        Whether to validate format string. Defaults to True.\n    defaults : dict[str, object] | None, optional\n        Default values for format string. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import logging\n    &gt;&gt;&gt; handler = logging.StreamHandler()\n    &gt;&gt;&gt; handler.setFormatter(JsonFormatter())\n    &gt;&gt;&gt; logger = logging.getLogger(\"test\")\n    &gt;&gt;&gt; logger.addHandler(handler)\n    &gt;&gt;&gt; logger.info(\"Test message\", extra={\"operation\": \"test\", \"status\": \"success\"})\n    \"\"\"\n\n    def format(self, record: logging.LogRecord) -&gt; str:\n        \"\"\"Format log record as JSON.\n\n        Converts a logging.LogRecord to a JSON string with structured fields.\n        Extracts correlation_id from contextvars if not present in the record.\n\n        Parameters\n        ----------\n        record : logging.LogRecord\n            Log record to format. May include extra fields in record.__dict__.\n\n        Returns\n        -------\n        str\n            JSON-encoded log entry with timestamp, level, message, and structured\n            fields. All extra fields from the record are included if they are\n            JSON-serializable.\n        \"\"\"\n        # Log data is JSON-serializable - use JsonValue instead of Any\n        data: dict[str, JsonValue] = {\n            \"ts\": self.formatTime(record, \"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\",\n            \"level\": record.levelname,\n            \"name\": record.name,\n            \"message\": record.getMessage(),\n        }\n\n        # Extract structured fields from extra (fields set via LoggerAdapter or extra dict)\n        structured_fields = [\"correlation_id\", \"operation\", \"status\", \"duration_ms\"]\n        for field in structured_fields:\n            value = getattr(record, field, None)\n            if value is not None:\n                data[field] = value\n\n        # Add correlation_id from context if not in extra\n        if \"correlation_id\" not in data:\n            ctx_correlation_id = _correlation_id.get()\n            if ctx_correlation_id is not None:\n                data[\"correlation_id\"] = ctx_correlation_id\n\n        # Add any additional extra fields (from extra dict passed to log calls)\n        # Standard logging attributes to exclude\n        excluded = {\n            \"name\",\n            \"msg\",\n            \"args\",\n            \"created\",\n            \"filename\",\n            \"funcName\",\n            \"levelname\",\n            \"levelno\",\n            \"lineno\",\n            \"module\",\n            \"msecs\",\n            \"message\",\n            \"pathname\",\n            \"process\",\n            \"processName\",\n            \"relativeCreated\",\n            \"thread\",\n            \"threadName\",\n            \"exc_info\",\n            \"exc_text\",\n            \"stack_info\",\n            \"getMessage\",\n            \"ts\",  # Not a standard attribute\n        }\n        # Include all extra fields from record attributes (excluding standard logging attributes)\n        for key, value in record.__dict__.items():\n            if (\n                key not in excluded\n                and key not in data\n                and not key.startswith(\"_\")\n                and value is not None\n                and isinstance(value, (str, int, float, bool, list, dict))\n            ):\n                data[key] = value\n\n        return json.dumps(data, default=str)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.JsonFormatter.format","title":"<code>format(record)</code>","text":"<p>Format log record as JSON.</p> <p>Converts a logging.LogRecord to a JSON string with structured fields. Extracts correlation_id from contextvars if not present in the record.</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>LogRecord</code> <p>Log record to format. May include extra fields in record.dict.</p> required <p>Returns:</p> Type Description <code>str</code> <p>JSON-encoded log entry with timestamp, level, message, and structured fields. All extra fields from the record are included if they are JSON-serializable.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def format(self, record: logging.LogRecord) -&gt; str:\n    \"\"\"Format log record as JSON.\n\n    Converts a logging.LogRecord to a JSON string with structured fields.\n    Extracts correlation_id from contextvars if not present in the record.\n\n    Parameters\n    ----------\n    record : logging.LogRecord\n        Log record to format. May include extra fields in record.__dict__.\n\n    Returns\n    -------\n    str\n        JSON-encoded log entry with timestamp, level, message, and structured\n        fields. All extra fields from the record are included if they are\n        JSON-serializable.\n    \"\"\"\n    # Log data is JSON-serializable - use JsonValue instead of Any\n    data: dict[str, JsonValue] = {\n        \"ts\": self.formatTime(record, \"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\",\n        \"level\": record.levelname,\n        \"name\": record.name,\n        \"message\": record.getMessage(),\n    }\n\n    # Extract structured fields from extra (fields set via LoggerAdapter or extra dict)\n    structured_fields = [\"correlation_id\", \"operation\", \"status\", \"duration_ms\"]\n    for field in structured_fields:\n        value = getattr(record, field, None)\n        if value is not None:\n            data[field] = value\n\n    # Add correlation_id from context if not in extra\n    if \"correlation_id\" not in data:\n        ctx_correlation_id = _correlation_id.get()\n        if ctx_correlation_id is not None:\n            data[\"correlation_id\"] = ctx_correlation_id\n\n    # Add any additional extra fields (from extra dict passed to log calls)\n    # Standard logging attributes to exclude\n    excluded = {\n        \"name\",\n        \"msg\",\n        \"args\",\n        \"created\",\n        \"filename\",\n        \"funcName\",\n        \"levelname\",\n        \"levelno\",\n        \"lineno\",\n        \"module\",\n        \"msecs\",\n        \"message\",\n        \"pathname\",\n        \"process\",\n        \"processName\",\n        \"relativeCreated\",\n        \"thread\",\n        \"threadName\",\n        \"exc_info\",\n        \"exc_text\",\n        \"stack_info\",\n        \"getMessage\",\n        \"ts\",  # Not a standard attribute\n    }\n    # Include all extra fields from record attributes (excluding standard logging attributes)\n    for key, value in record.__dict__.items():\n        if (\n            key not in excluded\n            and key not in data\n            and not key.startswith(\"_\")\n            and value is not None\n            and isinstance(value, (str, int, float, bool, list, dict))\n        ):\n            data[key] = value\n\n    return json.dumps(data, default=str)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonlogginglogcontextextra","title":"kgfoundry_common.logging.LogContextExtra","text":""},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LogContextExtra","title":"<code>kgfoundry_common.logging.LogContextExtra</code>  <code>dataclass</code>","text":"<p>Immutable logging context with required and optional structured fields.</p> <p>This frozen dataclass ensures thread-safe, immutable logging contexts that can be safely shared across async tasks. Use the <code>with_*</code> methods to create updated copies preserving immutability guarantees.</p> <p>Attributes:</p> Name Type Description <code>correlation_id</code> <code>str | None</code> <p>Request or correlation ID for tracing across services.</p> <code>operation</code> <code>str | None</code> <p>Name of the operation being logged (e.g., \"search\", \"index_build\").</p> <code>status</code> <code>str | None</code> <p>Operation status (\"success\", \"error\", \"started\", \"in_progress\").</p> <code>duration_ms</code> <code>float | None</code> <p>Operation duration in milliseconds.</p> <code>service</code> <code>str | None</code> <p>Name of the service producing the log.</p> <code>endpoint</code> <code>str | None</code> <p>HTTP endpoint or internal method being executed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ctx = LogContextExtra(correlation_id=\"req-123\", operation=\"search\")\n&gt;&gt;&gt; ctx_with_status = ctx.with_status(\"success\")\n&gt;&gt;&gt; ctx_with_status.status\n'success'\n&gt;&gt;&gt; # Immutable: original is unchanged\n&gt;&gt;&gt; ctx.status is None\nTrue\n</code></pre> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>@dataclass(frozen=True, slots=True)\n# [nav:anchor LogContextExtra]\nclass LogContextExtra:\n    \"\"\"Immutable logging context with required and optional structured fields.\n\n    This frozen dataclass ensures thread-safe, immutable logging contexts that\n    can be safely shared across async tasks. Use the `with_*` methods to create\n    updated copies preserving immutability guarantees.\n\n    Attributes\n    ----------\n    correlation_id : str | None\n        Request or correlation ID for tracing across services.\n    operation : str | None\n        Name of the operation being logged (e.g., \"search\", \"index_build\").\n    status : str | None\n        Operation status (\"success\", \"error\", \"started\", \"in_progress\").\n    duration_ms : float | None\n        Operation duration in milliseconds.\n    service : str | None\n        Name of the service producing the log.\n    endpoint : str | None\n        HTTP endpoint or internal method being executed.\n\n    Examples\n    --------\n    &gt;&gt;&gt; ctx = LogContextExtra(correlation_id=\"req-123\", operation=\"search\")\n    &gt;&gt;&gt; ctx_with_status = ctx.with_status(\"success\")\n    &gt;&gt;&gt; ctx_with_status.status\n    'success'\n    &gt;&gt;&gt; # Immutable: original is unchanged\n    &gt;&gt;&gt; ctx.status is None\n    True\n    \"\"\"\n\n    correlation_id: str | None = None\n    operation: str | None = None\n    status: str | None = None\n    duration_ms: float | None = None\n    service: str | None = None\n    endpoint: str | None = None\n\n    def with_correlation_id(self, correlation_id: str) -&gt; Self:\n        \"\"\"Return copy with updated correlation_id.\n\n        Parameters\n        ----------\n        correlation_id : str\n            Correlation ID to set.\n\n        Returns\n        -------\n        LogContextExtra\n            New instance with updated correlation_id.\n        \"\"\"\n        return replace(self, correlation_id=correlation_id)\n\n    def with_operation(self, operation: str) -&gt; Self:\n        \"\"\"Return copy with updated operation.\n\n        Parameters\n        ----------\n        operation : str\n            Operation name to set.\n\n        Returns\n        -------\n        LogContextExtra\n            New instance with updated operation.\n        \"\"\"\n        return replace(self, operation=operation)\n\n    def with_status(self, status: str) -&gt; Self:\n        \"\"\"Return copy with updated status.\n\n        Parameters\n        ----------\n        status : str\n            Status value to set.\n\n        Returns\n        -------\n        LogContextExtra\n            New instance with updated status.\n        \"\"\"\n        return replace(self, status=status)\n\n    def with_duration_ms(self, duration_ms: float) -&gt; Self:\n        \"\"\"Return copy with updated duration_ms.\n\n        Parameters\n        ----------\n        duration_ms : float\n            Duration in milliseconds to set.\n\n        Returns\n        -------\n        LogContextExtra\n            New instance with updated duration_ms.\n        \"\"\"\n        return replace(self, duration_ms=duration_ms)\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Convert to dict, excluding None values for logging.\n\n        Returns\n        -------\n        dict[str, Any]\n            Dictionary with non-None fields only.\n        \"\"\"\n        return {\n            k: v\n            for k, v in {\n                \"correlation_id\": self.correlation_id,\n                \"operation\": self.operation,\n                \"status\": self.status,\n                \"duration_ms\": self.duration_ms,\n                \"service\": self.service,\n                \"endpoint\": self.endpoint,\n            }.items()\n            if v is not None\n        }\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LogContextExtra.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dict, excluding None values for logging.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with non-None fields only.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert to dict, excluding None values for logging.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary with non-None fields only.\n    \"\"\"\n    return {\n        k: v\n        for k, v in {\n            \"correlation_id\": self.correlation_id,\n            \"operation\": self.operation,\n            \"status\": self.status,\n            \"duration_ms\": self.duration_ms,\n            \"service\": self.service,\n            \"endpoint\": self.endpoint,\n        }.items()\n        if v is not None\n    }\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LogContextExtra.with_correlation_id","title":"<code>with_correlation_id(correlation_id)</code>","text":"<p>Return copy with updated correlation_id.</p> <p>Parameters:</p> Name Type Description Default <code>correlation_id</code> <code>str</code> <p>Correlation ID to set.</p> required <p>Returns:</p> Type Description <code>LogContextExtra</code> <p>New instance with updated correlation_id.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def with_correlation_id(self, correlation_id: str) -&gt; Self:\n    \"\"\"Return copy with updated correlation_id.\n\n    Parameters\n    ----------\n    correlation_id : str\n        Correlation ID to set.\n\n    Returns\n    -------\n    LogContextExtra\n        New instance with updated correlation_id.\n    \"\"\"\n    return replace(self, correlation_id=correlation_id)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LogContextExtra.with_duration_ms","title":"<code>with_duration_ms(duration_ms)</code>","text":"<p>Return copy with updated duration_ms.</p> <p>Parameters:</p> Name Type Description Default <code>duration_ms</code> <code>float</code> <p>Duration in milliseconds to set.</p> required <p>Returns:</p> Type Description <code>LogContextExtra</code> <p>New instance with updated duration_ms.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def with_duration_ms(self, duration_ms: float) -&gt; Self:\n    \"\"\"Return copy with updated duration_ms.\n\n    Parameters\n    ----------\n    duration_ms : float\n        Duration in milliseconds to set.\n\n    Returns\n    -------\n    LogContextExtra\n        New instance with updated duration_ms.\n    \"\"\"\n    return replace(self, duration_ms=duration_ms)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LogContextExtra.with_operation","title":"<code>with_operation(operation)</code>","text":"<p>Return copy with updated operation.</p> <p>Parameters:</p> Name Type Description Default <code>operation</code> <code>str</code> <p>Operation name to set.</p> required <p>Returns:</p> Type Description <code>LogContextExtra</code> <p>New instance with updated operation.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def with_operation(self, operation: str) -&gt; Self:\n    \"\"\"Return copy with updated operation.\n\n    Parameters\n    ----------\n    operation : str\n        Operation name to set.\n\n    Returns\n    -------\n    LogContextExtra\n        New instance with updated operation.\n    \"\"\"\n    return replace(self, operation=operation)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LogContextExtra.with_status","title":"<code>with_status(status)</code>","text":"<p>Return copy with updated status.</p> <p>Parameters:</p> Name Type Description Default <code>status</code> <code>str</code> <p>Status value to set.</p> required <p>Returns:</p> Type Description <code>LogContextExtra</code> <p>New instance with updated status.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def with_status(self, status: str) -&gt; Self:\n    \"\"\"Return copy with updated status.\n\n    Parameters\n    ----------\n    status : str\n        Status value to set.\n\n    Returns\n    -------\n    LogContextExtra\n        New instance with updated status.\n    \"\"\"\n    return replace(self, status=status)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonloggingloggeradapter","title":"kgfoundry_common.logging.LoggerAdapter","text":"<p>Bases: _LoggerAdapterBase</p>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggerAdapter","title":"<code>kgfoundry_common.logging.LoggerAdapter</code>","text":"<p>               Bases: <code>_LoggerAdapterBase</code></p> <p>Logger adapter that injects structured context fields.</p> <p>This adapter ensures that all log entries include correlation_id, operation, status, and duration_ms fields. It propagates correlation IDs from context variables for async-safe operation.</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Logger</code> <p>Base logger instance to wrap.</p> required <code>extra</code> <code>LogContextExtra | Mapping[str, object] | None</code> <p>Structured fields to inject into log entries. Can be a LogContextExtra frozen dataclass or dict of fields. Defaults to None.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.logging import get_logger\n&gt;&gt;&gt; logger = get_logger(__name__)\n&gt;&gt;&gt; logger.info(\"Search started\", extra={\"operation\": \"search\", \"status\": \"started\"})\n&gt;&gt;&gt; # Correlation ID is automatically injected from context\n</code></pre> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>class LoggerAdapter(_LoggerAdapterBase):\n    \"\"\"Logger adapter that injects structured context fields.\n\n    This adapter ensures that all log entries include correlation_id,\n    operation, status, and duration_ms fields. It propagates correlation\n    IDs from context variables for async-safe operation.\n\n    Parameters\n    ----------\n    logger : logging.Logger\n        Base logger instance to wrap.\n    extra : LogContextExtra | Mapping[str, object] | None, optional\n        Structured fields to inject into log entries. Can be a LogContextExtra\n        frozen dataclass or dict of fields. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.logging import get_logger\n    &gt;&gt;&gt; logger = get_logger(__name__)\n    &gt;&gt;&gt; logger.info(\"Search started\", extra={\"operation\": \"search\", \"status\": \"started\"})\n    &gt;&gt;&gt; # Correlation ID is automatically injected from context\n    \"\"\"\n\n    logger: logging.Logger\n\n    def process(self, msg: str, kwargs: Mapping[str, Any]) -&gt; tuple[str, Any]:\n        \"\"\"Process log message and inject structured fields.\n\n        Merges structured fields from the adapter's extra dict and contextvars\n        into the log record's extra dict. Ensures operation and status fields\n        are always present.\n\n        Parameters\n        ----------\n        msg : str\n            Log message string.\n        kwargs : Mapping[str, Any]\n            Keyword arguments from logging call, including 'extra' dict.\n\n        Returns\n        -------\n        tuple[str, Any]\n            Processed message and kwargs with injected fields. The kwargs dict\n            is modified in-place to include correlation_id, operation, and status.\n        \"\"\"\n        if not isinstance(kwargs, dict):\n            return msg, kwargs\n\n        extra = kwargs.setdefault(\"extra\", {})\n\n        # Handle LogContextExtra dataclass: convert to dict if needed\n        if isinstance(self.extra, LogContextExtra):\n            for key, value in self.extra.to_dict().items():\n                if key not in extra:\n                    extra[key] = value\n        # Merge self.extra (fields from LoggerAdapter constructor) into extra\n        # This allows with_fields to inject fields that persist across log calls\n        elif isinstance(self.extra, dict):\n            for key, value in self.extra.items():\n                if key not in extra:\n                    extra[key] = value\n\n        # Inject correlation_id from context if not provided\n        if \"correlation_id\" not in extra:\n            ctx_correlation_id = _correlation_id.get()\n            if ctx_correlation_id is not None:\n                extra[\"correlation_id\"] = ctx_correlation_id\n\n        # Ensure operation and status are present (defaults if missing)\n        self._ensure_operation_and_status(extra, kwargs.get(\"level\", logging.INFO))\n\n        return msg, kwargs\n\n    @staticmethod\n    def _ensure_operation_and_status(extra: dict[str, Any], level: int) -&gt; None:\n        \"\"\"Ensure operation and status fields are present in extra dict.\n\n        Parameters\n        ----------\n        extra : dict[str, Any]\n            Extra dict to populate.\n        level : int\n            Log level to determine status.\n        \"\"\"\n        if \"operation\" not in extra:\n            extra[\"operation\"] = \"unknown\"\n        if \"status\" not in extra:\n            # Infer status from log level\n            if level &gt;= logging.ERROR:\n                extra[\"status\"] = \"error\"\n            elif level &gt;= logging.WARNING:\n                extra[\"status\"] = \"warning\"\n            else:\n                extra[\"status\"] = \"success\"\n\n    def debug(self, msg: object, *args: object, **kwargs: object) -&gt; None:\n        \"\"\"Log a debug message with structured fields.\"\"\"\n        kwargs_dict = cast(\"dict[str, Any]\", kwargs)\n        extra = kwargs_dict.get(\"extra\", {})\n        if not isinstance(extra, dict):\n            extra = {}\n        extra = cast(\"dict[str, Any]\", extra)\n        # Handle LogContextExtra dataclass: convert to dict if needed\n        if isinstance(self.extra, LogContextExtra):\n            for key, value in self.extra.to_dict().items():\n                if key not in extra:\n                    extra[key] = value\n        # Merge self.extra (fields from LoggerAdapter constructor) into extra\n        elif isinstance(self.extra, dict):\n            for key, value in self.extra.items():\n                if key not in extra:\n                    extra[key] = value\n        # Inject correlation_id from context if not provided\n        if \"correlation_id\" not in extra:\n            ctx_correlation_id = _correlation_id.get()\n            if ctx_correlation_id is not None:\n                extra[\"correlation_id\"] = ctx_correlation_id\n        self._ensure_operation_and_status(extra, logging.DEBUG)\n        kwargs_dict[\"extra\"] = extra\n        self.logger.debug(msg, *args, **kwargs_dict)\n\n    def info(self, msg: object, *args: object, **kwargs: object) -&gt; None:\n        \"\"\"Log an info message with structured fields.\"\"\"\n        kwargs_dict = cast(\"dict[str, Any]\", kwargs)\n        extra = kwargs_dict.get(\"extra\", {})\n        if not isinstance(extra, dict):\n            extra = {}\n        extra = cast(\"dict[str, Any]\", extra)\n        # Handle LogContextExtra dataclass: convert to dict if needed\n        if isinstance(self.extra, LogContextExtra):\n            for key, value in self.extra.to_dict().items():\n                if key not in extra:\n                    extra[key] = value\n        # Merge self.extra (fields from LoggerAdapter constructor) into extra\n        elif isinstance(self.extra, dict):\n            for key, value in self.extra.items():\n                if key not in extra:\n                    extra[key] = value\n        # Inject correlation_id from context if not provided\n        if \"correlation_id\" not in extra:\n            ctx_correlation_id = _correlation_id.get()\n            if ctx_correlation_id is not None:\n                extra[\"correlation_id\"] = ctx_correlation_id\n        self._ensure_operation_and_status(extra, logging.INFO)\n        kwargs_dict[\"extra\"] = extra\n        self.logger.info(msg, *args, **kwargs_dict)\n\n    def warning(self, msg: object, *args: object, **kwargs: object) -&gt; None:\n        \"\"\"Log a warning message with structured fields.\"\"\"\n        kwargs_dict = cast(\"dict[str, Any]\", kwargs)\n        extra = kwargs_dict.get(\"extra\", {})\n        if not isinstance(extra, dict):\n            extra = {}\n        extra = cast(\"dict[str, Any]\", extra)\n        # Handle LogContextExtra dataclass: convert to dict if needed\n        if isinstance(self.extra, LogContextExtra):\n            for key, value in self.extra.to_dict().items():\n                if key not in extra:\n                    extra[key] = value\n        # Merge self.extra (fields from LoggerAdapter constructor) into extra\n        elif isinstance(self.extra, dict):\n            for key, value in self.extra.items():\n                if key not in extra:\n                    extra[key] = value\n        # Inject correlation_id from context if not provided\n        if \"correlation_id\" not in extra:\n            ctx_correlation_id = _correlation_id.get()\n            if ctx_correlation_id is not None:\n                extra[\"correlation_id\"] = ctx_correlation_id\n        self._ensure_operation_and_status(extra, logging.WARNING)\n        kwargs_dict[\"extra\"] = extra\n        self.logger.warning(msg, *args, **kwargs_dict)\n\n    def error(self, msg: object, *args: object, **kwargs: object) -&gt; None:\n        \"\"\"Log an error message with structured fields.\"\"\"\n        kwargs_dict = cast(\"dict[str, Any]\", kwargs)\n        extra = kwargs_dict.get(\"extra\", {})\n        if not isinstance(extra, dict):\n            extra = {}\n        extra = cast(\"dict[str, Any]\", extra)\n        # Handle LogContextExtra dataclass: convert to dict if needed\n        if isinstance(self.extra, LogContextExtra):\n            for key, value in self.extra.to_dict().items():\n                if key not in extra:\n                    extra[key] = value\n        # Merge self.extra (fields from LoggerAdapter constructor) into extra\n        elif isinstance(self.extra, dict):\n            for key, value in self.extra.items():\n                if key not in extra:\n                    extra[key] = value\n        # Inject correlation_id from context if not provided\n        if \"correlation_id\" not in extra:\n            ctx_correlation_id = _correlation_id.get()\n            if ctx_correlation_id is not None:\n                extra[\"correlation_id\"] = ctx_correlation_id\n        self._ensure_operation_and_status(extra, logging.ERROR)\n        kwargs_dict[\"extra\"] = extra\n        self.logger.error(msg, *args, **kwargs_dict)\n\n    def exception(\n        self,\n        msg: object,\n        *args: object,\n        exc_info: object | bool = True,\n        **kwargs: object,\n    ) -&gt; None:\n        \"\"\"Log an error with traceback using structured fields.\"\"\"\n        kwargs_dict = cast(\"dict[str, Any]\", kwargs)\n        if \"exc_info\" not in kwargs_dict or kwargs_dict[\"exc_info\"] is False:\n            kwargs_dict[\"exc_info\"] = exc_info\n        self.error(msg, *args, **kwargs_dict)\n\n    def critical(self, msg: object, *args: object, **kwargs: object) -&gt; None:\n        \"\"\"Log a critical message with structured fields.\"\"\"\n        kwargs_dict = cast(\"dict[str, Any]\", kwargs)\n        extra = kwargs_dict.get(\"extra\", {})\n        if not isinstance(extra, dict):\n            extra = {}\n        extra = cast(\"dict[str, Any]\", extra)\n        # Handle LogContextExtra dataclass: convert to dict if needed\n        if isinstance(self.extra, LogContextExtra):\n            for key, value in self.extra.to_dict().items():\n                if key not in extra:\n                    extra[key] = value\n        # Merge self.extra (fields from LoggerAdapter constructor) into extra\n        elif isinstance(self.extra, dict):\n            for key, value in self.extra.items():\n                if key not in extra:\n                    extra[key] = value\n        # Inject correlation_id from context if not provided\n        if \"correlation_id\" not in extra:\n            ctx_correlation_id = _correlation_id.get()\n            if ctx_correlation_id is not None:\n                extra[\"correlation_id\"] = ctx_correlation_id\n        self._ensure_operation_and_status(extra, logging.CRITICAL)\n        kwargs_dict[\"extra\"] = extra\n        self.logger.critical(msg, *args, **kwargs_dict)\n\n    def log(self, level: int, msg: object, *args: object, **kwargs: object) -&gt; None:\n        \"\"\"Log a message at the given level with structured fields.\"\"\"\n        kwargs_dict = cast(\"dict[str, Any]\", kwargs)\n        extra = kwargs_dict.get(\"extra\", {})\n        if not isinstance(extra, dict):\n            extra = {}\n        extra = cast(\"dict[str, Any]\", extra)\n        # Handle LogContextExtra dataclass: convert to dict if needed\n        if isinstance(self.extra, LogContextExtra):\n            for key, value in self.extra.to_dict().items():\n                if key not in extra:\n                    extra[key] = value\n        # Merge self.extra (fields from LoggerAdapter constructor) into extra\n        elif isinstance(self.extra, dict):\n            for key, value in self.extra.items():\n                if key not in extra:\n                    extra[key] = value\n        # Inject correlation_id from context if not provided\n        if \"correlation_id\" not in extra:\n            ctx_correlation_id = _correlation_id.get()\n            if ctx_correlation_id is not None:\n                extra[\"correlation_id\"] = ctx_correlation_id\n        self._ensure_operation_and_status(extra, level)\n        kwargs_dict[\"extra\"] = extra\n        self.logger.log(level, msg, *args, **kwargs_dict)\n\n    def log_success(\n        self,\n        message: str,\n        *,\n        operation: str | None = None,\n        duration_ms: float | None = None,\n        **fields: object,\n    ) -&gt; None:\n        \"\"\"Log a successful operation with structured fields.\n\n        Parameters\n        ----------\n        message : str\n            Success message.\n        operation : str | None, optional\n            Operation name. If not provided, uses current context value or \"unknown\".\n            Defaults to ``None``.\n        duration_ms : float | None, optional\n            Operation duration in milliseconds. Defaults to ``None``.\n        **fields : object\n            Additional structured fields to include in log record.\n\n        Examples\n        --------\n        &gt;&gt;&gt; from kgfoundry_common.logging import get_logger\n        &gt;&gt;&gt; logger = get_logger(__name__)\n        &gt;&gt;&gt; logger.log_success(\"Index built\", operation=\"build_index\", duration_ms=1234.5)\n        \"\"\"\n        extra: dict[str, object] = {\"status\": \"success\"}\n        if operation is not None:\n            extra[\"operation\"] = operation\n        if duration_ms is not None:\n            extra[\"duration_ms\"] = duration_ms\n        extra.update(fields)\n        self.info(message, extra=extra)\n\n    def log_failure(\n        self,\n        message: str,\n        *,\n        exception: Exception | None = None,\n        operation: str | None = None,\n        duration_ms: float | None = None,\n        **fields: object,\n    ) -&gt; None:\n        \"\"\"Log a failure with structured fields and optional exception chaining.\n\n        Parameters\n        ----------\n        message : str\n            Failure message.\n        exception : Exception | None, optional\n            Exception that caused the failure (preserved in extras). Defaults to ``None``.\n        operation : str | None, optional\n            Operation name. Defaults to ``None``.\n        duration_ms : float | None, optional\n            Operation duration in milliseconds. Defaults to ``None``.\n        **fields : object\n            Additional structured fields.\n\n        Examples\n        --------\n        &gt;&gt;&gt; from kgfoundry_common.logging import get_logger\n        &gt;&gt;&gt; logger = get_logger(__name__)\n        &gt;&gt;&gt; try:\n        ...     raise ValueError(\"Invalid data\")\n        ... except ValueError as e:\n        ...     logger.log_failure(\"Failed to process\", exception=e, operation=\"process_data\")\n        \"\"\"\n        extra: dict[str, object] = {\"status\": \"error\"}\n        if operation is not None:\n            extra[\"operation\"] = operation\n        if duration_ms is not None:\n            extra[\"duration_ms\"] = duration_ms\n        if exception is not None:\n            extra[\"error_type\"] = exception.__class__.__name__\n            extra[\"error_detail\"] = str(exception)\n        extra.update(fields)\n        self.error(message, extra=extra)\n\n    def log_io(\n        self,\n        message: str,\n        *,\n        operation: str | None = None,\n        io_type: str = \"unknown\",\n        size_bytes: int | None = None,\n        duration_ms: float | None = None,\n        **fields: object,\n    ) -&gt; None:\n        \"\"\"Log I/O operation with structured fields.\n\n        Parameters\n        ----------\n        message : str\n            I/O operation message.\n        operation : str | None, optional\n            Operation name. Defaults to ``None``.\n        io_type : str, optional\n            I/O type (\"read\", \"write\", \"delete\", \"unknown\"). Defaults to ``\"unknown\"``.\n        size_bytes : int | None, optional\n            Bytes transferred/processed. Defaults to ``None``.\n        duration_ms : float | None, optional\n            I/O duration in milliseconds. Defaults to ``None``.\n        **fields : object\n            Additional structured fields.\n\n        Examples\n        --------\n        &gt;&gt;&gt; from kgfoundry_common.logging import get_logger\n        &gt;&gt;&gt; logger = get_logger(__name__)\n        &gt;&gt;&gt; logger.log_io(\n        ...     \"Downloaded file\",\n        ...     operation=\"download\",\n        ...     io_type=\"read\",\n        ...     size_bytes=1024,\n        ...     duration_ms=500.0,\n        ... )\n        \"\"\"\n        extra: dict[str, object] = {\"status\": \"success\", \"io_type\": io_type}\n        if operation is not None:\n            extra[\"operation\"] = operation\n        if size_bytes is not None:\n            extra[\"size_bytes\"] = size_bytes\n        if duration_ms is not None:\n            extra[\"duration_ms\"] = duration_ms\n        extra.update(fields)\n        self.info(message, extra=extra)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggerAdapter.__init__","title":"<code>__init__(logger, extra)</code>","text":"<p>Initialize logger adapter.</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Logger</code> <p>Base logger instance.</p> required <code>extra</code> <code>LogContextExtra | Mapping[str, object] | None</code> <p>Structured fields to inject into log entries.</p> required Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def __init__(\n    self,\n    logger: logging.Logger,\n    extra: LogContextExtra | Mapping[str, object] | None,\n) -&gt; None:\n    \"\"\"Initialize logger adapter.\n\n    Parameters\n    ----------\n    logger : logging.Logger\n        Base logger instance.\n    extra : LogContextExtra | Mapping[str, object] | None, optional\n        Structured fields to inject into log entries.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggerAdapter.critical","title":"<code>critical(msg, *args, **kwargs)</code>","text":"<p>Log a critical message with structured fields.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def critical(self, msg: object, *args: object, **kwargs: object) -&gt; None:\n    \"\"\"Log a critical message with structured fields.\"\"\"\n    kwargs_dict = cast(\"dict[str, Any]\", kwargs)\n    extra = kwargs_dict.get(\"extra\", {})\n    if not isinstance(extra, dict):\n        extra = {}\n    extra = cast(\"dict[str, Any]\", extra)\n    # Handle LogContextExtra dataclass: convert to dict if needed\n    if isinstance(self.extra, LogContextExtra):\n        for key, value in self.extra.to_dict().items():\n            if key not in extra:\n                extra[key] = value\n    # Merge self.extra (fields from LoggerAdapter constructor) into extra\n    elif isinstance(self.extra, dict):\n        for key, value in self.extra.items():\n            if key not in extra:\n                extra[key] = value\n    # Inject correlation_id from context if not provided\n    if \"correlation_id\" not in extra:\n        ctx_correlation_id = _correlation_id.get()\n        if ctx_correlation_id is not None:\n            extra[\"correlation_id\"] = ctx_correlation_id\n    self._ensure_operation_and_status(extra, logging.CRITICAL)\n    kwargs_dict[\"extra\"] = extra\n    self.logger.critical(msg, *args, **kwargs_dict)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggerAdapter.debug","title":"<code>debug(msg, *args, **kwargs)</code>","text":"<p>Log a debug message with structured fields.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def debug(self, msg: object, *args: object, **kwargs: object) -&gt; None:\n    \"\"\"Log a debug message with structured fields.\"\"\"\n    kwargs_dict = cast(\"dict[str, Any]\", kwargs)\n    extra = kwargs_dict.get(\"extra\", {})\n    if not isinstance(extra, dict):\n        extra = {}\n    extra = cast(\"dict[str, Any]\", extra)\n    # Handle LogContextExtra dataclass: convert to dict if needed\n    if isinstance(self.extra, LogContextExtra):\n        for key, value in self.extra.to_dict().items():\n            if key not in extra:\n                extra[key] = value\n    # Merge self.extra (fields from LoggerAdapter constructor) into extra\n    elif isinstance(self.extra, dict):\n        for key, value in self.extra.items():\n            if key not in extra:\n                extra[key] = value\n    # Inject correlation_id from context if not provided\n    if \"correlation_id\" not in extra:\n        ctx_correlation_id = _correlation_id.get()\n        if ctx_correlation_id is not None:\n            extra[\"correlation_id\"] = ctx_correlation_id\n    self._ensure_operation_and_status(extra, logging.DEBUG)\n    kwargs_dict[\"extra\"] = extra\n    self.logger.debug(msg, *args, **kwargs_dict)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggerAdapter.error","title":"<code>error(msg, *args, **kwargs)</code>","text":"<p>Log an error message with structured fields.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def error(self, msg: object, *args: object, **kwargs: object) -&gt; None:\n    \"\"\"Log an error message with structured fields.\"\"\"\n    kwargs_dict = cast(\"dict[str, Any]\", kwargs)\n    extra = kwargs_dict.get(\"extra\", {})\n    if not isinstance(extra, dict):\n        extra = {}\n    extra = cast(\"dict[str, Any]\", extra)\n    # Handle LogContextExtra dataclass: convert to dict if needed\n    if isinstance(self.extra, LogContextExtra):\n        for key, value in self.extra.to_dict().items():\n            if key not in extra:\n                extra[key] = value\n    # Merge self.extra (fields from LoggerAdapter constructor) into extra\n    elif isinstance(self.extra, dict):\n        for key, value in self.extra.items():\n            if key not in extra:\n                extra[key] = value\n    # Inject correlation_id from context if not provided\n    if \"correlation_id\" not in extra:\n        ctx_correlation_id = _correlation_id.get()\n        if ctx_correlation_id is not None:\n            extra[\"correlation_id\"] = ctx_correlation_id\n    self._ensure_operation_and_status(extra, logging.ERROR)\n    kwargs_dict[\"extra\"] = extra\n    self.logger.error(msg, *args, **kwargs_dict)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggerAdapter.exception","title":"<code>exception(msg, *args, exc_info=True, **kwargs)</code>","text":"<p>Log an error with traceback using structured fields.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def exception(\n    self,\n    msg: object,\n    *args: object,\n    exc_info: object | bool = True,\n    **kwargs: object,\n) -&gt; None:\n    \"\"\"Log an error with traceback using structured fields.\"\"\"\n    kwargs_dict = cast(\"dict[str, Any]\", kwargs)\n    if \"exc_info\" not in kwargs_dict or kwargs_dict[\"exc_info\"] is False:\n        kwargs_dict[\"exc_info\"] = exc_info\n    self.error(msg, *args, **kwargs_dict)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggerAdapter.info","title":"<code>info(msg, *args, **kwargs)</code>","text":"<p>Log an info message with structured fields.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def info(self, msg: object, *args: object, **kwargs: object) -&gt; None:\n    \"\"\"Log an info message with structured fields.\"\"\"\n    kwargs_dict = cast(\"dict[str, Any]\", kwargs)\n    extra = kwargs_dict.get(\"extra\", {})\n    if not isinstance(extra, dict):\n        extra = {}\n    extra = cast(\"dict[str, Any]\", extra)\n    # Handle LogContextExtra dataclass: convert to dict if needed\n    if isinstance(self.extra, LogContextExtra):\n        for key, value in self.extra.to_dict().items():\n            if key not in extra:\n                extra[key] = value\n    # Merge self.extra (fields from LoggerAdapter constructor) into extra\n    elif isinstance(self.extra, dict):\n        for key, value in self.extra.items():\n            if key not in extra:\n                extra[key] = value\n    # Inject correlation_id from context if not provided\n    if \"correlation_id\" not in extra:\n        ctx_correlation_id = _correlation_id.get()\n        if ctx_correlation_id is not None:\n            extra[\"correlation_id\"] = ctx_correlation_id\n    self._ensure_operation_and_status(extra, logging.INFO)\n    kwargs_dict[\"extra\"] = extra\n    self.logger.info(msg, *args, **kwargs_dict)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggerAdapter.log","title":"<code>log(level, msg, *args, **kwargs)</code>","text":"<p>Log a message at the given level with structured fields.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def log(self, level: int, msg: object, *args: object, **kwargs: object) -&gt; None:\n    \"\"\"Log a message at the given level with structured fields.\"\"\"\n    kwargs_dict = cast(\"dict[str, Any]\", kwargs)\n    extra = kwargs_dict.get(\"extra\", {})\n    if not isinstance(extra, dict):\n        extra = {}\n    extra = cast(\"dict[str, Any]\", extra)\n    # Handle LogContextExtra dataclass: convert to dict if needed\n    if isinstance(self.extra, LogContextExtra):\n        for key, value in self.extra.to_dict().items():\n            if key not in extra:\n                extra[key] = value\n    # Merge self.extra (fields from LoggerAdapter constructor) into extra\n    elif isinstance(self.extra, dict):\n        for key, value in self.extra.items():\n            if key not in extra:\n                extra[key] = value\n    # Inject correlation_id from context if not provided\n    if \"correlation_id\" not in extra:\n        ctx_correlation_id = _correlation_id.get()\n        if ctx_correlation_id is not None:\n            extra[\"correlation_id\"] = ctx_correlation_id\n    self._ensure_operation_and_status(extra, level)\n    kwargs_dict[\"extra\"] = extra\n    self.logger.log(level, msg, *args, **kwargs_dict)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggerAdapter.log_failure","title":"<code>log_failure(message, *, exception=None, operation=None, duration_ms=None, **fields)</code>","text":"<p>Log a failure with structured fields and optional exception chaining.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Failure message.</p> required <code>exception</code> <code>Exception | None</code> <p>Exception that caused the failure (preserved in extras). Defaults to <code>None</code>.</p> <code>None</code> <code>operation</code> <code>str | None</code> <p>Operation name. Defaults to <code>None</code>.</p> <code>None</code> <code>duration_ms</code> <code>float | None</code> <p>Operation duration in milliseconds. Defaults to <code>None</code>.</p> <code>None</code> <code>**fields</code> <code>object</code> <p>Additional structured fields.</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.logging import get_logger\n&gt;&gt;&gt; logger = get_logger(__name__)\n&gt;&gt;&gt; try:\n...     raise ValueError(\"Invalid data\")\n... except ValueError as e:\n...     logger.log_failure(\"Failed to process\", exception=e, operation=\"process_data\")\n</code></pre> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def log_failure(\n    self,\n    message: str,\n    *,\n    exception: Exception | None = None,\n    operation: str | None = None,\n    duration_ms: float | None = None,\n    **fields: object,\n) -&gt; None:\n    \"\"\"Log a failure with structured fields and optional exception chaining.\n\n    Parameters\n    ----------\n    message : str\n        Failure message.\n    exception : Exception | None, optional\n        Exception that caused the failure (preserved in extras). Defaults to ``None``.\n    operation : str | None, optional\n        Operation name. Defaults to ``None``.\n    duration_ms : float | None, optional\n        Operation duration in milliseconds. Defaults to ``None``.\n    **fields : object\n        Additional structured fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.logging import get_logger\n    &gt;&gt;&gt; logger = get_logger(__name__)\n    &gt;&gt;&gt; try:\n    ...     raise ValueError(\"Invalid data\")\n    ... except ValueError as e:\n    ...     logger.log_failure(\"Failed to process\", exception=e, operation=\"process_data\")\n    \"\"\"\n    extra: dict[str, object] = {\"status\": \"error\"}\n    if operation is not None:\n        extra[\"operation\"] = operation\n    if duration_ms is not None:\n        extra[\"duration_ms\"] = duration_ms\n    if exception is not None:\n        extra[\"error_type\"] = exception.__class__.__name__\n        extra[\"error_detail\"] = str(exception)\n    extra.update(fields)\n    self.error(message, extra=extra)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggerAdapter.log_io","title":"<code>log_io(message, *, operation=None, io_type='unknown', size_bytes=None, duration_ms=None, **fields)</code>","text":"<p>Log I/O operation with structured fields.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>I/O operation message.</p> required <code>operation</code> <code>str | None</code> <p>Operation name. Defaults to <code>None</code>.</p> <code>None</code> <code>io_type</code> <code>str</code> <p>I/O type (\"read\", \"write\", \"delete\", \"unknown\"). Defaults to <code>\"unknown\"</code>.</p> <code>'unknown'</code> <code>size_bytes</code> <code>int | None</code> <p>Bytes transferred/processed. Defaults to <code>None</code>.</p> <code>None</code> <code>duration_ms</code> <code>float | None</code> <p>I/O duration in milliseconds. Defaults to <code>None</code>.</p> <code>None</code> <code>**fields</code> <code>object</code> <p>Additional structured fields.</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.logging import get_logger\n&gt;&gt;&gt; logger = get_logger(__name__)\n&gt;&gt;&gt; logger.log_io(\n...     \"Downloaded file\",\n...     operation=\"download\",\n...     io_type=\"read\",\n...     size_bytes=1024,\n...     duration_ms=500.0,\n... )\n</code></pre> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def log_io(\n    self,\n    message: str,\n    *,\n    operation: str | None = None,\n    io_type: str = \"unknown\",\n    size_bytes: int | None = None,\n    duration_ms: float | None = None,\n    **fields: object,\n) -&gt; None:\n    \"\"\"Log I/O operation with structured fields.\n\n    Parameters\n    ----------\n    message : str\n        I/O operation message.\n    operation : str | None, optional\n        Operation name. Defaults to ``None``.\n    io_type : str, optional\n        I/O type (\"read\", \"write\", \"delete\", \"unknown\"). Defaults to ``\"unknown\"``.\n    size_bytes : int | None, optional\n        Bytes transferred/processed. Defaults to ``None``.\n    duration_ms : float | None, optional\n        I/O duration in milliseconds. Defaults to ``None``.\n    **fields : object\n        Additional structured fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.logging import get_logger\n    &gt;&gt;&gt; logger = get_logger(__name__)\n    &gt;&gt;&gt; logger.log_io(\n    ...     \"Downloaded file\",\n    ...     operation=\"download\",\n    ...     io_type=\"read\",\n    ...     size_bytes=1024,\n    ...     duration_ms=500.0,\n    ... )\n    \"\"\"\n    extra: dict[str, object] = {\"status\": \"success\", \"io_type\": io_type}\n    if operation is not None:\n        extra[\"operation\"] = operation\n    if size_bytes is not None:\n        extra[\"size_bytes\"] = size_bytes\n    if duration_ms is not None:\n        extra[\"duration_ms\"] = duration_ms\n    extra.update(fields)\n    self.info(message, extra=extra)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggerAdapter.log_success","title":"<code>log_success(message, *, operation=None, duration_ms=None, **fields)</code>","text":"<p>Log a successful operation with structured fields.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Success message.</p> required <code>operation</code> <code>str | None</code> <p>Operation name. If not provided, uses current context value or \"unknown\". Defaults to <code>None</code>.</p> <code>None</code> <code>duration_ms</code> <code>float | None</code> <p>Operation duration in milliseconds. Defaults to <code>None</code>.</p> <code>None</code> <code>**fields</code> <code>object</code> <p>Additional structured fields to include in log record.</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.logging import get_logger\n&gt;&gt;&gt; logger = get_logger(__name__)\n&gt;&gt;&gt; logger.log_success(\"Index built\", operation=\"build_index\", duration_ms=1234.5)\n</code></pre> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def log_success(\n    self,\n    message: str,\n    *,\n    operation: str | None = None,\n    duration_ms: float | None = None,\n    **fields: object,\n) -&gt; None:\n    \"\"\"Log a successful operation with structured fields.\n\n    Parameters\n    ----------\n    message : str\n        Success message.\n    operation : str | None, optional\n        Operation name. If not provided, uses current context value or \"unknown\".\n        Defaults to ``None``.\n    duration_ms : float | None, optional\n        Operation duration in milliseconds. Defaults to ``None``.\n    **fields : object\n        Additional structured fields to include in log record.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.logging import get_logger\n    &gt;&gt;&gt; logger = get_logger(__name__)\n    &gt;&gt;&gt; logger.log_success(\"Index built\", operation=\"build_index\", duration_ms=1234.5)\n    \"\"\"\n    extra: dict[str, object] = {\"status\": \"success\"}\n    if operation is not None:\n        extra[\"operation\"] = operation\n    if duration_ms is not None:\n        extra[\"duration_ms\"] = duration_ms\n    extra.update(fields)\n    self.info(message, extra=extra)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggerAdapter.process","title":"<code>process(msg, kwargs)</code>","text":"<p>Process log message and inject structured fields.</p> <p>Merges structured fields from the adapter's extra dict and contextvars into the log record's extra dict. Ensures operation and status fields are always present.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>Log message string.</p> required <code>kwargs</code> <code>Mapping[str, Any]</code> <p>Keyword arguments from logging call, including 'extra' dict.</p> required <p>Returns:</p> Type Description <code>tuple[str, Any]</code> <p>Processed message and kwargs with injected fields. The kwargs dict is modified in-place to include correlation_id, operation, and status.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def process(self, msg: str, kwargs: Mapping[str, Any]) -&gt; tuple[str, Any]:\n    \"\"\"Process log message and inject structured fields.\n\n    Merges structured fields from the adapter's extra dict and contextvars\n    into the log record's extra dict. Ensures operation and status fields\n    are always present.\n\n    Parameters\n    ----------\n    msg : str\n        Log message string.\n    kwargs : Mapping[str, Any]\n        Keyword arguments from logging call, including 'extra' dict.\n\n    Returns\n    -------\n    tuple[str, Any]\n        Processed message and kwargs with injected fields. The kwargs dict\n        is modified in-place to include correlation_id, operation, and status.\n    \"\"\"\n    if not isinstance(kwargs, dict):\n        return msg, kwargs\n\n    extra = kwargs.setdefault(\"extra\", {})\n\n    # Handle LogContextExtra dataclass: convert to dict if needed\n    if isinstance(self.extra, LogContextExtra):\n        for key, value in self.extra.to_dict().items():\n            if key not in extra:\n                extra[key] = value\n    # Merge self.extra (fields from LoggerAdapter constructor) into extra\n    # This allows with_fields to inject fields that persist across log calls\n    elif isinstance(self.extra, dict):\n        for key, value in self.extra.items():\n            if key not in extra:\n                extra[key] = value\n\n    # Inject correlation_id from context if not provided\n    if \"correlation_id\" not in extra:\n        ctx_correlation_id = _correlation_id.get()\n        if ctx_correlation_id is not None:\n            extra[\"correlation_id\"] = ctx_correlation_id\n\n    # Ensure operation and status are present (defaults if missing)\n    self._ensure_operation_and_status(extra, kwargs.get(\"level\", logging.INFO))\n\n    return msg, kwargs\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggerAdapter.warning","title":"<code>warning(msg, *args, **kwargs)</code>","text":"<p>Log a warning message with structured fields.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def warning(self, msg: object, *args: object, **kwargs: object) -&gt; None:\n    \"\"\"Log a warning message with structured fields.\"\"\"\n    kwargs_dict = cast(\"dict[str, Any]\", kwargs)\n    extra = kwargs_dict.get(\"extra\", {})\n    if not isinstance(extra, dict):\n        extra = {}\n    extra = cast(\"dict[str, Any]\", extra)\n    # Handle LogContextExtra dataclass: convert to dict if needed\n    if isinstance(self.extra, LogContextExtra):\n        for key, value in self.extra.to_dict().items():\n            if key not in extra:\n                extra[key] = value\n    # Merge self.extra (fields from LoggerAdapter constructor) into extra\n    elif isinstance(self.extra, dict):\n        for key, value in self.extra.items():\n            if key not in extra:\n                extra[key] = value\n    # Inject correlation_id from context if not provided\n    if \"correlation_id\" not in extra:\n        ctx_correlation_id = _correlation_id.get()\n        if ctx_correlation_id is not None:\n            extra[\"correlation_id\"] = ctx_correlation_id\n    self._ensure_operation_and_status(extra, logging.WARNING)\n    kwargs_dict[\"extra\"] = extra\n    self.logger.warning(msg, *args, **kwargs_dict)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonloggingloggingcache","title":"kgfoundry_common.logging.LoggingCache","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggingCache","title":"<code>kgfoundry_common.logging.LoggingCache</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for logging cache implementations.</p> <p>This protocol defines a contract for caching logging configurations, formatters, or other logging-related state without exposing internal implementation details. Implementations provide a public interface for retrieving cached logging resources.</p> <p>Methods:</p> Name Description <code>get_formatter</code> <p>Get or create a cached JSON formatter instance.</p> <code>clear</code> <p>Clear all cached entries and reset state.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.logging import LoggingCache, get_logging_cache\n&gt;&gt;&gt; cache = get_logging_cache()\n&gt;&gt;&gt; # cache implements LoggingCache protocol\n&gt;&gt;&gt; assert isinstance(cache, LoggingCache)\n</code></pre> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>@runtime_checkable\n# [nav:anchor LoggingCache]\nclass LoggingCache(Protocol):\n    \"\"\"Protocol for logging cache implementations.\n\n    This protocol defines a contract for caching logging configurations,\n    formatters, or other logging-related state without exposing internal\n    implementation details. Implementations provide a public interface\n    for retrieving cached logging resources.\n\n    Methods\n    -------\n    get_formatter() -&gt; JsonFormatter\n        Get or create a cached JSON formatter instance.\n    clear() -&gt; None\n        Clear all cached entries and reset state.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.logging import LoggingCache, get_logging_cache\n    &gt;&gt;&gt; cache = get_logging_cache()\n    &gt;&gt;&gt; # cache implements LoggingCache protocol\n    &gt;&gt;&gt; assert isinstance(cache, LoggingCache)\n    \"\"\"\n\n    def get_formatter(self) -&gt; JsonFormatter:\n        \"\"\"Get or create a cached JSON formatter instance.\n\n        Returns\n        -------\n        JsonFormatter\n            A JsonFormatter instance from cache or newly created.\n        \"\"\"\n        ...\n\n    def clear(self) -&gt; None:\n        \"\"\"Clear all cached entries and reset state.\n\n        This method clears formatter caches and any other logging-related cached state.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggingCache.clear","title":"<code>clear()</code>","text":"<p>Clear all cached entries and reset state.</p> <p>This method clears formatter caches and any other logging-related cached state.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Clear all cached entries and reset state.\n\n    This method clears formatter caches and any other logging-related cached state.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.LoggingCache.get_formatter","title":"<code>get_formatter()</code>","text":"<p>Get or create a cached JSON formatter instance.</p> <p>Returns:</p> Type Description <code>JsonFormatter</code> <p>A JsonFormatter instance from cache or newly created.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def get_formatter(self) -&gt; JsonFormatter:\n    \"\"\"Get or create a cached JSON formatter instance.\n\n    Returns\n    -------\n    JsonFormatter\n        A JsonFormatter instance from cache or newly created.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonlogging_defaultloggingcache","title":"kgfoundry_common.logging._DefaultLoggingCache","text":""},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging._DefaultLoggingCache","title":"<code>kgfoundry_common.logging._DefaultLoggingCache</code>","text":"<p>Default implementation of LoggingCache protocol.</p> <p>This class provides a simple cache for logging formatters and configuration. It implements the LoggingCache protocol and can be retrieved via get_logging_cache().</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>class _DefaultLoggingCache:\n    \"\"\"Default implementation of LoggingCache protocol.\n\n    This class provides a simple cache for logging formatters and configuration. It implements the\n    LoggingCache protocol and can be retrieved via get_logging_cache().\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the logging cache.\"\"\"\n        self._formatter_cache: JsonFormatter | None = None\n\n    def get_formatter(self) -&gt; JsonFormatter:\n        \"\"\"Get or create a cached JSON formatter instance.\n\n        Returns\n        -------\n        JsonFormatter\n            A JsonFormatter instance from cache or newly created.\n        \"\"\"\n        if self._formatter_cache is None:\n            self._formatter_cache = JsonFormatter()\n        return self._formatter_cache\n\n    def clear(self) -&gt; None:\n        \"\"\"Clear all cached entries and reset state.\n\n        This method clears the formatter cache and resets internal state.\n        \"\"\"\n        self._formatter_cache = None\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging._DefaultLoggingCache.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the logging cache.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the logging cache.\"\"\"\n    self._formatter_cache: JsonFormatter | None = None\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging._DefaultLoggingCache.clear","title":"<code>clear()</code>","text":"<p>Clear all cached entries and reset state.</p> <p>This method clears the formatter cache and resets internal state.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def clear(self) -&gt; None:\n    \"\"\"Clear all cached entries and reset state.\n\n    This method clears the formatter cache and resets internal state.\n    \"\"\"\n    self._formatter_cache = None\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging._DefaultLoggingCache.get_formatter","title":"<code>get_formatter()</code>","text":"<p>Get or create a cached JSON formatter instance.</p> <p>Returns:</p> Type Description <code>JsonFormatter</code> <p>A JsonFormatter instance from cache or newly created.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def get_formatter(self) -&gt; JsonFormatter:\n    \"\"\"Get or create a cached JSON formatter instance.\n\n    Returns\n    -------\n    JsonFormatter\n        A JsonFormatter instance from cache or newly created.\n    \"\"\"\n    if self._formatter_cache is None:\n        self._formatter_cache = JsonFormatter()\n    return self._formatter_cache\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonlogging_loggeradapterbase","title":"kgfoundry_common.logging._LoggerAdapterBase","text":""},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging._LoggerAdapterBase","title":"<code>kgfoundry_common.logging._LoggerAdapterBase</code>","text":"<p>Typing helper matching logging.LoggerAdapter interface.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>class _LoggerAdapterBase:  # pragma: no cover - typing helper\n    \"\"\"Typing helper matching logging.LoggerAdapter interface.\"\"\"\n\n    logger: logging.Logger\n    extra: LogContextExtra | Mapping[str, object] | None\n\n    def __init__(\n        self,\n        logger: logging.Logger,\n        extra: LogContextExtra | Mapping[str, object] | None,\n    ) -&gt; None:\n        \"\"\"Initialize logger adapter.\n\n        Parameters\n        ----------\n        logger : logging.Logger\n            Base logger instance.\n        extra : LogContextExtra | Mapping[str, object] | None, optional\n            Structured fields to inject into log entries.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging._LoggerAdapterBase.__init__","title":"<code>__init__(logger, extra)</code>","text":"<p>Initialize logger adapter.</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Logger</code> <p>Base logger instance.</p> required <code>extra</code> <code>LogContextExtra | Mapping[str, object] | None</code> <p>Structured fields to inject into log entries.</p> required Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def __init__(\n    self,\n    logger: logging.Logger,\n    extra: LogContextExtra | Mapping[str, object] | None,\n) -&gt; None:\n    \"\"\"Initialize logger adapter.\n\n    Parameters\n    ----------\n    logger : logging.Logger\n        Base logger instance.\n    extra : LogContextExtra | Mapping[str, object] | None, optional\n        Structured fields to inject into log entries.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonlogging_withfieldscontext","title":"kgfoundry_common.logging._WithFieldsContext","text":"<p>Bases: AbstractContextManager</p>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging._WithFieldsContext","title":"<code>kgfoundry_common.logging._WithFieldsContext</code>","text":"<p>               Bases: <code>AbstractContextManager[LoggerAdapter]</code></p> <p>Context manager implementation for <code>with_fields</code>.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>class _WithFieldsContext(AbstractContextManager[LoggerAdapter]):\n    \"\"\"Context manager implementation for `with_fields`.\"\"\"\n\n    def __init__(\n        self, logger: logging.Logger | LoggerAdapter, fields: Mapping[str, object]\n    ) -&gt; None:\n        \"\"\"Initialize context manager with logger and fields.\n\n        Parameters\n        ----------\n        logger : logging.Logger | LoggerAdapter\n            Base logger to wrap (may already be an adapter).\n        fields : Mapping[str, object]\n            Structured fields to inject into log entries.\n        \"\"\"\n        self._logger = logger\n        self._fields = dict(fields)\n        self._token: contextvars.Token[str | None] | None = None\n        self._adapter: LoggerAdapter | None = None\n\n    def __enter__(self) -&gt; LoggerAdapter:\n        \"\"\"Enter context and return logger adapter with fields.\n\n        Sets correlation_id in contextvars if provided in fields.\n\n        Returns\n        -------\n        LoggerAdapter\n            Logger adapter with structured fields injected.\n        \"\"\"\n        base_logger = (\n            self._logger.logger if isinstance(self._logger, LoggerAdapter) else self._logger\n        )\n        correlation_id = self._fields.get(\"correlation_id\")\n        if isinstance(correlation_id, str):\n            self._token = _correlation_id.set(correlation_id)\n        self._adapter = LoggerAdapter(base_logger, dict(self._fields))\n        return self._adapter\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_value: BaseException | None,\n        exc_tb: TracebackType | None,\n    ) -&gt; bool | None:\n        \"\"\"Exit context and restore correlation_id state.\n\n        Parameters\n        ----------\n        exc_type : type[BaseException] | None\n            Exception type if raised, None otherwise.\n        exc_value : BaseException | None\n            Exception value if raised, None otherwise.\n        exc_tb : TracebackType | None\n            Exception traceback if raised, None otherwise.\n\n        Returns\n        -------\n        bool | None\n            None (does not suppress exceptions).\n        \"\"\"\n        if self._token is not None:\n            _correlation_id.reset(self._token)\n        del exc_type, exc_value, exc_tb\n        return None\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging._WithFieldsContext.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter context and return logger adapter with fields.</p> <p>Sets correlation_id in contextvars if provided in fields.</p> <p>Returns:</p> Type Description <code>LoggerAdapter</code> <p>Logger adapter with structured fields injected.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def __enter__(self) -&gt; LoggerAdapter:\n    \"\"\"Enter context and return logger adapter with fields.\n\n    Sets correlation_id in contextvars if provided in fields.\n\n    Returns\n    -------\n    LoggerAdapter\n        Logger adapter with structured fields injected.\n    \"\"\"\n    base_logger = (\n        self._logger.logger if isinstance(self._logger, LoggerAdapter) else self._logger\n    )\n    correlation_id = self._fields.get(\"correlation_id\")\n    if isinstance(correlation_id, str):\n        self._token = _correlation_id.set(correlation_id)\n    self._adapter = LoggerAdapter(base_logger, dict(self._fields))\n    return self._adapter\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging._WithFieldsContext.__exit__","title":"<code>__exit__(exc_type, exc_value, exc_tb)</code>","text":"<p>Exit context and restore correlation_id state.</p> <p>Parameters:</p> Name Type Description Default <code>exc_type</code> <code>type[BaseException] | None</code> <p>Exception type if raised, None otherwise.</p> required <code>exc_value</code> <code>BaseException | None</code> <p>Exception value if raised, None otherwise.</p> required <code>exc_tb</code> <code>TracebackType | None</code> <p>Exception traceback if raised, None otherwise.</p> required <p>Returns:</p> Type Description <code>bool | None</code> <p>None (does not suppress exceptions).</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def __exit__(\n    self,\n    exc_type: type[BaseException] | None,\n    exc_value: BaseException | None,\n    exc_tb: TracebackType | None,\n) -&gt; bool | None:\n    \"\"\"Exit context and restore correlation_id state.\n\n    Parameters\n    ----------\n    exc_type : type[BaseException] | None\n        Exception type if raised, None otherwise.\n    exc_value : BaseException | None\n        Exception value if raised, None otherwise.\n    exc_tb : TracebackType | None\n        Exception traceback if raised, None otherwise.\n\n    Returns\n    -------\n    bool | None\n        None (does not suppress exceptions).\n    \"\"\"\n    if self._token is not None:\n        _correlation_id.reset(self._token)\n    del exc_type, exc_value, exc_tb\n    return None\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging._WithFieldsContext.__init__","title":"<code>__init__(logger, fields)</code>","text":"<p>Initialize context manager with logger and fields.</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Logger | LoggerAdapter</code> <p>Base logger to wrap (may already be an adapter).</p> required <code>fields</code> <code>Mapping[str, object]</code> <p>Structured fields to inject into log entries.</p> required Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def __init__(\n    self, logger: logging.Logger | LoggerAdapter, fields: Mapping[str, object]\n) -&gt; None:\n    \"\"\"Initialize context manager with logger and fields.\n\n    Parameters\n    ----------\n    logger : logging.Logger | LoggerAdapter\n        Base logger to wrap (may already be an adapter).\n    fields : Mapping[str, object]\n        Structured fields to inject into log entries.\n    \"\"\"\n    self._logger = logger\n    self._fields = dict(fields)\n    self._token: contextvars.Token[str | None] | None = None\n    self._adapter: LoggerAdapter | None = None\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonloggingget_correlation_id","title":"kgfoundry_common.logging.get_correlation_id","text":""},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.get_correlation_id","title":"<code>kgfoundry_common.logging.get_correlation_id()</code>","text":"<p>Get current correlation ID from context.</p> <p>Retrieves the correlation ID that was set via set_correlation_id() or CorrelationContext. Returns None if no correlation ID is currently set.</p> <p>Returns:</p> Type Description <code>str | None</code> <p>Current correlation ID from contextvars, or None if not set.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.logging import set_correlation_id, get_correlation_id\n&gt;&gt;&gt; set_correlation_id(\"req-123\")\n&gt;&gt;&gt; assert get_correlation_id() == \"req-123\"\n&gt;&gt;&gt; set_correlation_id(None)\n&gt;&gt;&gt; assert get_correlation_id() is None\n</code></pre> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def get_correlation_id() -&gt; str | None:\n    \"\"\"Get current correlation ID from context.\n\n    Retrieves the correlation ID that was set via set_correlation_id() or\n    CorrelationContext. Returns None if no correlation ID is currently set.\n\n    Returns\n    -------\n    str | None\n        Current correlation ID from contextvars, or None if not set.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.logging import set_correlation_id, get_correlation_id\n    &gt;&gt;&gt; set_correlation_id(\"req-123\")\n    &gt;&gt;&gt; assert get_correlation_id() == \"req-123\"\n    &gt;&gt;&gt; set_correlation_id(None)\n    &gt;&gt;&gt; assert get_correlation_id() is None\n    \"\"\"\n    return _correlation_id.get()\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonloggingget_logger","title":"kgfoundry_common.logging.get_logger","text":""},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.get_logger","title":"<code>kgfoundry_common.logging.get_logger(name)</code>","text":"<p>Get a logger adapter with structured logging support.</p> <p>Creates a logger adapter that automatically injects structured fields (correlation_id, operation, status, duration_ms) into all log entries. Module-level loggers use NullHandler to prevent duplicate handlers in libraries. Applications should configure handlers via setup_logging().</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Logger name (typically name from the calling module).</p> required <p>Returns:</p> Type Description <code>LoggerAdapter</code> <p>Logger adapter with structured context injection. Correlation IDs are automatically extracted from contextvars if set.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.logging import get_logger\n&gt;&gt;&gt; logger = get_logger(__name__)\n&gt;&gt;&gt; logger.info(\"Operation complete\", extra={\"operation\": \"index_build\", \"status\": \"success\"})\n</code></pre> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def get_logger(name: str) -&gt; LoggerAdapter:\n    \"\"\"Get a logger adapter with structured logging support.\n\n    Creates a logger adapter that automatically injects structured fields\n    (correlation_id, operation, status, duration_ms) into all log entries.\n    Module-level loggers use NullHandler to prevent duplicate handlers\n    in libraries. Applications should configure handlers via setup_logging().\n\n    Parameters\n    ----------\n    name : str\n        Logger name (typically __name__ from the calling module).\n\n    Returns\n    -------\n    LoggerAdapter\n        Logger adapter with structured context injection. Correlation IDs\n        are automatically extracted from contextvars if set.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.logging import get_logger\n    &gt;&gt;&gt; logger = get_logger(__name__)\n    &gt;&gt;&gt; logger.info(\"Operation complete\", extra={\"operation\": \"index_build\", \"status\": \"success\"})\n    \"\"\"\n    logger = logging.getLogger(name)\n\n    # Add NullHandler if no handlers exist (prevents duplicate handlers in libraries)\n    if not logger.handlers:\n        logger.addHandler(logging.NullHandler())\n\n    return LoggerAdapter(logger, {})\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonloggingget_logging_cache","title":"kgfoundry_common.logging.get_logging_cache","text":""},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.get_logging_cache","title":"<code>kgfoundry_common.logging.get_logging_cache()</code>","text":"<p>Get the global logging cache instance.</p> <p>Returns a LoggingCache implementation that can be used to retrieve cached logging formatters and configurations. The returned object implements the LoggingCache protocol and provides a stable interface for accessing logging infrastructure without exposing internal details.</p> <p>Returns:</p> Type Description <code>LoggingCache</code> <p>Global logging cache instance implementing the LoggingCache protocol.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.logging import get_logging_cache\n&gt;&gt;&gt; cache = get_logging_cache()\n&gt;&gt;&gt; formatter = cache.get_formatter()\n&gt;&gt;&gt; # Use formatter for logging...\n</code></pre> Notes <p>The returned cache is a singleton instance shared across the entire application. Call cache.clear() to reset cached state if needed.</p> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def get_logging_cache() -&gt; LoggingCache:\n    \"\"\"Get the global logging cache instance.\n\n    Returns a LoggingCache implementation that can be used to retrieve\n    cached logging formatters and configurations. The returned object\n    implements the LoggingCache protocol and provides a stable interface\n    for accessing logging infrastructure without exposing internal details.\n\n    Returns\n    -------\n    LoggingCache\n        Global logging cache instance implementing the LoggingCache protocol.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.logging import get_logging_cache\n    &gt;&gt;&gt; cache = get_logging_cache()\n    &gt;&gt;&gt; formatter = cache.get_formatter()\n    &gt;&gt;&gt; # Use formatter for logging...\n\n    Notes\n    -----\n    The returned cache is a singleton instance shared across the entire\n    application. Call cache.clear() to reset cached state if needed.\n    \"\"\"\n    return _logging_cache\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonloggingmeasure_duration","title":"kgfoundry_common.logging.measure_duration","text":""},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.measure_duration","title":"<code>kgfoundry_common.logging.measure_duration()</code>","text":"<p>Get current monotonic time for measuring operation duration.</p> <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple of (start_time, current_time) both from monotonic clock.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; start_time, _ = measure_duration()\n&gt;&gt;&gt; # do work...\n&gt;&gt;&gt; _, end_time = measure_duration()\n&gt;&gt;&gt; duration_ms = (end_time - start_time) * 1000\n</code></pre> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def measure_duration() -&gt; tuple[float, float]:\n    \"\"\"Get current monotonic time for measuring operation duration.\n\n    Returns\n    -------\n    tuple[float, float]\n        Tuple of (start_time, current_time) both from monotonic clock.\n\n    Examples\n    --------\n    &gt;&gt;&gt; start_time, _ = measure_duration()\n    &gt;&gt;&gt; # do work...\n    &gt;&gt;&gt; _, end_time = measure_duration()\n    &gt;&gt;&gt; duration_ms = (end_time - start_time) * 1000\n    \"\"\"\n    current = time.monotonic()\n    return current, current\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonloggingset_correlation_id","title":"kgfoundry_common.logging.set_correlation_id","text":""},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.set_correlation_id","title":"<code>kgfoundry_common.logging.set_correlation_id(correlation_id)</code>","text":"<p>Set correlation ID in context for async propagation.</p> <p>Uses <code>contextvars.ContextVar</code> to ensure correlation IDs propagate correctly through async tasks and thread pools without cross-contamination between concurrent requests.</p> <p>Parameters:</p> Name Type Description Default <code>correlation_id</code> <code>str | None</code> <p>Correlation ID to set (or None to clear). This ID will be automatically injected into all log entries via LoggerAdapter.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.logging import set_correlation_id, get_logger\n&gt;&gt;&gt; set_correlation_id(\"req-123\")\n&gt;&gt;&gt; logger = get_logger(__name__)\n&gt;&gt;&gt; logger.info(\"Request started\")  # correlation_id=\"req-123\" auto-injected\n</code></pre> Notes <ul> <li>Async propagation: Correlation IDs automatically propagate through   async tasks via <code>contextvars.ContextVar</code>, ensuring each concurrent   request maintains its own correlation ID.</li> <li>Thread safety: ContextVar is thread-safe and isolates correlation   IDs between different threads/async tasks.</li> <li>Cancellation: If an async task is cancelled, the correlation ID   context is automatically cleaned up.</li> </ul> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def set_correlation_id(correlation_id: str | None) -&gt; None:\n    \"\"\"Set correlation ID in context for async propagation.\n\n    Uses `contextvars.ContextVar` to ensure correlation IDs propagate correctly\n    through async tasks and thread pools without cross-contamination between\n    concurrent requests.\n\n    Parameters\n    ----------\n    correlation_id : str | None\n        Correlation ID to set (or None to clear). This ID will be automatically\n        injected into all log entries via LoggerAdapter.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.logging import set_correlation_id, get_logger\n    &gt;&gt;&gt; set_correlation_id(\"req-123\")\n    &gt;&gt;&gt; logger = get_logger(__name__)\n    &gt;&gt;&gt; logger.info(\"Request started\")  # correlation_id=\"req-123\" auto-injected\n\n    Notes\n    -----\n    - **Async propagation**: Correlation IDs automatically propagate through\n      async tasks via `contextvars.ContextVar`, ensuring each concurrent\n      request maintains its own correlation ID.\n    - **Thread safety**: ContextVar is thread-safe and isolates correlation\n      IDs between different threads/async tasks.\n    - **Cancellation**: If an async task is cancelled, the correlation ID\n      context is automatically cleaned up.\n    \"\"\"\n    _correlation_id.set(correlation_id)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonloggingsetup_logging","title":"kgfoundry_common.logging.setup_logging","text":""},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.setup_logging","title":"<code>kgfoundry_common.logging.setup_logging(level=logging.INFO)</code>","text":"<p>Configure root logger with JSON formatter.</p> <p>Sets up structured JSON logging to stdout. Configures the root logger with a StreamHandler that uses JsonFormatter. Should be called once at application startup.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>int</code> <p>Logging level threshold. Use logging.DEBUG, logging.INFO, etc. Defaults to logging.INFO (20).</p> <code>INFO</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.logging import setup_logging\n&gt;&gt;&gt; import logging\n&gt;&gt;&gt; setup_logging(level=logging.DEBUG)\n</code></pre> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def setup_logging(level: int = logging.INFO) -&gt; None:\n    \"\"\"Configure root logger with JSON formatter.\n\n    Sets up structured JSON logging to stdout. Configures the root logger\n    with a StreamHandler that uses JsonFormatter. Should be called once\n    at application startup.\n\n    Parameters\n    ----------\n    level : int, optional\n        Logging level threshold. Use logging.DEBUG, logging.INFO, etc.\n        Defaults to logging.INFO (20).\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.logging import setup_logging\n    &gt;&gt;&gt; import logging\n    &gt;&gt;&gt; setup_logging(level=logging.DEBUG)\n    \"\"\"\n    handler = logging.StreamHandler(sys.stdout)\n    handler.setFormatter(JsonFormatter())\n    logging.basicConfig(level=level, handlers=[handler], force=True)\n</code></pre>"},{"location":"modules/kgfoundry_common.logging/#kgfoundry_commonloggingwith_fields","title":"kgfoundry_common.logging.with_fields","text":""},{"location":"modules/kgfoundry_common.logging/#kgfoundry_common.logging.with_fields","title":"<code>kgfoundry_common.logging.with_fields(logger, **fields)</code>","text":"<p>Context manager for attaching structured fields to log entries.</p> <p>Provides a context manager that: 1. Sets correlation_id in contextvars if provided in fields 2. Returns a LoggerAdapter with bound fields 3. Automatically restores correlation_id when context exits</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Logger | LoggerAdapter</code> <p>Base logger to wrap (may already be an adapter).</p> required <code>**fields</code> <code>object</code> <p>Structured fields to inject into all log entries (e.g., correlation_id, operation, status). These fields persist for all log calls within the context.</p> <code>{}</code> <p>Returns:</p> Type Description <code>AbstractContextManager[LoggerAdapter]</code> <p>Context manager that yields a LoggerAdapter with bound fields and correlation_id in context. The correlation_id is automatically restored when the context exits.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.logging import get_logger, with_fields\n&gt;&gt;&gt; logger = get_logger(__name__)\n&gt;&gt;&gt; with with_fields(logger, correlation_id=\"req-123\", operation=\"search\") as ctx_logger:\n...     ctx_logger.info(\"Starting search\")  # Both fields auto-injected\n&gt;&gt;&gt; # Fields are cleared when context exits\n</code></pre> Source code in <code>src/kgfoundry_common/logging.py</code> <pre><code>def with_fields(\n    logger: logging.Logger | LoggerAdapter,\n    **fields: object,\n) -&gt; AbstractContextManager[LoggerAdapter]:\n    \"\"\"Context manager for attaching structured fields to log entries.\n\n    Provides a context manager that:\n    1. Sets correlation_id in contextvars if provided in fields\n    2. Returns a LoggerAdapter with bound fields\n    3. Automatically restores correlation_id when context exits\n\n    Parameters\n    ----------\n    logger : logging.Logger | LoggerAdapter\n        Base logger to wrap (may already be an adapter).\n    **fields : object\n        Structured fields to inject into all log entries (e.g., correlation_id,\n        operation, status). These fields persist for all log calls within the\n        context.\n\n    Returns\n    -------\n    AbstractContextManager[LoggerAdapter]\n        Context manager that yields a LoggerAdapter with bound fields and\n        correlation_id in context. The correlation_id is automatically restored\n        when the context exits.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.logging import get_logger, with_fields\n    &gt;&gt;&gt; logger = get_logger(__name__)\n    &gt;&gt;&gt; with with_fields(logger, correlation_id=\"req-123\", operation=\"search\") as ctx_logger:\n    ...     ctx_logger.info(\"Starting search\")  # Both fields auto-injected\n    &gt;&gt;&gt; # Fields are cleared when context exits\n    \"\"\"\n    return _WithFieldsContext(logger, fields)\n</code></pre>"},{"location":"modules/kgfoundry_common/","title":"kgfoundry_common","text":""},{"location":"modules/kgfoundry_common/#kgfoundry_common","title":"kgfoundry_common","text":"<p>Shared utilities and data structures used across KgFoundry services and tools.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common code <p>See the full diagram: kgfoundry_common</p>"},{"location":"modules/kgfoundry_common/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p>"},{"location":"modules/kgfoundry_common.models/","title":"kgfoundry_common.models","text":""},{"location":"modules/kgfoundry_common.models/#kgfoundry_commonmodels","title":"kgfoundry_common.models","text":"<p>Typed models shared across kgfoundry services</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.models/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class Chunk\n    class BaseModel\n    BaseModel &lt;|-- Chunk\n    class Doc\n    BaseModel &lt;|-- Doc\n    class DoctagsAsset\n    BaseModel &lt;|-- DoctagsAsset\n    class LinkAssertion\n    BaseModel &lt;|-- LinkAssertion\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.models__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.pydantic.BaseModelpydantic.ConfigDictpydantic.Fieldtyping.Literalkgfoundry_common.models code <p>See the full diagram: kgfoundry_common.models</p>"},{"location":"modules/kgfoundry_common.models/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.models.Chunk</li> <li>kgfoundry_common.models.Doc</li> <li>kgfoundry_common.models.DoctagsAsset</li> </ul>"},{"location":"modules/kgfoundry_common.models/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.pydantic.BaseModel</code>, <code>pydantic.ConfigDict</code>, <code>pydantic.Field</code>, <code>typing.Literal</code></p>"},{"location":"modules/kgfoundry_common.models/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.models/#kgfoundry_commonmodelschunk","title":"kgfoundry_common.models.Chunk","text":"<p>Bases: BaseModel</p>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.Chunk","title":"<code>kgfoundry_common.models.Chunk</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Document chunk model for text segmentation.</p> <p>Pydantic model representing a contiguous segment of text from a document. Contains character offsets, token counts, and references to doctags spans for visual document tags.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>Id</code> <p>Unique chunk identifier.</p> required <code>doc_id</code> <code>Id</code> <p>Document identifier that this chunk belongs to.</p> required <code>section</code> <code>str | None</code> <p>Section name or identifier within the document.</p> required <code>start_char</code> <code>int</code> <p>Start character offset in the original document.</p> required <code>end_char</code> <code>int</code> <p>End character offset in the original document.</p> required <code>tokens</code> <code>int</code> <p>Number of tokens in the chunk.</p> required <code>doctags_span</code> <code>dict[str, int]</code> <p>Dictionary mapping doctags page numbers to character offsets.</p> required Source code in <code>src/kgfoundry_common/models.py</code> <pre><code>class Chunk(BaseModel):\n    \"\"\"Document chunk model for text segmentation.\n\n    Pydantic model representing a contiguous segment of text from a document.\n    Contains character offsets, token counts, and references to doctags spans\n    for visual document tags.\n\n    Parameters\n    ----------\n    id : Id\n        Unique chunk identifier.\n    doc_id : Id\n        Document identifier that this chunk belongs to.\n    section : str | None\n        Section name or identifier within the document.\n    start_char : int\n        Start character offset in the original document.\n    end_char : int\n        End character offset in the original document.\n    tokens : int\n        Number of tokens in the chunk.\n    doctags_span : dict[str, int]\n        Dictionary mapping doctags page numbers to character offsets.\n    \"\"\"\n\n    id: Id\n    doc_id: Id\n    section: str | None\n    start_char: int\n    end_char: int\n    tokens: int\n    doctags_span: dict[str, int]\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.Chunk.__init__","title":"<code>__init__(**data)</code>","text":"<p>Populate the model from keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>**data</code> <code>Any</code> <p>Keyword arguments forwarded to the underlying Pydantic model constructor.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def __init__(self, **data: object) -&gt; None:\n    \"\"\"Populate the model from keyword arguments.\n\n    Parameters\n    ----------\n    **data : Any\n        Keyword arguments forwarded to the underlying Pydantic model\n        constructor.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.Chunk.model_dump","title":"<code>model_dump(**model_dump_kwargs)</code>","text":"<p>Return the dictionary representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump(self, **model_dump_kwargs: object) -&gt; dict[str, object]:\n    \"\"\"Return the dictionary representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump`.\n    \"\"\"\n    del self, model_dump_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.Chunk.model_dump_json","title":"<code>model_dump_json(**model_dump_json_kwargs)</code>","text":"<p>Return the JSON representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_json_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump_json</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump_json(self, **model_dump_json_kwargs: object) -&gt; str:\n    \"\"\"Return the JSON representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_json_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump_json`.\n    \"\"\"\n    del self, model_dump_json_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.Chunk.model_validate","title":"<code>model_validate(obj)</code>  <code>classmethod</code>","text":"<p>Validate <code>obj</code> using the underlying Pydantic implementation.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Instance or mapping to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to forbid coercion during validation. Defaults to <code>None</code> (defer to Pydantic).</p> required <code>extra</code> <code>ExtraValues | None</code> <p>Strategy for handling extra keys. Defaults to <code>None</code> (use model configuration).</p> required <code>from_attributes</code> <code>bool | None</code> <p>Allow attribute-based population when <code>obj</code> is not a mapping. Defaults to <code>None</code> (follow model configuration).</p> required <code>context</code> <code>Any | None</code> <p>Context data available to validators. Defaults to <code>None</code>.</p> required <code>by_alias</code> <code>bool | None</code> <p>Interpret alias names when reading <code>obj</code>. Defaults to <code>None</code> (inherit from configuration).</p> required <code>by_name</code> <code>bool | None</code> <p>Permit field-name based population alongside aliases. Defaults to <code>None</code>.</p> required Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>@classmethod\ndef model_validate(cls, obj: object, /) -&gt; Self:\n    \"\"\"Validate ``obj`` using the underlying Pydantic implementation.\n\n    Parameters\n    ----------\n    obj : Any\n        Instance or mapping to validate.\n    strict : bool | None, optional\n        Whether to forbid coercion during validation.\n        Defaults to ``None`` (defer to Pydantic).\n    extra : ExtraValues | None, optional\n        Strategy for handling extra keys.\n        Defaults to ``None`` (use model configuration).\n    from_attributes : bool | None, optional\n        Allow attribute-based population when ``obj`` is not a mapping.\n        Defaults to ``None`` (follow model configuration).\n    context : Any | None, optional\n        Context data available to validators.\n        Defaults to ``None``.\n    by_alias : bool | None, optional\n        Interpret alias names when reading ``obj``.\n        Defaults to ``None`` (inherit from configuration).\n    by_name : bool | None, optional\n        Permit field-name based population alongside aliases.\n        Defaults to ``None``.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_commonmodelsdoc","title":"kgfoundry_common.models.Doc","text":"<p>Bases: BaseModel</p>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.Doc","title":"<code>kgfoundry_common.models.Doc</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Document model representing academic papers and publications.</p> <p>Pydantic model for representing document metadata including identifiers (OpenAlex, DOI, arXiv, PMCID), bibliographic information (title, authors, publication date), and content references (PDF URI, content hash).</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>Id</code> <p>Unique document identifier (URN or other unique string).</p> required <code>openalex_id</code> <code>str | None</code> <p>OpenAlex work identifier. Defaults to None.</p> required <code>doi</code> <code>str | None</code> <p>Digital Object Identifier (DOI). Defaults to None.</p> required <code>arxiv_id</code> <code>str | None</code> <p>arXiv preprint identifier. Defaults to None.</p> required <code>pmcid</code> <code>str | None</code> <p>PubMed Central identifier. Defaults to None.</p> required <code>title</code> <code>str</code> <p>Document title. Defaults to empty string.</p> required <code>authors</code> <code>list[str]</code> <p>List of author names. Defaults to empty list.</p> required <code>pub_date</code> <code>str | None</code> <p>Publication date string. Defaults to None.</p> required <code>license</code> <code>str | None</code> <p>License identifier (e.g., \"CC-BY\"). Defaults to None.</p> required <code>language</code> <code>str | None</code> <p>Language code (e.g., \"en\"). Defaults to \"en\".</p> required <code>pdf_uri</code> <code>str</code> <p>URI or path to PDF file. Defaults to empty string.</p> required <code>source</code> <code>str</code> <p>Source identifier (e.g., \"openalex\", \"arxiv\"). Defaults to \"unknown\".</p> required <code>content_hash</code> <code>str | None</code> <p>SHA256 hash of document content for deduplication. Defaults to None.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from kgfoundry_common.schema_helpers import assert_model_roundtrip\n&gt;&gt;&gt; example_path = (\n...     Path(__file__).parent.parent.parent / \"schema\" / \"examples\" / \"models\" / \"doc.v1.json\"\n... )\n&gt;&gt;&gt; assert_model_roundtrip(Doc, example_path)\n</code></pre> Source code in <code>src/kgfoundry_common/models.py</code> <pre><code>class Doc(BaseModel):\n    \"\"\"Document model representing academic papers and publications.\n\n    Pydantic model for representing document metadata including identifiers\n    (OpenAlex, DOI, arXiv, PMCID), bibliographic information (title, authors,\n    publication date), and content references (PDF URI, content hash).\n\n    Parameters\n    ----------\n    id : Id\n        Unique document identifier (URN or other unique string).\n    openalex_id : str | None, optional\n        OpenAlex work identifier. Defaults to None.\n    doi : str | None, optional\n        Digital Object Identifier (DOI). Defaults to None.\n    arxiv_id : str | None, optional\n        arXiv preprint identifier. Defaults to None.\n    pmcid : str | None, optional\n        PubMed Central identifier. Defaults to None.\n    title : str, optional\n        Document title. Defaults to empty string.\n    authors : list[str], optional\n        List of author names. Defaults to empty list.\n    pub_date : str | None, optional\n        Publication date string. Defaults to None.\n    license : str | None, optional\n        License identifier (e.g., \"CC-BY\"). Defaults to None.\n    language : str | None, optional\n        Language code (e.g., \"en\"). Defaults to \"en\".\n    pdf_uri : str, optional\n        URI or path to PDF file. Defaults to empty string.\n    source : str, optional\n        Source identifier (e.g., \"openalex\", \"arxiv\"). Defaults to \"unknown\".\n    content_hash : str | None, optional\n        SHA256 hash of document content for deduplication. Defaults to None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; from kgfoundry_common.schema_helpers import assert_model_roundtrip\n    &gt;&gt;&gt; example_path = (\n    ...     Path(__file__).parent.parent.parent / \"schema\" / \"examples\" / \"models\" / \"doc.v1.json\"\n    ... )\n    &gt;&gt;&gt; assert_model_roundtrip(Doc, example_path)\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n\n    id: Id\n    openalex_id: str | None = None\n    doi: str | None = None\n    arxiv_id: str | None = None\n    pmcid: str | None = None\n    title: str = \"\"\n    authors: list[str] = Field(default_factory=list)\n    pub_date: str | None = None\n    license: str | None = None\n    language: str | None = \"en\"\n    pdf_uri: str = \"\"\n    source: str = \"unknown\"\n    content_hash: str | None = None\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.Doc.__init__","title":"<code>__init__(**data)</code>","text":"<p>Populate the model from keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>**data</code> <code>Any</code> <p>Keyword arguments forwarded to the underlying Pydantic model constructor.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def __init__(self, **data: object) -&gt; None:\n    \"\"\"Populate the model from keyword arguments.\n\n    Parameters\n    ----------\n    **data : Any\n        Keyword arguments forwarded to the underlying Pydantic model\n        constructor.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.Doc.model_dump","title":"<code>model_dump(**model_dump_kwargs)</code>","text":"<p>Return the dictionary representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump(self, **model_dump_kwargs: object) -&gt; dict[str, object]:\n    \"\"\"Return the dictionary representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump`.\n    \"\"\"\n    del self, model_dump_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.Doc.model_dump_json","title":"<code>model_dump_json(**model_dump_json_kwargs)</code>","text":"<p>Return the JSON representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_json_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump_json</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump_json(self, **model_dump_json_kwargs: object) -&gt; str:\n    \"\"\"Return the JSON representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_json_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump_json`.\n    \"\"\"\n    del self, model_dump_json_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.Doc.model_validate","title":"<code>model_validate(obj)</code>  <code>classmethod</code>","text":"<p>Validate <code>obj</code> using the underlying Pydantic implementation.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Instance or mapping to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to forbid coercion during validation. Defaults to <code>None</code> (defer to Pydantic).</p> required <code>extra</code> <code>ExtraValues | None</code> <p>Strategy for handling extra keys. Defaults to <code>None</code> (use model configuration).</p> required <code>from_attributes</code> <code>bool | None</code> <p>Allow attribute-based population when <code>obj</code> is not a mapping. Defaults to <code>None</code> (follow model configuration).</p> required <code>context</code> <code>Any | None</code> <p>Context data available to validators. Defaults to <code>None</code>.</p> required <code>by_alias</code> <code>bool | None</code> <p>Interpret alias names when reading <code>obj</code>. Defaults to <code>None</code> (inherit from configuration).</p> required <code>by_name</code> <code>bool | None</code> <p>Permit field-name based population alongside aliases. Defaults to <code>None</code>.</p> required Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>@classmethod\ndef model_validate(cls, obj: object, /) -&gt; Self:\n    \"\"\"Validate ``obj`` using the underlying Pydantic implementation.\n\n    Parameters\n    ----------\n    obj : Any\n        Instance or mapping to validate.\n    strict : bool | None, optional\n        Whether to forbid coercion during validation.\n        Defaults to ``None`` (defer to Pydantic).\n    extra : ExtraValues | None, optional\n        Strategy for handling extra keys.\n        Defaults to ``None`` (use model configuration).\n    from_attributes : bool | None, optional\n        Allow attribute-based population when ``obj`` is not a mapping.\n        Defaults to ``None`` (follow model configuration).\n    context : Any | None, optional\n        Context data available to validators.\n        Defaults to ``None``.\n    by_alias : bool | None, optional\n        Interpret alias names when reading ``obj``.\n        Defaults to ``None`` (inherit from configuration).\n    by_name : bool | None, optional\n        Permit field-name based population alongside aliases.\n        Defaults to ``None``.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_commonmodelsdoctagsasset","title":"kgfoundry_common.models.DoctagsAsset","text":"<p>Bases: BaseModel</p>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.DoctagsAsset","title":"<code>kgfoundry_common.models.DoctagsAsset</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Doctags asset model for visual document tags.</p> <p>Pydantic model representing visual document tags generated by vision-language models (VLMs). Contains references to the doctags file and metadata about the model that generated the tags.</p> <p>Parameters:</p> Name Type Description Default <code>doc_id</code> <code>Id</code> <p>Document identifier that this doctags asset belongs to.</p> required <code>doctags_uri</code> <code>str</code> <p>URI or path to the doctags file (typically JSON or Parquet).</p> required <code>pages</code> <code>int</code> <p>Number of pages in the document.</p> required <code>vlm_model</code> <code>str</code> <p>Vision-language model identifier used to generate tags.</p> required <code>vlm_revision</code> <code>str</code> <p>Model revision or version identifier.</p> required <code>avg_logprob</code> <code>float | None</code> <p>Average log probability score from the VLM. Defaults to None.</p> required Source code in <code>src/kgfoundry_common/models.py</code> <pre><code>class DoctagsAsset(BaseModel):\n    \"\"\"Doctags asset model for visual document tags.\n\n    Pydantic model representing visual document tags generated by vision-language\n    models (VLMs). Contains references to the doctags file and metadata about\n    the model that generated the tags.\n\n    Parameters\n    ----------\n    doc_id : Id\n        Document identifier that this doctags asset belongs to.\n    doctags_uri : str\n        URI or path to the doctags file (typically JSON or Parquet).\n    pages : int\n        Number of pages in the document.\n    vlm_model : str\n        Vision-language model identifier used to generate tags.\n    vlm_revision : str\n        Model revision or version identifier.\n    avg_logprob : float | None, optional\n        Average log probability score from the VLM. Defaults to None.\n    \"\"\"\n\n    doc_id: Id\n    doctags_uri: str\n    pages: int\n    vlm_model: str\n    vlm_revision: str\n    avg_logprob: float | None = None\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.DoctagsAsset.__init__","title":"<code>__init__(**data)</code>","text":"<p>Populate the model from keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>**data</code> <code>Any</code> <p>Keyword arguments forwarded to the underlying Pydantic model constructor.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def __init__(self, **data: object) -&gt; None:\n    \"\"\"Populate the model from keyword arguments.\n\n    Parameters\n    ----------\n    **data : Any\n        Keyword arguments forwarded to the underlying Pydantic model\n        constructor.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.DoctagsAsset.model_dump","title":"<code>model_dump(**model_dump_kwargs)</code>","text":"<p>Return the dictionary representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump(self, **model_dump_kwargs: object) -&gt; dict[str, object]:\n    \"\"\"Return the dictionary representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump`.\n    \"\"\"\n    del self, model_dump_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.DoctagsAsset.model_dump_json","title":"<code>model_dump_json(**model_dump_json_kwargs)</code>","text":"<p>Return the JSON representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_json_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump_json</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump_json(self, **model_dump_json_kwargs: object) -&gt; str:\n    \"\"\"Return the JSON representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_json_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump_json`.\n    \"\"\"\n    del self, model_dump_json_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.DoctagsAsset.model_validate","title":"<code>model_validate(obj)</code>  <code>classmethod</code>","text":"<p>Validate <code>obj</code> using the underlying Pydantic implementation.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Instance or mapping to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to forbid coercion during validation. Defaults to <code>None</code> (defer to Pydantic).</p> required <code>extra</code> <code>ExtraValues | None</code> <p>Strategy for handling extra keys. Defaults to <code>None</code> (use model configuration).</p> required <code>from_attributes</code> <code>bool | None</code> <p>Allow attribute-based population when <code>obj</code> is not a mapping. Defaults to <code>None</code> (follow model configuration).</p> required <code>context</code> <code>Any | None</code> <p>Context data available to validators. Defaults to <code>None</code>.</p> required <code>by_alias</code> <code>bool | None</code> <p>Interpret alias names when reading <code>obj</code>. Defaults to <code>None</code> (inherit from configuration).</p> required <code>by_name</code> <code>bool | None</code> <p>Permit field-name based population alongside aliases. Defaults to <code>None</code>.</p> required Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>@classmethod\ndef model_validate(cls, obj: object, /) -&gt; Self:\n    \"\"\"Validate ``obj`` using the underlying Pydantic implementation.\n\n    Parameters\n    ----------\n    obj : Any\n        Instance or mapping to validate.\n    strict : bool | None, optional\n        Whether to forbid coercion during validation.\n        Defaults to ``None`` (defer to Pydantic).\n    extra : ExtraValues | None, optional\n        Strategy for handling extra keys.\n        Defaults to ``None`` (use model configuration).\n    from_attributes : bool | None, optional\n        Allow attribute-based population when ``obj`` is not a mapping.\n        Defaults to ``None`` (follow model configuration).\n    context : Any | None, optional\n        Context data available to validators.\n        Defaults to ``None``.\n    by_alias : bool | None, optional\n        Interpret alias names when reading ``obj``.\n        Defaults to ``None`` (inherit from configuration).\n    by_name : bool | None, optional\n        Permit field-name based population alongside aliases.\n        Defaults to ``None``.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_commonmodelslinkassertion","title":"kgfoundry_common.models.LinkAssertion","text":"<p>Bases: BaseModel</p>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.LinkAssertion","title":"<code>kgfoundry_common.models.LinkAssertion</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Link assertion model for knowledge graph connections.</p> <p>Pydantic model representing a link between a document chunk and a knowledge graph concept. Contains scoring information, decision status, and optional evidence spans and feature vectors.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>Id</code> <p>Unique link assertion identifier.</p> required <code>chunk_id</code> <code>Id</code> <p>Chunk identifier that this link refers to.</p> required <code>concept_id</code> <code>Id</code> <p>Knowledge graph concept identifier.</p> required <code>score</code> <code>float</code> <p>Link score or confidence value.</p> required <code>decision</code> <code>Literal['link', 'reject', 'uncertain']</code> <p>Decision status: 'link' (accepted), 'reject' (rejected), or 'uncertain' (requires review).</p> required <code>evidence_span</code> <code>str | None</code> <p>Text span from the chunk that provides evidence for the link. Defaults to None.</p> required <code>features</code> <code>dict[str, float]</code> <p>Feature vector dictionary for the link (e.g., embedding distances, similarity scores). Defaults to empty dictionary.</p> required <code>run_id</code> <code>str</code> <p>Run identifier that created this link assertion.</p> required Source code in <code>src/kgfoundry_common/models.py</code> <pre><code>class LinkAssertion(BaseModel):\n    \"\"\"Link assertion model for knowledge graph connections.\n\n    Pydantic model representing a link between a document chunk and a knowledge\n    graph concept. Contains scoring information, decision status, and optional\n    evidence spans and feature vectors.\n\n    Parameters\n    ----------\n    id : Id\n        Unique link assertion identifier.\n    chunk_id : Id\n        Chunk identifier that this link refers to.\n    concept_id : Id\n        Knowledge graph concept identifier.\n    score : float\n        Link score or confidence value.\n    decision : Literal['link', 'reject', 'uncertain']\n        Decision status: 'link' (accepted), 'reject' (rejected), or\n        'uncertain' (requires review).\n    evidence_span : str | None, optional\n        Text span from the chunk that provides evidence for the link.\n        Defaults to None.\n    features : dict[str, float], optional\n        Feature vector dictionary for the link (e.g., embedding distances,\n        similarity scores). Defaults to empty dictionary.\n    run_id : str\n        Run identifier that created this link assertion.\n    \"\"\"\n\n    id: Id\n    chunk_id: Id\n    concept_id: Id\n    score: float\n    decision: Literal[\"link\", \"reject\", \"uncertain\"]\n    evidence_span: str | None = None\n    features: dict[str, float] = Field(default_factory=dict)\n    run_id: str\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.LinkAssertion.__init__","title":"<code>__init__(**data)</code>","text":"<p>Populate the model from keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>**data</code> <code>Any</code> <p>Keyword arguments forwarded to the underlying Pydantic model constructor.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def __init__(self, **data: object) -&gt; None:\n    \"\"\"Populate the model from keyword arguments.\n\n    Parameters\n    ----------\n    **data : Any\n        Keyword arguments forwarded to the underlying Pydantic model\n        constructor.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.LinkAssertion.model_dump","title":"<code>model_dump(**model_dump_kwargs)</code>","text":"<p>Return the dictionary representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump(self, **model_dump_kwargs: object) -&gt; dict[str, object]:\n    \"\"\"Return the dictionary representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump`.\n    \"\"\"\n    del self, model_dump_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.LinkAssertion.model_dump_json","title":"<code>model_dump_json(**model_dump_json_kwargs)</code>","text":"<p>Return the JSON representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_json_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump_json</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump_json(self, **model_dump_json_kwargs: object) -&gt; str:\n    \"\"\"Return the JSON representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_json_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump_json`.\n    \"\"\"\n    del self, model_dump_json_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.models/#kgfoundry_common.models.LinkAssertion.model_validate","title":"<code>model_validate(obj)</code>  <code>classmethod</code>","text":"<p>Validate <code>obj</code> using the underlying Pydantic implementation.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Instance or mapping to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to forbid coercion during validation. Defaults to <code>None</code> (defer to Pydantic).</p> required <code>extra</code> <code>ExtraValues | None</code> <p>Strategy for handling extra keys. Defaults to <code>None</code> (use model configuration).</p> required <code>from_attributes</code> <code>bool | None</code> <p>Allow attribute-based population when <code>obj</code> is not a mapping. Defaults to <code>None</code> (follow model configuration).</p> required <code>context</code> <code>Any | None</code> <p>Context data available to validators. Defaults to <code>None</code>.</p> required <code>by_alias</code> <code>bool | None</code> <p>Interpret alias names when reading <code>obj</code>. Defaults to <code>None</code> (inherit from configuration).</p> required <code>by_name</code> <code>bool | None</code> <p>Permit field-name based population alongside aliases. Defaults to <code>None</code>.</p> required Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>@classmethod\ndef model_validate(cls, obj: object, /) -&gt; Self:\n    \"\"\"Validate ``obj`` using the underlying Pydantic implementation.\n\n    Parameters\n    ----------\n    obj : Any\n        Instance or mapping to validate.\n    strict : bool | None, optional\n        Whether to forbid coercion during validation.\n        Defaults to ``None`` (defer to Pydantic).\n    extra : ExtraValues | None, optional\n        Strategy for handling extra keys.\n        Defaults to ``None`` (use model configuration).\n    from_attributes : bool | None, optional\n        Allow attribute-based population when ``obj`` is not a mapping.\n        Defaults to ``None`` (follow model configuration).\n    context : Any | None, optional\n        Context data available to validators.\n        Defaults to ``None``.\n    by_alias : bool | None, optional\n        Interpret alias names when reading ``obj``.\n        Defaults to ``None`` (inherit from configuration).\n    by_name : bool | None, optional\n        Permit field-name based population alongside aliases.\n        Defaults to ``None``.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.navmap_loader/","title":"kgfoundry_common.navmap_loader","text":""},{"location":"modules/kgfoundry_common.navmap_loader/#kgfoundry_commonnavmap_loader","title":"kgfoundry_common.navmap_loader","text":"<p>Shared utilities and data structures used across KgFoundry services and tools.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.navmap_loader/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.navmap_loader__future__.annotationscopyfunctools.cacheimportlibjsonpathlib.Pathsystyping.Anykgfoundry_common.navmap_loader code <p>See the full diagram: kgfoundry_common.navmap_loader</p>"},{"location":"modules/kgfoundry_common.navmap_loader/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.navmap_loader._candidate_sidecars</li> <li>kgfoundry_common.navmap_loader._load_runtime_nav</li> <li>kgfoundry_common.navmap_loader._load_sidecar_data</li> </ul>"},{"location":"modules/kgfoundry_common.navmap_loader/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>copy</code>, <code>functools.cache</code>, <code>importlib</code>, <code>json</code>, <code>pathlib.Path</code>, <code>sys</code>, <code>typing.Any</code></p>"},{"location":"modules/kgfoundry_common.navmap_loader/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.navmap_loader/#kgfoundry_commonnavmap_loader_candidate_sidecars","title":"kgfoundry_common.navmap_loader._candidate_sidecars","text":""},{"location":"modules/kgfoundry_common.navmap_loader/#kgfoundry_common.navmap_loader._candidate_sidecars","title":"<code>kgfoundry_common.navmap_loader._candidate_sidecars(package)</code>","text":"<p>Return ordered sidecar file candidates for <code>package</code>.</p> <p>Returns:</p> Type Description <code>list[Path]</code> <p>Candidate paths in priority order where <code>_nav.json</code> sidecars may live.</p> Source code in <code>src/kgfoundry_common/navmap_loader.py</code> <pre><code>def _candidate_sidecars(package: str) -&gt; list[Path]:\n    \"\"\"Return ordered sidecar file candidates for ``package``.\n\n    Returns\n    -------\n    list[Path]\n        Candidate paths in priority order where `_nav.json` sidecars may live.\n    \"\"\"\n    spec = importlib.util.find_spec(package)\n    if spec is None:\n        return []\n\n    candidates: list[Path] = []\n    origin = Path(spec.origin) if isinstance(spec.origin, str) else None\n\n    if origin is not None:\n        if origin.name != \"__init__.py\":\n            candidates.append(origin.with_name(f\"{origin.stem}._nav.json\"))\n        candidates.append(origin.parent / \"_nav.json\")\n\n    if spec.submodule_search_locations:\n        for location in spec.submodule_search_locations:\n            location_path = Path(location)\n            candidate = location_path / \"_nav.json\"\n            if candidate not in candidates:\n                candidates.append(candidate)\n\n    # Remove duplicates while preserving order.\n    deduped: list[Path] = []\n    seen: set[Path] = set()\n    for candidate in candidates:\n        if candidate in seen:\n            continue\n        seen.add(candidate)\n        deduped.append(candidate)\n\n    return deduped\n</code></pre>"},{"location":"modules/kgfoundry_common.navmap_loader/#kgfoundry_commonnavmap_loader_load_runtime_nav","title":"kgfoundry_common.navmap_loader._load_runtime_nav","text":""},{"location":"modules/kgfoundry_common.navmap_loader/#kgfoundry_common.navmap_loader._load_runtime_nav","title":"<code>kgfoundry_common.navmap_loader._load_runtime_nav(package)</code>","text":"<p>Return runtime <code>__navmap__</code> data if available.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Deep-copied runtime navmap if exposed by the module, else empty dict.</p> Source code in <code>src/kgfoundry_common/navmap_loader.py</code> <pre><code>def _load_runtime_nav(package: str) -&gt; dict[str, Any]:\n    \"\"\"Return runtime ``__navmap__`` data if available.\n\n    Returns\n    -------\n    dict[str, Any]\n        Deep-copied runtime navmap if exposed by the module, else empty dict.\n    \"\"\"\n    module = sys.modules.get(package)\n    if module is None:\n        try:\n            module = importlib.import_module(package)\n        except ImportError:\n            module = None\n    if module is None:\n        return {}\n    runtime_nav = getattr(module, \"__navmap__\", None)\n    if isinstance(runtime_nav, dict):\n        return copy.deepcopy(runtime_nav)\n    return {}\n</code></pre>"},{"location":"modules/kgfoundry_common.navmap_loader/#kgfoundry_commonnavmap_loader_load_sidecar_data","title":"kgfoundry_common.navmap_loader._load_sidecar_data","text":""},{"location":"modules/kgfoundry_common.navmap_loader/#kgfoundry_common.navmap_loader._load_sidecar_data","title":"<code>kgfoundry_common.navmap_loader._load_sidecar_data(package)</code>","text":"<p>Return metadata loaded from package sidecar files.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Parsed JSON payload when a sidecar exists, otherwise an empty dict.</p> Source code in <code>src/kgfoundry_common/navmap_loader.py</code> <pre><code>def _load_sidecar_data(package: str) -&gt; dict[str, Any]:\n    \"\"\"Return metadata loaded from package sidecar files.\n\n    Returns\n    -------\n    dict[str, Any]\n        Parsed JSON payload when a sidecar exists, otherwise an empty dict.\n    \"\"\"\n    for candidate in _candidate_sidecars(package):\n        if candidate.is_file():\n            with candidate.open(\"r\", encoding=\"utf-8\") as handle:\n                return json.load(handle)\n    return {}\n</code></pre>"},{"location":"modules/kgfoundry_common.navmap_loader/#kgfoundry_commonnavmap_loaderload_nav_metadata","title":"kgfoundry_common.navmap_loader.load_nav_metadata","text":""},{"location":"modules/kgfoundry_common.navmap_loader/#kgfoundry_common.navmap_loader.load_nav_metadata","title":"<code>kgfoundry_common.navmap_loader.load_nav_metadata(package, exports)</code>  <code>cached</code>","text":"<p>Return navigation metadata for <code>package</code>.</p> <p>Parameters:</p> Name Type Description Default <code>package</code> <code>str</code> <p>Fully qualified package name whose metadata should be loaded.</p> required <code>exports</code> <code>tuple[str, ...]</code> <p>Public export names exposed via <code>__all__</code>. These drive the default section and symbol lists when the sidecar omits explicit values.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary matching the <code>__navmap__</code> schema historically used by the documentation toolchain. When no sidecar is present a minimal fallback derived from <code>exports</code> is returned.</p> Source code in <code>src/kgfoundry_common/navmap_loader.py</code> <pre><code>@cache\ndef load_nav_metadata(package: str, exports: tuple[str, ...]) -&gt; dict[str, Any]:\n    \"\"\"Return navigation metadata for ``package``.\n\n    Parameters\n    ----------\n    package : str\n        Fully qualified package name whose metadata should be loaded.\n    exports : tuple[str, ...]\n        Public export names exposed via ``__all__``. These drive the default\n        section and symbol lists when the sidecar omits explicit values.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary matching the ``__navmap__`` schema historically used by the\n        documentation toolchain. When no sidecar is present a minimal fallback\n        derived from ``exports`` is returned.\n    \"\"\"\n    data = _load_sidecar_data(package) or _load_runtime_nav(package)\n\n    normalized_exports = list(dict.fromkeys(exports))\n\n    sections = data.get(\"sections\") or [\n        {\n            \"id\": \"public-api\",\n            \"title\": \"Public API\",\n            \"symbols\": normalized_exports,\n        }\n    ]\n\n    raw_symbols = data.get(\"symbols\") or {}\n    symbol_meta = {\n        name: raw_symbols[name] if isinstance(raw_symbols.get(name), dict) else {}\n        for name in normalized_exports\n    }\n\n    navmap: dict[str, Any] = {\n        \"title\": data.get(\"title\", package),\n        \"synopsis\": data.get(\"synopsis\"),\n        \"exports\": normalized_exports,\n        \"sections\": sections,\n        \"module_meta\": data.get(\"module_meta\", {}),\n        \"symbols\": symbol_meta,\n    }\n\n    extras = {key: value for key, value in data.items() if key not in navmap}\n    navmap.update(extras)\n    return navmap\n</code></pre>"},{"location":"modules/kgfoundry_common.navmap_types/","title":"kgfoundry_common.navmap_types","text":""},{"location":"modules/kgfoundry_common.navmap_types/#kgfoundry_commonnavmap_types","title":"kgfoundry_common.navmap_types","text":"<p>Shared navigation metadata structures used across kgfoundry.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.navmap_types/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class ModuleMeta\n    class TypedDict\n    TypedDict &lt;|-- ModuleMeta\n    class NavMap\n    TypedDict &lt;|-- NavMap\n    class NavSection\n    TypedDict &lt;|-- NavSection\n    class SymbolMeta\n    TypedDict &lt;|-- SymbolMeta\n</code></pre>"},{"location":"modules/kgfoundry_common.navmap_types/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.navmap_types__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatatyping.Literaltyping.NotRequiredtyping.TypedDictkgfoundry_common.navmap_types code <p>See the full diagram: kgfoundry_common.navmap_types</p>"},{"location":"modules/kgfoundry_common.navmap_types/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.navmap_types.ModuleMeta</li> <li>kgfoundry_common.navmap_types.NavMap</li> <li>kgfoundry_common.navmap_types.NavSection</li> </ul>"},{"location":"modules/kgfoundry_common.navmap_types/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>typing.Literal</code>, <code>typing.NotRequired</code>, <code>typing.TypedDict</code></p>"},{"location":"modules/kgfoundry_common.navmap_types/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.navmap_types/#kgfoundry_commonnavmap_typesmodulemeta","title":"kgfoundry_common.navmap_types.ModuleMeta","text":"<p>Bases: TypedDict</p>"},{"location":"modules/kgfoundry_common.navmap_types/#kgfoundry_common.navmap_types.ModuleMeta","title":"<code>kgfoundry_common.navmap_types.ModuleMeta</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Module-level metadata for documentation.</p> <p>TypedDict representing metadata about a module in the navigation map. Used for documentation generation and module organization.</p> <p>Parameters:</p> Name Type Description Default <code>owner</code> <code>str</code> <p>Owner or team responsible for the module.</p> required <code>stability</code> <code>Stability</code> <p>Stability level of the module.</p> required <code>since</code> <code>str</code> <p>Version when the module was introduced.</p> required <code>deprecated_in</code> <code>str</code> <p>Version when the module was deprecated.</p> required Source code in <code>src/kgfoundry_common/navmap_types.py</code> <pre><code>class ModuleMeta(TypedDict, total=False):\n    \"\"\"Module-level metadata for documentation.\n\n    TypedDict representing metadata about a module in the navigation map.\n    Used for documentation generation and module organization.\n\n    Parameters\n    ----------\n    owner : str\n        Owner or team responsible for the module.\n    stability : Stability\n        Stability level of the module.\n    since : str\n        Version when the module was introduced.\n    deprecated_in : str, optional\n        Version when the module was deprecated.\n    \"\"\"\n\n    owner: str\n    stability: Stability\n    since: str\n    deprecated_in: str\n</code></pre>"},{"location":"modules/kgfoundry_common.navmap_types/#kgfoundry_commonnavmap_typesnavmap","title":"kgfoundry_common.navmap_types.NavMap","text":"<p>Bases: TypedDict</p>"},{"location":"modules/kgfoundry_common.navmap_types/#kgfoundry_common.navmap_types.NavMap","title":"<code>kgfoundry_common.navmap_types.NavMap</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Navigation map metadata structure.</p> <p>TypedDict representing the complete navigation map for a module. Contains all metadata needed for documentation generation, including exports, sections, symbol metadata, and module information.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>Module title.</p> required <code>synopsis</code> <code>str</code> <p>Brief description of the module.</p> required <code>exports</code> <code>list[str]</code> <p>List of public symbol names exported by the module.</p> required <code>sections</code> <code>list[NavSection]</code> <p>List of navigation sections organizing the symbols.</p> required <code>see_also</code> <code>list[str]</code> <p>List of related modules or resources.</p> required <code>tags</code> <code>list[str]</code> <p>List of tags for categorization.</p> required <code>since</code> <code>str</code> <p>Version when the module was introduced.</p> required <code>deprecated</code> <code>str</code> <p>Version when the module was deprecated.</p> required <code>symbols</code> <code>dict[str, SymbolMeta]</code> <p>Dictionary mapping symbol names to their metadata.</p> required <code>edit_scopes</code> <code>dict[str, list[str]]</code> <p>Dictionary mapping edit scopes to symbol lists.</p> required <code>deps</code> <code>list[str]</code> <p>List of dependency module names.</p> required <code>module_meta</code> <code>ModuleMeta</code> <p>Module-level metadata.</p> required Source code in <code>src/kgfoundry_common/navmap_types.py</code> <pre><code>class NavMap(TypedDict, total=False):\n    \"\"\"Navigation map metadata structure.\n\n    TypedDict representing the complete navigation map for a module.\n    Contains all metadata needed for documentation generation, including\n    exports, sections, symbol metadata, and module information.\n\n    Parameters\n    ----------\n    title : str\n        Module title.\n    synopsis : str\n        Brief description of the module.\n    exports : list[str]\n        List of public symbol names exported by the module.\n    sections : list[NavSection]\n        List of navigation sections organizing the symbols.\n    see_also : list[str], optional\n        List of related modules or resources.\n    tags : list[str], optional\n        List of tags for categorization.\n    since : str, optional\n        Version when the module was introduced.\n    deprecated : str, optional\n        Version when the module was deprecated.\n    symbols : dict[str, SymbolMeta], optional\n        Dictionary mapping symbol names to their metadata.\n    edit_scopes : dict[str, list[str]], optional\n        Dictionary mapping edit scopes to symbol lists.\n    deps : list[str], optional\n        List of dependency module names.\n    module_meta : ModuleMeta, optional\n        Module-level metadata.\n    \"\"\"\n\n    title: str\n    synopsis: str\n    exports: list[str]\n    sections: list[NavSection]\n    see_also: list[str]\n    tags: list[str]\n    since: str\n    deprecated: str\n    symbols: dict[str, SymbolMeta]\n    edit_scopes: dict[str, list[str]]\n    deps: list[str]\n    module_meta: ModuleMeta\n</code></pre>"},{"location":"modules/kgfoundry_common.navmap_types/#kgfoundry_commonnavmap_typesnavsection","title":"kgfoundry_common.navmap_types.NavSection","text":"<p>Bases: TypedDict</p>"},{"location":"modules/kgfoundry_common.navmap_types/#kgfoundry_common.navmap_types.NavSection","title":"<code>kgfoundry_common.navmap_types.NavSection</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Navigation section metadata.</p> <p>TypedDict representing a section in the navigation map. Sections group related symbols together for documentation organization.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Unique section identifier.</p> required <code>title</code> <code>str</code> <p>Human-readable section title.</p> required <code>symbols</code> <code>list[str]</code> <p>List of symbol names included in this section.</p> required Source code in <code>src/kgfoundry_common/navmap_types.py</code> <pre><code>class NavSection(TypedDict):\n    \"\"\"Navigation section metadata.\n\n    TypedDict representing a section in the navigation map. Sections\n    group related symbols together for documentation organization.\n\n    Parameters\n    ----------\n    id : str\n        Unique section identifier.\n    title : str\n        Human-readable section title.\n    symbols : list[str]\n        List of symbol names included in this section.\n    \"\"\"\n\n    id: str\n    title: str\n    symbols: list[str]\n</code></pre>"},{"location":"modules/kgfoundry_common.navmap_types/#kgfoundry_commonnavmap_typessymbolmeta","title":"kgfoundry_common.navmap_types.SymbolMeta","text":"<p>Bases: TypedDict</p>"},{"location":"modules/kgfoundry_common.navmap_types/#kgfoundry_common.navmap_types.SymbolMeta","title":"<code>kgfoundry_common.navmap_types.SymbolMeta</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Symbol metadata for documentation and tooling.</p> <p>TypedDict representing metadata about a symbol (function, class, etc.) in the navigation map. Used for documentation generation, testing, and tooling support.</p> <p>Parameters:</p> Name Type Description Default <code>since</code> <code>str</code> <p>Version when the symbol was introduced.</p> required <code>stability</code> <code>Stability</code> <p>Stability level of the symbol.</p> required <code>side_effects</code> <code>list[Literal['none', 'fs', 'net', 'gpu', 'db']]</code> <p>List of side effects the symbol may have.</p> required <code>thread_safety</code> <code>Literal['reentrant', 'threadsafe', 'not-threadsafe']</code> <p>Thread safety guarantee of the symbol.</p> required <code>async_ok</code> <code>bool</code> <p>Whether the symbol is safe to use in async contexts.</p> required <code>perf_budget_ms</code> <code>float</code> <p>Performance budget in milliseconds.</p> required <code>tests</code> <code>list[str]</code> <p>List of test file paths or identifiers.</p> required <code>owner</code> <code>str</code> <p>Owner or team responsible for the symbol.</p> required <code>deprecated_in</code> <code>str</code> <p>Version when the symbol was deprecated.</p> required <code>replaced_by</code> <code>str</code> <p>Symbol name that replaces this deprecated symbol.</p> required <code>deprecated_msg</code> <code>str</code> <p>Deprecation message explaining the change.</p> required <code>contracts</code> <code>list[str]</code> <p>List of contract identifiers (e.g., JSON Schema URIs).</p> required <code>coverage_target</code> <code>float</code> <p>Test coverage target percentage.</p> required Source code in <code>src/kgfoundry_common/navmap_types.py</code> <pre><code>class SymbolMeta(TypedDict, total=False):\n    \"\"\"Symbol metadata for documentation and tooling.\n\n    TypedDict representing metadata about a symbol (function, class, etc.)\n    in the navigation map. Used for documentation generation, testing,\n    and tooling support.\n\n    Parameters\n    ----------\n    since : str\n        Version when the symbol was introduced.\n    stability : Stability\n        Stability level of the symbol.\n    side_effects : list[Literal['none', 'fs', 'net', 'gpu', 'db']]\n        List of side effects the symbol may have.\n    thread_safety : Literal['reentrant', 'threadsafe', 'not-threadsafe']\n        Thread safety guarantee of the symbol.\n    async_ok : bool\n        Whether the symbol is safe to use in async contexts.\n    perf_budget_ms : float\n        Performance budget in milliseconds.\n    tests : list[str]\n        List of test file paths or identifiers.\n    owner : str, optional\n        Owner or team responsible for the symbol.\n    deprecated_in : str, optional\n        Version when the symbol was deprecated.\n    replaced_by : str, optional\n        Symbol name that replaces this deprecated symbol.\n    deprecated_msg : str, optional\n        Deprecation message explaining the change.\n    contracts : list[str], optional\n        List of contract identifiers (e.g., JSON Schema URIs).\n    coverage_target : float, optional\n        Test coverage target percentage.\n    \"\"\"\n\n    since: str\n    stability: Stability\n    side_effects: list[Literal[\"none\", \"fs\", \"net\", \"gpu\", \"db\"]]\n    thread_safety: Literal[\"reentrant\", \"threadsafe\", \"not-threadsafe\"]\n    async_ok: bool\n    perf_budget_ms: float\n    tests: list[str]\n    owner: NotRequired[str]\n    deprecated_in: NotRequired[str]\n    replaced_by: NotRequired[str]\n    deprecated_msg: NotRequired[str]\n    contracts: NotRequired[list[str]]\n    coverage_target: NotRequired[float]\n</code></pre>"},{"location":"modules/kgfoundry_common.numpy_typing/","title":"kgfoundry_common.numpy_typing","text":""},{"location":"modules/kgfoundry_common.numpy_typing/#kgfoundry_commonnumpy_typing","title":"kgfoundry_common.numpy_typing","text":"<p>Typed NumPy helpers shared across vector search modules.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.numpy_typing/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.numpy_typing__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatanumpynumpy.typingtyping.Finaltyping.TYPE_CHECKINGtyping.castkgfoundry_common.numpy_typing code <p>See the full diagram: kgfoundry_common.numpy_typing</p>"},{"location":"modules/kgfoundry_common.numpy_typing/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.numpy_typing.normalize_l2</li> <li>kgfoundry_common.numpy_typing.safe_argpartition</li> <li>kgfoundry_common.numpy_typing.topk_indices</li> </ul>"},{"location":"modules/kgfoundry_common.numpy_typing/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>numpy</code>, <code>numpy.typing</code>, <code>typing.Final</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.numpy_typing/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.numpy_typing/#kgfoundry_commonnumpy_typingnormalize_l2","title":"kgfoundry_common.numpy_typing.normalize_l2","text":""},{"location":"modules/kgfoundry_common.numpy_typing/#kgfoundry_common.numpy_typing.normalize_l2","title":"<code>kgfoundry_common.numpy_typing.normalize_l2(matrix, *, axis=1, epsilon=MIN_EPSILON)</code>","text":"<p>Return an L2-normalised copy of <code>matrix</code> with numerical safeguards.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>FloatMatrix</code> <p>Input vectors that are expected to be contiguous <code>float32</code> values.</p> required <code>axis</code> <code>int</code> <p>Axis along which norms are computed. Defaults to <code>1</code> for row vectors.</p> <code>1</code> <code>epsilon</code> <code>float</code> <p>Minimum norm value to clamp to for zero or denormalised rows.</p> <code>MIN_EPSILON</code> <p>Returns:</p> Type Description <code>FloatMatrix</code> <p>L2-normalized matrix with same shape as input.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from kgfoundry_common.numpy_typing import normalize_l2\n&gt;&gt;&gt; mat = np.array([[3.0, 4.0], [0.0, 0.0]], dtype=np.float32)\n&gt;&gt;&gt; normalize_l2(mat)\narray([[0.6, 0.8],\n       [0. , 0. ]], dtype=float32)\n</code></pre> <pre><code>&gt;&gt;&gt; normalize_l2(np.zeros((1, 4), dtype=np.float32))\narray([[0., 0., 0., 0.]], dtype=float32)\n</code></pre> Source code in <code>src/kgfoundry_common/numpy_typing.py</code> <pre><code>def normalize_l2(\n    matrix: FloatMatrix,\n    *,\n    axis: int = 1,\n    epsilon: float = MIN_EPSILON,\n) -&gt; FloatMatrix:\n    \"\"\"Return an L2-normalised copy of ``matrix`` with numerical safeguards.\n\n    Parameters\n    ----------\n    matrix:\n        Input vectors that are expected to be contiguous ``float32`` values.\n    axis:\n        Axis along which norms are computed. Defaults to ``1`` for row vectors.\n    epsilon:\n        Minimum norm value to clamp to for zero or denormalised rows.\n\n    Returns\n    -------\n    FloatMatrix\n        L2-normalized matrix with same shape as input.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from kgfoundry_common.numpy_typing import normalize_l2\n    &gt;&gt;&gt; mat = np.array([[3.0, 4.0], [0.0, 0.0]], dtype=np.float32)\n    &gt;&gt;&gt; normalize_l2(mat)\n    array([[0.6, 0.8],\n           [0. , 0. ]], dtype=float32)\n\n    &gt;&gt;&gt; normalize_l2(np.zeros((1, 4), dtype=np.float32))\n    array([[0., 0., 0., 0.]], dtype=float32)\n    \"\"\"\n    matrix_f32: FloatMatrix = np.asarray(matrix, dtype=np.float32, order=\"C\")\n    norms_untyped: Float64Matrix = np.linalg.norm(matrix_f32, axis=axis, keepdims=True)\n    norms: FloatMatrix = norms_untyped.astype(np.float32, copy=False)\n    np.maximum(norms, epsilon, out=norms)\n    np.divide(matrix_f32, norms, out=matrix_f32)\n    return matrix_f32\n</code></pre>"},{"location":"modules/kgfoundry_common.numpy_typing/#kgfoundry_commonnumpy_typingsafe_argpartition","title":"kgfoundry_common.numpy_typing.safe_argpartition","text":""},{"location":"modules/kgfoundry_common.numpy_typing/#kgfoundry_common.numpy_typing.safe_argpartition","title":"<code>kgfoundry_common.numpy_typing.safe_argpartition(values, k)</code>","text":"<p>Return indices of the smallest <code>k</code> values with predictable ordering.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>FloatVector</code> <p>Input vector to partition.</p> required <code>k</code> <code>int</code> <p>Number of smallest values to select.</p> required <p>Returns:</p> Type Description <code>IntVector</code> <p>Indices of the smallest k values, sorted.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If k is negative.</p> Source code in <code>src/kgfoundry_common/numpy_typing.py</code> <pre><code>def safe_argpartition(values: FloatVector, k: int) -&gt; IntVector:\n    \"\"\"Return indices of the smallest ``k`` values with predictable ordering.\n\n    Parameters\n    ----------\n    values : FloatVector\n        Input vector to partition.\n    k : int\n        Number of smallest values to select.\n\n    Returns\n    -------\n    IntVector\n        Indices of the smallest k values, sorted.\n\n    Raises\n    ------\n    ValueError\n        If k is negative.\n    \"\"\"\n    if k &lt; 0:\n        msg = \"k must be non-negative\"\n        raise ValueError(msg)\n\n    values_array: FloatVector = np.asarray(values, dtype=np.float32, order=\"C\")\n    if k == 0 or values_array.size == 0:\n        return cast(\"IntVector\", np.empty(0, dtype=np.int64))\n\n    trimmed_k = min(k, values_array.size)\n    partition = np.argpartition(values_array, trimmed_k - 1)[:trimmed_k]\n    return np.sort(partition).astype(np.int64, copy=False)\n</code></pre>"},{"location":"modules/kgfoundry_common.numpy_typing/#kgfoundry_commonnumpy_typingtopk_indices","title":"kgfoundry_common.numpy_typing.topk_indices","text":""},{"location":"modules/kgfoundry_common.numpy_typing/#kgfoundry_common.numpy_typing.topk_indices","title":"<code>kgfoundry_common.numpy_typing.topk_indices(scores, k)</code>","text":"<p>Return indices of the top <code>k</code> scores sorted by descending score.</p> <p>Parameters:</p> Name Type Description Default <code>scores</code> <code>FloatVector</code> <p>Input score vector.</p> required <code>k</code> <code>int</code> <p>Number of top scores to select.</p> required <p>Returns:</p> Type Description <code>IntVector</code> <p>Indices of the top k scores, sorted by descending score.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If k is not positive.</p> Source code in <code>src/kgfoundry_common/numpy_typing.py</code> <pre><code>def topk_indices(scores: FloatVector, k: int) -&gt; IntVector:\n    \"\"\"Return indices of the top ``k`` scores sorted by descending score.\n\n    Parameters\n    ----------\n    scores : FloatVector\n        Input score vector.\n    k : int\n        Number of top scores to select.\n\n    Returns\n    -------\n    IntVector\n        Indices of the top k scores, sorted by descending score.\n\n    Raises\n    ------\n    ValueError\n        If k is not positive.\n    \"\"\"\n    if k &lt;= 0:\n        msg = \"k must be positive\"\n        raise ValueError(msg)\n\n    scores_array: FloatVector = np.asarray(scores, dtype=np.float32, order=\"C\")\n    total = scores_array.size\n    if total == 0:\n        return cast(\"IntVector\", np.empty(0, dtype=np.int64))\n\n    trimmed_k = min(k, total)\n    score_list = cast(\"list[float]\", scores_array.astype(np.float64, copy=False).tolist())\n\n    def sort_key(idx: int) -&gt; tuple[float, int]:\n        \"\"\"Return sort key tuple for index ranking.\n\n        Parameters\n        ----------\n        idx : int\n            Index into score_list.\n\n        Returns\n        -------\n        tuple[float, int]\n            Tuple of (score, negative_index) for stable sorting.\n        \"\"\"\n        return (float(score_list[idx]), -idx)\n\n    ranked = sorted(range(total), key=sort_key, reverse=True)[:trimmed_k]\n    ranked_array: IntVector = np.asarray(ranked, dtype=np.int64)\n    return ranked_array\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/","title":"kgfoundry_common.observability","text":""},{"location":"modules/kgfoundry_common.observability/#kgfoundry_commonobservability","title":"kgfoundry_common.observability","text":"<p>Prometheus metrics and OpenTelemetry tracing helpers</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.observability/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class MetricsProvider\n    class MetricsRegistry\n    class _DurationObserver\n    class _ObservabilityCache\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.observability__future__.annotationscollections.abc.Iteratorcollections.abc.Mappingcontextlib.contextmanagerdataclasses.dataclassdataclasses.fieldkgfoundry_common.logging.get_loggerkgfoundry_common.logging.with_fieldskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.opentelemetry_types.StatusCodeProtocolkgfoundry_common.opentelemetry_types.TraceRuntimekgfoundry_common.opentelemetry_types.load_trace_runtimekgfoundry_common.prometheus.CollectorRegistrykgfoundry_common.prometheus.CounterLikekgfoundry_common.prometheus.HistogramLikekgfoundry_common.prometheus.build_counterkgfoundry_common.prometheus.build_histogramkgfoundry_common.prometheus.get_default_registrytimetyping.Literaltyping.TYPE_CHECKINGtyping.castkgfoundry_common.observability code <p>See the full diagram: kgfoundry_common.observability</p>"},{"location":"modules/kgfoundry_common.observability/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.observability.MetricsProvider</li> <li>kgfoundry_common.observability.MetricsRegistry</li> <li>kgfoundry_common.observability._DurationObserver</li> <li>kgfoundry_common.observability._finalise_observation</li> <li>kgfoundry_common.observability.get_metrics_registry</li> <li>kgfoundry_common.observability.observe_duration</li> </ul>"},{"location":"modules/kgfoundry_common.observability/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Iterator</code>, <code>collections.abc.Mapping</code>, <code>contextlib.contextmanager</code>, <code>dataclasses.dataclass</code>, <code>dataclasses.field</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>kgfoundry_common.logging.with_fields</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.opentelemetry_types.StatusCodeProtocol</code>, <code>kgfoundry_common.opentelemetry_types.TraceRuntime</code>, <code>kgfoundry_common.opentelemetry_types.load_trace_runtime</code>, <code>kgfoundry_common.prometheus.CollectorRegistry</code>, <code>kgfoundry_common.prometheus.CounterLike</code>, <code>kgfoundry_common.prometheus.HistogramLike</code>, <code>kgfoundry_common.prometheus.build_counter</code>, <code>kgfoundry_common.prometheus.build_histogram</code>, <code>kgfoundry_common.prometheus.get_default_registry</code>, <code>time</code>, <code>typing.Literal</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.observability/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.observability/#kgfoundry_commonobservabilitymetricsprovider","title":"kgfoundry_common.observability.MetricsProvider","text":""},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability.MetricsProvider","title":"<code>kgfoundry_common.observability.MetricsProvider</code>  <code>dataclass</code>","text":"<p>Provide component-level metrics for long-running operations.</p> Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>@dataclass(slots=True)\n# [nav:anchor MetricsProvider]\nclass MetricsProvider:\n    \"\"\"Provide component-level metrics for long-running operations.\"\"\"\n\n    runs_total: CounterLike\n    operation_duration_seconds: HistogramLike\n    _registry: CollectorRegistry | None = field(default=None, repr=False)\n\n    def __init__(self, registry: CollectorRegistry | None = None) -&gt; None:\n        \"\"\"Initialise the metrics provider.\"\"\"\n        resolved_registry = cast(\"CollectorRegistry | None\", registry or get_default_registry())\n        self._registry = resolved_registry\n        self.runs_total = build_counter(\n            \"kgfoundry_runs_total\",\n            \"Total number of operations executed by a component.\",\n            (\"component\", \"status\"),\n            registry=resolved_registry,\n        )\n        self.operation_duration_seconds = build_histogram(\n            \"kgfoundry_operation_duration_seconds\",\n            \"Operation duration in seconds for each component/operation pair.\",\n            (\"component\", \"operation\", \"status\"),\n            registry=resolved_registry,\n        )\n\n    @property\n    def registry(self) -&gt; CollectorRegistry | None:\n        \"\"\"Return the underlying Prometheus registry (may be ``None``).\"\"\"\n        return self._registry\n\n    @classmethod\n    def default(cls) -&gt; MetricsProvider:\n        \"\"\"Return a cached provider instance suitable for process-wide use.\n\n        Returns\n        -------\n        MetricsProvider\n            Cached metrics provider instance.\n        \"\"\"\n        if _OBS_CACHE.provider is None:\n            _OBS_CACHE.provider = MetricsProvider()\n        return _OBS_CACHE.provider\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability.MetricsProvider.registry","title":"<code>registry</code>  <code>property</code>","text":"<p>Return the underlying Prometheus registry (may be <code>None</code>).</p>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability.MetricsProvider.__init__","title":"<code>__init__(registry=None)</code>","text":"<p>Initialise the metrics provider.</p> Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>def __init__(self, registry: CollectorRegistry | None = None) -&gt; None:\n    \"\"\"Initialise the metrics provider.\"\"\"\n    resolved_registry = cast(\"CollectorRegistry | None\", registry or get_default_registry())\n    self._registry = resolved_registry\n    self.runs_total = build_counter(\n        \"kgfoundry_runs_total\",\n        \"Total number of operations executed by a component.\",\n        (\"component\", \"status\"),\n        registry=resolved_registry,\n    )\n    self.operation_duration_seconds = build_histogram(\n        \"kgfoundry_operation_duration_seconds\",\n        \"Operation duration in seconds for each component/operation pair.\",\n        (\"component\", \"operation\", \"status\"),\n        registry=resolved_registry,\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability.MetricsProvider.default","title":"<code>default()</code>  <code>classmethod</code>","text":"<p>Return a cached provider instance suitable for process-wide use.</p> <p>Returns:</p> Type Description <code>MetricsProvider</code> <p>Cached metrics provider instance.</p> Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>@classmethod\ndef default(cls) -&gt; MetricsProvider:\n    \"\"\"Return a cached provider instance suitable for process-wide use.\n\n    Returns\n    -------\n    MetricsProvider\n        Cached metrics provider instance.\n    \"\"\"\n    if _OBS_CACHE.provider is None:\n        _OBS_CACHE.provider = MetricsProvider()\n    return _OBS_CACHE.provider\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_commonobservabilitymetricsregistry","title":"kgfoundry_common.observability.MetricsRegistry","text":""},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability.MetricsRegistry","title":"<code>kgfoundry_common.observability.MetricsRegistry</code>  <code>dataclass</code>","text":"<p>Expose request-level counters and histograms for HTTP surfaces.</p> Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>@dataclass(slots=True)\n# [nav:anchor MetricsRegistry]\nclass MetricsRegistry:\n    \"\"\"Expose request-level counters and histograms for HTTP surfaces.\"\"\"\n\n    requests_total: CounterLike\n    request_errors_total: CounterLike\n    request_duration_seconds: HistogramLike\n    _registry: CollectorRegistry | None = field(default=None, repr=False)\n\n    def __init__(\n        self,\n        *,\n        namespace: str = \"kgfoundry\",\n        registry: CollectorRegistry | None = None,\n    ) -&gt; None:\n        \"\"\"Initialise a metrics registry scoped to ``namespace``.\"\"\"\n        resolved_registry = cast(\"CollectorRegistry | None\", registry or get_default_registry())\n        metric_prefix = namespace.replace(\"-\", \"_\")\n        labels = (\"operation\", \"status\")\n        self._registry = resolved_registry\n        self.requests_total = build_counter(\n            f\"{metric_prefix}_requests_total\",\n            \"Total number of processed operations.\",\n            labels,\n            registry=resolved_registry,\n        )\n        self.request_errors_total = build_counter(\n            f\"{metric_prefix}_request_errors_total\",\n            \"Total number of failed operations.\",\n            labels,\n            registry=resolved_registry,\n        )\n        self.request_duration_seconds = build_histogram(\n            f\"{metric_prefix}_request_duration_seconds\",\n            \"Operation latency in seconds.\",\n            (\"operation\",),\n            registry=resolved_registry,\n        )\n\n    @property\n    def registry(self) -&gt; CollectorRegistry | None:\n        \"\"\"Return the underlying Prometheus registry (may be ``None``).\"\"\"\n        return self._registry\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability.MetricsRegistry.registry","title":"<code>registry</code>  <code>property</code>","text":"<p>Return the underlying Prometheus registry (may be <code>None</code>).</p>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability.MetricsRegistry.__init__","title":"<code>__init__(*, namespace='kgfoundry', registry=None)</code>","text":"<p>Initialise a metrics registry scoped to <code>namespace</code>.</p> Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>def __init__(\n    self,\n    *,\n    namespace: str = \"kgfoundry\",\n    registry: CollectorRegistry | None = None,\n) -&gt; None:\n    \"\"\"Initialise a metrics registry scoped to ``namespace``.\"\"\"\n    resolved_registry = cast(\"CollectorRegistry | None\", registry or get_default_registry())\n    metric_prefix = namespace.replace(\"-\", \"_\")\n    labels = (\"operation\", \"status\")\n    self._registry = resolved_registry\n    self.requests_total = build_counter(\n        f\"{metric_prefix}_requests_total\",\n        \"Total number of processed operations.\",\n        labels,\n        registry=resolved_registry,\n    )\n    self.request_errors_total = build_counter(\n        f\"{metric_prefix}_request_errors_total\",\n        \"Total number of failed operations.\",\n        labels,\n        registry=resolved_registry,\n    )\n    self.request_duration_seconds = build_histogram(\n        f\"{metric_prefix}_request_duration_seconds\",\n        \"Operation latency in seconds.\",\n        (\"operation\",),\n        registry=resolved_registry,\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_commonobservability_durationobserver","title":"kgfoundry_common.observability._DurationObserver","text":""},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability._DurationObserver","title":"<code>kgfoundry_common.observability._DurationObserver</code>  <code>dataclass</code>","text":"<p>Track the state of an in-flight operation for structured recording.</p> Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>@dataclass(slots=True)\nclass _DurationObserver:\n    \"\"\"Track the state of an in-flight operation for structured recording.\"\"\"\n\n    metrics: MetricsProvider\n    operation: str\n    component: str\n    correlation_id: str | None\n    status: StatusLiteral = \"success\"\n    _start: float = field(default_factory=time.monotonic)\n\n    def success(self) -&gt; None:\n        \"\"\"Mark the operation as successful.\"\"\"\n        self.status = \"success\"\n\n    def error(self) -&gt; None:\n        \"\"\"Mark the operation as failed.\"\"\"\n        self.status = \"error\"\n\n    def duration_seconds(self) -&gt; float:\n        \"\"\"Return the elapsed duration in seconds.\n\n        Returns\n        -------\n        float\n            Elapsed duration in seconds since the observer was created.\n        \"\"\"\n        return time.monotonic() - self._start\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability._DurationObserver.duration_seconds","title":"<code>duration_seconds()</code>","text":"<p>Return the elapsed duration in seconds.</p> <p>Returns:</p> Type Description <code>float</code> <p>Elapsed duration in seconds since the observer was created.</p> Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>def duration_seconds(self) -&gt; float:\n    \"\"\"Return the elapsed duration in seconds.\n\n    Returns\n    -------\n    float\n        Elapsed duration in seconds since the observer was created.\n    \"\"\"\n    return time.monotonic() - self._start\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability._DurationObserver.error","title":"<code>error()</code>","text":"<p>Mark the operation as failed.</p> Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>def error(self) -&gt; None:\n    \"\"\"Mark the operation as failed.\"\"\"\n    self.status = \"error\"\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability._DurationObserver.success","title":"<code>success()</code>","text":"<p>Mark the operation as successful.</p> Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>def success(self) -&gt; None:\n    \"\"\"Mark the operation as successful.\"\"\"\n    self.status = \"success\"\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_commonobservability_observabilitycache","title":"kgfoundry_common.observability._ObservabilityCache","text":""},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability._ObservabilityCache","title":"<code>kgfoundry_common.observability._ObservabilityCache</code>  <code>dataclass</code>","text":"Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>@dataclass(slots=True)\nclass _ObservabilityCache:\n    provider: MetricsProvider | None = None\n    registry: MetricsRegistry | None = None\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_commonobservability_finalise_observation","title":"kgfoundry_common.observability._finalise_observation","text":""},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability._finalise_observation","title":"<code>kgfoundry_common.observability._finalise_observation(observer)</code>","text":"Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>def _finalise_observation(observer: _DurationObserver) -&gt; None:\n    duration = observer.duration_seconds()\n    observer.metrics.runs_total.labels(\n        component=observer.component,\n        status=observer.status,\n    ).inc()\n    observer.metrics.operation_duration_seconds.labels(\n        component=observer.component,\n        operation=observer.operation,\n        status=observer.status,\n    ).observe(duration)\n    extra = {\n        \"component\": observer.component,\n        \"duration_ms\": duration * 1000,\n    }\n    with with_fields(\n        LOGGER,\n        correlation_id=observer.correlation_id,\n        operation=observer.operation,\n        status=observer.status,\n    ) as adapter:\n        adapter.info(\"Operation completed\", extra=extra)\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_commonobservabilityget_metrics_registry","title":"kgfoundry_common.observability.get_metrics_registry","text":""},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability.get_metrics_registry","title":"<code>kgfoundry_common.observability.get_metrics_registry()</code>","text":"<p>Return the process-wide metrics registry singleton.</p> <p>Returns:</p> Type Description <code>MetricsRegistry</code> <p>Process-wide metrics registry instance.</p> Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>def get_metrics_registry() -&gt; MetricsRegistry:\n    \"\"\"Return the process-wide metrics registry singleton.\n\n    Returns\n    -------\n    MetricsRegistry\n        Process-wide metrics registry instance.\n    \"\"\"\n    if _OBS_CACHE.registry is None:\n        _OBS_CACHE.registry = MetricsRegistry()\n    return _OBS_CACHE.registry\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_commonobservabilityobserve_duration","title":"kgfoundry_common.observability.observe_duration","text":""},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability.observe_duration","title":"<code>kgfoundry_common.observability.observe_duration(metrics, operation, *, component='unknown', correlation_id=None)</code>","text":"<p>Record metrics and structured logs for a component operation.</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>MetricsProvider</code> <p>Metrics provider instance.</p> required <code>operation</code> <code>str</code> <p>Operation name.</p> required <code>component</code> <code>str</code> <p>Component name. Defaults to \"unknown\".</p> <code>'unknown'</code> <code>correlation_id</code> <code>str | None</code> <p>Correlation ID for tracing.</p> <code>None</code> <p>Yields:</p> Type Description <code>_DurationObserver</code> <p>Observer instance for tracking operation state.</p> Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>@contextmanager\n# [nav:anchor observe_duration]\ndef observe_duration(\n    metrics: MetricsProvider,\n    operation: str,\n    *,\n    component: str = \"unknown\",\n    correlation_id: str | None = None,\n) -&gt; Iterator[_DurationObserver]:\n    \"\"\"Record metrics and structured logs for a component operation.\n\n    Parameters\n    ----------\n    metrics : MetricsProvider\n        Metrics provider instance.\n    operation : str\n        Operation name.\n    component : str, optional\n        Component name. Defaults to \"unknown\".\n    correlation_id : str | None, optional\n        Correlation ID for tracing.\n\n    Yields\n    ------\n    _DurationObserver\n        Observer instance for tracking operation state.\n    \"\"\"\n    observer = _DurationObserver(metrics, operation, component, correlation_id)\n    try:\n        yield observer\n    except Exception:\n        observer.status = \"error\"\n        _finalise_observation(observer)\n        raise\n    else:\n        _finalise_observation(observer)\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_commonobservabilityrecord_operation","title":"kgfoundry_common.observability.record_operation","text":""},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability.record_operation","title":"<code>kgfoundry_common.observability.record_operation(metrics=None, *, operation='unknown', correlation_id=None)</code>","text":"<p>Track request counters and latency for an externally visible operation.</p> Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>@contextmanager\n# [nav:anchor record_operation]\ndef record_operation(\n    metrics: MetricsRegistry | None = None,\n    *,\n    operation: str = \"unknown\",\n    correlation_id: str | None = None,\n) -&gt; Iterator[None]:\n    \"\"\"Track request counters and latency for an externally visible operation.\"\"\"\n    registry = metrics or get_metrics_registry()\n    status: StatusLiteral = \"success\"\n    start = time.monotonic()\n    try:\n        yield\n    except Exception:\n        status = \"error\"\n        raise\n    finally:\n        duration = time.monotonic() - start\n        registry.requests_total.labels(operation=operation, status=status).inc()\n        if status == \"error\":\n            registry.request_errors_total.labels(operation=operation, status=status).inc()\n        registry.request_duration_seconds.labels(operation=operation).observe(duration)\n        extra = {\"duration_ms\": duration * 1000}\n        with with_fields(\n            LOGGER,\n            correlation_id=correlation_id,\n            operation=operation,\n            status=status,\n        ) as adapter:\n            if status == \"error\":\n                adapter.error(\"Operation failed\", extra=extra)\n            else:\n                adapter.info(\"Operation completed\", extra=extra)\n</code></pre>"},{"location":"modules/kgfoundry_common.observability/#kgfoundry_commonobservabilitystart_span","title":"kgfoundry_common.observability.start_span","text":""},{"location":"modules/kgfoundry_common.observability/#kgfoundry_common.observability.start_span","title":"<code>kgfoundry_common.observability.start_span(name, attributes=None)</code>","text":"<p>Start an OpenTelemetry span when the optional dependency is available.</p> Source code in <code>src/kgfoundry_common/observability.py</code> <pre><code>@contextmanager\n# [nav:anchor start_span]\ndef start_span(\n    name: str,\n    attributes: Mapping[str, str | int | float | bool] | None = None,\n) -&gt; Iterator[None]:\n    \"\"\"Start an OpenTelemetry span when the optional dependency is available.\"\"\"\n    if trace_api is None:\n        yield\n        return\n\n    tracer = trace_api.get_tracer(__name__)\n    with tracer.start_as_current_span(name) as span:\n        if attributes:\n            for key, value in attributes.items():\n                span.set_attribute(key, value)\n        try:\n            yield\n        except Exception as exc:  # pragma: no cover - requires OpenTelemetry at runtime\n            span.record_exception(exc)\n            if Status is not None and StatusCode is not None:\n                error_code: StatusCodeProtocol = StatusCode.ERROR\n                span.set_status(Status(error_code))\n            raise\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/","title":"kgfoundry_common.opentelemetry_types","text":""},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_commonopentelemetry_types","title":"kgfoundry_common.opentelemetry_types","text":"<p>Shared utilities and data structures used across KgFoundry services and tools.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class SpanExporterProtocol\n    class Protocol\n    Protocol &lt;|-- SpanExporterProtocol\n    class SpanProcessorProtocol\n    Protocol &lt;|-- SpanProcessorProtocol\n    class SpanProtocol\n    Protocol &lt;|-- SpanProtocol\n    class StatusCodeProtocol\n    Protocol &lt;|-- StatusCodeProtocol\n    class StatusFactory\n    Protocol &lt;|-- StatusFactory\n    class TraceAPIProtocol\n    Protocol &lt;|-- TraceAPIProtocol\n    class TraceRuntime\n    class TracerProtocol\n    Protocol &lt;|-- TracerProtocol\n    class TracerProviderProtocol\n    Protocol &lt;|-- TracerProviderProtocol\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.opentelemetry_types__future__.annotationscollections.abc.Callablecollections.abc.Mappingcollections.abc.Sequencecontextlib.AbstractContextManagerdataclasses.dataclassimportlib.import_moduletyping.Protocoltyping.TYPE_CHECKINGtyping.castkgfoundry_common.opentelemetry_types code <p>See the full diagram: kgfoundry_common.opentelemetry_types</p>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.opentelemetry_types.SpanExporterProtocol</li> <li>kgfoundry_common.opentelemetry_types.SpanProcessorProtocol</li> <li>kgfoundry_common.opentelemetry_types.SpanProtocol</li> <li>kgfoundry_common.opentelemetry_types._safe_getattr</li> <li>kgfoundry_common.opentelemetry_types.load_in_memory_span_exporter_cls</li> <li>kgfoundry_common.opentelemetry_types.load_trace_runtime</li> </ul>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Callable</code>, <code>collections.abc.Mapping</code>, <code>collections.abc.Sequence</code>, <code>contextlib.AbstractContextManager</code>, <code>dataclasses.dataclass</code>, <code>importlib.import_module</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_commonopentelemetry_typesspanexporterprotocol","title":"kgfoundry_common.opentelemetry_types.SpanExporterProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.SpanExporterProtocol","title":"<code>kgfoundry_common.opentelemetry_types.SpanExporterProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Minimal exporter interface used by the OpenTelemetry fixtures.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>class SpanExporterProtocol(Protocol):\n    \"\"\"Minimal exporter interface used by the OpenTelemetry fixtures.\"\"\"\n\n    def export(self, spans: Sequence[object]) -&gt; None:\n        \"\"\"Export ``spans`` to the configured backend.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.SpanExporterProtocol.export","title":"<code>export(spans)</code>","text":"<p>Export <code>spans</code> to the configured backend.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def export(self, spans: Sequence[object]) -&gt; None:\n    \"\"\"Export ``spans`` to the configured backend.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_commonopentelemetry_typesspanprocessorprotocol","title":"kgfoundry_common.opentelemetry_types.SpanProcessorProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.SpanProcessorProtocol","title":"<code>kgfoundry_common.opentelemetry_types.SpanProcessorProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Span processor lifecycle hooks invoked by the tests.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>class SpanProcessorProtocol(Protocol):\n    \"\"\"Span processor lifecycle hooks invoked by the tests.\"\"\"\n\n    def on_start(self, span: SpanProtocol, parent_context: object | None = None) -&gt; None:\n        \"\"\"Observe ``span`` immediately after creation.\"\"\"\n        del self, span, parent_context\n        raise NotImplementedError\n\n    def on_end(self, span: SpanProtocol) -&gt; None:\n        \"\"\"Observe ``span`` once it has completed.\"\"\"\n        ...\n\n    def shutdown(self) -&gt; None:\n        \"\"\"Release resources associated with the processor.\"\"\"\n        ...\n\n    def force_flush(self, timeout_millis: int | None = None) -&gt; bool:\n        \"\"\"Flush buffered spans within ``timeout_millis``.\"\"\"\n        del self, timeout_millis\n        raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.SpanProcessorProtocol.force_flush","title":"<code>force_flush(timeout_millis=None)</code>","text":"<p>Flush buffered spans within <code>timeout_millis</code>.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def force_flush(self, timeout_millis: int | None = None) -&gt; bool:\n    \"\"\"Flush buffered spans within ``timeout_millis``.\"\"\"\n    del self, timeout_millis\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.SpanProcessorProtocol.on_end","title":"<code>on_end(span)</code>","text":"<p>Observe <code>span</code> once it has completed.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def on_end(self, span: SpanProtocol) -&gt; None:\n    \"\"\"Observe ``span`` once it has completed.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.SpanProcessorProtocol.on_start","title":"<code>on_start(span, parent_context=None)</code>","text":"<p>Observe <code>span</code> immediately after creation.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def on_start(self, span: SpanProtocol, parent_context: object | None = None) -&gt; None:\n    \"\"\"Observe ``span`` immediately after creation.\"\"\"\n    del self, span, parent_context\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.SpanProcessorProtocol.shutdown","title":"<code>shutdown()</code>","text":"<p>Release resources associated with the processor.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def shutdown(self) -&gt; None:\n    \"\"\"Release resources associated with the processor.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_commonopentelemetry_typesspanprotocol","title":"kgfoundry_common.opentelemetry_types.SpanProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.SpanProtocol","title":"<code>kgfoundry_common.opentelemetry_types.SpanProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Minimal span surface exercised by the observability helpers.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>class SpanProtocol(Protocol):\n    \"\"\"Minimal span surface exercised by the observability helpers.\"\"\"\n\n    def set_attribute(self, key: str, value: SpanAttributeValue) -&gt; None:\n        \"\"\"Attach ``value`` to ``key`` on the span.\"\"\"\n\n    def record_exception(self, exception: BaseException) -&gt; None:\n        \"\"\"Record ``exception`` on the span.\"\"\"\n\n    def set_status(self, status: object) -&gt; None:\n        \"\"\"Persist ``status`` on the span.\"\"\"\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.SpanProtocol.record_exception","title":"<code>record_exception(exception)</code>","text":"<p>Record <code>exception</code> on the span.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def record_exception(self, exception: BaseException) -&gt; None:\n    \"\"\"Record ``exception`` on the span.\"\"\"\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.SpanProtocol.set_attribute","title":"<code>set_attribute(key, value)</code>","text":"<p>Attach <code>value</code> to <code>key</code> on the span.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def set_attribute(self, key: str, value: SpanAttributeValue) -&gt; None:\n    \"\"\"Attach ``value`` to ``key`` on the span.\"\"\"\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.SpanProtocol.set_status","title":"<code>set_status(status)</code>","text":"<p>Persist <code>status</code> on the span.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def set_status(self, status: object) -&gt; None:\n    \"\"\"Persist ``status`` on the span.\"\"\"\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_commonopentelemetry_typesstatuscodeprotocol","title":"kgfoundry_common.opentelemetry_types.StatusCodeProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.StatusCodeProtocol","title":"<code>kgfoundry_common.opentelemetry_types.StatusCodeProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Subset of <code>opentelemetry.trace.StatusCode</code> used in observability.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>class StatusCodeProtocol(Protocol):\n    \"\"\"Subset of ``opentelemetry.trace.StatusCode`` used in observability.\"\"\"\n\n    ERROR: StatusCodeProtocol\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_commonopentelemetry_typesstatusfactory","title":"kgfoundry_common.opentelemetry_types.StatusFactory","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.StatusFactory","title":"<code>kgfoundry_common.opentelemetry_types.StatusFactory</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Factory callable for instantiating <code>Status</code> instances.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>class StatusFactory(Protocol):\n    \"\"\"Factory callable for instantiating ``Status`` instances.\"\"\"\n\n    def __call__(\n        self,\n        status_code: StatusCodeProtocol,\n        description: str | None = None,\n    ) -&gt; object:\n        \"\"\"Create a status object using ``status_code`` and ``description``.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.StatusFactory.__call__","title":"<code>__call__(status_code, description=None)</code>","text":"<p>Create a status object using <code>status_code</code> and <code>description</code>.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def __call__(\n    self,\n    status_code: StatusCodeProtocol,\n    description: str | None = None,\n) -&gt; object:\n    \"\"\"Create a status object using ``status_code`` and ``description``.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_commonopentelemetry_typestraceapiprotocol","title":"kgfoundry_common.opentelemetry_types.TraceAPIProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.TraceAPIProtocol","title":"<code>kgfoundry_common.opentelemetry_types.TraceAPIProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Subset of the OpenTelemetry trace module used by the codebase.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>class TraceAPIProtocol(Protocol):\n    \"\"\"Subset of the OpenTelemetry trace module used by the codebase.\"\"\"\n\n    def get_tracer(self, name: str) -&gt; TracerProtocol:\n        \"\"\"Return a tracer for ``name``.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.TraceAPIProtocol.get_tracer","title":"<code>get_tracer(name)</code>","text":"<p>Return a tracer for <code>name</code>.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def get_tracer(self, name: str) -&gt; TracerProtocol:\n    \"\"\"Return a tracer for ``name``.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_commonopentelemetry_typestraceruntime","title":"kgfoundry_common.opentelemetry_types.TraceRuntime","text":""},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.TraceRuntime","title":"<code>kgfoundry_common.opentelemetry_types.TraceRuntime</code>  <code>dataclass</code>","text":"<p>Container for optional OpenTelemetry runtime handles.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>@dataclass(slots=True)\nclass TraceRuntime:\n    \"\"\"Container for optional OpenTelemetry runtime handles.\"\"\"\n\n    api: TraceAPIProtocol | None\n    status_factory: StatusFactory | None\n    status_codes: StatusCodeProtocol | None\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_commonopentelemetry_typestracerprotocol","title":"kgfoundry_common.opentelemetry_types.TracerProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.TracerProtocol","title":"<code>kgfoundry_common.opentelemetry_types.TracerProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Tracer facade returned by <code>opentelemetry.trace.get_tracer</code>.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>class TracerProtocol(Protocol):\n    \"\"\"Tracer facade returned by ``opentelemetry.trace.get_tracer``.\"\"\"\n\n    def start_as_current_span(self, name: str) -&gt; AbstractContextManager[SpanProtocol]:\n        \"\"\"Return a context manager yielding a span.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.TracerProtocol.start_as_current_span","title":"<code>start_as_current_span(name)</code>","text":"<p>Return a context manager yielding a span.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def start_as_current_span(self, name: str) -&gt; AbstractContextManager[SpanProtocol]:\n    \"\"\"Return a context manager yielding a span.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_commonopentelemetry_typestracerproviderprotocol","title":"kgfoundry_common.opentelemetry_types.TracerProviderProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.TracerProviderProtocol","title":"<code>kgfoundry_common.opentelemetry_types.TracerProviderProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Tracer provider constructor and helpers used in fixtures.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>class TracerProviderProtocol(Protocol):\n    \"\"\"Tracer provider constructor and helpers used in fixtures.\"\"\"\n\n    def __init__(self, *args: object, **kwargs: object) -&gt; None:\n        \"\"\"Initialise the provider with optional configuration.\"\"\"\n\n    def get_tracer(\n        self,\n        instrumenting_module_name: str,\n        instrumenting_library_version: str | None = None,\n        schema_url: str | None = None,\n        attributes: Attributes | None = None,\n    ) -&gt; TracerProtocol:\n        \"\"\"Return a tracer configured for the given instrumentation metadata.\"\"\"\n        del self, instrumenting_module_name, instrumenting_library_version, schema_url, attributes\n        raise NotImplementedError\n\n    def add_span_processor(self, processor: SpanProcessorProtocol) -&gt; None:\n        \"\"\"Register ``processor`` for span lifecycle callbacks.\"\"\"\n        del self, processor\n        raise NotImplementedError\n\n    def shutdown(self) -&gt; None:\n        \"\"\"Shut down the provider gracefully.\"\"\"\n        ...\n\n    def force_flush(self, timeout_millis: int | None = None) -&gt; bool:\n        \"\"\"Flush pending spans and return ``True`` on success.\"\"\"\n        del self, timeout_millis\n        raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.TracerProviderProtocol.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Initialise the provider with optional configuration.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def __init__(self, *args: object, **kwargs: object) -&gt; None:\n    \"\"\"Initialise the provider with optional configuration.\"\"\"\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.TracerProviderProtocol.add_span_processor","title":"<code>add_span_processor(processor)</code>","text":"<p>Register <code>processor</code> for span lifecycle callbacks.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def add_span_processor(self, processor: SpanProcessorProtocol) -&gt; None:\n    \"\"\"Register ``processor`` for span lifecycle callbacks.\"\"\"\n    del self, processor\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.TracerProviderProtocol.force_flush","title":"<code>force_flush(timeout_millis=None)</code>","text":"<p>Flush pending spans and return <code>True</code> on success.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def force_flush(self, timeout_millis: int | None = None) -&gt; bool:\n    \"\"\"Flush pending spans and return ``True`` on success.\"\"\"\n    del self, timeout_millis\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.TracerProviderProtocol.get_tracer","title":"<code>get_tracer(instrumenting_module_name, instrumenting_library_version=None, schema_url=None, attributes=None)</code>","text":"<p>Return a tracer configured for the given instrumentation metadata.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def get_tracer(\n    self,\n    instrumenting_module_name: str,\n    instrumenting_library_version: str | None = None,\n    schema_url: str | None = None,\n    attributes: Attributes | None = None,\n) -&gt; TracerProtocol:\n    \"\"\"Return a tracer configured for the given instrumentation metadata.\"\"\"\n    del self, instrumenting_module_name, instrumenting_library_version, schema_url, attributes\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.TracerProviderProtocol.shutdown","title":"<code>shutdown()</code>","text":"<p>Shut down the provider gracefully.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def shutdown(self) -&gt; None:\n    \"\"\"Shut down the provider gracefully.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_commonopentelemetry_types_safe_getattr","title":"kgfoundry_common.opentelemetry_types._safe_getattr","text":""},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types._safe_getattr","title":"<code>kgfoundry_common.opentelemetry_types._safe_getattr(module, name)</code>","text":"Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def _safe_getattr(module: object, name: str) -&gt; object | None:\n    try:\n        return cast(\"object\", getattr(module, name))\n    except AttributeError:  # pragma: no cover - defensive\n        return None\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_commonopentelemetry_typesload_in_memory_span_exporter_cls","title":"kgfoundry_common.opentelemetry_types.load_in_memory_span_exporter_cls","text":""},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.load_in_memory_span_exporter_cls","title":"<code>kgfoundry_common.opentelemetry_types.load_in_memory_span_exporter_cls()</code>","text":"<p>Return a factory for the in-memory span exporter if available.</p> <p>Returns:</p> Type Description <code>Callable[[], SpanExporterProtocol] | None</code> <p>Factory function for creating InMemorySpanExporter instances, or None if not available.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def load_in_memory_span_exporter_cls() -&gt; Callable[[], SpanExporterProtocol] | None:\n    \"\"\"Return a factory for the in-memory span exporter if available.\n\n    Returns\n    -------\n    Callable[[], SpanExporterProtocol] | None\n        Factory function for creating InMemorySpanExporter instances, or None if not available.\n    \"\"\"\n    try:\n        exporter_module = import_module(\"opentelemetry.sdk.trace.export.in_memory_span_exporter\")\n    except ImportError:\n        return None\n\n    exporter_raw = _safe_getattr(exporter_module, \"InMemorySpanExporter\")\n    if exporter_raw is None or not callable(exporter_raw):\n        return None\n    exporter_factory = cast(\"Callable[[], object]\", exporter_raw)\n\n    def factory() -&gt; SpanExporterProtocol:\n        \"\"\"Create and return an InMemorySpanExporter instance.\n\n        Returns\n        -------\n        SpanExporterProtocol\n            SpanExporter instance conforming to protocol.\n        \"\"\"\n        exporter = exporter_factory()\n        return cast(\"SpanExporterProtocol\", exporter)\n\n    return factory\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_commonopentelemetry_typesload_trace_runtime","title":"kgfoundry_common.opentelemetry_types.load_trace_runtime","text":""},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.load_trace_runtime","title":"<code>kgfoundry_common.opentelemetry_types.load_trace_runtime()</code>","text":"<p>Return the OpenTelemetry trace runtime handles if available.</p> <p>Returns:</p> Type Description <code>TraceRuntime</code> <p>Trace runtime handles with API, status factory, and status codes.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def load_trace_runtime() -&gt; TraceRuntime:\n    \"\"\"Return the OpenTelemetry trace runtime handles if available.\n\n    Returns\n    -------\n    TraceRuntime\n        Trace runtime handles with API, status factory, and status codes.\n    \"\"\"\n    try:\n        trace_module = import_module(\"opentelemetry.trace\")\n    except ImportError:\n        return TraceRuntime(api=None, status_factory=None, status_codes=None)\n\n    api = cast(\"TraceAPIProtocol\", trace_module)\n    status_factory = _safe_getattr(trace_module, \"Status\")\n    status_codes = _safe_getattr(trace_module, \"StatusCode\")\n    return TraceRuntime(\n        api=api,\n        status_factory=cast(\"StatusFactory | None\", status_factory),\n        status_codes=cast(\"StatusCodeProtocol | None\", status_codes),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_commonopentelemetry_typesload_tracer_provider_cls","title":"kgfoundry_common.opentelemetry_types.load_tracer_provider_cls","text":""},{"location":"modules/kgfoundry_common.opentelemetry_types/#kgfoundry_common.opentelemetry_types.load_tracer_provider_cls","title":"<code>kgfoundry_common.opentelemetry_types.load_tracer_provider_cls()</code>","text":"<p>Return a factory for the OpenTelemetry <code>TracerProvider</code> if present.</p> <p>Returns:</p> Type Description <code>Callable[[], TracerProviderProtocol] | None</code> <p>Factory function for creating TracerProvider instances, or None if not available.</p> Source code in <code>src/kgfoundry_common/opentelemetry_types.py</code> <pre><code>def load_tracer_provider_cls() -&gt; Callable[[], TracerProviderProtocol] | None:\n    \"\"\"Return a factory for the OpenTelemetry ``TracerProvider`` if present.\n\n    Returns\n    -------\n    Callable[[], TracerProviderProtocol] | None\n        Factory function for creating TracerProvider instances, or None if not available.\n    \"\"\"\n    try:\n        sdk_trace_module = import_module(\"opentelemetry.sdk.trace\")\n    except ImportError:\n        return None\n\n    provider_raw = _safe_getattr(sdk_trace_module, \"TracerProvider\")\n    if provider_raw is None or not callable(provider_raw):\n        return None\n    provider_factory = cast(\"Callable[[], object]\", provider_raw)\n\n    def factory() -&gt; TracerProviderProtocol:\n        \"\"\"Create and return a TracerProvider instance.\n\n        Returns\n        -------\n        TracerProviderProtocol\n            TracerProvider instance conforming to protocol.\n        \"\"\"\n        provider = provider_factory()\n        return cast(\"TracerProviderProtocol\", provider)\n\n    return factory\n</code></pre>"},{"location":"modules/kgfoundry_common.optional_deps/","title":"kgfoundry_common.optional_deps","text":""},{"location":"modules/kgfoundry_common.optional_deps/#kgfoundry_commonoptional_deps","title":"kgfoundry_common.optional_deps","text":"<p>Guarded optional dependency imports with Problem Details and observability.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.optional_deps/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class OptionalDependencyError\n    class ArtifactDependencyError\n    ArtifactDependencyError &lt;|-- OptionalDependencyError\n</code></pre>"},{"location":"modules/kgfoundry_common.optional_deps/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.optional_deps__future__.annotationscollections.abc.Mappingimportlibkgfoundry_common.errors.ArtifactDependencyErrorkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.problem_details.build_problem_detailskgfoundry_common.types.JsonValueloggingtyping.TYPE_CHECKINGtyping.TypeVartyping.castuuidkgfoundry_common.optional_deps code <p>See the full diagram: kgfoundry_common.optional_deps</p>"},{"location":"modules/kgfoundry_common.optional_deps/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.optional_deps.OptionalDependencyError</li> <li>kgfoundry_common.optional_deps._make_remediation_guidance</li> <li>kgfoundry_common.optional_deps.safe_import_autoapi</li> <li>kgfoundry_common.optional_deps.safe_import_griffe</li> </ul>"},{"location":"modules/kgfoundry_common.optional_deps/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Mapping</code>, <code>importlib</code>, <code>kgfoundry_common.errors.ArtifactDependencyError</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.problem_details.build_problem_details</code>, <code>kgfoundry_common.types.JsonValue</code>, <code>logging</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.TypeVar</code>, <code>typing.cast</code>, <code>uuid</code></p>"},{"location":"modules/kgfoundry_common.optional_deps/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.optional_deps/#kgfoundry_commonoptional_depsoptionaldependencyerror","title":"kgfoundry_common.optional_deps.OptionalDependencyError","text":"<p>Bases: ArtifactDependencyError</p>"},{"location":"modules/kgfoundry_common.optional_deps/#kgfoundry_common.optional_deps.OptionalDependencyError","title":"<code>kgfoundry_common.optional_deps.OptionalDependencyError</code>","text":"<p>               Bases: <code>ArtifactDependencyError</code></p> <p>Raised when an optional dependency cannot be imported.</p> <p>This error includes RFC 9457 Problem Details, remediation guidance, and correlation IDs for observability.</p> <p>Parameters:</p> Name Type Description Default <code>module_name</code> <code>str</code> <p>Name of the missing module (e.g., \"griffe\", \"autoapi\").</p> <code>''</code> <code>extra</code> <code>dict[str, object]</code> <p>Additional context fields for Problem Details.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.optional_deps import OptionalDependencyError\n&gt;&gt;&gt; try:\n...     raise OptionalDependencyError(\n...         \"Module griffe not found\",\n...         module_name=\"griffe\",\n...         extra={\"install_command\": \"pip install kgfoundry[docs]\"},\n...     )\n... except OptionalDependencyError as e:\n...     print(f\"Error: {e}\")\n...     assert e.context is not None\n...     assert e.context.get(\"module_name\") == \"griffe\"\nError: OptionalDependencyError[artifact-dependency-error]: Module griffe not found\n</code></pre> Source code in <code>src/kgfoundry_common/optional_deps.py</code> <pre><code>class OptionalDependencyError(ArtifactDependencyError):\n    \"\"\"Raised when an optional dependency cannot be imported.\n\n    This error includes RFC 9457 Problem Details, remediation guidance,\n    and correlation IDs for observability.\n\n    Parameters\n    ----------\n    module_name : str\n        Name of the missing module (e.g., \"griffe\", \"autoapi\").\n    extra : dict[str, object], optional\n        Additional context fields for Problem Details.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.optional_deps import OptionalDependencyError\n    &gt;&gt;&gt; try:\n    ...     raise OptionalDependencyError(\n    ...         \"Module griffe not found\",\n    ...         module_name=\"griffe\",\n    ...         extra={\"install_command\": \"pip install kgfoundry[docs]\"},\n    ...     )\n    ... except OptionalDependencyError as e:\n    ...     print(f\"Error: {e}\")\n    ...     assert e.context is not None\n    ...     assert e.context.get(\"module_name\") == \"griffe\"\n    Error: OptionalDependencyError[artifact-dependency-error]: Module griffe not found\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        module_name: str = \"\",\n        extra: Mapping[str, object] | None = None,\n        cause: Exception | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize optional dependency error.\"\"\"\n        context = dict(extra or {})\n        context[\"module_name\"] = module_name\n        context[\"correlation_id\"] = str(uuid.uuid4())\n        super().__init__(message, cause=cause, context=context)\n</code></pre>"},{"location":"modules/kgfoundry_common.optional_deps/#kgfoundry_common.optional_deps.OptionalDependencyError.__init__","title":"<code>__init__(message, module_name='', extra=None, cause=None)</code>","text":"<p>Initialize optional dependency error.</p> Source code in <code>src/kgfoundry_common/optional_deps.py</code> <pre><code>def __init__(\n    self,\n    message: str,\n    module_name: str = \"\",\n    extra: Mapping[str, object] | None = None,\n    cause: Exception | None = None,\n) -&gt; None:\n    \"\"\"Initialize optional dependency error.\"\"\"\n    context = dict(extra or {})\n    context[\"module_name\"] = module_name\n    context[\"correlation_id\"] = str(uuid.uuid4())\n    super().__init__(message, cause=cause, context=context)\n</code></pre>"},{"location":"modules/kgfoundry_common.optional_deps/#kgfoundry_common.optional_deps.OptionalDependencyError.__str__","title":"<code>__str__()</code>","text":"<p>Return formatted error string.</p> <p>Returns a string representation of the error including the class name, error code, and message. If a cause exception is present, includes information about the cause.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").</p> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return formatted error string.\n\n    Returns a string representation of the error including the class\n    name, error code, and message. If a cause exception is present,\n    includes information about the cause.\n\n    Returns\n    -------\n    str\n        Formatted error string (e.g., \"DownloadError[download-failed]: Failed to fetch resource\").\n    \"\"\"\n    base = f\"{self.__class__.__name__}[{self.code.value}]: {self.message}\"\n    if self.__cause__:\n        base += f\" (caused by: {type(self.__cause__).__name__})\"\n    return base\n</code></pre>"},{"location":"modules/kgfoundry_common.optional_deps/#kgfoundry_common.optional_deps.OptionalDependencyError.to_problem_details","title":"<code>to_problem_details(instance=None, title=None)</code>","text":"<p>Convert to RFC 9457 Problem Details JSON.</p> <p>Converts the exception to a Problem Details JSON structure suitable for HTTP error responses. Includes type URI, title, status, detail, instance, code, and optional context extensions.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str | None</code> <p>URI identifying the specific occurrence. Defaults to None.</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Short summary. Defaults to the exception class name. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details object with type, title, status, detail, code, instance, and optional errors fields.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; error = KgFoundryError(\n...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n... )\n&gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n&gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n&gt;&gt;&gt; assert details[\"status\"] == 404\n&gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n</code></pre> Source code in <code>src/kgfoundry_common/errors/exceptions.py</code> <pre><code>def to_problem_details(\n    self,\n    instance: str | None = None,\n    title: str | None = None,\n) -&gt; ProblemDetails:\n    \"\"\"Convert to RFC 9457 Problem Details JSON.\n\n    Converts the exception to a Problem Details JSON structure suitable\n    for HTTP error responses. Includes type URI, title, status, detail,\n    instance, code, and optional context extensions.\n\n    Parameters\n    ----------\n    instance : str | None, optional\n        URI identifying the specific occurrence. Defaults to None.\n    title : str | None, optional\n        Short summary. Defaults to the exception class name.\n        Defaults to None.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details object with type, title, status, detail, code,\n        instance, and optional errors fields.\n\n    Examples\n    --------\n    &gt;&gt;&gt; error = KgFoundryError(\n    ...     \"Not found\", code=ErrorCode.RESOURCE_UNAVAILABLE, http_status=404\n    ... )\n    &gt;&gt;&gt; details = error.to_problem_details(instance=\"/api/resource/123\")\n    &gt;&gt;&gt; assert details[\"type\"] == \"https://kgfoundry.dev/problems/resource-unavailable\"\n    &gt;&gt;&gt; assert details[\"status\"] == 404\n    &gt;&gt;&gt; assert details[\"code\"] == \"resource-unavailable\"\n    \"\"\"\n    return build_problem_details(\n        problem_type=get_type_uri(self.code),\n        title=title or self.__class__.__name__,\n        status=self.http_status,\n        detail=self.message,\n        instance=instance or \"urn:kgfoundry:error\",\n        code=self.code.value,\n        extensions=cast(\n            \"Mapping[str, JsonValue] | None\", self.context if self.context else None\n        ),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.optional_deps/#kgfoundry_commonoptional_deps_make_remediation_guidance","title":"kgfoundry_common.optional_deps._make_remediation_guidance","text":""},{"location":"modules/kgfoundry_common.optional_deps/#kgfoundry_common.optional_deps._make_remediation_guidance","title":"<code>kgfoundry_common.optional_deps._make_remediation_guidance(module_name)</code>","text":"<p>Build remediation guidance for missing optional dependency.</p> <p>Parameters:</p> Name Type Description Default <code>module_name</code> <code>str</code> <p>The name of the missing module.</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Guidance with install commands and documentation links.</p> Source code in <code>src/kgfoundry_common/optional_deps.py</code> <pre><code>def _make_remediation_guidance(module_name: str) -&gt; dict[str, str]:\n    \"\"\"Build remediation guidance for missing optional dependency.\n\n    Parameters\n    ----------\n    module_name : str\n        The name of the missing module.\n\n    Returns\n    -------\n    dict[str, str]\n        Guidance with install commands and documentation links.\n    \"\"\"\n    guidance_map = {\n        \"griffe\": {\n            \"install\": \"pip install kgfoundry[docs]\",\n            \"docs\": \"https://docs.kgfoundry.dev/getting-started\",\n        },\n        \"autoapi\": {\n            \"install\": \"pip install kgfoundry[docs]\",\n            \"docs\": \"https://docs.kgfoundry.dev/docs-toolchain\",\n        },\n        \"sphinx\": {\n            \"install\": \"pip install kgfoundry[docs]\",\n            \"docs\": \"https://docs.kgfoundry.dev/docs-toolchain\",\n        },\n    }\n    return guidance_map.get(module_name, {\"install\": f\"pip install {module_name}\"})\n</code></pre>"},{"location":"modules/kgfoundry_common.optional_deps/#kgfoundry_commonoptional_depssafe_import_autoapi","title":"kgfoundry_common.optional_deps.safe_import_autoapi","text":""},{"location":"modules/kgfoundry_common.optional_deps/#kgfoundry_common.optional_deps.safe_import_autoapi","title":"<code>kgfoundry_common.optional_deps.safe_import_autoapi()</code>","text":"<p>Safely import AutoAPI with Problem Details on failure.</p> <p>Returns:</p> Type Description <code>object</code> <p>The autoapi module.</p> <p>Raises:</p> Type Description <code>OptionalDependencyError</code> <p>If AutoAPI is not installed or cannot be imported.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.optional_deps import safe_import_autoapi\n&gt;&gt;&gt; try:\n...     autoapi = safe_import_autoapi()\n...     # Use autoapi\n... except OptionalDependencyError as e:\n...     print(f\"AutoAPI not available: {e}\")\n</code></pre> Source code in <code>src/kgfoundry_common/optional_deps.py</code> <pre><code>def safe_import_autoapi() -&gt; object:\n    \"\"\"Safely import AutoAPI with Problem Details on failure.\n\n    Returns\n    -------\n    object\n        The autoapi module.\n\n    Raises\n    ------\n    OptionalDependencyError\n        If AutoAPI is not installed or cannot be imported.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.optional_deps import safe_import_autoapi\n    &gt;&gt;&gt; try:\n    ...     autoapi = safe_import_autoapi()\n    ...     # Use autoapi\n    ... except OptionalDependencyError as e:\n    ...     print(f\"AutoAPI not available: {e}\")\n    \"\"\"\n    correlation_id = str(uuid.uuid4())\n    try:\n        autoapi = importlib.import_module(\"autoapi\")\n    except ImportError as exc:\n        remediation = _make_remediation_guidance(\"autoapi\")\n        message = f\"AutoAPI is not installed. Install it with: {remediation['install']}\"\n        logger.exception(\n            \"AutoAPI import failed\",\n            extra={\n                \"operation\": \"optional_dependency_import\",\n                \"dependency_module\": \"autoapi\",\n                \"status\": \"error\",\n                \"correlation_id\": correlation_id,\n                \"reason\": str(exc),\n            },\n        )\n\n        problem = build_problem_details(\n            problem_type=\"https://docs.kgfoundry.dev/problems/optional-dependency-missing\",\n            title=\"Optional dependency not installed\",\n            status=400,\n            detail=message,\n            instance=f\"urn:kgfoundry:docs:autoapi:{correlation_id}\",\n            extensions=cast(\n                \"Mapping[str, JsonValue]\",\n                {\n                    \"module\": \"autoapi\",\n                    \"correlation_id\": correlation_id,\n                    \"remediation\": remediation,\n                },\n            ),\n        )\n\n        raise OptionalDependencyError(\n            message,\n            module_name=\"autoapi\",\n            extra={\n                \"correlation_id\": correlation_id,\n                \"remediation\": remediation,\n                \"problem_details\": problem,\n            },\n            cause=exc,\n        ) from exc\n    else:\n        logger.info(\n            \"AutoAPI imported successfully\",\n            extra={\n                \"operation\": \"optional_dependency_import\",\n                \"dependency_module\": \"autoapi\",\n                \"status\": \"success\",\n                \"correlation_id\": correlation_id,\n            },\n        )\n        return autoapi\n</code></pre>"},{"location":"modules/kgfoundry_common.optional_deps/#kgfoundry_commonoptional_depssafe_import_griffe","title":"kgfoundry_common.optional_deps.safe_import_griffe","text":""},{"location":"modules/kgfoundry_common.optional_deps/#kgfoundry_common.optional_deps.safe_import_griffe","title":"<code>kgfoundry_common.optional_deps.safe_import_griffe()</code>","text":"<p>Safely import Griffe with Problem Details on failure.</p> <p>Returns:</p> Type Description <code>object</code> <p>The griffe module.</p> <p>Raises:</p> Type Description <code>OptionalDependencyError</code> <p>If Griffe is not installed or cannot be imported.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.optional_deps import safe_import_griffe\n&gt;&gt;&gt; try:\n...     griffe = safe_import_griffe()\n...     # Use griffe\n... except OptionalDependencyError as e:\n...     print(f\"Griffe not available: {e}\")\n</code></pre> Source code in <code>src/kgfoundry_common/optional_deps.py</code> <pre><code>def safe_import_griffe() -&gt; object:\n    \"\"\"Safely import Griffe with Problem Details on failure.\n\n    Returns\n    -------\n    object\n        The griffe module.\n\n    Raises\n    ------\n    OptionalDependencyError\n        If Griffe is not installed or cannot be imported.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.optional_deps import safe_import_griffe\n    &gt;&gt;&gt; try:\n    ...     griffe = safe_import_griffe()\n    ...     # Use griffe\n    ... except OptionalDependencyError as e:\n    ...     print(f\"Griffe not available: {e}\")\n    \"\"\"\n    correlation_id = str(uuid.uuid4())\n    try:\n        griffe = importlib.import_module(\"griffe\")\n    except ImportError as exc:\n        remediation = _make_remediation_guidance(\"griffe\")\n        message = f\"Griffe is not installed. Install it with: {remediation['install']}\"\n        logger.exception(\n            \"Griffe import failed\",\n            extra={\n                \"operation\": \"optional_dependency_import\",\n                \"dependency_module\": \"griffe\",\n                \"status\": \"error\",\n                \"correlation_id\": correlation_id,\n                \"reason\": str(exc),\n            },\n        )\n\n        # Build Problem Details\n        problem = build_problem_details(\n            problem_type=\"https://docs.kgfoundry.dev/problems/optional-dependency-missing\",\n            title=\"Optional dependency not installed\",\n            status=400,\n            detail=message,\n            instance=f\"urn:kgfoundry:docs:griffe:{correlation_id}\",\n            extensions=cast(\n                \"Mapping[str, JsonValue]\",\n                {\n                    \"module\": \"griffe\",\n                    \"correlation_id\": correlation_id,\n                    \"remediation\": remediation,\n                },\n            ),\n        )\n\n        raise OptionalDependencyError(\n            message,\n            module_name=\"griffe\",\n            extra={\n                \"correlation_id\": correlation_id,\n                \"remediation\": remediation,\n                \"problem_details\": problem,\n            },\n            cause=exc,\n        ) from exc\n    else:\n        logger.info(\n            \"Griffe imported successfully\",\n            extra={\n                \"operation\": \"optional_dependency_import\",\n                \"dependency_module\": \"griffe\",\n                \"status\": \"success\",\n                \"correlation_id\": correlation_id,\n            },\n        )\n        return griffe\n</code></pre>"},{"location":"modules/kgfoundry_common.optional_deps/#kgfoundry_commonoptional_depssafe_import_sphinx","title":"kgfoundry_common.optional_deps.safe_import_sphinx","text":""},{"location":"modules/kgfoundry_common.optional_deps/#kgfoundry_common.optional_deps.safe_import_sphinx","title":"<code>kgfoundry_common.optional_deps.safe_import_sphinx()</code>","text":"<p>Safely import Sphinx with Problem Details on failure.</p> <p>Returns:</p> Type Description <code>object</code> <p>The sphinx module.</p> <p>Raises:</p> Type Description <code>OptionalDependencyError</code> <p>If Sphinx is not installed or cannot be imported.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.optional_deps import safe_import_sphinx\n&gt;&gt;&gt; try:\n...     sphinx = safe_import_sphinx()\n...     # Use sphinx\n... except OptionalDependencyError as e:\n...     print(f\"Sphinx not available: {e}\")\n</code></pre> Source code in <code>src/kgfoundry_common/optional_deps.py</code> <pre><code>def safe_import_sphinx() -&gt; object:\n    \"\"\"Safely import Sphinx with Problem Details on failure.\n\n    Returns\n    -------\n    object\n        The sphinx module.\n\n    Raises\n    ------\n    OptionalDependencyError\n        If Sphinx is not installed or cannot be imported.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.optional_deps import safe_import_sphinx\n    &gt;&gt;&gt; try:\n    ...     sphinx = safe_import_sphinx()\n    ...     # Use sphinx\n    ... except OptionalDependencyError as e:\n    ...     print(f\"Sphinx not available: {e}\")\n    \"\"\"\n    correlation_id = str(uuid.uuid4())\n    try:\n        sphinx = importlib.import_module(\"sphinx\")\n    except ImportError as exc:\n        remediation = _make_remediation_guidance(\"sphinx\")\n        message = f\"Sphinx is not installed. Install it with: {remediation['install']}\"\n        logger.exception(\n            \"Sphinx import failed\",\n            extra={\n                \"operation\": \"optional_dependency_import\",\n                \"dependency_module\": \"sphinx\",\n                \"status\": \"error\",\n                \"correlation_id\": correlation_id,\n                \"reason\": str(exc),\n            },\n        )\n\n        problem = build_problem_details(\n            problem_type=\"https://docs.kgfoundry.dev/problems/optional-dependency-missing\",\n            title=\"Optional dependency not installed\",\n            status=400,\n            detail=message,\n            instance=f\"urn:kgfoundry:docs:sphinx:{correlation_id}\",\n            extensions=cast(\n                \"Mapping[str, JsonValue]\",\n                {\n                    \"module\": \"sphinx\",\n                    \"correlation_id\": correlation_id,\n                    \"remediation\": remediation,\n                },\n            ),\n        )\n\n        raise OptionalDependencyError(\n            message,\n            module_name=\"sphinx\",\n            extra={\n                \"correlation_id\": correlation_id,\n                \"remediation\": remediation,\n                \"problem_details\": problem,\n            },\n            cause=exc,\n        ) from exc\n    else:\n        logger.info(\n            \"Sphinx imported successfully\",\n            extra={\n                \"operation\": \"optional_dependency_import\",\n                \"dependency_module\": \"sphinx\",\n                \"status\": \"success\",\n                \"correlation_id\": correlation_id,\n            },\n        )\n        return sphinx\n</code></pre>"},{"location":"modules/kgfoundry_common.parquet_io/","title":"kgfoundry_common.parquet_io","text":""},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_commonparquet_io","title":"kgfoundry_common.parquet_io","text":"<p>Utilities for writing embedding vectors and chunks to Parquet</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.parquet_io/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class ChunkDocTags\n    class TypedDict\n    TypedDict &lt;|-- ChunkDocTags\n    class ChunkRow\n    TypedDict &lt;|-- ChunkRow\n    class ParquetChunkWriter\n    class ParquetVectorWriter\n</code></pre>"},{"location":"modules/kgfoundry_common.parquet_io/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.parquet_io__future__.annotationscollections.abc.Iterabledatetimekgfoundry_common.errors.DeserializationErrorkgfoundry_common.navmap_loader.load_nav_metadatapandaspandas.DataFramepathlib.Pathpyarrowpyarrow.parquettypes.ModuleTypetyping.Anytyping.NotRequiredtyping.TYPE_CHECKINGtyping.TypedDictkgfoundry_common.parquet_io code <p>See the full diagram: kgfoundry_common.parquet_io</p>"},{"location":"modules/kgfoundry_common.parquet_io/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.parquet_io.ChunkDocTags</li> <li>kgfoundry_common.parquet_io.ChunkRow</li> <li>kgfoundry_common.parquet_io.ParquetChunkWriter</li> <li>kgfoundry_common.parquet_io.read_table</li> <li>kgfoundry_common.parquet_io.read_table_to_dataframe</li> <li>kgfoundry_common.parquet_io.validate_table_schema</li> </ul>"},{"location":"modules/kgfoundry_common.parquet_io/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Iterable</code>, <code>datetime</code>, <code>kgfoundry_common.errors.DeserializationError</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>pandas</code>, <code>pandas.DataFrame</code>, <code>pathlib.Path</code>, <code>pyarrow</code>, <code>pyarrow.parquet</code>, <code>types.ModuleType</code>, <code>typing.Any</code>, <code>typing.NotRequired</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.TypedDict</code></p>"},{"location":"modules/kgfoundry_common.parquet_io/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_commonparquet_iochunkdoctags","title":"kgfoundry_common.parquet_io.ChunkDocTags","text":"<p>Bases: TypedDict</p>"},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_common.parquet_io.ChunkDocTags","title":"<code>kgfoundry_common.parquet_io.ChunkDocTags</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Structured metadata describing a chunk's doctags span.</p> Source code in <code>src/kgfoundry_common/parquet_io.py</code> <pre><code>class ChunkDocTags(TypedDict, total=False):\n    \"\"\"Structured metadata describing a chunk's doctags span.\"\"\"\n\n    node_id: str\n    start: int\n    end: int\n</code></pre>"},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_commonparquet_iochunkrow","title":"kgfoundry_common.parquet_io.ChunkRow","text":"<p>Bases: TypedDict</p>"},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_common.parquet_io.ChunkRow","title":"<code>kgfoundry_common.parquet_io.ChunkRow</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Row expected by :class:<code>ParquetChunkWriter</code>.</p> Source code in <code>src/kgfoundry_common/parquet_io.py</code> <pre><code>class ChunkRow(TypedDict, total=False):\n    \"\"\"Row expected by :class:`ParquetChunkWriter`.\"\"\"\n\n    chunk_id: str\n    doc_id: str\n    section: str\n    start_char: int\n    end_char: int\n    doctags_span: NotRequired[ChunkDocTags | None]\n    text: str\n    tokens: int\n    created_at: NotRequired[int]\n</code></pre>"},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_commonparquet_ioparquetchunkwriter","title":"kgfoundry_common.parquet_io.ParquetChunkWriter","text":""},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_common.parquet_io.ParquetChunkWriter","title":"<code>kgfoundry_common.parquet_io.ParquetChunkWriter</code>","text":"<p>Writer for document chunks in Parquet format.</p> <p>Provides utilities for writing document chunks (text segments with metadata) to Parquet files with Hive-style partitioning. Supports chunk text, character offsets, section information, and optional doctags spans.</p> <p>Initializes the Parquet chunk writer with root directory and partitioning parameters.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>str</code> <p>Root directory path for Parquet output. Converted to Path object and combined with model and run_id partitioning. Chunks will be written to subdirectories partitioned by model and run_id.</p> required <code>model</code> <code>str</code> <p>Model identifier used for partitioning. Defaults to \"docling_hybrid\".</p> <code>'docling_hybrid'</code> <code>run_id</code> <code>str</code> <p>Run identifier used for partitioning. Defaults to \"dev\".</p> <code>'dev'</code> Notes <p>The writer creates Hive-style partitioned directories: <code>root/model={model}/run_id={run_id}/shard=00000/part-00000.parquet</code></p> <p>Files are compressed with ZSTD compression (level 6) and use a row group size of 4096 bytes for optimal read performance.</p> Source code in <code>src/kgfoundry_common/parquet_io.py</code> <pre><code>class ParquetChunkWriter:\n    \"\"\"Writer for document chunks in Parquet format.\n\n    Provides utilities for writing document chunks (text segments with metadata)\n    to Parquet files with Hive-style partitioning. Supports chunk text, character\n    offsets, section information, and optional doctags spans.\n\n    Initializes the Parquet chunk writer with root directory and partitioning parameters.\n\n    Parameters\n    ----------\n    root : str\n        Root directory path for Parquet output. Converted to Path object\n        and combined with model and run_id partitioning. Chunks will be written to\n        subdirectories partitioned by model and run_id.\n    model : str, optional\n        Model identifier used for partitioning. Defaults to \"docling_hybrid\".\n    run_id : str, optional\n        Run identifier used for partitioning. Defaults to \"dev\".\n\n    Notes\n    -----\n    The writer creates Hive-style partitioned directories:\n    ``root/model={model}/run_id={run_id}/shard=00000/part-00000.parquet``\n\n    Files are compressed with ZSTD compression (level 6) and use a row group\n    size of 4096 bytes for optimal read performance.\n    \"\"\"\n\n    @staticmethod\n    def chunk_schema() -&gt; pa.Schema:\n        \"\"\"Create PyArrow schema for document chunks.\n\n        Defines the schema for document chunks with text, metadata, and optional\n        doctags spans. Includes chunk_id, doc_id, section, character offsets,\n        text content, token count, and timestamp.\n\n        Returns\n        -------\n        pa.Schema\n            PyArrow schema with fields: chunk_id (string), doc_id (string),\n            section (string), start_char (int32), end_char (int32), doctags_span\n            (struct, nullable), text (string), tokens (int32), created_at\n            (timestamp).\n        \"\"\"\n        doctags_fields = (\n            pa.field(\"node_id\", pa.string()),\n            pa.field(\"start\", pa.int32()),\n            pa.field(\"end\", pa.int32()),\n        )\n        chunk_fields = (\n            pa.field(\"chunk_id\", pa.string()),\n            pa.field(\"doc_id\", pa.string()),\n            pa.field(\"section\", pa.string()),\n            pa.field(\"start_char\", pa.int32()),\n            pa.field(\"end_char\", pa.int32()),\n            pa.field(\"doctags_span\", pa.struct(doctags_fields), nullable=True),\n            pa.field(\"text\", pa.string()),\n            pa.field(\"tokens\", pa.int32()),\n            pa.field(\"created_at\", pa.timestamp(\"ms\")),\n        )\n        return pa.schema(chunk_fields)\n\n    def __init__(self, root: str, model: str = \"docling_hybrid\", run_id: str = \"dev\") -&gt; None:\n        self.root = Path(root) / f\"model={model}\" / f\"run_id={run_id}\" / \"shard=00000\"\n        self.root.mkdir(parents=True, exist_ok=True)\n\n    def write(self, rows: Iterable[ChunkRow]) -&gt; str:\n        \"\"\"Write document chunks to Parquet file.\n\n        Writes an iterable of chunk rows to a Parquet file. Automatically adds\n        created_at timestamp if not present in rows. Validates rows against the\n        chunk schema before writing.\n\n        Parameters\n        ----------\n        rows : Iterable[ChunkRow]\n            Iterable of chunk row dictionaries. Each row must conform to\n            :class:`ChunkRow` TypedDict structure. Missing created_at fields\n            are automatically populated with current timestamp.\n\n        Returns\n        -------\n        str\n            Root directory path (two levels up from the actual file location)\n            where the Parquet file was written.\n\n        Notes\n        -----\n        The created_at timestamp is set to the current UTC time in milliseconds\n        if not provided in the row. All rows are validated against the chunk\n        schema before writing.\n        \"\"\"\n        timestamp_ms = int(dt.datetime.now(dt.UTC).timestamp() * 1000)\n        prepared: list[ChunkRow] = []\n        for row in rows:\n            materialized: ChunkRow = {**row}\n            materialized.setdefault(\"created_at\", timestamp_ms)\n            prepared.append(materialized)\n        table = pa.Table.from_pylist(prepared, schema=self.chunk_schema())\n        pq.write_table(\n            table,\n            self.root / \"part-00000.parquet\",\n            compression=\"zstd\",\n            compression_level=ZSTD_LEVEL,\n            data_page_size=ROW_GROUP_SIZE,\n        )\n        return str(self.root.parent.parent)\n</code></pre>"},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_common.parquet_io.ParquetChunkWriter.chunk_schema","title":"<code>chunk_schema()</code>  <code>staticmethod</code>","text":"<p>Create PyArrow schema for document chunks.</p> <p>Defines the schema for document chunks with text, metadata, and optional doctags spans. Includes chunk_id, doc_id, section, character offsets, text content, token count, and timestamp.</p> <p>Returns:</p> Type Description <code>Schema</code> <p>PyArrow schema with fields: chunk_id (string), doc_id (string), section (string), start_char (int32), end_char (int32), doctags_span (struct, nullable), text (string), tokens (int32), created_at (timestamp).</p> Source code in <code>src/kgfoundry_common/parquet_io.py</code> <pre><code>@staticmethod\ndef chunk_schema() -&gt; pa.Schema:\n    \"\"\"Create PyArrow schema for document chunks.\n\n    Defines the schema for document chunks with text, metadata, and optional\n    doctags spans. Includes chunk_id, doc_id, section, character offsets,\n    text content, token count, and timestamp.\n\n    Returns\n    -------\n    pa.Schema\n        PyArrow schema with fields: chunk_id (string), doc_id (string),\n        section (string), start_char (int32), end_char (int32), doctags_span\n        (struct, nullable), text (string), tokens (int32), created_at\n        (timestamp).\n    \"\"\"\n    doctags_fields = (\n        pa.field(\"node_id\", pa.string()),\n        pa.field(\"start\", pa.int32()),\n        pa.field(\"end\", pa.int32()),\n    )\n    chunk_fields = (\n        pa.field(\"chunk_id\", pa.string()),\n        pa.field(\"doc_id\", pa.string()),\n        pa.field(\"section\", pa.string()),\n        pa.field(\"start_char\", pa.int32()),\n        pa.field(\"end_char\", pa.int32()),\n        pa.field(\"doctags_span\", pa.struct(doctags_fields), nullable=True),\n        pa.field(\"text\", pa.string()),\n        pa.field(\"tokens\", pa.int32()),\n        pa.field(\"created_at\", pa.timestamp(\"ms\")),\n    )\n    return pa.schema(chunk_fields)\n</code></pre>"},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_common.parquet_io.ParquetChunkWriter.write","title":"<code>write(rows)</code>","text":"<p>Write document chunks to Parquet file.</p> <p>Writes an iterable of chunk rows to a Parquet file. Automatically adds created_at timestamp if not present in rows. Validates rows against the chunk schema before writing.</p> <p>Parameters:</p> Name Type Description Default <code>rows</code> <code>Iterable[ChunkRow]</code> <p>Iterable of chunk row dictionaries. Each row must conform to :class:<code>ChunkRow</code> TypedDict structure. Missing created_at fields are automatically populated with current timestamp.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Root directory path (two levels up from the actual file location) where the Parquet file was written.</p> Notes <p>The created_at timestamp is set to the current UTC time in milliseconds if not provided in the row. All rows are validated against the chunk schema before writing.</p> Source code in <code>src/kgfoundry_common/parquet_io.py</code> <pre><code>def write(self, rows: Iterable[ChunkRow]) -&gt; str:\n    \"\"\"Write document chunks to Parquet file.\n\n    Writes an iterable of chunk rows to a Parquet file. Automatically adds\n    created_at timestamp if not present in rows. Validates rows against the\n    chunk schema before writing.\n\n    Parameters\n    ----------\n    rows : Iterable[ChunkRow]\n        Iterable of chunk row dictionaries. Each row must conform to\n        :class:`ChunkRow` TypedDict structure. Missing created_at fields\n        are automatically populated with current timestamp.\n\n    Returns\n    -------\n    str\n        Root directory path (two levels up from the actual file location)\n        where the Parquet file was written.\n\n    Notes\n    -----\n    The created_at timestamp is set to the current UTC time in milliseconds\n    if not provided in the row. All rows are validated against the chunk\n    schema before writing.\n    \"\"\"\n    timestamp_ms = int(dt.datetime.now(dt.UTC).timestamp() * 1000)\n    prepared: list[ChunkRow] = []\n    for row in rows:\n        materialized: ChunkRow = {**row}\n        materialized.setdefault(\"created_at\", timestamp_ms)\n        prepared.append(materialized)\n    table = pa.Table.from_pylist(prepared, schema=self.chunk_schema())\n    pq.write_table(\n        table,\n        self.root / \"part-00000.parquet\",\n        compression=\"zstd\",\n        compression_level=ZSTD_LEVEL,\n        data_page_size=ROW_GROUP_SIZE,\n    )\n    return str(self.root.parent.parent)\n</code></pre>"},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_commonparquet_ioparquetvectorwriter","title":"kgfoundry_common.parquet_io.ParquetVectorWriter","text":""},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_common.parquet_io.ParquetVectorWriter","title":"<code>kgfoundry_common.parquet_io.ParquetVectorWriter</code>","text":"<p>Writer for embedding vectors in Parquet format.</p> <p>Provides utilities for writing dense and sparse (SPLADE) embedding vectors to Parquet files with Hive-style partitioning. Supports partitioning by model, run_id, and shard for efficient querying.</p> <p>Initializes the Parquet vector writer with root directory.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>str</code> <p>Root directory path for Parquet output. Converted to Path object and stored for use by write methods. Vectors will be written to subdirectories partitioned by model, run_id, and shard.</p> required <p>Raises:</p> Type Description <code>ImportError</code> <p>If pandas is not installed.</p> Notes <p>The writer creates Hive-style partitioned directories: <code>root/model={model}/run_id={run_id}/shard={shard:05d}/part-00000.parquet</code></p> <p>Files are compressed with ZSTD compression (level 6) and use a row group size of 4096 bytes for optimal read performance.</p> Source code in <code>src/kgfoundry_common/parquet_io.py</code> <pre><code>class ParquetVectorWriter:\n    \"\"\"Writer for embedding vectors in Parquet format.\n\n    Provides utilities for writing dense and sparse (SPLADE) embedding vectors\n    to Parquet files with Hive-style partitioning. Supports partitioning by\n    model, run_id, and shard for efficient querying.\n\n    Initializes the Parquet vector writer with root directory.\n\n    Parameters\n    ----------\n    root : str\n        Root directory path for Parquet output. Converted to Path object\n        and stored for use by write methods. Vectors will be written to\n        subdirectories partitioned by model, run_id, and shard.\n\n    Raises\n    ------\n    ImportError\n        If pandas is not installed.\n\n    Notes\n    -----\n    The writer creates Hive-style partitioned directories:\n    ``root/model={model}/run_id={run_id}/shard={shard:05d}/part-00000.parquet``\n\n    Files are compressed with ZSTD compression (level 6) and use a row group\n    size of 4096 bytes for optimal read performance.\n    \"\"\"\n\n    @staticmethod\n    def dense_schema(dim: int) -&gt; pa.Schema:\n        \"\"\"Create PyArrow schema for dense vector embeddings.\n\n        Defines the schema for dense embedding vectors with fixed dimension.\n        Includes chunk_id, model, run_id, vector array, L2 norm, and timestamp.\n\n        Parameters\n        ----------\n        dim : int\n            Vector dimension (must match the length of vector arrays).\n\n        Returns\n        -------\n        pa.Schema\n            PyArrow schema with fields: chunk_id (string), model (dictionary),\n            run_id (dictionary), dim (int16), vector (list&lt;float32&gt;), l2_norm\n            (float32), created_at (timestamp).\n        \"\"\"\n        return pa.schema(\n            [\n                pa.field(\"chunk_id\", pa.string()),\n                pa.field(\"model\", pa.dictionary(pa.int32(), pa.string())),\n                pa.field(\"run_id\", pa.dictionary(pa.int32(), pa.string())),\n                pa.field(\"dim\", pa.int16()),\n                pa.field(\"vector\", pa.list_(pa.float32(), list_size=dim)),\n                pa.field(\"l2_norm\", pa.float32()),\n                pa.field(\"created_at\", pa.timestamp(\"ms\")),\n            ]\n        )\n\n    def __init__(self, root: str) -&gt; None:\n        self.root = Path(root)\n\n    def write_dense(\n        self,\n        model: str,\n        run_id: str,\n        dim: int,\n        records: Iterable[tuple[str, list[float], float]],\n        shard: int = 0,\n    ) -&gt; str:\n        \"\"\"Write dense embedding vectors to Parquet file.\n\n        Writes dense embedding vectors (fixed-dimension float arrays) to a\n        Parquet file with Hive-style partitioning. Each record consists of\n        chunk_id, vector array, and L2 norm.\n\n        Parameters\n        ----------\n        model : str\n            Model identifier used for partitioning (e.g., \"qwen3\", \"sentence-transformers\").\n        run_id : str\n            Run identifier used for partitioning (e.g., \"dev\", \"prod-v1\").\n        dim : int\n            Vector dimension. Must match the length of all vector arrays in records.\n        records : Iterable[tuple[str, list[float], float]]\n            Iterable of (chunk_id, vector, l2_norm) tuples. Each vector must\n            be a list of floats with length equal to dim.\n        shard : int, optional\n            Shard number for partitioning. Used to distribute data across\n            multiple files. Defaults to 0.\n\n        Returns\n        -------\n        str\n            Root directory path where the Parquet file was written.\n\n        Notes\n        -----\n        Creates a timestamp (milliseconds since epoch) for all records in this\n        batch. The output file is written to:\n        ``root/model={model}/run_id={run_id}/shard={shard:05d}/part-00000.parquet``\n        \"\"\"\n        part_dir = self.root / f\"model={model}\" / f\"run_id={run_id}\" / f\"shard={shard:05d}\"\n        part_dir.mkdir(parents=True, exist_ok=True)\n        now = int(dt.datetime.now(dt.UTC).timestamp() * 1000)\n        rows = [\n            {\n                \"chunk_id\": cid,\n                \"model\": model,\n                \"run_id\": run_id,\n                \"dim\": dim,\n                \"vector\": vec,\n                \"l2_norm\": float(l2),\n                \"created_at\": now,\n            }\n            for cid, vec, l2 in records\n        ]\n        table = pa.Table.from_pylist(rows, schema=self.dense_schema(dim))\n        pq.write_table(\n            table,\n            part_dir / \"part-00000.parquet\",\n            compression=\"zstd\",\n            compression_level=ZSTD_LEVEL,\n            data_page_size=ROW_GROUP_SIZE,\n        )\n        return str(self.root)\n\n    @staticmethod\n    def splade_schema() -&gt; pa.Schema:\n        \"\"\"Create PyArrow schema for SPLADE sparse vectors.\n\n        Defines the schema for SPLADE (Sparse Lexical and Expansion) sparse\n        embedding vectors. Includes vocab_ids, weights, and non-zero count.\n\n        Returns\n        -------\n        pa.Schema\n            PyArrow schema with fields: chunk_id (string), model (dictionary),\n            run_id (dictionary), vocab_ids (list&lt;int32&gt;), weights\n            (list&lt;float32&gt;), nnz (int16), created_at (timestamp).\n        \"\"\"\n        splade_fields = (\n            pa.field(\"chunk_id\", pa.string()),\n            pa.field(\"model\", pa.dictionary(pa.int32(), pa.string())),\n            pa.field(\"run_id\", pa.dictionary(pa.int32(), pa.string())),\n            pa.field(\"vocab_ids\", pa.list_(pa.int32())),\n            pa.field(\"weights\", pa.list_(pa.float32())),\n            pa.field(\"nnz\", pa.int16()),\n            pa.field(\"created_at\", pa.timestamp(\"ms\")),\n        )\n        return pa.schema(splade_fields)\n\n    def write_splade(\n        self,\n        model: str,\n        run_id: str,\n        records: Iterable[tuple[str, list[int], list[float]]],\n        shard: int = 0,\n    ) -&gt; str:\n        \"\"\"Write SPLADE sparse vectors to Parquet file.\n\n        Writes SPLADE (Sparse Lexical and Expansion) sparse embedding vectors\n        to a Parquet file with Hive-style partitioning. Each record consists of\n        chunk_id, vocabulary IDs, and corresponding weights.\n\n        Parameters\n        ----------\n        model : str\n            Model identifier used for partitioning (e.g., \"splade-v2\").\n        run_id : str\n            Run identifier used for partitioning (e.g., \"dev\", \"prod-v1\").\n        records : Iterable[tuple[str, list[int], list[float]]]\n            Iterable of (chunk_id, vocab_ids, weights) tuples. vocab_ids and\n            weights must have the same length (non-zero elements).\n        shard : int, optional\n            Shard number for partitioning. Used to distribute data across\n            multiple files. Defaults to 0.\n\n        Returns\n        -------\n        str\n            Root directory path where the Parquet file was written.\n\n        Notes\n        -----\n        The nnz (number of non-zeros) field is automatically computed from the\n        length of vocab_ids. Creates a timestamp (milliseconds since epoch) for\n        all records in this batch.\n        \"\"\"\n        part_dir = self.root / f\"model={model}\" / f\"run_id={run_id}\" / f\"shard={shard:05d}\"\n        part_dir.mkdir(parents=True, exist_ok=True)\n        now = int(dt.datetime.now(dt.UTC).timestamp() * 1000)\n        rows = [\n            {\n                \"chunk_id\": cid,\n                \"model\": model,\n                \"run_id\": run_id,\n                \"vocab_ids\": ids,\n                \"weights\": wts,\n                \"nnz\": len(ids),\n                \"created_at\": now,\n            }\n            for cid, ids, wts in records\n        ]\n        table = pa.Table.from_pylist(rows, schema=self.splade_schema())\n        pq.write_table(\n            table,\n            part_dir / \"part-00000.parquet\",\n            compression=\"zstd\",\n            compression_level=ZSTD_LEVEL,\n            data_page_size=ROW_GROUP_SIZE,\n        )\n        return str(self.root)\n</code></pre>"},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_common.parquet_io.ParquetVectorWriter.dense_schema","title":"<code>dense_schema(dim)</code>  <code>staticmethod</code>","text":"<p>Create PyArrow schema for dense vector embeddings.</p> <p>Defines the schema for dense embedding vectors with fixed dimension. Includes chunk_id, model, run_id, vector array, L2 norm, and timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>Vector dimension (must match the length of vector arrays).</p> required <p>Returns:</p> Type Description <code>Schema</code> <p>PyArrow schema with fields: chunk_id (string), model (dictionary), run_id (dictionary), dim (int16), vector (list), l2_norm (float32), created_at (timestamp).</p> Source code in <code>src/kgfoundry_common/parquet_io.py</code> <pre><code>@staticmethod\ndef dense_schema(dim: int) -&gt; pa.Schema:\n    \"\"\"Create PyArrow schema for dense vector embeddings.\n\n    Defines the schema for dense embedding vectors with fixed dimension.\n    Includes chunk_id, model, run_id, vector array, L2 norm, and timestamp.\n\n    Parameters\n    ----------\n    dim : int\n        Vector dimension (must match the length of vector arrays).\n\n    Returns\n    -------\n    pa.Schema\n        PyArrow schema with fields: chunk_id (string), model (dictionary),\n        run_id (dictionary), dim (int16), vector (list&lt;float32&gt;), l2_norm\n        (float32), created_at (timestamp).\n    \"\"\"\n    return pa.schema(\n        [\n            pa.field(\"chunk_id\", pa.string()),\n            pa.field(\"model\", pa.dictionary(pa.int32(), pa.string())),\n            pa.field(\"run_id\", pa.dictionary(pa.int32(), pa.string())),\n            pa.field(\"dim\", pa.int16()),\n            pa.field(\"vector\", pa.list_(pa.float32(), list_size=dim)),\n            pa.field(\"l2_norm\", pa.float32()),\n            pa.field(\"created_at\", pa.timestamp(\"ms\")),\n        ]\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_common.parquet_io.ParquetVectorWriter.splade_schema","title":"<code>splade_schema()</code>  <code>staticmethod</code>","text":"<p>Create PyArrow schema for SPLADE sparse vectors.</p> <p>Defines the schema for SPLADE (Sparse Lexical and Expansion) sparse embedding vectors. Includes vocab_ids, weights, and non-zero count.</p> <p>Returns:</p> Type Description <code>Schema</code> <p>PyArrow schema with fields: chunk_id (string), model (dictionary), run_id (dictionary), vocab_ids (list), weights (list), nnz (int16), created_at (timestamp).</p> Source code in <code>src/kgfoundry_common/parquet_io.py</code> <pre><code>@staticmethod\ndef splade_schema() -&gt; pa.Schema:\n    \"\"\"Create PyArrow schema for SPLADE sparse vectors.\n\n    Defines the schema for SPLADE (Sparse Lexical and Expansion) sparse\n    embedding vectors. Includes vocab_ids, weights, and non-zero count.\n\n    Returns\n    -------\n    pa.Schema\n        PyArrow schema with fields: chunk_id (string), model (dictionary),\n        run_id (dictionary), vocab_ids (list&lt;int32&gt;), weights\n        (list&lt;float32&gt;), nnz (int16), created_at (timestamp).\n    \"\"\"\n    splade_fields = (\n        pa.field(\"chunk_id\", pa.string()),\n        pa.field(\"model\", pa.dictionary(pa.int32(), pa.string())),\n        pa.field(\"run_id\", pa.dictionary(pa.int32(), pa.string())),\n        pa.field(\"vocab_ids\", pa.list_(pa.int32())),\n        pa.field(\"weights\", pa.list_(pa.float32())),\n        pa.field(\"nnz\", pa.int16()),\n        pa.field(\"created_at\", pa.timestamp(\"ms\")),\n    )\n    return pa.schema(splade_fields)\n</code></pre>"},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_common.parquet_io.ParquetVectorWriter.write_dense","title":"<code>write_dense(model, run_id, dim, records, shard=0)</code>","text":"<p>Write dense embedding vectors to Parquet file.</p> <p>Writes dense embedding vectors (fixed-dimension float arrays) to a Parquet file with Hive-style partitioning. Each record consists of chunk_id, vector array, and L2 norm.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Model identifier used for partitioning (e.g., \"qwen3\", \"sentence-transformers\").</p> required <code>run_id</code> <code>str</code> <p>Run identifier used for partitioning (e.g., \"dev\", \"prod-v1\").</p> required <code>dim</code> <code>int</code> <p>Vector dimension. Must match the length of all vector arrays in records.</p> required <code>records</code> <code>Iterable[tuple[str, list[float], float]]</code> <p>Iterable of (chunk_id, vector, l2_norm) tuples. Each vector must be a list of floats with length equal to dim.</p> required <code>shard</code> <code>int</code> <p>Shard number for partitioning. Used to distribute data across multiple files. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>str</code> <p>Root directory path where the Parquet file was written.</p> Notes <p>Creates a timestamp (milliseconds since epoch) for all records in this batch. The output file is written to: <code>root/model={model}/run_id={run_id}/shard={shard:05d}/part-00000.parquet</code></p> Source code in <code>src/kgfoundry_common/parquet_io.py</code> <pre><code>def write_dense(\n    self,\n    model: str,\n    run_id: str,\n    dim: int,\n    records: Iterable[tuple[str, list[float], float]],\n    shard: int = 0,\n) -&gt; str:\n    \"\"\"Write dense embedding vectors to Parquet file.\n\n    Writes dense embedding vectors (fixed-dimension float arrays) to a\n    Parquet file with Hive-style partitioning. Each record consists of\n    chunk_id, vector array, and L2 norm.\n\n    Parameters\n    ----------\n    model : str\n        Model identifier used for partitioning (e.g., \"qwen3\", \"sentence-transformers\").\n    run_id : str\n        Run identifier used for partitioning (e.g., \"dev\", \"prod-v1\").\n    dim : int\n        Vector dimension. Must match the length of all vector arrays in records.\n    records : Iterable[tuple[str, list[float], float]]\n        Iterable of (chunk_id, vector, l2_norm) tuples. Each vector must\n        be a list of floats with length equal to dim.\n    shard : int, optional\n        Shard number for partitioning. Used to distribute data across\n        multiple files. Defaults to 0.\n\n    Returns\n    -------\n    str\n        Root directory path where the Parquet file was written.\n\n    Notes\n    -----\n    Creates a timestamp (milliseconds since epoch) for all records in this\n    batch. The output file is written to:\n    ``root/model={model}/run_id={run_id}/shard={shard:05d}/part-00000.parquet``\n    \"\"\"\n    part_dir = self.root / f\"model={model}\" / f\"run_id={run_id}\" / f\"shard={shard:05d}\"\n    part_dir.mkdir(parents=True, exist_ok=True)\n    now = int(dt.datetime.now(dt.UTC).timestamp() * 1000)\n    rows = [\n        {\n            \"chunk_id\": cid,\n            \"model\": model,\n            \"run_id\": run_id,\n            \"dim\": dim,\n            \"vector\": vec,\n            \"l2_norm\": float(l2),\n            \"created_at\": now,\n        }\n        for cid, vec, l2 in records\n    ]\n    table = pa.Table.from_pylist(rows, schema=self.dense_schema(dim))\n    pq.write_table(\n        table,\n        part_dir / \"part-00000.parquet\",\n        compression=\"zstd\",\n        compression_level=ZSTD_LEVEL,\n        data_page_size=ROW_GROUP_SIZE,\n    )\n    return str(self.root)\n</code></pre>"},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_common.parquet_io.ParquetVectorWriter.write_splade","title":"<code>write_splade(model, run_id, records, shard=0)</code>","text":"<p>Write SPLADE sparse vectors to Parquet file.</p> <p>Writes SPLADE (Sparse Lexical and Expansion) sparse embedding vectors to a Parquet file with Hive-style partitioning. Each record consists of chunk_id, vocabulary IDs, and corresponding weights.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Model identifier used for partitioning (e.g., \"splade-v2\").</p> required <code>run_id</code> <code>str</code> <p>Run identifier used for partitioning (e.g., \"dev\", \"prod-v1\").</p> required <code>records</code> <code>Iterable[tuple[str, list[int], list[float]]]</code> <p>Iterable of (chunk_id, vocab_ids, weights) tuples. vocab_ids and weights must have the same length (non-zero elements).</p> required <code>shard</code> <code>int</code> <p>Shard number for partitioning. Used to distribute data across multiple files. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>str</code> <p>Root directory path where the Parquet file was written.</p> Notes <p>The nnz (number of non-zeros) field is automatically computed from the length of vocab_ids. Creates a timestamp (milliseconds since epoch) for all records in this batch.</p> Source code in <code>src/kgfoundry_common/parquet_io.py</code> <pre><code>def write_splade(\n    self,\n    model: str,\n    run_id: str,\n    records: Iterable[tuple[str, list[int], list[float]]],\n    shard: int = 0,\n) -&gt; str:\n    \"\"\"Write SPLADE sparse vectors to Parquet file.\n\n    Writes SPLADE (Sparse Lexical and Expansion) sparse embedding vectors\n    to a Parquet file with Hive-style partitioning. Each record consists of\n    chunk_id, vocabulary IDs, and corresponding weights.\n\n    Parameters\n    ----------\n    model : str\n        Model identifier used for partitioning (e.g., \"splade-v2\").\n    run_id : str\n        Run identifier used for partitioning (e.g., \"dev\", \"prod-v1\").\n    records : Iterable[tuple[str, list[int], list[float]]]\n        Iterable of (chunk_id, vocab_ids, weights) tuples. vocab_ids and\n        weights must have the same length (non-zero elements).\n    shard : int, optional\n        Shard number for partitioning. Used to distribute data across\n        multiple files. Defaults to 0.\n\n    Returns\n    -------\n    str\n        Root directory path where the Parquet file was written.\n\n    Notes\n    -----\n    The nnz (number of non-zeros) field is automatically computed from the\n    length of vocab_ids. Creates a timestamp (milliseconds since epoch) for\n    all records in this batch.\n    \"\"\"\n    part_dir = self.root / f\"model={model}\" / f\"run_id={run_id}\" / f\"shard={shard:05d}\"\n    part_dir.mkdir(parents=True, exist_ok=True)\n    now = int(dt.datetime.now(dt.UTC).timestamp() * 1000)\n    rows = [\n        {\n            \"chunk_id\": cid,\n            \"model\": model,\n            \"run_id\": run_id,\n            \"vocab_ids\": ids,\n            \"weights\": wts,\n            \"nnz\": len(ids),\n            \"created_at\": now,\n        }\n        for cid, ids, wts in records\n    ]\n    table = pa.Table.from_pylist(rows, schema=self.splade_schema())\n    pq.write_table(\n        table,\n        part_dir / \"part-00000.parquet\",\n        compression=\"zstd\",\n        compression_level=ZSTD_LEVEL,\n        data_page_size=ROW_GROUP_SIZE,\n    )\n    return str(self.root)\n</code></pre>"},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_commonparquet_ioread_table","title":"kgfoundry_common.parquet_io.read_table","text":""},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_common.parquet_io.read_table","title":"<code>kgfoundry_common.parquet_io.read_table(path, *, schema=None, validate_schema=True)</code>","text":"<p>Read a Parquet file and return a typed Table.</p> <p>Loads a Parquet file or directory and returns a PyArrow Table. Optionally validates the table schema against an expected schema.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to Parquet file or directory containing Parquet files.</p> required <code>schema</code> <code>Schema | None</code> <p>Expected schema for validation. If provided and validate_schema=True, raises DeserializationError if the table schema does not match. Defaults to None.</p> <code>None</code> <code>validate_schema</code> <code>bool</code> <p>Whether to validate against the provided schema. Only used if schema is not None. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Table</code> <p>PyArrow Table with concrete schema. Contains all rows from the Parquet file(s).</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the Parquet file or directory does not exist.</p> <code>DeserializationError</code> <p>If schema validation fails (when schema is provided and validation enabled) or if the file is corrupted or invalid.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from kgfoundry_common.parquet_io import read_table\n&gt;&gt;&gt; # Note: requires existing Parquet file\n&gt;&gt;&gt; # table = read_table(\"data.parquet\")\n&gt;&gt;&gt; # assert table.num_rows &gt; 0\n</code></pre> Source code in <code>src/kgfoundry_common/parquet_io.py</code> <pre><code>def read_table(\n    path: str | Path,\n    *,\n    schema: pa.Schema | None = None,\n    validate_schema: bool = True,\n) -&gt; pa.Table:\n    \"\"\"Read a Parquet file and return a typed Table.\n\n    Loads a Parquet file or directory and returns a PyArrow Table. Optionally\n    validates the table schema against an expected schema.\n\n    Parameters\n    ----------\n    path : str | Path\n        Path to Parquet file or directory containing Parquet files.\n    schema : pa.Schema | None, optional\n        Expected schema for validation. If provided and validate_schema=True,\n        raises DeserializationError if the table schema does not match.\n        Defaults to None.\n    validate_schema : bool, optional\n        Whether to validate against the provided schema. Only used if schema\n        is not None. Defaults to True.\n\n    Returns\n    -------\n    pa.Table\n        PyArrow Table with concrete schema. Contains all rows from the Parquet\n        file(s).\n\n    Raises\n    ------\n    FileNotFoundError\n        If the Parquet file or directory does not exist.\n    DeserializationError\n        If schema validation fails (when schema is provided and validation\n        enabled) or if the file is corrupted or invalid.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; from kgfoundry_common.parquet_io import read_table\n    &gt;&gt;&gt; # Note: requires existing Parquet file\n    &gt;&gt;&gt; # table = read_table(\"data.parquet\")\n    &gt;&gt;&gt; # assert table.num_rows &gt; 0\n    \"\"\"\n    path_obj = Path(path)\n    if not path_obj.exists():\n        msg = f\"Parquet file not found: {path_obj}\"\n        raise FileNotFoundError(msg)\n\n    try:\n        table = pq.read_table(path_obj)\n    except Exception as exc:\n        msg = f\"Failed to read Parquet file {path_obj}: {exc}\"\n        raise DeserializationError(msg) from exc\n\n    if schema is not None and validate_schema:\n        validate_table_schema(table, schema)\n\n    return table\n</code></pre>"},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_commonparquet_ioread_table_to_dataframe","title":"kgfoundry_common.parquet_io.read_table_to_dataframe","text":""},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_common.parquet_io.read_table_to_dataframe","title":"<code>kgfoundry_common.parquet_io.read_table_to_dataframe(path, *, schema=None, validate_schema=True)</code>","text":"<p>Read a Parquet file and return a typed DataFrame.</p> <p>Loads a Parquet file or directory and converts it to a pandas DataFrame. Optionally validates the table schema before conversion. Requires pandas to be installed.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to Parquet file or directory containing Parquet files.</p> required <code>schema</code> <code>Schema | None</code> <p>Expected schema for validation. If provided and validate_schema=True, raises DeserializationError if the table schema does not match. Defaults to None.</p> <code>None</code> <code>validate_schema</code> <code>bool</code> <p>Whether to validate against the provided schema. Only used if schema is not None. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Pandas DataFrame with schema metadata preserved. Contains all rows from the Parquet file(s).</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If pandas is not installed.</p> Notes <p>This function wraps :func:<code>read_table</code> and converts the result to a pandas DataFrame. Schema validation or file-related errors raised by :func:<code>read_table</code> propagate unchanged.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from kgfoundry_common.parquet_io import read_table_to_dataframe\n&gt;&gt;&gt; # Note: requires existing Parquet file and pandas\n&gt;&gt;&gt; # df = read_table_to_dataframe(\"data.parquet\")\n&gt;&gt;&gt; # assert len(df) &gt; 0\n</code></pre> Source code in <code>src/kgfoundry_common/parquet_io.py</code> <pre><code>def read_table_to_dataframe(\n    path: str | Path,\n    *,\n    schema: pa.Schema | None = None,\n    validate_schema: bool = True,\n) -&gt; DataFrame:\n    \"\"\"Read a Parquet file and return a typed DataFrame.\n\n    Loads a Parquet file or directory and converts it to a pandas DataFrame.\n    Optionally validates the table schema before conversion. Requires pandas\n    to be installed.\n\n    Parameters\n    ----------\n    path : str | Path\n        Path to Parquet file or directory containing Parquet files.\n    schema : pa.Schema | None, optional\n        Expected schema for validation. If provided and validate_schema=True,\n        raises DeserializationError if the table schema does not match.\n        Defaults to None.\n    validate_schema : bool, optional\n        Whether to validate against the provided schema. Only used if schema\n        is not None. Defaults to True.\n\n    Returns\n    -------\n    DataFrame\n        Pandas DataFrame with schema metadata preserved. Contains all rows\n        from the Parquet file(s).\n\n    Raises\n    ------\n    ImportError\n        If pandas is not installed.\n\n    Notes\n    -----\n    This function wraps :func:`read_table` and converts the result to a pandas\n    DataFrame. Schema validation or file-related errors raised by\n    :func:`read_table` propagate unchanged.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; from kgfoundry_common.parquet_io import read_table_to_dataframe\n    &gt;&gt;&gt; # Note: requires existing Parquet file and pandas\n    &gt;&gt;&gt; # df = read_table_to_dataframe(\"data.parquet\")\n    &gt;&gt;&gt; # assert len(df) &gt; 0\n    \"\"\"\n    if pd is None:\n        msg = \"pandas is required for DataFrame conversion\"\n        raise ImportError(msg)\n\n    table = read_table(path, schema=schema, validate_schema=validate_schema)\n    return table.to_pandas()\n</code></pre>"},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_commonparquet_iovalidate_table_schema","title":"kgfoundry_common.parquet_io.validate_table_schema","text":""},{"location":"modules/kgfoundry_common.parquet_io/#kgfoundry_common.parquet_io.validate_table_schema","title":"<code>kgfoundry_common.parquet_io.validate_table_schema(table, expected_schema)</code>","text":"<p>Validate that a table matches an expected schema.</p> <p>Compares the schema of a PyArrow Table against an expected schema and raises an exception if they do not match exactly.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table</code> <p>PyArrow Table to validate.</p> required <code>expected_schema</code> <code>Schema</code> <p>Expected schema that the table should match.</p> required <p>Raises:</p> Type Description <code>DeserializationError</code> <p>If the table schema does not match the expected schema. The error message includes both schemas for debugging.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; from kgfoundry_common.parquet_io import validate_table_schema\n&gt;&gt;&gt; schema = pa.schema([pa.field(\"id\", pa.string())])\n&gt;&gt;&gt; table = pa.Table.from_pylist([{\"id\": \"test\"}], schema=schema)\n&gt;&gt;&gt; validate_table_schema(table, schema)  # No error\n</code></pre> Source code in <code>src/kgfoundry_common/parquet_io.py</code> <pre><code>def validate_table_schema(table: pa.Table, expected_schema: pa.Schema) -&gt; None:\n    \"\"\"Validate that a table matches an expected schema.\n\n    Compares the schema of a PyArrow Table against an expected schema and\n    raises an exception if they do not match exactly.\n\n    Parameters\n    ----------\n    table : pa.Table\n        PyArrow Table to validate.\n    expected_schema : pa.Schema\n        Expected schema that the table should match.\n\n    Raises\n    ------\n    DeserializationError\n        If the table schema does not match the expected schema. The error\n        message includes both schemas for debugging.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pyarrow as pa\n    &gt;&gt;&gt; from kgfoundry_common.parquet_io import validate_table_schema\n    &gt;&gt;&gt; schema = pa.schema([pa.field(\"id\", pa.string())])\n    &gt;&gt;&gt; table = pa.Table.from_pylist([{\"id\": \"test\"}], schema=schema)\n    &gt;&gt;&gt; validate_table_schema(table, schema)  # No error\n    \"\"\"\n    if not table.schema.equals(expected_schema):\n        msg = f\"Schema mismatch: expected {expected_schema}, got {table.schema}\"\n        raise DeserializationError(msg)\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/","title":"kgfoundry_common.problem_details","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_details","title":"kgfoundry_common.problem_details","text":"<p>RFC 9457 Problem Details helpers with schema validation.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.problem_details/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class ExceptionProblemDetailsParams\n    class ProblemDetails\n    class TypedDict\n    TypedDict &lt;|-- ProblemDetails\n    class ProblemDetailsParams\n    class ProblemDetailsValidationError\n    class Exception\n    Exception &lt;|-- ProblemDetailsValidationError\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.problem_details__future__.annotationscollections.abc.Mappingdataclasses.dataclassjsonkgfoundry_common.fs.read_textkgfoundry_common.jsonschema_utils.Draft202012Validatorkgfoundry_common.jsonschema_utils.SchemaErrorkgfoundry_common.jsonschema_utils.ValidationErrorkgfoundry_common.jsonschema_utils.ValidationErrorProtocolkgfoundry_common.jsonschema_utils.validatekgfoundry_common.logging.get_loggerkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.types.JsonPrimitivekgfoundry_common.types.JsonValuepathlib.Pathtyping.NoReturntyping.TYPE_CHECKINGtyping.TypedDicttyping.casttyping.overloadkgfoundry_common.problem_details code <p>See the full diagram: kgfoundry_common.problem_details</p>"},{"location":"modules/kgfoundry_common.problem_details/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.problem_details.ExceptionProblemDetailsParams</li> <li>kgfoundry_common.problem_details.ProblemDetails</li> <li>kgfoundry_common.problem_details.ProblemDetailsParams</li> <li>kgfoundry_common.problem_details._coerce_exception_params</li> <li>kgfoundry_common.problem_details._coerce_problem_details_params</li> <li>kgfoundry_common.problem_details._ensure_exception</li> </ul>"},{"location":"modules/kgfoundry_common.problem_details/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Mapping</code>, <code>dataclasses.dataclass</code>, <code>json</code>, <code>kgfoundry_common.fs.read_text</code>, <code>kgfoundry_common.jsonschema_utils.Draft202012Validator</code>, <code>kgfoundry_common.jsonschema_utils.SchemaError</code>, <code>kgfoundry_common.jsonschema_utils.ValidationError</code>, <code>kgfoundry_common.jsonschema_utils.ValidationErrorProtocol</code>, <code>kgfoundry_common.jsonschema_utils.validate</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.types.JsonPrimitive</code>, <code>kgfoundry_common.types.JsonValue</code>, <code>pathlib.Path</code>, <code>typing.NoReturn</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.TypedDict</code>, <code>typing.cast</code>, <code>typing.overload</code></p>"},{"location":"modules/kgfoundry_common.problem_details/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_detailsexceptionproblemdetailsparams","title":"kgfoundry_common.problem_details.ExceptionProblemDetailsParams","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details.ExceptionProblemDetailsParams","title":"<code>kgfoundry_common.problem_details.ExceptionProblemDetailsParams</code>  <code>dataclass</code>","text":"<p>Parameters describing an exception converted to Problem Details.</p> Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>@dataclass(slots=True)\n# [nav:anchor ExceptionProblemDetailsParams]\nclass ExceptionProblemDetailsParams:\n    \"\"\"Parameters describing an exception converted to Problem Details.\"\"\"\n\n    exception: Exception\n    base: ProblemDetailsParams\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_detailsproblemdetails","title":"kgfoundry_common.problem_details.ProblemDetails","text":"<p>Bases: TypedDict</p>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details.ProblemDetails","title":"<code>kgfoundry_common.problem_details.ProblemDetails</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>TypedDict for RFC 9457 Problem Details responses.</p> <p>This is a partial TypedDict (total=False) where all fields are optional, allowing for flexible payload construction with validation.</p> Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>class ProblemDetails(TypedDict, total=False):\n    \"\"\"TypedDict for RFC 9457 Problem Details responses.\n\n    This is a partial TypedDict (total=False) where all fields are optional, allowing for flexible\n    payload construction with validation.\n    \"\"\"\n\n    type: str\n    title: str\n    status: int\n    detail: str\n    instance: str\n    code: str  # NotRequired via total=False\n    extensions: dict[str, JsonValue]  # NotRequired via total=False\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_detailsproblemdetailsparams","title":"kgfoundry_common.problem_details.ProblemDetailsParams","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details.ProblemDetailsParams","title":"<code>kgfoundry_common.problem_details.ProblemDetailsParams</code>  <code>dataclass</code>","text":"<p>Parameters used to construct a Problem Details payload.</p> Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>@dataclass(slots=True)\n# [nav:anchor ProblemDetailsParams]\nclass ProblemDetailsParams:\n    \"\"\"Parameters used to construct a Problem Details payload.\"\"\"\n\n    problem_type: str\n    title: str\n    status: int\n    detail: str\n    instance: str\n    code: str | None = None\n    extensions: Mapping[str, JsonValue] | None = None\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_detailsproblemdetailsvalidationerror","title":"kgfoundry_common.problem_details.ProblemDetailsValidationError","text":"<p>Bases: Exception</p>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details.ProblemDetailsValidationError","title":"<code>kgfoundry_common.problem_details.ProblemDetailsValidationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when Problem Details payload fails schema validation.</p> <p>This exception is raised when a Problem Details dictionary does not conform to the RFC 9457 schema or fails validation against the canonical JSON Schema.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error message describing the validation failure.</p> required <code>validation_errors</code> <code>list[str] | None</code> <p>List of specific validation error messages from the schema validator. Provides detailed path and constraint information. Defaults to None.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>validation_errors</code> <code>list[str]</code> <p>List of validation error messages (empty list if not provided).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise ProblemDetailsValidationError(\"Missing required field: type\")\nTraceback (most recent call last):\n    ...\nProblemDetailsValidationError: Missing required field: type\n</code></pre> Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>class ProblemDetailsValidationError(Exception):\n    \"\"\"Raised when Problem Details payload fails schema validation.\n\n    This exception is raised when a Problem Details dictionary does not conform\n    to the RFC 9457 schema or fails validation against the canonical JSON Schema.\n\n    Parameters\n    ----------\n    message : str\n        Human-readable error message describing the validation failure.\n    validation_errors : list[str] | None, optional\n        List of specific validation error messages from the schema validator.\n        Provides detailed path and constraint information. Defaults to None.\n\n    Attributes\n    ----------\n    validation_errors : list[str]\n        List of validation error messages (empty list if not provided).\n\n    Examples\n    --------\n    &gt;&gt;&gt; raise ProblemDetailsValidationError(\"Missing required field: type\")\n    Traceback (most recent call last):\n        ...\n    ProblemDetailsValidationError: Missing required field: type\n    \"\"\"\n\n    def __init__(self, message: str, validation_errors: list[str] | None = None) -&gt; None:\n        \"\"\"Initialize validation error.\n\n        Parameters\n        ----------\n        message : str\n            Error message describing the validation failure.\n        validation_errors : list[str] | None, optional\n            List of specific validation error messages from the schema validator.\n            Defaults to None.\n        \"\"\"\n        super().__init__(message)\n        self.validation_errors = validation_errors or []\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details.ProblemDetailsValidationError.__init__","title":"<code>__init__(message, validation_errors=None)</code>","text":"<p>Initialize validation error.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error message describing the validation failure.</p> required <code>validation_errors</code> <code>list[str] | None</code> <p>List of specific validation error messages from the schema validator. Defaults to None.</p> <code>None</code> Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>def __init__(self, message: str, validation_errors: list[str] | None = None) -&gt; None:\n    \"\"\"Initialize validation error.\n\n    Parameters\n    ----------\n    message : str\n        Error message describing the validation failure.\n    validation_errors : list[str] | None, optional\n        List of specific validation error messages from the schema validator.\n        Defaults to None.\n    \"\"\"\n    super().__init__(message)\n    self.validation_errors = validation_errors or []\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_details_coerce_exception_params","title":"kgfoundry_common.problem_details._coerce_exception_params","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details._coerce_exception_params","title":"<code>kgfoundry_common.problem_details._coerce_exception_params(*args, **kwargs)</code>","text":"Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>def _coerce_exception_params(*args: object, **kwargs: object) -&gt; ExceptionProblemDetailsParams:\n    if len(args) &gt; 0 and isinstance(args[0], ExceptionProblemDetailsParams):\n        if len(args) &gt; 1 or kwargs:\n            _type_error(\"problem_from_exception() received unexpected extra arguments\")\n        return args[0]\n\n    if len(args) == 0:\n        _type_error(\"problem_from_exception() missing required argument: 'exc'\")\n\n    first_arg = _first_arg(args, func_name=\"problem_from_exception\")\n    exc = _ensure_exception(\n        first_arg,\n        message=\"problem_from_exception() first argument must be an Exception instance\",\n    )\n\n    if \"detail\" in kwargs:\n        _type_error(\"problem_from_exception() does not accept a 'detail' argument\")\n\n    base_args = args[1:]\n    combined_kwargs = dict(kwargs)\n    combined_kwargs[\"detail\"] = str(exc)\n\n    base_params = _coerce_problem_details_params(*base_args, **combined_kwargs)\n    return ExceptionProblemDetailsParams(exception=exc, base=base_params)\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_details_coerce_problem_details_params","title":"kgfoundry_common.problem_details._coerce_problem_details_params","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details._coerce_problem_details_params","title":"<code>kgfoundry_common.problem_details._coerce_problem_details_params(*args, **kwargs)</code>","text":"Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>def _coerce_problem_details_params(*args: object, **kwargs: object) -&gt; ProblemDetailsParams:\n    if len(args) &gt; 0 and isinstance(args[0], ProblemDetailsParams):\n        if len(args) &gt; 1 or kwargs:\n            _type_error(\"build_problem_details() received unexpected extra arguments\")\n        return args[0]\n\n    positional = (\"problem_type\", \"title\", \"status\", \"detail\", \"instance\")\n    if len(args) &gt; len(positional):\n        _type_error(\"build_problem_details() received too many positional arguments\")\n\n    values: dict[str, object] = dict(zip(positional, args, strict=False))\n\n    remaining_fields = positional[len(args) :]\n    missing_fields = [field_name for field_name in remaining_fields if field_name not in kwargs]\n    if missing_fields:\n        missing = missing_fields[0]\n        _type_error(f\"build_problem_details() missing required argument: '{missing}'\")\n    values.update({field_name: kwargs.pop(field_name) for field_name in remaining_fields})\n\n    code = kwargs.pop(\"code\", None)\n    extensions = kwargs.pop(\"extensions\", None)\n    if kwargs:\n        unexpected = \", \".join(sorted(kwargs))\n        _type_error(f\"build_problem_details() got unexpected keyword arguments: {unexpected}\")\n\n    status_int = _ensure_int(\n        values[\"status\"], message=\"build_problem_details() expected 'status' to be an int\"\n    )\n\n    return ProblemDetailsParams(\n        problem_type=str(values[\"problem_type\"]),\n        title=str(values[\"title\"]),\n        status=status_int,\n        detail=str(values[\"detail\"]),\n        instance=str(values[\"instance\"]),\n        code=None if code is None else str(code),\n        extensions=cast(\"Mapping[str, JsonValue] | None\", extensions),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_details_ensure_exception","title":"kgfoundry_common.problem_details._ensure_exception","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details._ensure_exception","title":"<code>kgfoundry_common.problem_details._ensure_exception(value, *, message)</code>","text":"Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>def _ensure_exception(value: object, *, message: str) -&gt; Exception:\n    if isinstance(value, Exception):\n        return value\n    _type_error(message)\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_details_ensure_int","title":"kgfoundry_common.problem_details._ensure_int","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details._ensure_int","title":"<code>kgfoundry_common.problem_details._ensure_int(value, *, message)</code>","text":"Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>def _ensure_int(value: object, *, message: str) -&gt; int:\n    if isinstance(value, int):\n        return value\n    _type_error(message)\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_details_first_arg","title":"kgfoundry_common.problem_details._first_arg","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details._first_arg","title":"<code>kgfoundry_common.problem_details._first_arg(args, *, func_name)</code>","text":"Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>def _first_arg(args: tuple[object, ...], *, func_name: str) -&gt; object:\n    if len(args) == 0:\n        _type_error(f\"{func_name}() missing required argument\")\n    return args[0]\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_details_load_schema","title":"kgfoundry_common.problem_details._load_schema","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details._load_schema","title":"<code>kgfoundry_common.problem_details._load_schema()</code>","text":"<p>Return the cached Problem Details JSON Schema.</p> <p>Returns:</p> Type Description <code>JsonSchema</code> <p>Cached JSON Schema for Problem Details.</p> Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>def _load_schema() -&gt; JsonSchema:\n    \"\"\"Return the cached Problem Details JSON Schema.\n\n    Returns\n    -------\n    JsonSchema\n        Cached JSON Schema for Problem Details.\n    \"\"\"\n    cached = _SCHEMA_CACHE.get(\"problem_details\")\n    if cached is not None:\n        return cached\n\n    schema = _load_schema_impl()\n    _SCHEMA_CACHE[\"problem_details\"] = schema\n    return schema\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_details_load_schema_impl","title":"kgfoundry_common.problem_details._load_schema_impl","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details._load_schema_impl","title":"<code>kgfoundry_common.problem_details._load_schema_impl()</code>","text":"<p>Load and parse the Problem Details schema from disk.</p> <p>Loads the canonical RFC 9457 Problem Details schema file, validates it against the JSON Schema 2020-12 meta-schema, and returns the parsed dictionary.</p> <p>Returns:</p> Type Description <code>JsonSchema</code> <p>Parsed schema dictionary conforming to JSON Schema 2020-12.</p> <p>Raises:</p> Type Description <code>ProblemDetailsValidationError</code> <p>If schema file is missing, invalid JSON, or fails meta-schema validation.</p> Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>def _load_schema_impl() -&gt; JsonSchema:\n    \"\"\"Load and parse the Problem Details schema from disk.\n\n    Loads the canonical RFC 9457 Problem Details schema file, validates it\n    against the JSON Schema 2020-12 meta-schema, and returns the parsed\n    dictionary.\n\n    Returns\n    -------\n    JsonSchema\n        Parsed schema dictionary conforming to JSON Schema 2020-12.\n\n    Raises\n    ------\n    ProblemDetailsValidationError\n        If schema file is missing, invalid JSON, or fails meta-schema\n        validation.\n    \"\"\"\n    if not _SCHEMA_PATH.exists():\n        msg = f\"Problem Details schema not found: {_SCHEMA_PATH}\"\n        raise ProblemDetailsValidationError(msg)\n\n    try:\n        schema_text = read_text(_SCHEMA_PATH)\n        schema_obj: dict[str, object] = json.loads(schema_text)\n    except (OSError, json.JSONDecodeError) as exc:\n        msg = f\"Failed to load Problem Details schema: {exc}\"\n        raise ProblemDetailsValidationError(msg) from exc\n\n    # Validate against JSON Schema 2020-12 meta-schema\n    try:\n        Draft202012Validator.check_schema(schema_obj)\n    except SchemaError as exc:\n        msg = f\"Invalid Problem Details schema: {exc}\"\n        raise ProblemDetailsValidationError(msg) from exc\n\n    return schema_obj\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_details_type_error","title":"kgfoundry_common.problem_details._type_error","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details._type_error","title":"<code>kgfoundry_common.problem_details._type_error(message)</code>","text":"Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>def _type_error(message: str) -&gt; NoReturn:\n    raise TypeError(message)\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_detailsbuild_configuration_problem","title":"kgfoundry_common.problem_details.build_configuration_problem","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details.build_configuration_problem","title":"<code>kgfoundry_common.problem_details.build_configuration_problem(config_error)</code>","text":"<p>Build Problem Details from a ConfigurationError.</p> <p>Parameters:</p> Name Type Description Default <code>config_error</code> <code>Exception</code> <p>A ConfigurationError instance with validation context.</p> required <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details payload with configuration error details.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the provided exception is not a ConfigurationError.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.errors import ConfigurationError\n&gt;&gt;&gt; error = ConfigurationError.with_details(\n...     field=\"api_key\",\n...     issue=\"Missing required environment variable\",\n...     hint=\"Set KGFOUNDRY_API_KEY before running\",\n... )\n&gt;&gt;&gt; problem = build_configuration_problem(error)\n&gt;&gt;&gt; assert problem[\"status\"] == 500\n&gt;&gt;&gt; assert \"api_key\" in str(problem[\"extensions\"])\n</code></pre> Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>def build_configuration_problem(\n    config_error: Exception,\n) -&gt; ProblemDetails:\n    \"\"\"Build Problem Details from a ConfigurationError.\n\n    Parameters\n    ----------\n    config_error : Exception\n        A ConfigurationError instance with validation context.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details payload with configuration error details.\n\n    Raises\n    ------\n    TypeError\n        If the provided exception is not a ConfigurationError.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.errors import ConfigurationError\n    &gt;&gt;&gt; error = ConfigurationError.with_details(\n    ...     field=\"api_key\",\n    ...     issue=\"Missing required environment variable\",\n    ...     hint=\"Set KGFOUNDRY_API_KEY before running\",\n    ... )\n    &gt;&gt;&gt; problem = build_configuration_problem(error)\n    &gt;&gt;&gt; assert problem[\"status\"] == 500\n    &gt;&gt;&gt; assert \"api_key\" in str(problem[\"extensions\"])\n    \"\"\"\n    # Check class name to avoid circular import\n    if type(config_error).__name__ != \"ConfigurationError\":\n        msg = (\n            f\"build_configuration_problem() expected ConfigurationError, \"\n            f\"got {type(config_error).__name__}\"\n        )\n        raise TypeError(msg)\n\n    # Verify it has the expected attributes\n    if not hasattr(config_error, \"message\") or not hasattr(config_error, \"http_status\"):\n        msg = (\n            \"build_configuration_problem() expected object with 'message' \"\n            \"and 'http_status' attributes\"\n        )\n        raise TypeError(msg)\n\n    # Extract field details from context if available\n    extensions: dict[str, JsonValue] = {\n        \"exception_type\": \"ConfigurationError\",\n    }\n    context_value: object = getattr(config_error, \"context\", None)\n    if isinstance(context_value, dict):\n        extensions[\"validation\"] = cast(\"dict[str, JsonValue]\", context_value)\n\n    # Get the message - use str() as fallback\n    msg_value: object = getattr(config_error, \"message\", None)\n    message: str = msg_value if isinstance(msg_value, str) else str(config_error)\n\n    # Get http_status - expect int, default to 500\n    http_attr: object = getattr(config_error, \"http_status\", 500)\n    http_status: int = http_attr if isinstance(http_attr, int) else 500\n\n    # Get code value - should be ErrorCode enum with .value attribute\n    code_obj: object = getattr(config_error, \"code\", None)\n    value_attr: object = getattr(code_obj, \"value\", None)\n    code_value: str = value_attr if isinstance(value_attr, str) else \"configuration-error\"\n\n    return build_problem_details(\n        problem_type=\"https://kgfoundry.dev/problems/configuration-error\",\n        title=\"Configuration Error\",\n        status=http_status,\n        detail=message,\n        instance=\"urn:config:validation\",\n        code=code_value,\n        extensions=extensions,\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_detailsbuild_problem_details","title":"kgfoundry_common.problem_details.build_problem_details","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details.build_problem_details","title":"<code>kgfoundry_common.problem_details.build_problem_details(*args, **kwargs)</code>","text":"<pre><code>build_problem_details(\n    params: ProblemDetailsParams,\n) -&gt; ProblemDetails\n</code></pre><pre><code>build_problem_details(\n    problem_type: str,\n    title: str,\n    status: int,\n    detail: str,\n    instance: str,\n    *,\n    code: str | None = ...,\n    extensions: Mapping[str, JsonValue] | None = ...\n) -&gt; ProblemDetails\n</code></pre> <p>Build an RFC 9457 Problem Details payload.</p> <p>Constructs a Problem Details dictionary conforming to RFC 9457 and validates it against the canonical schema. Supports both dataclass and positional/keyword argument calling styles.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>tuple</code> <p>Either a single :class:<code>ProblemDetailsParams</code> instance or the positional fields <code>(problem_type, title, status, detail, instance)</code> in that order.</p> <code>()</code> <code>**kwargs</code> <code>dict[str, object]</code> <p>Optional keyword arguments accepted when the dataclass form is not used. Supports <code>code</code> and <code>extensions</code> for the legacy calling style.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details payload conforming to RFC 9457 and validated against schema. Contains required fields: type, title, status, detail, instance. May include optional fields: code, extensions.</p> Notes <p>The function performs runtime type coercion and validation before constructing the payload. Schema validation errors raised by :func:<code>validate_problem_details</code> propagate unchanged.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; problem = build_problem_details(\n...     problem_type=\"https://kgfoundry.dev/problems/tool-timeout\",\n...     title=\"Tool execution timed out\",\n...     status=504,\n...     detail=\"Command 'git' timed out after 10.0 seconds\",\n...     instance=\"urn:tool:git:timeout\",\n...     extensions={\"command\": [\"git\", \"status\"], \"timeout\": 10.0},\n... )\n&gt;&gt;&gt; assert problem[\"type\"] == \"https://kgfoundry.dev/problems/tool-timeout\"\n&gt;&gt;&gt; assert problem[\"status\"] == 504\n</code></pre> Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>def build_problem_details(*args: object, **kwargs: object) -&gt; ProblemDetails:\n    \"\"\"Build an RFC 9457 Problem Details payload.\n\n    Constructs a Problem Details dictionary conforming to RFC 9457 and\n    validates it against the canonical schema. Supports both dataclass\n    and positional/keyword argument calling styles.\n\n    Parameters\n    ----------\n    *args : tuple\n        Either a single :class:`ProblemDetailsParams` instance or the\n        positional fields ``(problem_type, title, status, detail, instance)``\n        in that order.\n    **kwargs : dict[str, object]\n        Optional keyword arguments accepted when the dataclass form is not\n        used. Supports ``code`` and ``extensions`` for the legacy calling\n        style.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details payload conforming to RFC 9457 and validated against\n        schema. Contains required fields: type, title, status, detail, instance.\n        May include optional fields: code, extensions.\n\n    Notes\n    -----\n    The function performs runtime type coercion and validation before\n    constructing the payload. Schema validation errors raised by\n    :func:`validate_problem_details` propagate unchanged.\n\n    Examples\n    --------\n    &gt;&gt;&gt; problem = build_problem_details(\n    ...     problem_type=\"https://kgfoundry.dev/problems/tool-timeout\",\n    ...     title=\"Tool execution timed out\",\n    ...     status=504,\n    ...     detail=\"Command 'git' timed out after 10.0 seconds\",\n    ...     instance=\"urn:tool:git:timeout\",\n    ...     extensions={\"command\": [\"git\", \"status\"], \"timeout\": 10.0},\n    ... )\n    &gt;&gt;&gt; assert problem[\"type\"] == \"https://kgfoundry.dev/problems/tool-timeout\"\n    &gt;&gt;&gt; assert problem[\"status\"] == 504\n    \"\"\"\n    params = _coerce_problem_details_params(*args, **kwargs)\n    payload: dict[str, object] = {\n        \"type\": params.problem_type,\n        \"title\": params.title,\n        \"status\": params.status,\n        \"detail\": params.detail,\n        \"instance\": params.instance,\n    }\n    if params.code is not None:\n        payload[\"code\"] = params.code\n    if params.extensions:\n        payload[\"extensions\"] = dict(params.extensions)\n\n    # Validate against schema (cast since dict[str, object] \u2287 Mapping[str, JsonValue])\n    validate_problem_details(cast(\"Mapping[str, JsonValue]\", payload))\n\n    return cast(\"ProblemDetails\", payload)\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_detailsproblem_from_exception","title":"kgfoundry_common.problem_details.problem_from_exception","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details.problem_from_exception","title":"<code>kgfoundry_common.problem_details.problem_from_exception(*args, **kwargs)</code>","text":"<pre><code>problem_from_exception(\n    params: ExceptionProblemDetailsParams,\n) -&gt; ProblemDetails\n</code></pre><pre><code>problem_from_exception(\n    exc: Exception,\n    problem_type: str,\n    title: str,\n    status: int,\n    instance: str,\n    *,\n    code: str | None = ...,\n    extensions: Mapping[str, JsonValue] | None = ...\n) -&gt; ProblemDetails\n</code></pre> <p>Build Problem Details from an exception.</p> <p>Constructs a Problem Details payload from an exception instance, extracting the exception message as the detail field and automatically including exception type and cause chain information in extensions.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>tuple</code> <p>Either a single :class:<code>ExceptionProblemDetailsParams</code> instance or the legacy positional arguments <code>(exc, problem_type, title, status, instance)</code>.</p> <code>()</code> <code>**kwargs</code> <code>dict[str, object]</code> <p>Optional keyword arguments accepted when the dataclass form is not used. Supports <code>code</code> and <code>extensions</code> for backward compatibility. Note that <code>detail</code> cannot be provided as a keyword argument; it is automatically extracted from the exception.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>Problem Details payload with detail field set to the exception's string representation. Extensions include <code>exception_type</code> and optionally <code>caused_by</code> if the exception has a cause chain.</p> Notes <p>The exception's string representation (via <code>str(exc)</code>) is used as the detail field. The exception type name is added to extensions. If the exception has a <code>__cause__</code> attribute, it is included in extensions as <code>caused_by</code>. Schema validation errors raised by :func:<code>validate_problem_details</code> propagate unchanged.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; try:\n...     raise ValueError(\"Invalid input\")\n... except ValueError as e:\n...     problem = problem_from_exception(\n...         e,\n...         problem_type=\"https://kgfoundry.dev/problems/invalid-input\",\n...         title=\"Invalid input\",\n...         status=400,\n...         instance=\"urn:validation:input\",\n...     )\n&gt;&gt;&gt; assert \"Invalid input\" in problem[\"detail\"]\n&gt;&gt;&gt; assert problem[\"extensions\"][\"exception_type\"] == \"ValueError\"\n</code></pre> Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>def problem_from_exception(*args: object, **kwargs: object) -&gt; ProblemDetails:\n    \"\"\"Build Problem Details from an exception.\n\n    Constructs a Problem Details payload from an exception instance,\n    extracting the exception message as the detail field and automatically\n    including exception type and cause chain information in extensions.\n\n    Parameters\n    ----------\n    *args : tuple\n        Either a single :class:`ExceptionProblemDetailsParams` instance or\n        the legacy positional arguments ``(exc, problem_type, title, status,\n        instance)``.\n    **kwargs : dict[str, object]\n        Optional keyword arguments accepted when the dataclass form is not used.\n        Supports ``code`` and ``extensions`` for backward compatibility. Note\n        that ``detail`` cannot be provided as a keyword argument; it is\n        automatically extracted from the exception.\n\n    Returns\n    -------\n    ProblemDetails\n        Problem Details payload with detail field set to the exception's\n        string representation. Extensions include ``exception_type`` and\n        optionally ``caused_by`` if the exception has a cause chain.\n\n    Notes\n    -----\n    The exception's string representation (via ``str(exc)``) is used as the\n    detail field. The exception type name is added to extensions. If the\n    exception has a ``__cause__`` attribute, it is included in extensions as\n    ``caused_by``. Schema validation errors raised by\n    :func:`validate_problem_details` propagate unchanged.\n\n    Examples\n    --------\n    &gt;&gt;&gt; try:\n    ...     raise ValueError(\"Invalid input\")\n    ... except ValueError as e:\n    ...     problem = problem_from_exception(\n    ...         e,\n    ...         problem_type=\"https://kgfoundry.dev/problems/invalid-input\",\n    ...         title=\"Invalid input\",\n    ...         status=400,\n    ...         instance=\"urn:validation:input\",\n    ...     )\n    &gt;&gt;&gt; assert \"Invalid input\" in problem[\"detail\"]\n    &gt;&gt;&gt; assert problem[\"extensions\"][\"exception_type\"] == \"ValueError\"\n    \"\"\"\n    params = _coerce_exception_params(*args, **kwargs)\n    exc = params.exception\n    detail = params.base.detail\n    exc_type_name = exc.__class__.__name__\n    merged_extensions: dict[str, JsonValue] = {\n        \"exception_type\": exc_type_name,\n    }\n    if params.base.extensions:\n        merged_extensions.update(dict(params.base.extensions))\n\n    # Preserve cause chain if present\n    if exc.__cause__ is not None:\n        merged_extensions[\"caused_by\"] = exc.__cause__.__class__.__name__\n\n    return build_problem_details(\n        ProblemDetailsParams(\n            problem_type=params.base.problem_type,\n            title=params.base.title,\n            status=params.base.status,\n            detail=detail,\n            instance=params.base.instance,\n            code=params.base.code,\n            extensions=merged_extensions,\n        )\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_detailsrender_problem","title":"kgfoundry_common.problem_details.render_problem","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details.render_problem","title":"<code>kgfoundry_common.problem_details.render_problem(problem)</code>","text":"<p>Render Problem Details as JSON string.</p> <p>Serializes a Problem Details payload to a JSON string suitable for stdout output or HTTP response bodies. The output is minified (no indentation) and does not include a trailing newline.</p> <p>Parameters:</p> Name Type Description Default <code>problem</code> <code>ProblemDetails | dict[str, object]</code> <p>Problem Details payload to serialize. Must be JSON-serializable.</p> required <p>Returns:</p> Type Description <code>str</code> <p>JSON-encoded Problem Details string (minified, no trailing newline). Uses UTF-8 encoding and preserves non-ASCII characters.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; problem = build_problem_details(\n...     problem_type=\"https://kgfoundry.dev/problems/tool-failure\",\n...     title=\"Tool failed\",\n...     status=500,\n...     detail=\"Command failed\",\n...     instance=\"urn:tool:git:exit-1\",\n... )\n&gt;&gt;&gt; json_str = render_problem(problem)\n&gt;&gt;&gt; assert json_str.startswith(\"{\")\n&gt;&gt;&gt; assert \"tool-failure\" in json_str\n</code></pre> Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>def render_problem(problem: ProblemDetails | dict[str, object]) -&gt; str:\n    \"\"\"Render Problem Details as JSON string.\n\n    Serializes a Problem Details payload to a JSON string suitable for\n    stdout output or HTTP response bodies. The output is minified (no\n    indentation) and does not include a trailing newline.\n\n    Parameters\n    ----------\n    problem : ProblemDetails | dict[str, object]\n        Problem Details payload to serialize. Must be JSON-serializable.\n\n    Returns\n    -------\n    str\n        JSON-encoded Problem Details string (minified, no trailing newline).\n        Uses UTF-8 encoding and preserves non-ASCII characters.\n\n    Examples\n    --------\n    &gt;&gt;&gt; problem = build_problem_details(\n    ...     problem_type=\"https://kgfoundry.dev/problems/tool-failure\",\n    ...     title=\"Tool failed\",\n    ...     status=500,\n    ...     detail=\"Command failed\",\n    ...     instance=\"urn:tool:git:exit-1\",\n    ... )\n    &gt;&gt;&gt; json_str = render_problem(problem)\n    &gt;&gt;&gt; assert json_str.startswith(\"{\")\n    &gt;&gt;&gt; assert \"tool-failure\" in json_str\n    \"\"\"\n    return json.dumps(problem, default=str, ensure_ascii=False)\n</code></pre>"},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_commonproblem_detailsvalidate_problem_details","title":"kgfoundry_common.problem_details.validate_problem_details","text":""},{"location":"modules/kgfoundry_common.problem_details/#kgfoundry_common.problem_details.validate_problem_details","title":"<code>kgfoundry_common.problem_details.validate_problem_details(payload)</code>","text":"<p>Validate Problem Details payload against canonical schema.</p> <p>Validates a Problem Details dictionary against the RFC 9457 schema (JSON Schema 2020-12). Raises an exception if validation fails with detailed error information including the JSON path where validation failed.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>Mapping[str, JsonValue]</code> <p>Problem Details payload to validate. Must conform to RFC 9457 structure with required fields: type, title, status, detail, instance.</p> required <p>Raises:</p> Type Description <code>ProblemDetailsValidationError</code> <p>If payload fails schema validation. The exception includes validation_errors list with specific constraint violations.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; problem = {\n...     \"type\": \"https://kgfoundry.dev/problems/runtime-error\",\n...     \"title\": \"Runtime Error\",\n...     \"status\": 500,\n...     \"detail\": \"Operation failed\",\n...     \"instance\": \"/api/v1/operation\",\n... }\n&gt;&gt;&gt; validate_problem_details(problem)\n</code></pre> Source code in <code>src/kgfoundry_common/problem_details.py</code> <pre><code>def validate_problem_details(payload: Mapping[str, JsonValue]) -&gt; None:\n    \"\"\"Validate Problem Details payload against canonical schema.\n\n    Validates a Problem Details dictionary against the RFC 9457 schema\n    (JSON Schema 2020-12). Raises an exception if validation fails with\n    detailed error information including the JSON path where validation\n    failed.\n\n    Parameters\n    ----------\n    payload : Mapping[str, JsonValue]\n        Problem Details payload to validate. Must conform to RFC 9457\n        structure with required fields: type, title, status, detail, instance.\n\n    Raises\n    ------\n    ProblemDetailsValidationError\n        If payload fails schema validation. The exception includes\n        validation_errors list with specific constraint violations.\n\n    Examples\n    --------\n    &gt;&gt;&gt; problem = {\n    ...     \"type\": \"https://kgfoundry.dev/problems/runtime-error\",\n    ...     \"title\": \"Runtime Error\",\n    ...     \"status\": 500,\n    ...     \"detail\": \"Operation failed\",\n    ...     \"instance\": \"/api/v1/operation\",\n    ... }\n    &gt;&gt;&gt; validate_problem_details(problem)\n    \"\"\"\n    schema = _load_schema()\n    try:\n        jsonschema_validate(instance=payload, schema=schema)\n    except ValidationError as exc:\n        error_details = cast(\"ValidationErrorProtocol\", exc)\n        errors = [error_details.message]\n        if error_details.absolute_path:\n            path_str = \".\".join(str(p) for p in error_details.absolute_path)\n            errors.append(f\"at path: {path_str}\")\n        msg = f\"Problem Details validation failed: {'; '.join(errors)}\"\n        raise ProblemDetailsValidationError(msg, validation_errors=errors) from exc\n    except SchemaError as exc:\n        msg = f\"Invalid schema: {exc}\"\n        raise ProblemDetailsValidationError(msg) from exc\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/","title":"kgfoundry_common.prometheus","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheus","title":"kgfoundry_common.prometheus","text":"<p>Typed Prometheus helpers with graceful fallbacks.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.prometheus/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class CounterLike\n    class Protocol\n    Protocol &lt;|-- CounterLike\n    class GaugeLike\n    Protocol &lt;|-- GaugeLike\n    class HistogramLike\n    Protocol &lt;|-- HistogramLike\n    class HistogramParams\n    class _CounterConstructor\n    Protocol &lt;|-- _CounterConstructor\n    class _GaugeConstructor\n    Protocol &lt;|-- _GaugeConstructor\n    class _HistogramConstructor\n    Protocol &lt;|-- _HistogramConstructor\n    class _NoopCounter\n    class _NoopGauge\n    class _NoopHistogram\n    class _PromCounterType\n    class _PromGaugeType\n    class _PromHistogramType\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.prometheus__future__.annotationscollections.abc.Sequencedataclasses.dataclasskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.sequence_guards.first_or_errorprometheus_clientprometheus_client.Counterprometheus_client.Gaugeprometheus_client.Histogramprometheus_client.REGISTRYprometheus_client.registry.CollectorRegistrytyping.NoReturntyping.Protocoltyping.TYPE_CHECKINGtyping.casttyping.overloadkgfoundry_common.prometheus code <p>See the full diagram: kgfoundry_common.prometheus</p>"},{"location":"modules/kgfoundry_common.prometheus/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.prometheus.CounterLike</li> <li>kgfoundry_common.prometheus.GaugeLike</li> <li>kgfoundry_common.prometheus.HistogramLike</li> <li>kgfoundry_common.prometheus._coerce_histogram_params</li> <li>kgfoundry_common.prometheus._existing_collector</li> <li>kgfoundry_common.prometheus._histogram_type_error</li> </ul>"},{"location":"modules/kgfoundry_common.prometheus/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Sequence</code>, <code>dataclasses.dataclass</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.sequence_guards.first_or_error</code>, <code>prometheus_client</code>, <code>prometheus_client.Counter</code>, <code>prometheus_client.Gauge</code>, <code>prometheus_client.Histogram</code>, <code>prometheus_client.REGISTRY</code>, <code>prometheus_client.registry.CollectorRegistry</code>, <code>typing.NoReturn</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code>, <code>typing.overload</code></p>"},{"location":"modules/kgfoundry_common.prometheus/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheuscounterlike","title":"kgfoundry_common.prometheus.CounterLike","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.CounterLike","title":"<code>kgfoundry_common.prometheus.CounterLike</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol describing Prometheus counter behaviour relied upon.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>class CounterLike(Protocol):\n    \"\"\"Protocol describing Prometheus counter behaviour relied upon.\"\"\"\n\n    def labels(self, **labels: object) -&gt; CounterLike:\n        \"\"\"Return a counter labelled with the provided fields.\"\"\"\n        ...\n\n    def inc(self, value: float = 1.0) -&gt; None:\n        \"\"\"Increment the counter by ``value``.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.CounterLike.inc","title":"<code>inc(value=1.0)</code>","text":"<p>Increment the counter by <code>value</code>.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def inc(self, value: float = 1.0) -&gt; None:\n    \"\"\"Increment the counter by ``value``.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.CounterLike.labels","title":"<code>labels(**labels)</code>","text":"<p>Return a counter labelled with the provided fields.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def labels(self, **labels: object) -&gt; CounterLike:\n    \"\"\"Return a counter labelled with the provided fields.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheusgaugelike","title":"kgfoundry_common.prometheus.GaugeLike","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.GaugeLike","title":"<code>kgfoundry_common.prometheus.GaugeLike</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol describing Prometheus gauge behaviour relied upon.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>class GaugeLike(Protocol):\n    \"\"\"Protocol describing Prometheus gauge behaviour relied upon.\"\"\"\n\n    def labels(self, **labels: object) -&gt; GaugeLike:\n        \"\"\"Return a gauge labelled with the provided fields.\"\"\"\n        ...\n\n    def set(self, value: float) -&gt; None:\n        \"\"\"Set the gauge to ``value``.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.GaugeLike.labels","title":"<code>labels(**labels)</code>","text":"<p>Return a gauge labelled with the provided fields.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def labels(self, **labels: object) -&gt; GaugeLike:\n    \"\"\"Return a gauge labelled with the provided fields.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.GaugeLike.set","title":"<code>set(value)</code>","text":"<p>Set the gauge to <code>value</code>.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def set(self, value: float) -&gt; None:\n    \"\"\"Set the gauge to ``value``.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheushistogramlike","title":"kgfoundry_common.prometheus.HistogramLike","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.HistogramLike","title":"<code>kgfoundry_common.prometheus.HistogramLike</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol describing Prometheus histogram behaviour relied upon.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>class HistogramLike(Protocol):\n    \"\"\"Protocol describing Prometheus histogram behaviour relied upon.\"\"\"\n\n    def labels(self, **labels: object) -&gt; HistogramLike:\n        \"\"\"Return a histogram labelled with the provided fields.\"\"\"\n        ...\n\n    def observe(self, value: float) -&gt; None:\n        \"\"\"Record an observation of ``value``.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.HistogramLike.labels","title":"<code>labels(**labels)</code>","text":"<p>Return a histogram labelled with the provided fields.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def labels(self, **labels: object) -&gt; HistogramLike:\n    \"\"\"Return a histogram labelled with the provided fields.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.HistogramLike.observe","title":"<code>observe(value)</code>","text":"<p>Record an observation of <code>value</code>.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def observe(self, value: float) -&gt; None:\n    \"\"\"Record an observation of ``value``.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheushistogramparams","title":"kgfoundry_common.prometheus.HistogramParams","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.HistogramParams","title":"<code>kgfoundry_common.prometheus.HistogramParams</code>  <code>dataclass</code>","text":"<p>Configuration for building a histogram metric.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>@dataclass(slots=True)\n# [nav:anchor HistogramParams]\nclass HistogramParams:\n    \"\"\"Configuration for building a histogram metric.\"\"\"\n\n    name: str\n    documentation: str\n    labelnames: Sequence[str] | None = None\n    buckets: Sequence[float] | None = None\n    registry: CollectorRegistry | None = None\n    unit: str | None = None\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheus_counterconstructor","title":"kgfoundry_common.prometheus._CounterConstructor","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._CounterConstructor","title":"<code>kgfoundry_common.prometheus._CounterConstructor</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>class _CounterConstructor(Protocol):\n    def __call__(\n        self,\n        name: str,\n        documentation: str,\n        labelnames: Sequence[str] | None = ...,\n        *,\n        registry: CollectorRegistry | None = ...,\n        unit: str | None = ...,\n        **kwargs: object,\n    ) -&gt; CounterLike:\n        \"\"\"Construct a Counter metric.\n\n        Parameters\n        ----------\n        name : str\n            Metric name.\n        documentation : str\n            Metric documentation/help text.\n        labelnames : Sequence[str] | None, optional\n            Label names for the metric.\n        registry : CollectorRegistry | None, optional\n            Prometheus registry instance.\n        unit : str | None, optional\n            Unit identifier for the metric.\n        **kwargs : object\n            Additional keyword arguments.\n\n        Returns\n        -------\n        CounterLike\n            Counter metric instance.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._CounterConstructor.__call__","title":"<code>__call__(name, documentation, labelnames=..., *, registry=..., unit=..., **kwargs)</code>","text":"<p>Construct a Counter metric.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Metric name.</p> required <code>documentation</code> <code>str</code> <p>Metric documentation/help text.</p> required <code>labelnames</code> <code>Sequence[str] | None</code> <p>Label names for the metric.</p> <code>...</code> <code>registry</code> <code>CollectorRegistry | None</code> <p>Prometheus registry instance.</p> <code>...</code> <code>unit</code> <code>str | None</code> <p>Unit identifier for the metric.</p> <code>...</code> <code>**kwargs</code> <code>object</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>CounterLike</code> <p>Counter metric instance.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def __call__(\n    self,\n    name: str,\n    documentation: str,\n    labelnames: Sequence[str] | None = ...,\n    *,\n    registry: CollectorRegistry | None = ...,\n    unit: str | None = ...,\n    **kwargs: object,\n) -&gt; CounterLike:\n    \"\"\"Construct a Counter metric.\n\n    Parameters\n    ----------\n    name : str\n        Metric name.\n    documentation : str\n        Metric documentation/help text.\n    labelnames : Sequence[str] | None, optional\n        Label names for the metric.\n    registry : CollectorRegistry | None, optional\n        Prometheus registry instance.\n    unit : str | None, optional\n        Unit identifier for the metric.\n    **kwargs : object\n        Additional keyword arguments.\n\n    Returns\n    -------\n    CounterLike\n        Counter metric instance.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheus_gaugeconstructor","title":"kgfoundry_common.prometheus._GaugeConstructor","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._GaugeConstructor","title":"<code>kgfoundry_common.prometheus._GaugeConstructor</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>class _GaugeConstructor(Protocol):\n    def __call__(\n        self,\n        name: str,\n        documentation: str,\n        labelnames: Sequence[str] | None = ...,\n        *,\n        registry: CollectorRegistry | None = ...,\n        unit: str | None = ...,\n        **kwargs: object,\n    ) -&gt; GaugeLike:\n        \"\"\"Construct a Gauge metric.\n\n        Parameters\n        ----------\n        name : str\n            Metric name.\n        documentation : str\n            Metric documentation/help text.\n        labelnames : Sequence[str] | None, optional\n            Label names for the metric.\n        registry : CollectorRegistry | None, optional\n            Prometheus registry instance.\n        unit : str | None, optional\n            Unit identifier for the metric.\n        **kwargs : object\n            Additional keyword arguments.\n\n        Returns\n        -------\n        GaugeLike\n            Gauge metric instance.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._GaugeConstructor.__call__","title":"<code>__call__(name, documentation, labelnames=..., *, registry=..., unit=..., **kwargs)</code>","text":"<p>Construct a Gauge metric.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Metric name.</p> required <code>documentation</code> <code>str</code> <p>Metric documentation/help text.</p> required <code>labelnames</code> <code>Sequence[str] | None</code> <p>Label names for the metric.</p> <code>...</code> <code>registry</code> <code>CollectorRegistry | None</code> <p>Prometheus registry instance.</p> <code>...</code> <code>unit</code> <code>str | None</code> <p>Unit identifier for the metric.</p> <code>...</code> <code>**kwargs</code> <code>object</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>GaugeLike</code> <p>Gauge metric instance.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def __call__(\n    self,\n    name: str,\n    documentation: str,\n    labelnames: Sequence[str] | None = ...,\n    *,\n    registry: CollectorRegistry | None = ...,\n    unit: str | None = ...,\n    **kwargs: object,\n) -&gt; GaugeLike:\n    \"\"\"Construct a Gauge metric.\n\n    Parameters\n    ----------\n    name : str\n        Metric name.\n    documentation : str\n        Metric documentation/help text.\n    labelnames : Sequence[str] | None, optional\n        Label names for the metric.\n    registry : CollectorRegistry | None, optional\n        Prometheus registry instance.\n    unit : str | None, optional\n        Unit identifier for the metric.\n    **kwargs : object\n        Additional keyword arguments.\n\n    Returns\n    -------\n    GaugeLike\n        Gauge metric instance.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheus_histogramconstructor","title":"kgfoundry_common.prometheus._HistogramConstructor","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._HistogramConstructor","title":"<code>kgfoundry_common.prometheus._HistogramConstructor</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>class _HistogramConstructor(Protocol):\n    def __call__(self, *args: object, **kwargs: object) -&gt; HistogramLike:\n        \"\"\"Construct a Histogram metric.\n\n        Parameters\n        ----------\n        *args : object\n            Positional arguments (name, documentation, etc.).\n        **kwargs : object\n            Keyword arguments (labelnames, buckets, registry, etc.).\n\n        Returns\n        -------\n        HistogramLike\n            Histogram metric instance.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._HistogramConstructor.__call__","title":"<code>__call__(*args, **kwargs)</code>","text":"<p>Construct a Histogram metric.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>object</code> <p>Positional arguments (name, documentation, etc.).</p> <code>()</code> <code>**kwargs</code> <code>object</code> <p>Keyword arguments (labelnames, buckets, registry, etc.).</p> <code>{}</code> <p>Returns:</p> Type Description <code>HistogramLike</code> <p>Histogram metric instance.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def __call__(self, *args: object, **kwargs: object) -&gt; HistogramLike:\n    \"\"\"Construct a Histogram metric.\n\n    Parameters\n    ----------\n    *args : object\n        Positional arguments (name, documentation, etc.).\n    **kwargs : object\n        Keyword arguments (labelnames, buckets, registry, etc.).\n\n    Returns\n    -------\n    HistogramLike\n        Histogram metric instance.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheus_noopcounter","title":"kgfoundry_common.prometheus._NoopCounter","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._NoopCounter","title":"<code>kgfoundry_common.prometheus._NoopCounter</code>","text":"<p>Counter stub used when Prometheus is unavailable.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>class _NoopCounter:\n    \"\"\"Counter stub used when Prometheus is unavailable.\"\"\"\n\n    __slots__ = ()\n\n    def labels(self, **labels: object) -&gt; _NoopCounter:\n        \"\"\"Return the stub counter regardless of label input.\n\n        Parameters\n        ----------\n        **labels : object\n            Label values (ignored).\n\n        Returns\n        -------\n        _NoopCounter\n            Counter stub instance.\n        \"\"\"\n        del labels\n        return self\n\n    def inc(self, value: float = 1.0) -&gt; None:\n        \"\"\"Perform no operation when Prometheus is absent.\"\"\"\n        _ = self\n        del value\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._NoopCounter.inc","title":"<code>inc(value=1.0)</code>","text":"<p>Perform no operation when Prometheus is absent.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def inc(self, value: float = 1.0) -&gt; None:\n    \"\"\"Perform no operation when Prometheus is absent.\"\"\"\n    _ = self\n    del value\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._NoopCounter.labels","title":"<code>labels(**labels)</code>","text":"<p>Return the stub counter regardless of label input.</p> <p>Parameters:</p> Name Type Description Default <code>**labels</code> <code>object</code> <p>Label values (ignored).</p> <code>{}</code> <p>Returns:</p> Type Description <code>_NoopCounter</code> <p>Counter stub instance.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def labels(self, **labels: object) -&gt; _NoopCounter:\n    \"\"\"Return the stub counter regardless of label input.\n\n    Parameters\n    ----------\n    **labels : object\n        Label values (ignored).\n\n    Returns\n    -------\n    _NoopCounter\n        Counter stub instance.\n    \"\"\"\n    del labels\n    return self\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheus_noopgauge","title":"kgfoundry_common.prometheus._NoopGauge","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._NoopGauge","title":"<code>kgfoundry_common.prometheus._NoopGauge</code>","text":"<p>Gauge stub used when Prometheus is unavailable.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>class _NoopGauge:\n    \"\"\"Gauge stub used when Prometheus is unavailable.\"\"\"\n\n    __slots__ = ()\n\n    def labels(self, **labels: object) -&gt; _NoopGauge:\n        \"\"\"Return the stub gauge regardless of label input.\n\n        Parameters\n        ----------\n        **labels : object\n            Label values (ignored).\n\n        Returns\n        -------\n        _NoopGauge\n            Gauge stub instance.\n        \"\"\"\n        del labels\n        return self\n\n    def set(self, value: float) -&gt; None:\n        \"\"\"Perform no operation when Prometheus is absent.\"\"\"\n        _ = self\n        del value\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._NoopGauge.labels","title":"<code>labels(**labels)</code>","text":"<p>Return the stub gauge regardless of label input.</p> <p>Parameters:</p> Name Type Description Default <code>**labels</code> <code>object</code> <p>Label values (ignored).</p> <code>{}</code> <p>Returns:</p> Type Description <code>_NoopGauge</code> <p>Gauge stub instance.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def labels(self, **labels: object) -&gt; _NoopGauge:\n    \"\"\"Return the stub gauge regardless of label input.\n\n    Parameters\n    ----------\n    **labels : object\n        Label values (ignored).\n\n    Returns\n    -------\n    _NoopGauge\n        Gauge stub instance.\n    \"\"\"\n    del labels\n    return self\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._NoopGauge.set","title":"<code>set(value)</code>","text":"<p>Perform no operation when Prometheus is absent.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def set(self, value: float) -&gt; None:\n    \"\"\"Perform no operation when Prometheus is absent.\"\"\"\n    _ = self\n    del value\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheus_noophistogram","title":"kgfoundry_common.prometheus._NoopHistogram","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._NoopHistogram","title":"<code>kgfoundry_common.prometheus._NoopHistogram</code>","text":"<p>Histogram stub used when Prometheus is unavailable.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>class _NoopHistogram:\n    \"\"\"Histogram stub used when Prometheus is unavailable.\"\"\"\n\n    __slots__ = ()\n\n    def labels(self, **labels: object) -&gt; _NoopHistogram:\n        \"\"\"Return the stub histogram regardless of label input.\n\n        Parameters\n        ----------\n        **labels : object\n            Label values (ignored).\n\n        Returns\n        -------\n        _NoopHistogram\n            Histogram stub instance.\n        \"\"\"\n        del labels\n        return self\n\n    def observe(self, value: float) -&gt; None:\n        \"\"\"Perform no operation when Prometheus is absent.\"\"\"\n        _ = self\n        del value\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._NoopHistogram.labels","title":"<code>labels(**labels)</code>","text":"<p>Return the stub histogram regardless of label input.</p> <p>Parameters:</p> Name Type Description Default <code>**labels</code> <code>object</code> <p>Label values (ignored).</p> <code>{}</code> <p>Returns:</p> Type Description <code>_NoopHistogram</code> <p>Histogram stub instance.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def labels(self, **labels: object) -&gt; _NoopHistogram:\n    \"\"\"Return the stub histogram regardless of label input.\n\n    Parameters\n    ----------\n    **labels : object\n        Label values (ignored).\n\n    Returns\n    -------\n    _NoopHistogram\n        Histogram stub instance.\n    \"\"\"\n    del labels\n    return self\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._NoopHistogram.observe","title":"<code>observe(value)</code>","text":"<p>Perform no operation when Prometheus is absent.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def observe(self, value: float) -&gt; None:\n    \"\"\"Perform no operation when Prometheus is absent.\"\"\"\n    _ = self\n    del value\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheus_promcountertype","title":"kgfoundry_common.prometheus._PromCounterType","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._PromCounterType","title":"<code>kgfoundry_common.prometheus._PromCounterType</code>","text":"<p>Runtime stub matching Prometheus counter surface.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>class _PromCounterType:\n    \"\"\"Runtime stub matching Prometheus counter surface.\"\"\"\n\n    def labels(self, **labels: object) -&gt; _PromCounterType:\n        \"\"\"Return the counter stub regardless of label input.\n\n        Parameters\n        ----------\n        **labels : object\n            Label values (ignored).\n\n        Returns\n        -------\n        _PromCounterType\n            Counter stub instance.\n        \"\"\"\n        del labels\n        return self\n\n    def inc(self, value: float = 1.0) -&gt; None:\n        \"\"\"Perform no operation when Prometheus is absent.\"\"\"\n        _ = self\n        del value\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._PromCounterType.inc","title":"<code>inc(value=1.0)</code>","text":"<p>Perform no operation when Prometheus is absent.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def inc(self, value: float = 1.0) -&gt; None:\n    \"\"\"Perform no operation when Prometheus is absent.\"\"\"\n    _ = self\n    del value\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._PromCounterType.labels","title":"<code>labels(**labels)</code>","text":"<p>Return the counter stub regardless of label input.</p> <p>Parameters:</p> Name Type Description Default <code>**labels</code> <code>object</code> <p>Label values (ignored).</p> <code>{}</code> <p>Returns:</p> Type Description <code>_PromCounterType</code> <p>Counter stub instance.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def labels(self, **labels: object) -&gt; _PromCounterType:\n    \"\"\"Return the counter stub regardless of label input.\n\n    Parameters\n    ----------\n    **labels : object\n        Label values (ignored).\n\n    Returns\n    -------\n    _PromCounterType\n        Counter stub instance.\n    \"\"\"\n    del labels\n    return self\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheus_promgaugetype","title":"kgfoundry_common.prometheus._PromGaugeType","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._PromGaugeType","title":"<code>kgfoundry_common.prometheus._PromGaugeType</code>","text":"<p>Runtime stub matching Prometheus gauge surface.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>class _PromGaugeType:\n    \"\"\"Runtime stub matching Prometheus gauge surface.\"\"\"\n\n    def labels(self, **labels: object) -&gt; _PromGaugeType:\n        \"\"\"Return the gauge stub regardless of label input.\n\n        Parameters\n        ----------\n        **labels : object\n            Label values (ignored).\n\n        Returns\n        -------\n        _PromGaugeType\n            Gauge stub instance.\n        \"\"\"\n        del labels\n        return self\n\n    def set(self, value: float) -&gt; None:\n        \"\"\"Perform no operation when Prometheus is absent.\"\"\"\n        _ = self\n        del value\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._PromGaugeType.labels","title":"<code>labels(**labels)</code>","text":"<p>Return the gauge stub regardless of label input.</p> <p>Parameters:</p> Name Type Description Default <code>**labels</code> <code>object</code> <p>Label values (ignored).</p> <code>{}</code> <p>Returns:</p> Type Description <code>_PromGaugeType</code> <p>Gauge stub instance.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def labels(self, **labels: object) -&gt; _PromGaugeType:\n    \"\"\"Return the gauge stub regardless of label input.\n\n    Parameters\n    ----------\n    **labels : object\n        Label values (ignored).\n\n    Returns\n    -------\n    _PromGaugeType\n        Gauge stub instance.\n    \"\"\"\n    del labels\n    return self\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._PromGaugeType.set","title":"<code>set(value)</code>","text":"<p>Perform no operation when Prometheus is absent.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def set(self, value: float) -&gt; None:\n    \"\"\"Perform no operation when Prometheus is absent.\"\"\"\n    _ = self\n    del value\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheus_promhistogramtype","title":"kgfoundry_common.prometheus._PromHistogramType","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._PromHistogramType","title":"<code>kgfoundry_common.prometheus._PromHistogramType</code>","text":"<p>Runtime stub matching Prometheus histogram surface.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>class _PromHistogramType:\n    \"\"\"Runtime stub matching Prometheus histogram surface.\"\"\"\n\n    def labels(self, **labels: object) -&gt; _PromHistogramType:\n        \"\"\"Return the histogram stub regardless of label input.\n\n        Parameters\n        ----------\n        **labels : object\n            Label values (ignored).\n\n        Returns\n        -------\n        _PromHistogramType\n            Histogram stub instance.\n        \"\"\"\n        del labels\n        return self\n\n    def observe(self, value: float) -&gt; None:\n        \"\"\"Perform no operation when Prometheus is absent.\"\"\"\n        _ = self\n        del value\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._PromHistogramType.labels","title":"<code>labels(**labels)</code>","text":"<p>Return the histogram stub regardless of label input.</p> <p>Parameters:</p> Name Type Description Default <code>**labels</code> <code>object</code> <p>Label values (ignored).</p> <code>{}</code> <p>Returns:</p> Type Description <code>_PromHistogramType</code> <p>Histogram stub instance.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def labels(self, **labels: object) -&gt; _PromHistogramType:\n    \"\"\"Return the histogram stub regardless of label input.\n\n    Parameters\n    ----------\n    **labels : object\n        Label values (ignored).\n\n    Returns\n    -------\n    _PromHistogramType\n        Histogram stub instance.\n    \"\"\"\n    del labels\n    return self\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._PromHistogramType.observe","title":"<code>observe(value)</code>","text":"<p>Perform no operation when Prometheus is absent.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def observe(self, value: float) -&gt; None:\n    \"\"\"Perform no operation when Prometheus is absent.\"\"\"\n    _ = self\n    del value\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheus_coerce_histogram_params","title":"kgfoundry_common.prometheus._coerce_histogram_params","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._coerce_histogram_params","title":"<code>kgfoundry_common.prometheus._coerce_histogram_params(*args, **kwargs)</code>","text":"<p>Normalize legacy histogram arguments into a :class:<code>HistogramParams</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>object</code> <p>Either a single HistogramParams instance or positional arguments.</p> <code>()</code> <code>**kwargs</code> <code>object</code> <p>Optional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>HistogramParams</code> <p>Normalized histogram parameters.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def _coerce_histogram_params(*args: object, **kwargs: object) -&gt; HistogramParams:\n    \"\"\"Normalize legacy histogram arguments into a :class:`HistogramParams` instance.\n\n    Parameters\n    ----------\n    *args : object\n        Either a single HistogramParams instance or positional arguments.\n    **kwargs : object\n        Optional keyword arguments.\n\n    Returns\n    -------\n    HistogramParams\n        Normalized histogram parameters.\n    \"\"\"\n    args_list = list(args)\n\n    if args_list and isinstance(args_list[0], HistogramParams):\n        if len(args_list) &gt; 1 or kwargs:\n            _histogram_type_error(\"build_histogram() received unexpected extra arguments\")\n        return args_list[0]\n\n    if not args_list:\n        _histogram_type_error(\"build_histogram() missing required argument: 'name'\")\n\n    if len(args_list) &gt; _MAX_HISTOGRAM_POSITIONAL_ARGS:\n        _histogram_type_error(\"build_histogram() received too many positional arguments\")\n\n    name = str(\n        first_or_error(\n            args_list,\n            context=\"histogram_args_name\",\n            operation=\"build_histogram_coerce_params\",\n        )\n    )\n    if len(args_list) &gt; _DOCUMENTATION_POSITION:\n        documentation = str(args_list[_DOCUMENTATION_POSITION])\n    else:\n        doc = kwargs.pop(\"documentation\", None)\n        if doc is None:\n            _histogram_type_error(\"build_histogram() missing required argument: 'documentation'\")\n        documentation = str(doc)\n\n    labelnames = kwargs.pop(\"labelnames\", None)\n    buckets = kwargs.pop(\"buckets\", None)\n    registry = kwargs.pop(\"registry\", None)\n    unit = kwargs.pop(\"unit\", None)\n    if kwargs:\n        unexpected = \", \".join(sorted(kwargs))\n        _histogram_type_error(f\"build_histogram() got unexpected keyword arguments: {unexpected}\")\n\n    return HistogramParams(\n        name=name,\n        documentation=documentation,\n        labelnames=cast(\"Sequence[str] | None\", labelnames),\n        buckets=cast(\"Sequence[float] | None\", buckets),\n        registry=cast(\"CollectorRegistry | None\", registry),\n        unit=None if unit is None else str(unit),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheus_existing_collector","title":"kgfoundry_common.prometheus._existing_collector","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._existing_collector","title":"<code>kgfoundry_common.prometheus._existing_collector(name, registry)</code>","text":"<p>Return an existing metric collector when one has already been registered.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Metric name to look up.</p> required <code>registry</code> <code>CollectorRegistry | None</code> <p>Registry to search in.</p> required <p>Returns:</p> Type Description <code>object | None</code> <p>Existing collector if found, None otherwise.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def _existing_collector(\n    name: str,\n    registry: CollectorRegistry | None,\n) -&gt; object | None:\n    \"\"\"Return an existing metric collector when one has already been registered.\n\n    Parameters\n    ----------\n    name : str\n        Metric name to look up.\n    registry : CollectorRegistry | None\n        Registry to search in.\n\n    Returns\n    -------\n    object | None\n        Existing collector if found, None otherwise.\n    \"\"\"\n    target_registry: CollectorRegistry | None\n    if registry is not None:\n        target_registry = registry\n    else:\n        target_registry = cast(\"CollectorRegistry | None\", _DEFAULT_REGISTRY)\n    if target_registry is None:\n        return None\n    names_to_collectors = cast(\n        \"dict[str, object] | None\",\n        getattr(target_registry, \"_names_to_collectors\", None),\n    )\n    if isinstance(names_to_collectors, dict):\n        return names_to_collectors.get(name)\n    return None\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheus_histogram_type_error","title":"kgfoundry_common.prometheus._histogram_type_error","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._histogram_type_error","title":"<code>kgfoundry_common.prometheus._histogram_type_error(message)</code>","text":"Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def _histogram_type_error(message: str) -&gt; NoReturn:\n    raise TypeError(message)\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheus_labels_or_default","title":"kgfoundry_common.prometheus._labels_or_default","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus._labels_or_default","title":"<code>kgfoundry_common.prometheus._labels_or_default(labelnames)</code>","text":"Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def _labels_or_default(labelnames: Sequence[str] | None) -&gt; Sequence[str]:\n    return tuple(labelnames) if labelnames is not None else ()\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheusbuild_counter","title":"kgfoundry_common.prometheus.build_counter","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.build_counter","title":"<code>kgfoundry_common.prometheus.build_counter(name, documentation, labelnames=None, *, registry=None, unit=None)</code>","text":"<p>Return a counter metric or a no-op stub.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Metric name registered with Prometheus.</p> required <code>documentation</code> <code>str</code> <p>Human readable description of the metric.</p> required <code>labelnames</code> <code>Sequence[str] | None</code> <p>Label names applied to the metric (defaults to empty tuple).</p> <code>None</code> <code>registry</code> <code>CollectorRegistry | None</code> <p>Prometheus registry to register against (defaults to global registry).</p> <code>None</code> <code>unit</code> <code>str | None</code> <p>Unit description recorded alongside the metric.</p> <code>None</code> <p>Returns:</p> Type Description <code>CounterLike</code> <p>Counter metric instance or no-op stub.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If metric registration fails and no existing collector is found.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def build_counter(\n    name: str,\n    documentation: str,\n    labelnames: Sequence[str] | None = None,\n    *,\n    registry: CollectorRegistry | None = None,\n    unit: str | None = None,\n) -&gt; CounterLike:\n    \"\"\"Return a counter metric or a no-op stub.\n\n    Parameters\n    ----------\n    name : str\n        Metric name registered with Prometheus.\n    documentation : str\n        Human readable description of the metric.\n    labelnames : Sequence[str] | None, optional\n        Label names applied to the metric (defaults to empty tuple).\n    registry : CollectorRegistry | None, optional\n        Prometheus registry to register against (defaults to global registry).\n    unit : str | None, optional\n        Unit description recorded alongside the metric.\n\n    Returns\n    -------\n    CounterLike\n        Counter metric instance or no-op stub.\n\n    Raises\n    ------\n    ValueError\n        If metric registration fails and no existing collector is found.\n    \"\"\"\n    constructor = _COUNTER_CONSTRUCTOR\n    if constructor is None:\n        return _NoopCounter()\n    try:\n        return constructor(\n            name,\n            documentation,\n            _labels_or_default(labelnames),\n            registry=registry,\n            unit=unit,\n        )\n    except ValueError:  # pragma: no cover - only hit when duplicates exist\n        existing = _existing_collector(name, registry)\n        if existing is None:\n            raise\n        return cast(\"CounterLike\", existing)\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheusbuild_gauge","title":"kgfoundry_common.prometheus.build_gauge","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.build_gauge","title":"<code>kgfoundry_common.prometheus.build_gauge(name, documentation, labelnames=None, *, registry=None, unit=None)</code>","text":"<p>Return a gauge metric or a no-op stub.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Metric name registered with Prometheus.</p> required <code>documentation</code> <code>str</code> <p>Human readable description of the metric.</p> required <code>labelnames</code> <code>Sequence[str] | None</code> <p>Label names applied to the metric (defaults to empty tuple).</p> <code>None</code> <code>registry</code> <code>CollectorRegistry | None</code> <p>Prometheus registry to register against (defaults to global registry).</p> <code>None</code> <code>unit</code> <code>str | None</code> <p>Unit description recorded alongside the metric.</p> <code>None</code> <p>Returns:</p> Type Description <code>GaugeLike</code> <p>Gauge metric instance or no-op stub.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If metric registration fails and no existing collector is found.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def build_gauge(\n    name: str,\n    documentation: str,\n    labelnames: Sequence[str] | None = None,\n    *,\n    registry: CollectorRegistry | None = None,\n    unit: str | None = None,\n) -&gt; GaugeLike:\n    \"\"\"Return a gauge metric or a no-op stub.\n\n    Parameters\n    ----------\n    name : str\n        Metric name registered with Prometheus.\n    documentation : str\n        Human readable description of the metric.\n    labelnames : Sequence[str] | None, optional\n        Label names applied to the metric (defaults to empty tuple).\n    registry : CollectorRegistry | None, optional\n        Prometheus registry to register against (defaults to global registry).\n    unit : str | None, optional\n        Unit description recorded alongside the metric.\n\n    Returns\n    -------\n    GaugeLike\n        Gauge metric instance or no-op stub.\n\n    Raises\n    ------\n    ValueError\n        If metric registration fails and no existing collector is found.\n    \"\"\"\n    constructor = _GAUGE_CONSTRUCTOR\n    if constructor is None:\n        return _NoopGauge()\n    try:\n        return constructor(\n            name,\n            documentation,\n            _labels_or_default(labelnames),\n            registry=registry,\n            unit=unit,\n        )\n    except ValueError:  # pragma: no cover - duplicates are rare\n        existing = _existing_collector(name, registry)\n        if existing is None:\n            raise\n        return cast(\"GaugeLike\", existing)\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheusbuild_histogram","title":"kgfoundry_common.prometheus.build_histogram","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.build_histogram","title":"<code>kgfoundry_common.prometheus.build_histogram(*args, **kwargs)</code>","text":"<pre><code>build_histogram(params: HistogramParams) -&gt; HistogramLike\n</code></pre><pre><code>build_histogram(\n    name: str,\n    documentation: str,\n    labelnames: Sequence[str] | None = ...,\n    *,\n    buckets: Sequence[float] | None = ...,\n    registry: CollectorRegistry | None = ...,\n    unit: str | None = ...\n) -&gt; HistogramLike\n</code></pre> <p>Return a histogram metric or a no-op stub.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>object</code> <p>Either a single HistogramParams instance or positional arguments (name, documentation).</p> <code>()</code> <code>**kwargs</code> <code>object</code> <p>Optional keyword arguments: labelnames, buckets, registry, unit.</p> <code>{}</code> <p>Returns:</p> Type Description <code>HistogramLike</code> <p>Histogram metric instance or no-op stub.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If metric registration fails and no existing collector is found.</p> Notes <p>Propagates :class:<code>TypeError</code> when the provided arguments are invalid or missing required parameters.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def build_histogram(*args: object, **kwargs: object) -&gt; HistogramLike:\n    \"\"\"Return a histogram metric or a no-op stub.\n\n    Parameters\n    ----------\n    *args : object\n        Either a single HistogramParams instance or positional arguments (name, documentation).\n    **kwargs : object\n        Optional keyword arguments: labelnames, buckets, registry, unit.\n\n    Returns\n    -------\n    HistogramLike\n        Histogram metric instance or no-op stub.\n\n    Raises\n    ------\n    ValueError\n        If metric registration fails and no existing collector is found.\n\n    Notes\n    -----\n    Propagates :class:`TypeError` when the provided arguments are invalid or\n    missing required parameters.\n    \"\"\"\n    constructor = _HISTOGRAM_CONSTRUCTOR\n    if constructor is None:\n        return _NoopHistogram()\n\n    params = _coerce_histogram_params(*args, **kwargs)\n    label_tuple = _labels_or_default(params.labelnames)\n    call_kwargs: dict[str, object] = {}\n    if params.registry is not None:\n        call_kwargs[\"registry\"] = params.registry\n    if params.unit is not None:\n        call_kwargs[\"unit\"] = params.unit\n    if params.buckets is not None:\n        call_kwargs[\"buckets\"] = tuple(params.buckets)\n\n    try:\n        return constructor(\n            params.name,\n            params.documentation,\n            label_tuple,\n            **call_kwargs,\n        )\n    except ValueError:  # pragma: no cover - duplicates are exceptional\n        existing = _existing_collector(params.name, params.registry)\n        if existing is None:\n            raise\n        return cast(\"HistogramLike\", existing)\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheusget_default_registry","title":"kgfoundry_common.prometheus.get_default_registry","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.get_default_registry","title":"<code>kgfoundry_common.prometheus.get_default_registry()</code>","text":"<p>Return the global Prometheus registry when the dependency is available.</p> <p>Returns:</p> Type Description <code>object | None</code> <p>Global Prometheus registry or None if not available.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def get_default_registry() -&gt; object | None:\n    \"\"\"Return the global Prometheus registry when the dependency is available.\n\n    Returns\n    -------\n    object | None\n        Global Prometheus registry or None if not available.\n    \"\"\"\n    return _DEFAULT_REGISTRY\n</code></pre>"},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_commonprometheusprometheus_version","title":"kgfoundry_common.prometheus.prometheus_version","text":""},{"location":"modules/kgfoundry_common.prometheus/#kgfoundry_common.prometheus.prometheus_version","title":"<code>kgfoundry_common.prometheus.prometheus_version()</code>","text":"<p>Return the detected :mod:<code>prometheus_client</code> version for diagnostics.</p> <p>Returns:</p> Type Description <code>str | None</code> <p>Version string or None if prometheus_client is not installed.</p> Source code in <code>src/kgfoundry_common/prometheus.py</code> <pre><code>def prometheus_version() -&gt; str | None:\n    \"\"\"Return the detected :mod:`prometheus_client` version for diagnostics.\n\n    Returns\n    -------\n    str | None\n        Version string or None if prometheus_client is not installed.\n    \"\"\"\n    return _PROMETHEUS_VERSION\n</code></pre>"},{"location":"modules/kgfoundry_common.pydantic/","title":"kgfoundry_common.pydantic","text":""},{"location":"modules/kgfoundry_common.pydantic/#kgfoundry_commonpydantic","title":"kgfoundry_common.pydantic","text":"<p>Shared utilities and data structures used across KgFoundry services and tools.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.pydantic/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class BaseModel\n</code></pre>"},{"location":"modules/kgfoundry_common.pydantic/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.pydantic__future__.annotationspydantic.BaseModeltyping.ClassVartyping.Selftyping.TYPE_CHECKINGkgfoundry_common.pydantic code <p>See the full diagram: kgfoundry_common.pydantic</p>"},{"location":"modules/kgfoundry_common.pydantic/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.pydantic.BaseModel</li> </ul>"},{"location":"modules/kgfoundry_common.pydantic/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>pydantic.BaseModel</code>, <code>typing.ClassVar</code>, <code>typing.Self</code>, <code>typing.TYPE_CHECKING</code></p>"},{"location":"modules/kgfoundry_common.pydantic/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.pydantic/#kgfoundry_commonpydanticbasemodel","title":"kgfoundry_common.pydantic.BaseModel","text":""},{"location":"modules/kgfoundry_common.pydantic/#kgfoundry_common.pydantic.BaseModel","title":"<code>kgfoundry_common.pydantic.BaseModel</code>","text":"<p>Typing-friendly stub that mirrors Pydantic's <code>BaseModel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>**data</code> <code>Any</code> <p>Keyword arguments accepted by the Pydantic model.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>class BaseModel:\n    \"\"\"Typing-friendly stub that mirrors Pydantic's ``BaseModel``.\n\n    Parameters\n    ----------\n    **data : Any\n        Keyword arguments accepted by the Pydantic model.\n    \"\"\"\n\n    model_config: ClassVar[object]\n\n    def __init__(self, **data: object) -&gt; None:\n        \"\"\"Populate the model from keyword arguments.\n\n        Parameters\n        ----------\n        **data : Any\n            Keyword arguments forwarded to the underlying Pydantic model\n            constructor.\n        \"\"\"\n        raise NotImplementedError\n\n    @classmethod\n    def model_validate(cls, obj: object, /) -&gt; Self:\n        \"\"\"Validate ``obj`` using the underlying Pydantic implementation.\n\n        Parameters\n        ----------\n        obj : Any\n            Instance or mapping to validate.\n        strict : bool | None, optional\n            Whether to forbid coercion during validation.\n            Defaults to ``None`` (defer to Pydantic).\n        extra : ExtraValues | None, optional\n            Strategy for handling extra keys.\n            Defaults to ``None`` (use model configuration).\n        from_attributes : bool | None, optional\n            Allow attribute-based population when ``obj`` is not a mapping.\n            Defaults to ``None`` (follow model configuration).\n        context : Any | None, optional\n            Context data available to validators.\n            Defaults to ``None``.\n        by_alias : bool | None, optional\n            Interpret alias names when reading ``obj``.\n            Defaults to ``None`` (inherit from configuration).\n        by_name : bool | None, optional\n            Permit field-name based population alongside aliases.\n            Defaults to ``None``.\n        \"\"\"\n        raise NotImplementedError\n\n    def model_dump(self, **model_dump_kwargs: object) -&gt; dict[str, object]:\n        \"\"\"Return the dictionary representation produced by Pydantic.\n\n        Parameters\n        ----------\n        **model_dump_kwargs : dict[str, object]\n            Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump`.\n        \"\"\"\n        del self, model_dump_kwargs\n        raise NotImplementedError\n\n    def model_dump_json(self, **model_dump_json_kwargs: object) -&gt; str:\n        \"\"\"Return the JSON representation produced by Pydantic.\n\n        Parameters\n        ----------\n        **model_dump_json_kwargs : dict[str, object]\n            Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump_json`.\n        \"\"\"\n        del self, model_dump_json_kwargs\n        raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.pydantic/#kgfoundry_common.pydantic.BaseModel.__init__","title":"<code>__init__(**data)</code>","text":"<p>Populate the model from keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>**data</code> <code>Any</code> <p>Keyword arguments forwarded to the underlying Pydantic model constructor.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def __init__(self, **data: object) -&gt; None:\n    \"\"\"Populate the model from keyword arguments.\n\n    Parameters\n    ----------\n    **data : Any\n        Keyword arguments forwarded to the underlying Pydantic model\n        constructor.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.pydantic/#kgfoundry_common.pydantic.BaseModel.model_dump","title":"<code>model_dump(**model_dump_kwargs)</code>","text":"<p>Return the dictionary representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump(self, **model_dump_kwargs: object) -&gt; dict[str, object]:\n    \"\"\"Return the dictionary representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump`.\n    \"\"\"\n    del self, model_dump_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.pydantic/#kgfoundry_common.pydantic.BaseModel.model_dump_json","title":"<code>model_dump_json(**model_dump_json_kwargs)</code>","text":"<p>Return the JSON representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_json_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump_json</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump_json(self, **model_dump_json_kwargs: object) -&gt; str:\n    \"\"\"Return the JSON representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_json_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump_json`.\n    \"\"\"\n    del self, model_dump_json_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.pydantic/#kgfoundry_common.pydantic.BaseModel.model_validate","title":"<code>model_validate(obj)</code>  <code>classmethod</code>","text":"<p>Validate <code>obj</code> using the underlying Pydantic implementation.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Instance or mapping to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to forbid coercion during validation. Defaults to <code>None</code> (defer to Pydantic).</p> required <code>extra</code> <code>ExtraValues | None</code> <p>Strategy for handling extra keys. Defaults to <code>None</code> (use model configuration).</p> required <code>from_attributes</code> <code>bool | None</code> <p>Allow attribute-based population when <code>obj</code> is not a mapping. Defaults to <code>None</code> (follow model configuration).</p> required <code>context</code> <code>Any | None</code> <p>Context data available to validators. Defaults to <code>None</code>.</p> required <code>by_alias</code> <code>bool | None</code> <p>Interpret alias names when reading <code>obj</code>. Defaults to <code>None</code> (inherit from configuration).</p> required <code>by_name</code> <code>bool | None</code> <p>Permit field-name based population alongside aliases. Defaults to <code>None</code>.</p> required Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>@classmethod\ndef model_validate(cls, obj: object, /) -&gt; Self:\n    \"\"\"Validate ``obj`` using the underlying Pydantic implementation.\n\n    Parameters\n    ----------\n    obj : Any\n        Instance or mapping to validate.\n    strict : bool | None, optional\n        Whether to forbid coercion during validation.\n        Defaults to ``None`` (defer to Pydantic).\n    extra : ExtraValues | None, optional\n        Strategy for handling extra keys.\n        Defaults to ``None`` (use model configuration).\n    from_attributes : bool | None, optional\n        Allow attribute-based population when ``obj`` is not a mapping.\n        Defaults to ``None`` (follow model configuration).\n    context : Any | None, optional\n        Context data available to validators.\n        Defaults to ``None``.\n    by_alias : bool | None, optional\n        Interpret alias names when reading ``obj``.\n        Defaults to ``None`` (inherit from configuration).\n    by_name : bool | None, optional\n        Permit field-name based population alongside aliases.\n        Defaults to ``None``.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/","title":"kgfoundry_common.safe_pickle_v2","text":""},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_commonsafe_pickle_v2","title":"kgfoundry_common.safe_pickle_v2","text":"<p>Secure pickle serialization with HMAC signing and class allow-list.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class SignedPickleWrapper\n    class UnsafeSerializationError\n    class ValueError\n    ValueError &lt;|-- UnsafeSerializationError\n    class _PickleModule\n    class Protocol\n    Protocol &lt;|-- _PickleModule\n    class _SafeUnpickler\n    class _StdlibUnpickler\n    _StdlibUnpickler &lt;|-- _SafeUnpickler\n    class _StdlibUnpickler_1\n    class _UnpicklerProtocol\n    _UnpicklerProtocol &lt;|-- _StdlibUnpickler_1\n    class _UnpicklerProtocol_1\n    Protocol &lt;|-- _UnpicklerProtocol_1\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.safe_pickle_v2__future__.annotationscollections.abc.Callablehashlibhmacimportlib.import_moduleiokgfoundry_common.logging.get_loggerkgfoundry_common.navmap_loader.load_nav_metadatatyping.BinaryIOtyping.Protocoltyping.TYPE_CHECKINGtyping.castkgfoundry_common.safe_pickle_v2 code <p>See the full diagram: kgfoundry_common.safe_pickle_v2</p>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.safe_pickle_v2.SignedPickleWrapper</li> <li>kgfoundry_common.safe_pickle_v2.UnsafeSerializationError</li> <li>kgfoundry_common.safe_pickle_v2._PickleModule</li> <li>kgfoundry_common.safe_pickle_v2._load_cloudpickle_dumps</li> <li>kgfoundry_common.safe_pickle_v2._load_stdlib_pickle</li> <li>kgfoundry_common.safe_pickle_v2._load_with_allow_list</li> </ul>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Callable</code>, <code>hashlib</code>, <code>hmac</code>, <code>importlib.import_module</code>, <code>io</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>typing.BinaryIO</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_commonsafe_pickle_v2signedpicklewrapper","title":"kgfoundry_common.safe_pickle_v2.SignedPickleWrapper","text":""},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2.SignedPickleWrapper","title":"<code>kgfoundry_common.safe_pickle_v2.SignedPickleWrapper</code>","text":"<p>HMAC-signed pickle with allow-list validation.</p> <p>Combines class allow-listing with HMAC-SHA256 signatures to prevent both arbitrary code execution and payload tampering.</p> <p>Parameters:</p> Name Type Description Default <code>signing_key</code> <code>bytes</code> <p>HMAC signing key (\u226532 bytes recommended).</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import os\n&gt;&gt;&gt; key = os.urandom(32)\n&gt;&gt;&gt; wrapper = SignedPickleWrapper(key)\n&gt;&gt;&gt; data = {\"index\": \"data\"}\n&gt;&gt;&gt; import io\n&gt;&gt;&gt; buffer = io.BytesIO()\n&gt;&gt;&gt; wrapper.dump(data, buffer)\n&gt;&gt;&gt; buffer.seek(0)\n&gt;&gt;&gt; loaded = wrapper.load(buffer)\n&gt;&gt;&gt; assert loaded == data\n</code></pre> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>class SignedPickleWrapper:\n    \"\"\"HMAC-signed pickle with allow-list validation.\n\n    Combines class allow-listing with HMAC-SHA256 signatures to prevent\n    both arbitrary code execution and payload tampering.\n\n    Parameters\n    ----------\n    signing_key : bytes\n        HMAC signing key (\u226532 bytes recommended).\n\n    Examples\n    --------\n    &gt;&gt;&gt; import os\n    &gt;&gt;&gt; key = os.urandom(32)\n    &gt;&gt;&gt; wrapper = SignedPickleWrapper(key)\n    &gt;&gt;&gt; data = {\"index\": \"data\"}\n    &gt;&gt;&gt; import io\n    &gt;&gt;&gt; buffer = io.BytesIO()\n    &gt;&gt;&gt; wrapper.dump(data, buffer)\n    &gt;&gt;&gt; buffer.seek(0)\n    &gt;&gt;&gt; loaded = wrapper.load(buffer)\n    &gt;&gt;&gt; assert loaded == data\n    \"\"\"\n\n    def __init__(self, signing_key: bytes) -&gt; None:\n        \"\"\"Initialize wrapper with signing key.\"\"\"\n        if len(signing_key) &lt; _MIN_SIGNING_KEY_BYTES:\n            logger.warning(\"Signing key &lt; 32 bytes; consider using a longer key\")\n        self.signing_key = signing_key\n\n    def dump(self, obj: object, file: BinaryIO) -&gt; None:\n        \"\"\"Dump object with HMAC signature.\n\n        Parameters\n        ----------\n        obj : object\n            Object to serialize (dict/list/primitives only).\n        file : BinaryIO\n            File-like object opened in binary write mode.\n\n        Notes\n        -----\n        Propagates :class:`ValueError` when the object contains disallowed\n        types according to :func:`_validate_object`.\n        \"\"\"\n        _validate_object(obj)\n\n        payload = _stdlib_pickle.dumps(obj)\n        signature = hmac.new(self.signing_key, payload, hashlib.sha256).digest()\n        file.write(signature + payload)\n\n        logger.debug(\"Serialized object with HMAC signature\", extra={\"size\": len(payload)})\n\n    def load(self, file: BinaryIO) -&gt; object:\n        \"\"\"Load and verify object signature.\n\n        Parameters\n        ----------\n        file : BinaryIO\n            File-like object opened in binary read mode.\n\n        Returns\n        -------\n        object\n            Deserialized object (verified safe).\n\n        Raises\n        ------\n        UnsafeSerializationError\n            If signature verification fails or object contains disallowed types.\n        \"\"\"\n        data = file.read()\n        if len(data) &lt; _SIGNATURE_LENGTH:\n            msg = \"Serialized data too short; unable to verify signature\"\n            raise UnsafeSerializationError(msg, reason=\"truncated\")\n\n        signature, payload = data[:_SIGNATURE_LENGTH], data[_SIGNATURE_LENGTH:]\n        expected_sig = hmac.new(self.signing_key, payload, hashlib.sha256).digest()\n\n        if not hmac.compare_digest(signature, expected_sig):\n            msg = \"Deserialization blocked: HMAC signature verification failed; payload may be tampered\"\n            raise UnsafeSerializationError(msg, reason=\"signature_mismatch\")\n\n        result = _load_with_allow_list(io.BytesIO(payload))\n\n        logger.debug(\"Deserialized object with verified signature\", extra={\"size\": len(payload)})\n        return result\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2.SignedPickleWrapper.__init__","title":"<code>__init__(signing_key)</code>","text":"<p>Initialize wrapper with signing key.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def __init__(self, signing_key: bytes) -&gt; None:\n    \"\"\"Initialize wrapper with signing key.\"\"\"\n    if len(signing_key) &lt; _MIN_SIGNING_KEY_BYTES:\n        logger.warning(\"Signing key &lt; 32 bytes; consider using a longer key\")\n    self.signing_key = signing_key\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2.SignedPickleWrapper.dump","title":"<code>dump(obj, file)</code>","text":"<p>Dump object with HMAC signature.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>Object to serialize (dict/list/primitives only).</p> required <code>file</code> <code>BinaryIO</code> <p>File-like object opened in binary write mode.</p> required Notes <p>Propagates :class:<code>ValueError</code> when the object contains disallowed types according to :func:<code>_validate_object</code>.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def dump(self, obj: object, file: BinaryIO) -&gt; None:\n    \"\"\"Dump object with HMAC signature.\n\n    Parameters\n    ----------\n    obj : object\n        Object to serialize (dict/list/primitives only).\n    file : BinaryIO\n        File-like object opened in binary write mode.\n\n    Notes\n    -----\n    Propagates :class:`ValueError` when the object contains disallowed\n    types according to :func:`_validate_object`.\n    \"\"\"\n    _validate_object(obj)\n\n    payload = _stdlib_pickle.dumps(obj)\n    signature = hmac.new(self.signing_key, payload, hashlib.sha256).digest()\n    file.write(signature + payload)\n\n    logger.debug(\"Serialized object with HMAC signature\", extra={\"size\": len(payload)})\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2.SignedPickleWrapper.load","title":"<code>load(file)</code>","text":"<p>Load and verify object signature.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>BinaryIO</code> <p>File-like object opened in binary read mode.</p> required <p>Returns:</p> Type Description <code>object</code> <p>Deserialized object (verified safe).</p> <p>Raises:</p> Type Description <code>UnsafeSerializationError</code> <p>If signature verification fails or object contains disallowed types.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def load(self, file: BinaryIO) -&gt; object:\n    \"\"\"Load and verify object signature.\n\n    Parameters\n    ----------\n    file : BinaryIO\n        File-like object opened in binary read mode.\n\n    Returns\n    -------\n    object\n        Deserialized object (verified safe).\n\n    Raises\n    ------\n    UnsafeSerializationError\n        If signature verification fails or object contains disallowed types.\n    \"\"\"\n    data = file.read()\n    if len(data) &lt; _SIGNATURE_LENGTH:\n        msg = \"Serialized data too short; unable to verify signature\"\n        raise UnsafeSerializationError(msg, reason=\"truncated\")\n\n    signature, payload = data[:_SIGNATURE_LENGTH], data[_SIGNATURE_LENGTH:]\n    expected_sig = hmac.new(self.signing_key, payload, hashlib.sha256).digest()\n\n    if not hmac.compare_digest(signature, expected_sig):\n        msg = \"Deserialization blocked: HMAC signature verification failed; payload may be tampered\"\n        raise UnsafeSerializationError(msg, reason=\"signature_mismatch\")\n\n    result = _load_with_allow_list(io.BytesIO(payload))\n\n    logger.debug(\"Deserialized object with verified signature\", extra={\"size\": len(payload)})\n    return result\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_commonsafe_pickle_v2unsafeserializationerror","title":"kgfoundry_common.safe_pickle_v2.UnsafeSerializationError","text":"<p>Bases: ValueError</p>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2.UnsafeSerializationError","title":"<code>kgfoundry_common.safe_pickle_v2.UnsafeSerializationError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Raised when serialization validation fails.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error description.</p> required <code>reason</code> <code>str</code> <p>Specific reason (e.g., \"signature_mismatch\", \"disallowed_type\").</p> <code>None</code> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>class UnsafeSerializationError(ValueError):\n    \"\"\"Raised when serialization validation fails.\n\n    Parameters\n    ----------\n    message : str\n        Error description.\n    reason : str, optional\n        Specific reason (e.g., \"signature_mismatch\", \"disallowed_type\").\n    \"\"\"\n\n    def __init__(self, message: str, reason: str | None = None) -&gt; None:\n        \"\"\"Initialize unsafe serialization error.\"\"\"\n        super().__init__(message)\n        self.reason = reason\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2.UnsafeSerializationError.__init__","title":"<code>__init__(message, reason=None)</code>","text":"<p>Initialize unsafe serialization error.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def __init__(self, message: str, reason: str | None = None) -&gt; None:\n    \"\"\"Initialize unsafe serialization error.\"\"\"\n    super().__init__(message)\n    self.reason = reason\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_commonsafe_pickle_v2_picklemodule","title":"kgfoundry_common.safe_pickle_v2._PickleModule","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._PickleModule","title":"<code>kgfoundry_common.safe_pickle_v2._PickleModule</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>class _PickleModule(Protocol):\n    Unpickler: type[_UnpicklerProtocol]\n\n    PicklingError: type[Exception]\n\n    def dump(self, obj: object, file: BinaryIO) -&gt; None:\n        \"\"\"Serialize object to file.\n\n        Parameters\n        ----------\n        obj : object\n            Object to serialize.\n        file : BinaryIO\n            Binary file handle to write to.\n        \"\"\"\n        ...\n\n    def dumps(self, obj: object) -&gt; bytes:\n        \"\"\"Serialize object to bytes.\n\n        Parameters\n        ----------\n        obj : object\n            Object to serialize.\n\n        Returns\n        -------\n        bytes\n            Serialized object as bytes.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._PickleModule.dump","title":"<code>dump(obj, file)</code>","text":"<p>Serialize object to file.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>Object to serialize.</p> required <code>file</code> <code>BinaryIO</code> <p>Binary file handle to write to.</p> required Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def dump(self, obj: object, file: BinaryIO) -&gt; None:\n    \"\"\"Serialize object to file.\n\n    Parameters\n    ----------\n    obj : object\n        Object to serialize.\n    file : BinaryIO\n        Binary file handle to write to.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._PickleModule.dumps","title":"<code>dumps(obj)</code>","text":"<p>Serialize object to bytes.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>Object to serialize.</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>Serialized object as bytes.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def dumps(self, obj: object) -&gt; bytes:\n    \"\"\"Serialize object to bytes.\n\n    Parameters\n    ----------\n    obj : object\n        Object to serialize.\n\n    Returns\n    -------\n    bytes\n        Serialized object as bytes.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_commonsafe_pickle_v2_safeunpickler","title":"kgfoundry_common.safe_pickle_v2._SafeUnpickler","text":"<p>Bases: _StdlibUnpickler</p>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._SafeUnpickler","title":"<code>kgfoundry_common.safe_pickle_v2._SafeUnpickler</code>","text":"<p>               Bases: <code>_StdlibUnpickler</code></p> <p>Unpickler enforcing allow-list of safe types.</p> <p>This prevents arbitrary code execution by restricting deserialization to primitive types and basic containers.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>class _SafeUnpickler(_StdlibUnpickler):\n    \"\"\"Unpickler enforcing allow-list of safe types.\n\n    This prevents arbitrary code execution by restricting deserialization to primitive types and\n    basic containers.\n    \"\"\"\n\n    def __init__(\n        self,\n        file: BinaryIO,\n        *,\n        fix_imports: bool = True,\n        encoding: str = \"ASCII\",\n        errors: str = \"strict\",\n        buffers: object | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize safe unpickler with file handle.\n\n        Parameters\n        ----------\n        file : BinaryIO\n            Binary file handle to read from.\n        fix_imports : bool, optional\n            Whether to fix imports for Python 2 compatibility.\n            Defaults to True.\n        encoding : str, optional\n            Text encoding for Python 2 compatibility.\n            Defaults to \"ASCII\".\n        errors : str, optional\n            Error handling mode for encoding.\n            Defaults to \"strict\".\n        buffers : object | None, optional\n            Buffer protocol support.\n            Defaults to None.\n        \"\"\"\n        super().__init__(\n            file,\n            fix_imports=fix_imports,\n            encoding=encoding,\n            errors=errors,\n            buffers=buffers,\n        )\n\n    def find_class(self, module: str, name: str) -&gt; type:\n        \"\"\"Find class with allow-list enforcement.\n\n        Parameters\n        ----------\n        module : str\n            Module name.\n        name : str\n            Class name.\n\n        Returns\n        -------\n        type\n            The class object.\n\n        Raises\n        ------\n        UnsafeSerializationError\n            If class is not in allow-list.\n        \"\"\"\n        full_name = f\"{module}.{name}\"\n        if full_name not in _ALLOWED_TYPES:\n            msg = f\"Deserialization blocked: {full_name} not in allow-list\"\n            raise UnsafeSerializationError(msg, reason=\"disallowed_type\")\n        return cast(\"type[object]\", super().find_class(module, name))\n\n    def load(self) -&gt; object:\n        \"\"\"Deserialize the payload using the hardened allow-list.\n\n        Returns\n        -------\n        object\n            Deserialized object.\n        \"\"\"\n        return super().load()\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._SafeUnpickler.__init__","title":"<code>__init__(file, *, fix_imports=True, encoding='ASCII', errors='strict', buffers=None)</code>","text":"<p>Initialize safe unpickler with file handle.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>BinaryIO</code> <p>Binary file handle to read from.</p> required <code>fix_imports</code> <code>bool</code> <p>Whether to fix imports for Python 2 compatibility. Defaults to True.</p> <code>True</code> <code>encoding</code> <code>str</code> <p>Text encoding for Python 2 compatibility. Defaults to \"ASCII\".</p> <code>'ASCII'</code> <code>errors</code> <code>str</code> <p>Error handling mode for encoding. Defaults to \"strict\".</p> <code>'strict'</code> <code>buffers</code> <code>object | None</code> <p>Buffer protocol support. Defaults to None.</p> <code>None</code> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def __init__(\n    self,\n    file: BinaryIO,\n    *,\n    fix_imports: bool = True,\n    encoding: str = \"ASCII\",\n    errors: str = \"strict\",\n    buffers: object | None = None,\n) -&gt; None:\n    \"\"\"Initialize safe unpickler with file handle.\n\n    Parameters\n    ----------\n    file : BinaryIO\n        Binary file handle to read from.\n    fix_imports : bool, optional\n        Whether to fix imports for Python 2 compatibility.\n        Defaults to True.\n    encoding : str, optional\n        Text encoding for Python 2 compatibility.\n        Defaults to \"ASCII\".\n    errors : str, optional\n        Error handling mode for encoding.\n        Defaults to \"strict\".\n    buffers : object | None, optional\n        Buffer protocol support.\n        Defaults to None.\n    \"\"\"\n    super().__init__(\n        file,\n        fix_imports=fix_imports,\n        encoding=encoding,\n        errors=errors,\n        buffers=buffers,\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._SafeUnpickler.find_class","title":"<code>find_class(module, name)</code>","text":"<p>Find class with allow-list enforcement.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>str</code> <p>Module name.</p> required <code>name</code> <code>str</code> <p>Class name.</p> required <p>Returns:</p> Type Description <code>type</code> <p>The class object.</p> <p>Raises:</p> Type Description <code>UnsafeSerializationError</code> <p>If class is not in allow-list.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def find_class(self, module: str, name: str) -&gt; type:\n    \"\"\"Find class with allow-list enforcement.\n\n    Parameters\n    ----------\n    module : str\n        Module name.\n    name : str\n        Class name.\n\n    Returns\n    -------\n    type\n        The class object.\n\n    Raises\n    ------\n    UnsafeSerializationError\n        If class is not in allow-list.\n    \"\"\"\n    full_name = f\"{module}.{name}\"\n    if full_name not in _ALLOWED_TYPES:\n        msg = f\"Deserialization blocked: {full_name} not in allow-list\"\n        raise UnsafeSerializationError(msg, reason=\"disallowed_type\")\n    return cast(\"type[object]\", super().find_class(module, name))\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._SafeUnpickler.load","title":"<code>load()</code>","text":"<p>Deserialize the payload using the hardened allow-list.</p> <p>Returns:</p> Type Description <code>object</code> <p>Deserialized object.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def load(self) -&gt; object:\n    \"\"\"Deserialize the payload using the hardened allow-list.\n\n    Returns\n    -------\n    object\n        Deserialized object.\n    \"\"\"\n    return super().load()\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_commonsafe_pickle_v2_stdlibunpickler","title":"kgfoundry_common.safe_pickle_v2._StdlibUnpickler","text":"<p>Bases: _UnpicklerProtocol</p>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._StdlibUnpickler","title":"<code>kgfoundry_common.safe_pickle_v2._StdlibUnpickler</code>","text":"<p>               Bases: <code>_UnpicklerProtocol</code></p> <p>Static typing shim for the stdlib Unpickler.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>class _StdlibUnpickler(_UnpicklerProtocol):\n    \"\"\"Static typing shim for the stdlib Unpickler.\"\"\"\n\n    def __init__(\n        self,\n        file: BinaryIO,\n        *,\n        fix_imports: bool = ...,\n        encoding: str = ...,\n        errors: str = ...,\n        buffers: object | None = ...,\n    ) -&gt; None:\n        \"\"\"Initialize unpickler with file handle.\n\n        Parameters\n        ----------\n        file : BinaryIO\n            Binary file handle to read from.\n        fix_imports : bool, optional\n            Whether to fix imports for Python 2 compatibility.\n        encoding : str, optional\n            Text encoding for Python 2 compatibility.\n        errors : str, optional\n            Error handling mode for encoding.\n        buffers : object | None, optional\n            Buffer protocol support.\n        \"\"\"\n        ...\n\n    def load(self) -&gt; object:\n        \"\"\"Load and return unpickled object.\n\n        Returns\n        -------\n        object\n            Unpickled object from file.\n        \"\"\"\n        ...\n\n    def find_class(self, module: str, name: str) -&gt; object:\n        \"\"\"Find class by module and name.\n\n        Parameters\n        ----------\n        module : str\n            Module name.\n        name : str\n            Class name.\n\n        Returns\n        -------\n        object\n            Class object.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._StdlibUnpickler.__init__","title":"<code>__init__(file, *, fix_imports=..., encoding=..., errors=..., buffers=...)</code>","text":"<p>Initialize unpickler with file handle.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>BinaryIO</code> <p>Binary file handle to read from.</p> required <code>fix_imports</code> <code>bool</code> <p>Whether to fix imports for Python 2 compatibility.</p> <code>...</code> <code>encoding</code> <code>str</code> <p>Text encoding for Python 2 compatibility.</p> <code>...</code> <code>errors</code> <code>str</code> <p>Error handling mode for encoding.</p> <code>...</code> <code>buffers</code> <code>object | None</code> <p>Buffer protocol support.</p> <code>...</code> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def __init__(\n    self,\n    file: BinaryIO,\n    *,\n    fix_imports: bool = ...,\n    encoding: str = ...,\n    errors: str = ...,\n    buffers: object | None = ...,\n) -&gt; None:\n    \"\"\"Initialize unpickler with file handle.\n\n    Parameters\n    ----------\n    file : BinaryIO\n        Binary file handle to read from.\n    fix_imports : bool, optional\n        Whether to fix imports for Python 2 compatibility.\n    encoding : str, optional\n        Text encoding for Python 2 compatibility.\n    errors : str, optional\n        Error handling mode for encoding.\n    buffers : object | None, optional\n        Buffer protocol support.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._StdlibUnpickler.find_class","title":"<code>find_class(module, name)</code>","text":"<p>Find class by module and name.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>str</code> <p>Module name.</p> required <code>name</code> <code>str</code> <p>Class name.</p> required <p>Returns:</p> Type Description <code>object</code> <p>Class object.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def find_class(self, module: str, name: str) -&gt; object:\n    \"\"\"Find class by module and name.\n\n    Parameters\n    ----------\n    module : str\n        Module name.\n    name : str\n        Class name.\n\n    Returns\n    -------\n    object\n        Class object.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._StdlibUnpickler.load","title":"<code>load()</code>","text":"<p>Load and return unpickled object.</p> <p>Returns:</p> Type Description <code>object</code> <p>Unpickled object from file.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def load(self) -&gt; object:\n    \"\"\"Load and return unpickled object.\n\n    Returns\n    -------\n    object\n        Unpickled object from file.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_commonsafe_pickle_v2_unpicklerprotocol","title":"kgfoundry_common.safe_pickle_v2._UnpicklerProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._UnpicklerProtocol","title":"<code>kgfoundry_common.safe_pickle_v2._UnpicklerProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>class _UnpicklerProtocol(Protocol):\n    def __init__(\n        self,\n        file: BinaryIO,\n        *,\n        fix_imports: bool = ...,\n        encoding: str = ...,\n        errors: str = ...,\n        buffers: object | None = ...,\n    ) -&gt; None:\n        \"\"\"Initialize unpickler with file handle.\n\n        Parameters\n        ----------\n        file : BinaryIO\n            Binary file handle to read from.\n        fix_imports : bool, optional\n            Whether to fix imports for Python 2 compatibility.\n        encoding : str, optional\n            Text encoding for Python 2 compatibility.\n        errors : str, optional\n            Error handling mode for encoding.\n        buffers : object | None, optional\n            Buffer protocol support.\n        \"\"\"\n        ...\n\n    def load(self) -&gt; object:\n        \"\"\"Load and return unpickled object.\n\n        Returns\n        -------\n        object\n            Unpickled object from file.\n        \"\"\"\n        ...\n\n    def find_class(self, module: str, name: str) -&gt; object:\n        \"\"\"Find class by module and name.\n\n        Parameters\n        ----------\n        module : str\n            Module name.\n        name : str\n            Class name.\n\n        Returns\n        -------\n        object\n            Class object.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._UnpicklerProtocol.__init__","title":"<code>__init__(file, *, fix_imports=..., encoding=..., errors=..., buffers=...)</code>","text":"<p>Initialize unpickler with file handle.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>BinaryIO</code> <p>Binary file handle to read from.</p> required <code>fix_imports</code> <code>bool</code> <p>Whether to fix imports for Python 2 compatibility.</p> <code>...</code> <code>encoding</code> <code>str</code> <p>Text encoding for Python 2 compatibility.</p> <code>...</code> <code>errors</code> <code>str</code> <p>Error handling mode for encoding.</p> <code>...</code> <code>buffers</code> <code>object | None</code> <p>Buffer protocol support.</p> <code>...</code> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def __init__(\n    self,\n    file: BinaryIO,\n    *,\n    fix_imports: bool = ...,\n    encoding: str = ...,\n    errors: str = ...,\n    buffers: object | None = ...,\n) -&gt; None:\n    \"\"\"Initialize unpickler with file handle.\n\n    Parameters\n    ----------\n    file : BinaryIO\n        Binary file handle to read from.\n    fix_imports : bool, optional\n        Whether to fix imports for Python 2 compatibility.\n    encoding : str, optional\n        Text encoding for Python 2 compatibility.\n    errors : str, optional\n        Error handling mode for encoding.\n    buffers : object | None, optional\n        Buffer protocol support.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._UnpicklerProtocol.find_class","title":"<code>find_class(module, name)</code>","text":"<p>Find class by module and name.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>str</code> <p>Module name.</p> required <code>name</code> <code>str</code> <p>Class name.</p> required <p>Returns:</p> Type Description <code>object</code> <p>Class object.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def find_class(self, module: str, name: str) -&gt; object:\n    \"\"\"Find class by module and name.\n\n    Parameters\n    ----------\n    module : str\n        Module name.\n    name : str\n        Class name.\n\n    Returns\n    -------\n    object\n        Class object.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._UnpicklerProtocol.load","title":"<code>load()</code>","text":"<p>Load and return unpickled object.</p> <p>Returns:</p> Type Description <code>object</code> <p>Unpickled object from file.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def load(self) -&gt; object:\n    \"\"\"Load and return unpickled object.\n\n    Returns\n    -------\n    object\n        Unpickled object from file.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_commonsafe_pickle_v2_load_cloudpickle_dumps","title":"kgfoundry_common.safe_pickle_v2._load_cloudpickle_dumps","text":""},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._load_cloudpickle_dumps","title":"<code>kgfoundry_common.safe_pickle_v2._load_cloudpickle_dumps()</code>","text":"Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def _load_cloudpickle_dumps() -&gt; Callable[[object], bytes] | None:\n    candidate_modules = (\n        \"kgfoundry_common.cloudpickle_shim\",\n        \"cloudpickle\",\n    )\n    for module_name in candidate_modules:\n        try:\n            module = import_module(module_name)\n        except ImportError:  # pragma: no cover - optional dependency missing\n            continue\n        dumps_candidate: object = getattr(module, \"dumps\", None)\n        if callable(dumps_candidate):\n            return cast(\"Callable[[object], bytes]\", dumps_candidate)\n    return None\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_commonsafe_pickle_v2_load_stdlib_pickle","title":"kgfoundry_common.safe_pickle_v2._load_stdlib_pickle","text":""},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._load_stdlib_pickle","title":"<code>kgfoundry_common.safe_pickle_v2._load_stdlib_pickle()</code>","text":"Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def _load_stdlib_pickle() -&gt; _PickleModule:\n    module_name = \"_pickle\"\n    return cast(\"_PickleModule\", import_module(module_name))\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_commonsafe_pickle_v2_load_with_allow_list","title":"kgfoundry_common.safe_pickle_v2._load_with_allow_list","text":""},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._load_with_allow_list","title":"<code>kgfoundry_common.safe_pickle_v2._load_with_allow_list(file_obj)</code>","text":"<p>Load pickle with allow-list validation.</p> <p>Parameters:</p> Name Type Description Default <code>file_obj</code> <code>BytesIO</code> <p>File object with pickled data.</p> required <p>Returns:</p> Type Description <code>object</code> <p>Deserialized object.</p> <p>Raises:</p> Type Description <code>UnsafeSerializationError</code> <p>If pickle contains disallowed types.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def _load_with_allow_list(file_obj: io.BytesIO) -&gt; object:\n    \"\"\"Load pickle with allow-list validation.\n\n    Parameters\n    ----------\n    file_obj : io.BytesIO\n        File object with pickled data.\n\n    Returns\n    -------\n    object\n        Deserialized object.\n\n    Raises\n    ------\n    UnsafeSerializationError\n        If pickle contains disallowed types.\n    \"\"\"\n    unpickler = _SafeUnpickler(file_obj)\n    try:\n        loaded: object = unpickler.load()\n    except UnsafeSerializationError:\n        raise\n    except Exception as exc:\n        msg = f\"Pickle deserialization failed: {exc}\"\n        raise UnsafeSerializationError(msg, reason=\"parse_error\") from exc\n    else:\n        return loaded\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_commonsafe_pickle_v2_validate_object","title":"kgfoundry_common.safe_pickle_v2._validate_object","text":""},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2._validate_object","title":"<code>kgfoundry_common.safe_pickle_v2._validate_object(obj, depth=0)</code>","text":"<p>Recursively validate object contains only safe types.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>Object to validate.</p> required <code>depth</code> <code>int</code> <p>Current recursion depth (prevents infinite recursion).</p> <code>0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If object contains disallowed types or exceeds depth limit.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def _validate_object(obj: object, depth: int = 0) -&gt; None:\n    \"\"\"Recursively validate object contains only safe types.\n\n    Parameters\n    ----------\n    obj : object\n        Object to validate.\n    depth : int\n        Current recursion depth (prevents infinite recursion).\n\n    Raises\n    ------\n    ValueError\n        If object contains disallowed types or exceeds depth limit.\n    \"\"\"\n    if depth &gt; _MAX_NESTING_DEPTH:\n        msg = f\"Object nesting exceeds maximum depth ({_MAX_NESTING_DEPTH})\"\n        raise ValueError(msg)\n\n    # Primitives are always safe\n    if isinstance(obj, (str, int, float, bool, type(None))):\n        return\n\n    # Containers\n    if isinstance(obj, dict):\n        for key, value in obj.items():\n            _validate_object(key, depth + 1)\n            _validate_object(value, depth + 1)\n        return\n\n    if isinstance(obj, (list, tuple)):\n        for item in obj:\n            _validate_object(item, depth + 1)\n        return\n\n    # Reject other types\n    msg = f\"Object type not allowed for safe pickling: {type(obj).__qualname__}\"\n    raise ValueError(msg)\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_commonsafe_pickle_v2create_unsigned_pickle_payload","title":"kgfoundry_common.safe_pickle_v2.create_unsigned_pickle_payload","text":""},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2.create_unsigned_pickle_payload","title":"<code>kgfoundry_common.safe_pickle_v2.create_unsigned_pickle_payload(obj)</code>","text":"<p>Return pickle bytes for constructing negative test fixtures.</p> <p>This helper first attempts stdlib pickle. If the object cannot be serialized (e.g., local classes defined inside tests), it falls back to <code>cloudpickle</code> when available. Production code should continue to use :class:<code>SignedPickleWrapper</code> or :func:<code>load_unsigned_legacy</code>.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>Object to serialize.</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>Pickle bytes representation of the object.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If cloudpickle is required but not available.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def create_unsigned_pickle_payload(obj: object) -&gt; bytes:\n    \"\"\"Return pickle bytes for constructing negative test fixtures.\n\n    This helper first attempts stdlib pickle. If the object cannot be serialized\n    (e.g., local classes defined inside tests), it falls back to ``cloudpickle``\n    when available. Production code should continue to use\n    :class:`SignedPickleWrapper` or :func:`load_unsigned_legacy`.\n\n    Parameters\n    ----------\n    obj : object\n        Object to serialize.\n\n    Returns\n    -------\n    bytes\n        Pickle bytes representation of the object.\n\n    Raises\n    ------\n    RuntimeError\n        If cloudpickle is required but not available.\n    \"\"\"\n    try:\n        return _stdlib_pickle.dumps(obj)\n    except (AttributeError, _PICKLING_ERROR, TypeError) as exc:\n        if _CLOUDPICKLE_DUMPS is None:\n            message = \"cloudpickle is required to serialize this object\"\n            raise RuntimeError(message) from exc\n        return _CLOUDPICKLE_DUMPS(obj)\n</code></pre>"},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_commonsafe_pickle_v2load_unsigned_legacy","title":"kgfoundry_common.safe_pickle_v2.load_unsigned_legacy","text":""},{"location":"modules/kgfoundry_common.safe_pickle_v2/#kgfoundry_common.safe_pickle_v2.load_unsigned_legacy","title":"<code>kgfoundry_common.safe_pickle_v2.load_unsigned_legacy(file)</code>","text":"<p>Deserialize an unsigned legacy pickle stream with allow-list validation.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>BinaryIO</code> <p>File-like object opened in binary read mode.</p> required <p>Returns:</p> Type Description <code>object</code> <p>Deserialized object containing only allow-listed primitives and containers.</p> Notes <p>Propagates :class:<code>UnsafeSerializationError</code> when the pickle stream contains disallowed types or cannot be parsed by :func:<code>_load_with_allow_list</code>.</p> Source code in <code>src/kgfoundry_common/safe_pickle_v2.py</code> <pre><code>def load_unsigned_legacy(file: BinaryIO) -&gt; object:\n    \"\"\"Deserialize an unsigned legacy pickle stream with allow-list validation.\n\n    Parameters\n    ----------\n    file : BinaryIO\n        File-like object opened in binary read mode.\n\n    Returns\n    -------\n    object\n        Deserialized object containing only allow-listed primitives and containers.\n\n    Notes\n    -----\n    Propagates :class:`UnsafeSerializationError` when the pickle stream contains\n    disallowed types or cannot be parsed by :func:`_load_with_allow_list`.\n    \"\"\"\n    data = file.read()\n    buffer = io.BytesIO(data)\n    return _load_with_allow_list(buffer)\n</code></pre>"},{"location":"modules/kgfoundry_common.schema_helpers/","title":"kgfoundry_common.schema_helpers","text":""},{"location":"modules/kgfoundry_common.schema_helpers/#kgfoundry_commonschema_helpers","title":"kgfoundry_common.schema_helpers","text":"<p>Schema and model round-trip validation helpers.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.schema_helpers/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.schema_helpers__future__.annotationsjsonkgfoundry_common.errors.DeserializationErrorkgfoundry_common.errors.SerializationErrorkgfoundry_common.fs.read_textkgfoundry_common.jsonschema_utils.Draft202012Validatorkgfoundry_common.jsonschema_utils.SchemaErrorkgfoundry_common.jsonschema_utils.ValidationErrorkgfoundry_common.jsonschema_utils.validatekgfoundry_common.logging.get_loggerkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.problem_details.JsonValuekgfoundry_common.pydantic.BaseModelpathlib.Pathtyping.TYPE_CHECKINGtyping.castkgfoundry_common.schema_helpers code <p>See the full diagram: kgfoundry_common.schema_helpers</p>"},{"location":"modules/kgfoundry_common.schema_helpers/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.schema_helpers.assert_model_roundtrip</li> <li>kgfoundry_common.schema_helpers.load_schema</li> <li>kgfoundry_common.schema_helpers.validate_model_against_schema</li> </ul>"},{"location":"modules/kgfoundry_common.schema_helpers/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>json</code>, <code>kgfoundry_common.errors.DeserializationError</code>, <code>kgfoundry_common.errors.SerializationError</code>, <code>kgfoundry_common.fs.read_text</code>, <code>kgfoundry_common.jsonschema_utils.Draft202012Validator</code>, <code>kgfoundry_common.jsonschema_utils.SchemaError</code>, <code>kgfoundry_common.jsonschema_utils.ValidationError</code>, <code>kgfoundry_common.jsonschema_utils.validate</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.problem_details.JsonValue</code>, <code>kgfoundry_common.pydantic.BaseModel</code>, <code>pathlib.Path</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.schema_helpers/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.schema_helpers/#kgfoundry_commonschema_helpersassert_model_roundtrip","title":"kgfoundry_common.schema_helpers.assert_model_roundtrip","text":""},{"location":"modules/kgfoundry_common.schema_helpers/#kgfoundry_common.schema_helpers.assert_model_roundtrip","title":"<code>kgfoundry_common.schema_helpers.assert_model_roundtrip(model_cls, example_path, *, schema_path=None)</code>","text":"<p>Assert that a Pydantic model round-trips correctly with an example JSON file.</p> <p>This function performs a complete round-trip validation: 1. Loads the example JSON file 2. Validates it against the schema (if provided) 3. Deserializes it into a model instance 4. Re-serializes the model instance 5. Validates the re-serialized data matches the schema 6. Compares the round-trip data structure (allowing for type coercion)</p> <p>Parameters:</p> Name Type Description Default <code>model_cls</code> <code>type[BaseModel]</code> <p>Pydantic model class to test.</p> required <code>example_path</code> <code>Path</code> <p>Path to example JSON file.</p> required <code>schema_path</code> <code>Path | None</code> <p>Path to JSON Schema file. If None, schema validation is skipped. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If example or schema file does not exist.</p> <code>DeserializationError</code> <p>If example JSON is invalid or fails schema validation.</p> <code>SerializationError</code> <p>If model instance fails schema validation after round-trip.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from kgfoundry_common.models import Doc\n&gt;&gt;&gt; example = Path(\"schema/examples/models/doc.v1.json\")\n&gt;&gt;&gt; schema = Path(\"schema/models/doc.v1.json\")\n&gt;&gt;&gt; assert_model_roundtrip(Doc, example, schema_path=schema)\n</code></pre> Source code in <code>src/kgfoundry_common/schema_helpers.py</code> <pre><code>def assert_model_roundtrip(\n    model_cls: type[BaseModel],\n    example_path: Path,\n    *,\n    schema_path: Path | None = None,\n) -&gt; None:\n    \"\"\"Assert that a Pydantic model round-trips correctly with an example JSON file.\n\n    This function performs a complete round-trip validation:\n    1. Loads the example JSON file\n    2. Validates it against the schema (if provided)\n    3. Deserializes it into a model instance\n    4. Re-serializes the model instance\n    5. Validates the re-serialized data matches the schema\n    6. Compares the round-trip data structure (allowing for type coercion)\n\n    Parameters\n    ----------\n    model_cls : type[BaseModel]\n        Pydantic model class to test.\n    example_path : Path\n        Path to example JSON file.\n    schema_path : Path | None, optional\n        Path to JSON Schema file. If None, schema validation is skipped.\n        Defaults to None.\n\n    Raises\n    ------\n    FileNotFoundError\n        If example or schema file does not exist.\n    DeserializationError\n        If example JSON is invalid or fails schema validation.\n    SerializationError\n        If model instance fails schema validation after round-trip.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; from kgfoundry_common.models import Doc\n    &gt;&gt;&gt; example = Path(\"schema/examples/models/doc.v1.json\")\n    &gt;&gt;&gt; schema = Path(\"schema/models/doc.v1.json\")\n    &gt;&gt;&gt; assert_model_roundtrip(Doc, example, schema_path=schema)\n    \"\"\"\n    if not example_path.exists():\n        msg = f\"Example file not found: {example_path}\"\n        raise FileNotFoundError(msg)\n\n    # Load example JSON\n    try:\n        example_text = read_text(example_path)\n        example_data: dict[str, JsonValue] = json.loads(example_text)\n    except json.JSONDecodeError as exc:\n        msg = f\"Invalid JSON in example file {example_path}: {exc}\"\n        raise DeserializationError(msg) from exc\n\n    # Load and validate schema if provided\n    schema_obj: dict[str, JsonValue] | None = None\n    if schema_path is not None:\n        schema_obj = load_schema(schema_path)\n        # Validate example against schema\n        try:\n            jsonschema_validate(instance=example_data, schema=schema_obj)\n        except ValidationError as exc:\n            msg = f\"Example JSON does not match schema: {exc}\"\n            raise DeserializationError(msg) from exc\n\n    # Deserialize example into model instance\n    try:\n        instance = model_cls.model_validate(example_data)\n    except Exception as exc:\n        msg = f\"Failed to deserialize example into {model_cls.__name__}: {exc}\"\n        raise DeserializationError(msg) from exc\n\n    # Re-serialize model instance (validates serialization works)\n    try:\n        _round_trip_data = instance.model_dump(mode=\"json\")\n    except Exception as exc:\n        msg = f\"Failed to serialize {model_cls.__name__} instance: {exc}\"\n        raise SerializationError(msg) from exc\n\n    # Validate round-trip data against schema if provided\n    if schema_obj is not None:\n        validate_model_against_schema(instance, schema_obj)\n\n    logger.debug(\n        \"Model round-trip validated\",\n        extra={\n            \"model\": model_cls.__name__,\n            \"example_path\": str(example_path),\n            \"schema_path\": str(schema_path) if schema_path else None,\n        },\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.schema_helpers/#kgfoundry_commonschema_helpersload_schema","title":"kgfoundry_common.schema_helpers.load_schema","text":""},{"location":"modules/kgfoundry_common.schema_helpers/#kgfoundry_common.schema_helpers.load_schema","title":"<code>kgfoundry_common.schema_helpers.load_schema(schema_path)</code>","text":"<p>Load and parse a JSON Schema file.</p> <p>Loads a JSON Schema 2020-12 file from disk, parses it, and validates it against the JSON Schema 2020-12 meta-schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema_path</code> <code>Path</code> <p>Path to JSON Schema 2020-12 file.</p> required <p>Returns:</p> Type Description <code>dict[str, JsonValue]</code> <p>Parsed schema dictionary.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If schema file does not exist.</p> <code>DeserializationError</code> <p>If schema is invalid JSON or fails validation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; schema = load_schema(Path(\"schema/models/doc.v1.json\"))\n&gt;&gt;&gt; assert \"$schema\" in schema\n</code></pre> Source code in <code>src/kgfoundry_common/schema_helpers.py</code> <pre><code>def load_schema(schema_path: Path) -&gt; dict[str, JsonValue]:\n    \"\"\"Load and parse a JSON Schema file.\n\n    Loads a JSON Schema 2020-12 file from disk, parses it, and validates\n    it against the JSON Schema 2020-12 meta-schema.\n\n    Parameters\n    ----------\n    schema_path : Path\n        Path to JSON Schema 2020-12 file.\n\n    Returns\n    -------\n    dict[str, JsonValue]\n        Parsed schema dictionary.\n\n    Raises\n    ------\n    FileNotFoundError\n        If schema file does not exist.\n    DeserializationError\n        If schema is invalid JSON or fails validation.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; schema = load_schema(Path(\"schema/models/doc.v1.json\"))\n    &gt;&gt;&gt; assert \"$schema\" in schema\n    \"\"\"\n    if not schema_path.exists():\n        msg = f\"Schema file not found: {schema_path}\"\n        raise FileNotFoundError(msg)\n\n    try:\n        schema_text = read_text(schema_path)\n        schema_obj: dict[str, JsonValue] = json.loads(schema_text)\n    except json.JSONDecodeError as exc:\n        msg = f\"Invalid JSON in schema file {schema_path}: {exc}\"\n        raise DeserializationError(msg) from exc\n\n    # Validate against JSON Schema 2020-12 meta-schema\n    try:\n        Draft202012Validator.check_schema(schema_obj)\n    except SchemaError as exc:\n        msg = f\"Invalid JSON Schema 2020-12 in {schema_path}: {exc}\"\n        raise DeserializationError(msg) from exc\n\n    return schema_obj\n</code></pre>"},{"location":"modules/kgfoundry_common.schema_helpers/#kgfoundry_commonschema_helpersvalidate_model_against_schema","title":"kgfoundry_common.schema_helpers.validate_model_against_schema","text":""},{"location":"modules/kgfoundry_common.schema_helpers/#kgfoundry_common.schema_helpers.validate_model_against_schema","title":"<code>kgfoundry_common.schema_helpers.validate_model_against_schema(model_instance, schema)</code>","text":"<p>Validate a Pydantic model instance against a JSON Schema.</p> <p>Converts the model instance to a dictionary and validates it against the provided JSON Schema 2020-12.</p> <p>Parameters:</p> Name Type Description Default <code>model_instance</code> <code>BaseModel</code> <p>Pydantic model instance to validate.</p> required <code>schema</code> <code>dict[str, JsonValue]</code> <p>JSON Schema 2020-12 dictionary.</p> required <p>Raises:</p> Type Description <code>SerializationError</code> <p>If validation fails or schema is invalid.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.models import Doc\n&gt;&gt;&gt; schema = {\"type\": \"object\", \"properties\": {\"id\": {\"type\": \"string\"}}}\n&gt;&gt;&gt; doc = Doc(id=\"urn:doc:test\")\n&gt;&gt;&gt; validate_model_against_schema(doc, schema)\n</code></pre> Source code in <code>src/kgfoundry_common/schema_helpers.py</code> <pre><code>def validate_model_against_schema(\n    model_instance: BaseModel,\n    schema: dict[str, JsonValue],\n) -&gt; None:\n    \"\"\"Validate a Pydantic model instance against a JSON Schema.\n\n    Converts the model instance to a dictionary and validates it against\n    the provided JSON Schema 2020-12.\n\n    Parameters\n    ----------\n    model_instance : BaseModel\n        Pydantic model instance to validate.\n    schema : dict[str, JsonValue]\n        JSON Schema 2020-12 dictionary.\n\n    Raises\n    ------\n    SerializationError\n        If validation fails or schema is invalid.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.models import Doc\n    &gt;&gt;&gt; schema = {\"type\": \"object\", \"properties\": {\"id\": {\"type\": \"string\"}}}\n    &gt;&gt;&gt; doc = Doc(id=\"urn:doc:test\")\n    &gt;&gt;&gt; validate_model_against_schema(doc, schema)\n    \"\"\"\n    try:\n        # Convert model to dict (using model_dump with mode='json' for JSON-compatible types)\n        # model_dump returns dict[str, object], cast to JsonValue since it's JSON-serializable\n        data: dict[str, JsonValue] = cast(\n            \"dict[str, JsonValue]\", model_instance.model_dump(mode=\"json\")\n        )\n        jsonschema_validate(instance=data, schema=schema)\n    except ValidationError as exc:\n        msg = f\"Model instance does not match schema: {exc}\"\n        raise SerializationError(msg) from exc\n    except SchemaError as exc:\n        msg = f\"Invalid schema: {exc}\"\n        raise SerializationError(msg) from exc\n</code></pre>"},{"location":"modules/kgfoundry_common.sequence_guards/","title":"kgfoundry_common.sequence_guards","text":""},{"location":"modules/kgfoundry_common.sequence_guards/#kgfoundry_commonsequence_guards","title":"kgfoundry_common.sequence_guards","text":"<p>Sequence access guards for observability-critical code paths.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.sequence_guards/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.sequence_guards__future__.annotationscollections.abccollections.abc.Sequencekgfoundry_common.errors.VectorSearchErrorkgfoundry_common.logging.get_loggerkgfoundry_common.logging.with_fieldskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.problem_details.build_problem_detailskgfoundry_common.problem_details.render_problemtyping.TYPE_CHECKINGkgfoundry_common.sequence_guards code <p>See the full diagram: kgfoundry_common.sequence_guards</p>"},{"location":"modules/kgfoundry_common.sequence_guards/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.sequence_guards.first_or_error</li> <li>kgfoundry_common.sequence_guards.first_or_error_multi_device</li> </ul>"},{"location":"modules/kgfoundry_common.sequence_guards/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc</code>, <code>collections.abc.Sequence</code>, <code>kgfoundry_common.errors.VectorSearchError</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>kgfoundry_common.logging.with_fields</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.problem_details.build_problem_details</code>, <code>kgfoundry_common.problem_details.render_problem</code>, <code>typing.TYPE_CHECKING</code></p>"},{"location":"modules/kgfoundry_common.sequence_guards/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.sequence_guards/#kgfoundry_commonsequence_guardsfirst_or_error","title":"kgfoundry_common.sequence_guards.first_or_error","text":""},{"location":"modules/kgfoundry_common.sequence_guards/#kgfoundry_common.sequence_guards.first_or_error","title":"<code>kgfoundry_common.sequence_guards.first_or_error(sequence, *, context, operation='sequence_access')</code>","text":"<p>Access first element of sequence or raise Problem Details error.</p> <p>Validates that the sequence is non-empty before indexing, ensuring observability instrumentation captures empty-input failures with structured logs and metrics.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>Sequence[T]</code> <p>The sequence from which to extract the first element.</p> required <code>context</code> <code>str</code> <p>Human-readable description of why the sequence was accessed (e.g., \"gpu_device_selection\", \"prometheus_parameter_extraction\").</p> required <code>operation</code> <code>str</code> <p>Name of the operation being performed. Defaults to \"sequence_access\".</p> <code>'sequence_access'</code> <p>Returns:</p> Type Description <code>T</code> <p>The first element of the sequence.</p> <p>Raises:</p> Type Description <code>VectorSearchError</code> <p>When the sequence is empty, with RFC 9457 Problem Details payload.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; devices = [0, 1]\n&gt;&gt;&gt; device = first_or_error(devices, context=\"gpu_devices\")\n&gt;&gt;&gt; device\n0\n</code></pre> <pre><code>&gt;&gt;&gt; empty = []\n&gt;&gt;&gt; try:\n...     first_or_error(empty, context=\"gpu_devices\")\n... except Exception as e:\n...     assert \"empty\" in str(e).lower()\n</code></pre> Source code in <code>src/kgfoundry_common/sequence_guards.py</code> <pre><code>def first_or_error[T](\n    sequence: Sequence[T],\n    *,\n    context: str,\n    operation: str = \"sequence_access\",\n) -&gt; T:\n    \"\"\"Access first element of sequence or raise Problem Details error.\n\n    Validates that the sequence is non-empty before indexing, ensuring\n    observability instrumentation captures empty-input failures with\n    structured logs and metrics.\n\n    Parameters\n    ----------\n    sequence : Sequence[T]\n        The sequence from which to extract the first element.\n    context : str\n        Human-readable description of why the sequence was accessed\n        (e.g., \"gpu_device_selection\", \"prometheus_parameter_extraction\").\n    operation : str, optional\n        Name of the operation being performed. Defaults to \"sequence_access\".\n\n    Returns\n    -------\n    T\n        The first element of the sequence.\n\n    Raises\n    ------\n    VectorSearchError\n        When the sequence is empty, with RFC 9457 Problem Details payload.\n\n    Examples\n    --------\n    &gt;&gt;&gt; devices = [0, 1]\n    &gt;&gt;&gt; device = first_or_error(devices, context=\"gpu_devices\")\n    &gt;&gt;&gt; device\n    0\n\n    &gt;&gt;&gt; empty = []\n    &gt;&gt;&gt; try:\n    ...     first_or_error(empty, context=\"gpu_devices\")\n    ... except Exception as e:\n    ...     assert \"empty\" in str(e).lower()\n    \"\"\"\n    if len(sequence) == 0:\n        msg = f\"Cannot access {context}: sequence is empty\"\n        problem = build_problem_details(\n            problem_type=\"https://kgfoundry.dev/problems/sequence-empty\",\n            title=\"Sequence access failed\",\n            status=400,\n            detail=msg,\n            instance=f\"urn:operation:{operation}:{context}\",\n            extensions={\n                \"context\": context,\n                \"operation\": operation,\n                \"sequence_length\": 0,\n            },\n        )\n\n        # Log structured error with correlation ID\n        with with_fields(\n            logger,\n            operation=operation,\n            status=\"error\",\n            context=context,\n        ) as structured_logger:\n            structured_logger.error(\n                \"Sequence access guard triggered: %s\",\n                msg,\n                extra={\n                    \"problem_details\": render_problem(problem),\n                },\n            )\n\n        raise VectorSearchError(msg) from None\n\n    return sequence[0]\n</code></pre>"},{"location":"modules/kgfoundry_common.sequence_guards/#kgfoundry_commonsequence_guardsfirst_or_error_multi_device","title":"kgfoundry_common.sequence_guards.first_or_error_multi_device","text":""},{"location":"modules/kgfoundry_common.sequence_guards/#kgfoundry_common.sequence_guards.first_or_error_multi_device","title":"<code>kgfoundry_common.sequence_guards.first_or_error_multi_device(sequence, *, context='device_selection', operation='multi_device_access')</code>","text":"<p>Access first element for multi-device scenarios.</p> <p>Specialized variant for FAISS multi-device GPU cloning that provides domain-specific error messages and metrics.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>Sequence[T]</code> <p>The device list or equivalent sequence.</p> required <code>context</code> <code>str</code> <p>Context description. Defaults to \"device_selection\".</p> <code>'device_selection'</code> <code>operation</code> <code>str</code> <p>Operation name. Defaults to \"multi_device_access\".</p> <code>'multi_device_access'</code> <p>Returns:</p> Type Description <code>T</code> <p>The first element of the sequence.</p> <p>Raises:</p> Type Description <code>VectorSearchError</code> <p>When the sequence is empty, with Problem Details including device context.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gpu_indices = [&lt;FaissIndex&gt;]\n&gt;&gt;&gt; index = first_or_error_multi_device(gpu_indices, context=\"gpu_indices\")\n&gt;&gt;&gt; index\n&lt;FaissIndex object at ...&gt;\n</code></pre> Source code in <code>src/kgfoundry_common/sequence_guards.py</code> <pre><code>def first_or_error_multi_device[T](\n    sequence: Sequence[T],\n    *,\n    context: str = \"device_selection\",\n    operation: str = \"multi_device_access\",\n) -&gt; T:\n    \"\"\"Access first element for multi-device scenarios.\n\n    Specialized variant for FAISS multi-device GPU cloning that provides\n    domain-specific error messages and metrics.\n\n    Parameters\n    ----------\n    sequence : Sequence[T]\n        The device list or equivalent sequence.\n    context : str, optional\n        Context description. Defaults to \"device_selection\".\n    operation : str, optional\n        Operation name. Defaults to \"multi_device_access\".\n\n    Returns\n    -------\n    T\n        The first element of the sequence.\n\n    Raises\n    ------\n    VectorSearchError\n        When the sequence is empty, with Problem Details including device context.\n\n    Examples\n    --------\n    &gt;&gt;&gt; gpu_indices = [&lt;FaissIndex&gt;]  # doctest: +SKIP\n    &gt;&gt;&gt; index = first_or_error_multi_device(gpu_indices, context=\"gpu_indices\")  # doctest: +SKIP\n    &gt;&gt;&gt; index  # doctest: +SKIP\n    &lt;FaissIndex object at ...&gt;\n    \"\"\"\n    if len(sequence) == 0:\n        msg = f\"FAISS GPU cloning failed: {context} is empty (no devices available)\"\n        problem = build_problem_details(\n            problem_type=\"https://kgfoundry.dev/problems/faiss-multi-device-empty\",\n            title=\"Multi-device GPU cloning failed\",\n            status=503,\n            detail=msg,\n            instance=f\"urn:operation:{operation}:{context}\",\n            extensions={\n                \"context\": context,\n                \"operation\": operation,\n                \"device_count\": 0,\n                \"remediation\": \"Ensure GPU resources are available and FAISS is compiled with GPU support\",\n            },\n        )\n\n        # Log structured error\n        with with_fields(\n            logger,\n            operation=operation,\n            status=\"error\",\n            context=context,\n            device_count=0,\n        ) as structured_logger:\n            structured_logger.error(\n                \"Multi-device access guard triggered: %s\",\n                msg,\n                extra={\n                    \"problem_details\": render_problem(problem),\n                },\n            )\n\n        raise VectorSearchError(msg) from None\n\n    return sequence[0]\n</code></pre>"},{"location":"modules/kgfoundry_common.serialization/","title":"kgfoundry_common.serialization","text":""},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_commonserialization","title":"kgfoundry_common.serialization","text":"<p>Safe serialization helpers with schema validation and checksums.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.serialization/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.serialization__future__.annotationscollections.abc.Mappinghashlibjsonkgfoundry_common.errors.DeserializationErrorkgfoundry_common.errors.SchemaValidationErrorkgfoundry_common.errors.SerializationErrorkgfoundry_common.fs.atomic_writekgfoundry_common.fs.read_textkgfoundry_common.fs.write_textkgfoundry_common.jsonschema_utils.SchemaErrorkgfoundry_common.jsonschema_utils.ValidationErrorkgfoundry_common.jsonschema_utils.validatekgfoundry_common.logging.get_loggerkgfoundry_common.navmap_loader.load_nav_metadatapathlib.Pathtyping.castkgfoundry_common.serialization code <p>See the full diagram: kgfoundry_common.serialization</p>"},{"location":"modules/kgfoundry_common.serialization/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.serialization._load_data_file</li> <li>kgfoundry_common.serialization._load_schema_by_path_str_impl</li> <li>kgfoundry_common.serialization._load_schema_cached</li> </ul>"},{"location":"modules/kgfoundry_common.serialization/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Mapping</code>, <code>hashlib</code>, <code>json</code>, <code>kgfoundry_common.errors.DeserializationError</code>, <code>kgfoundry_common.errors.SchemaValidationError</code>, <code>kgfoundry_common.errors.SerializationError</code>, <code>kgfoundry_common.fs.atomic_write</code>, <code>kgfoundry_common.fs.read_text</code>, <code>kgfoundry_common.fs.write_text</code>, <code>kgfoundry_common.jsonschema_utils.SchemaError</code>, <code>kgfoundry_common.jsonschema_utils.ValidationError</code>, <code>kgfoundry_common.jsonschema_utils.validate</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>pathlib.Path</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.serialization/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_commonserialization_load_data_file","title":"kgfoundry_common.serialization._load_data_file","text":""},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_common.serialization._load_data_file","title":"<code>kgfoundry_common.serialization._load_data_file(data_path)</code>","text":"<p>Load data file as text.</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>Path</code> <p>Path to JSON file.</p> required <p>Returns:</p> Type Description <code>str</code> <p>File contents as text.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If data file does not exist.</p> Source code in <code>src/kgfoundry_common/serialization.py</code> <pre><code>def _load_data_file(data_path: Path) -&gt; str:\n    \"\"\"Load data file as text.\n\n    Parameters\n    ----------\n    data_path : Path\n        Path to JSON file.\n\n    Returns\n    -------\n    str\n        File contents as text.\n\n    Raises\n    ------\n    FileNotFoundError\n        If data file does not exist.\n    \"\"\"\n    if not data_path.exists():\n        msg = f\"Data file not found: {data_path}\"\n        raise FileNotFoundError(msg)\n    return read_text(data_path)\n</code></pre>"},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_commonserialization_load_schema_by_path_str_impl","title":"kgfoundry_common.serialization._load_schema_by_path_str_impl","text":""},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_common.serialization._load_schema_by_path_str_impl","title":"<code>kgfoundry_common.serialization._load_schema_by_path_str_impl(schema_path_str)</code>","text":"<p>Load and parse a JSON Schema file with caching by string path.</p> <p>This internal helper caches by string path to avoid lru_cache descriptor typing issues with Path objects. Public API converts Path to string.</p> <p>Parameters:</p> Name Type Description Default <code>schema_path_str</code> <code>str</code> <p>Path to JSON Schema 2020-12 file (as string).</p> required <p>Returns:</p> Type Description <code>dict[str, object]</code> <p>Parsed schema dictionary.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If schema file does not exist.</p> <code>SchemaValidationError</code> <p>If schema is invalid JSON or fails schema validation.</p> Source code in <code>src/kgfoundry_common/serialization.py</code> <pre><code>def _load_schema_by_path_str_impl(schema_path_str: str) -&gt; dict[str, object]:\n    \"\"\"Load and parse a JSON Schema file with caching by string path.\n\n    This internal helper caches by string path to avoid lru_cache descriptor\n    typing issues with Path objects. Public API converts Path to string.\n\n    Parameters\n    ----------\n    schema_path_str : str\n        Path to JSON Schema 2020-12 file (as string).\n\n    Returns\n    -------\n    dict[str, object]\n        Parsed schema dictionary.\n\n    Raises\n    ------\n    FileNotFoundError\n        If schema file does not exist.\n    SchemaValidationError\n        If schema is invalid JSON or fails schema validation.\n    \"\"\"\n    schema_path = Path(schema_path_str)\n    if not schema_path.exists():\n        msg = f\"Schema file not found: {schema_path}\"\n        raise FileNotFoundError(msg)\n    schema_text = read_text(schema_path)\n    try:\n        schema_raw: object = json.loads(schema_text)\n        if not isinstance(schema_raw, dict):\n            msg = f\"Schema must be a JSON object at root, got {type(schema_raw).__name__}\"\n            raise SchemaValidationError(msg)\n        schema_obj = cast(\"dict[str, object]\", schema_raw)\n    except json.JSONDecodeError as e:\n        msg = f\"Failed to load schema from {schema_path_str}: {e}\"\n        raise SchemaValidationError(msg) from e\n    else:\n        return schema_obj\n</code></pre>"},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_commonserialization_load_schema_cached","title":"kgfoundry_common.serialization._load_schema_cached","text":""},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_common.serialization._load_schema_cached","title":"<code>kgfoundry_common.serialization._load_schema_cached(schema_path)</code>","text":"<p>Load and parse a JSON Schema file with caching.</p> <p>Uses an in-memory cache keyed by resolved path to avoid repeated I/O for the same schema file. The cache persists for the lifetime of the module.</p> <p>Parameters:</p> Name Type Description Default <code>schema_path</code> <code>Path</code> <p>Path to JSON Schema 2020-12 file. Must exist and be readable.</p> required <p>Returns:</p> Type Description <code>dict[str, object]</code> <p>Parsed schema dictionary ready for validation.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If schema file does not exist.</p> <code>SchemaValidationError</code> <p>If schema is invalid JSON or fails schema validation.</p> Source code in <code>src/kgfoundry_common/serialization.py</code> <pre><code>def _load_schema_cached(schema_path: Path) -&gt; dict[str, object]:\n    \"\"\"Load and parse a JSON Schema file with caching.\n\n    Uses an in-memory cache keyed by resolved path to avoid repeated I/O\n    for the same schema file. The cache persists for the lifetime of the\n    module.\n\n    Parameters\n    ----------\n    schema_path : Path\n        Path to JSON Schema 2020-12 file. Must exist and be readable.\n\n    Returns\n    -------\n    dict[str, object]\n        Parsed schema dictionary ready for validation.\n\n    Raises\n    ------\n    FileNotFoundError\n        If schema file does not exist.\n    SchemaValidationError\n        If schema is invalid JSON or fails schema validation.\n    \"\"\"\n    if not schema_path.exists():\n        msg = f\"Schema file not found: {schema_path}\"\n        raise FileNotFoundError(msg)\n\n    schema_key = str(schema_path.resolve())\n    cached = _schema_cache.get(schema_key)\n    if cached is not None:\n        return cached\n\n    try:\n        schema_obj = _load_schema_by_path_str_impl(schema_key)\n    except SchemaValidationError as exc:\n        msg = f\"Failed to load schema {schema_path}: {exc}\"\n        raise SchemaValidationError(msg) from exc\n    _schema_cache[schema_key] = schema_obj\n    return schema_obj\n</code></pre>"},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_commonserialization_validate_json_against_schema","title":"kgfoundry_common.serialization._validate_json_against_schema","text":""},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_common.serialization._validate_json_against_schema","title":"<code>kgfoundry_common.serialization._validate_json_against_schema(obj, schema_path)</code>","text":"<p>Validate JSON object against schema.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>Parsed JSON object.</p> required <code>schema_path</code> <code>Path</code> <p>Path to JSON Schema 2020-12 file.</p> required <p>Raises:</p> Type Description <code>SchemaValidationError</code> <p>If validation fails.</p> <code>FileNotFoundError</code> <p>If schema file does not exist.</p> Source code in <code>src/kgfoundry_common/serialization.py</code> <pre><code>def _validate_json_against_schema(obj: object, schema_path: Path) -&gt; None:\n    \"\"\"Validate JSON object against schema.\n\n    Parameters\n    ----------\n    obj : object\n        Parsed JSON object.\n    schema_path : Path\n        Path to JSON Schema 2020-12 file.\n\n    Raises\n    ------\n    SchemaValidationError\n        If validation fails.\n    FileNotFoundError\n        If schema file does not exist.\n    \"\"\"\n    if not schema_path.exists():\n        msg = f\"Schema file not found: {schema_path}\"\n        raise FileNotFoundError(msg)\n\n    if isinstance(obj, Mapping):\n        validate_payload(obj, schema_path)\n        return\n\n    schema_obj = _load_schema_cached(schema_path)\n    try:\n        jsonschema_validate(instance=obj, schema=schema_obj)\n    except ValidationError as exc:\n        msg = f\"Schema validation failed: {exc}\"\n        raise SchemaValidationError(msg) from exc\n    except SchemaError as exc:\n        msg = f\"Invalid schema: {exc}\"\n        raise SchemaValidationError(msg) from exc\n</code></pre>"},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_commonserialization_verify_checksum_file","title":"kgfoundry_common.serialization._verify_checksum_file","text":""},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_common.serialization._verify_checksum_file","title":"<code>kgfoundry_common.serialization._verify_checksum_file(data_path)</code>","text":"<p>Verify data against checksum file if it exists.</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>Path</code> <p>Path to JSON file.</p> required <p>Raises:</p> Type Description <code>DeserializationError</code> <p>If checksum verification fails.</p> Source code in <code>src/kgfoundry_common/serialization.py</code> <pre><code>def _verify_checksum_file(data_path: Path) -&gt; None:\n    \"\"\"Verify data against checksum file if it exists.\n\n    Parameters\n    ----------\n    data_path : Path\n        Path to JSON file.\n\n    Raises\n    ------\n    DeserializationError\n        If checksum verification fails.\n    \"\"\"\n    checksum_path = data_path.with_suffix(data_path.suffix + \".sha256\")\n    if not checksum_path.exists():\n        logger.warning(\n            \"Checksum file not found, skipping verification\",\n            extra={\"data_path\": str(data_path), \"checksum_path\": str(checksum_path)},\n        )\n        return\n\n    expected_checksum = read_text(checksum_path).strip()\n    data_bytes = data_path.read_bytes()\n    try:\n        verify_checksum(data_bytes, expected_checksum)\n    except SerializationError as exc:\n        msg = f\"Checksum verification failed for {data_path}\"\n        raise DeserializationError(msg) from exc\n</code></pre>"},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_commonserializationcompute_checksum","title":"kgfoundry_common.serialization.compute_checksum","text":""},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_common.serialization.compute_checksum","title":"<code>kgfoundry_common.serialization.compute_checksum(data)</code>","text":"<p>Compute SHA256 checksum of binary data.</p> <p>Computes the SHA256 hash of the input bytes and returns it as a hexadecimal string. Used for data integrity verification.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>Binary data to checksum.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Hexadecimal SHA256 checksum (64 characters, lowercase).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; checksum = compute_checksum(b\"test data\")\n&gt;&gt;&gt; len(checksum) == 64\nTrue\n&gt;&gt;&gt; checksum.startswith(\"9\")\nTrue\n</code></pre> Source code in <code>src/kgfoundry_common/serialization.py</code> <pre><code>def compute_checksum(data: bytes) -&gt; str:\n    \"\"\"Compute SHA256 checksum of binary data.\n\n    Computes the SHA256 hash of the input bytes and returns it as a\n    hexadecimal string. Used for data integrity verification.\n\n    Parameters\n    ----------\n    data : bytes\n        Binary data to checksum.\n\n    Returns\n    -------\n    str\n        Hexadecimal SHA256 checksum (64 characters, lowercase).\n\n    Examples\n    --------\n    &gt;&gt;&gt; checksum = compute_checksum(b\"test data\")\n    &gt;&gt;&gt; len(checksum) == 64\n    True\n    &gt;&gt;&gt; checksum.startswith(\"9\")\n    True\n    \"\"\"\n    return hashlib.sha256(data).hexdigest()\n</code></pre>"},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_commonserializationdeserialize_json","title":"kgfoundry_common.serialization.deserialize_json","text":""},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_common.serialization.deserialize_json","title":"<code>kgfoundry_common.serialization.deserialize_json(data_path, schema_path, *, verify_checksum_file=True)</code>","text":"<p>Deserialize JSON with schema validation and checksum verification.</p> <p>Loads a JSON file, optionally verifies its SHA256 checksum against a <code>.sha256</code> file, validates the parsed object against the provided schema, and returns the deserialized Python object.</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>Path</code> <p>Path to JSON file to deserialize. Must exist and be readable.</p> required <code>schema_path</code> <code>Path</code> <p>Path to JSON Schema 2020-12 file for validation. Must exist.</p> required <code>verify_checksum_file</code> <code>bool</code> <p>If True, verify against <code>.sha256</code> checksum file (if present). If the checksum file is missing, logs a warning but continues. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>object</code> <p>Deserialized Python object (JSON-serializable types: dict, list, str, int, float, bool, None, or nested combinations).</p> <p>Raises:</p> Type Description <code>DeserializationError</code> <p>If JSON parsing fails, checksum verification fails, or file read fails.</p> <code>SchemaValidationError</code> <p>If the parsed object does not conform to the schema.</p> <code>FileNotFoundError</code> <p>If data or schema file does not exist.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     tmp = Path(tmpdir)\n...     schema = tmp / \"schema.json\"\n...     schema.write_text('{\"type\": \"object\", \"properties\": {\"k1\": {\"type\": \"number\"}}}')\n...     data_path = tmp / \"data.json\"\n...     data_path.write_text('{\"k1\": 0.9}')\n...     loaded = deserialize_json(data_path, schema)\n...     assert loaded == {\"k1\": 0.9}\n</code></pre> Source code in <code>src/kgfoundry_common/serialization.py</code> <pre><code>def deserialize_json(\n    data_path: Path,\n    schema_path: Path,\n    *,\n    verify_checksum_file: bool = True,\n) -&gt; object:  # JSON types: dict, list, str, int, float, bool, None\n    \"\"\"Deserialize JSON with schema validation and checksum verification.\n\n    Loads a JSON file, optionally verifies its SHA256 checksum against a\n    `.sha256` file, validates the parsed object against the provided schema,\n    and returns the deserialized Python object.\n\n    Parameters\n    ----------\n    data_path : Path\n        Path to JSON file to deserialize. Must exist and be readable.\n    schema_path : Path\n        Path to JSON Schema 2020-12 file for validation. Must exist.\n    verify_checksum_file : bool, optional\n        If True, verify against `.sha256` checksum file (if present).\n        If the checksum file is missing, logs a warning but continues.\n        Defaults to True.\n\n    Returns\n    -------\n    object\n        Deserialized Python object (JSON-serializable types: dict, list, str,\n        int, float, bool, None, or nested combinations).\n\n    Raises\n    ------\n    DeserializationError\n        If JSON parsing fails, checksum verification fails, or file read fails.\n    SchemaValidationError\n        If the parsed object does not conform to the schema.\n    FileNotFoundError\n        If data or schema file does not exist.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; import tempfile\n    &gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n    ...     tmp = Path(tmpdir)\n    ...     schema = tmp / \"schema.json\"\n    ...     schema.write_text('{\"type\": \"object\", \"properties\": {\"k1\": {\"type\": \"number\"}}}')\n    ...     data_path = tmp / \"data.json\"\n    ...     data_path.write_text('{\"k1\": 0.9}')\n    ...     loaded = deserialize_json(data_path, schema)\n    ...     assert loaded == {\"k1\": 0.9}\n    \"\"\"\n    if not data_path.exists():\n        msg = f\"Data file not found: {data_path}\"\n        raise FileNotFoundError(msg)\n    if not schema_path.exists():\n        msg = f\"Schema file not found: {schema_path}\"\n        raise FileNotFoundError(msg)\n\n    if verify_checksum_file:\n        _verify_checksum_file(data_path)\n\n    json_text = _load_data_file(data_path)\n    try:\n        obj: object = json.loads(json_text)\n    except json.JSONDecodeError as exc:\n        msg = f\"Invalid JSON in {data_path}: {exc}\"\n        raise DeserializationError(msg) from exc\n\n    try:\n        _validate_json_against_schema(obj, schema_path)\n    except SchemaValidationError as exc:\n        msg = f\"Schema validation failed for {data_path} against {schema_path}: {exc}\"\n        raise SchemaValidationError(msg) from exc\n\n    logger.debug(\n        \"Deserialized JSON\",\n        extra={\n            \"data_path\": str(data_path),\n            \"schema_path\": str(schema_path),\n        },\n    )\n\n    return obj\n</code></pre>"},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_commonserializationserialize_json","title":"kgfoundry_common.serialization.serialize_json","text":""},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_common.serialization.serialize_json","title":"<code>kgfoundry_common.serialization.serialize_json(obj, schema_path, output_path, *, include_checksum=True, indent=2)</code>","text":"<p>Serialize object to JSON with schema validation and optional checksum.</p> <p>Serializes a Python object to JSON format, validates it against the provided JSON Schema 2020-12, and optionally writes a SHA256 checksum file alongside the JSON output. Uses atomic writes to prevent corruption.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>Python object to serialize. Must be JSON-serializable (dict, list, str, int, float, bool, None, or nested combinations).</p> required <code>schema_path</code> <code>Path</code> <p>Path to JSON Schema 2020-12 file for validation. Must exist.</p> required <code>output_path</code> <code>Path</code> <p>Output file path for JSON data. Parent directory must exist or be creatable.</p> required <code>include_checksum</code> <code>bool</code> <p>If True, write a <code>.sha256</code> checksum file alongside the JSON file. Defaults to True.</p> <code>True</code> <code>indent</code> <code>int | None</code> <p>JSON indentation level. Use None for compact (minified) output. Defaults to 2.</p> <code>2</code> <p>Returns:</p> Type Description <code>str</code> <p>SHA256 checksum of the serialized JSON (hexadecimal, 64 characters). Returns the checksum even if include_checksum=False.</p> <p>Raises:</p> Type Description <code>SerializationError</code> <p>If JSON serialization fails or file write fails.</p> <code>SchemaValidationError</code> <p>If the object does not conform to the schema.</p> <code>FileNotFoundError</code> <p>If schema file does not exist.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     tmp = Path(tmpdir)\n...     schema = tmp / \"schema.json\"\n...     schema.write_text('{\"type\": \"object\", \"properties\": {\"k1\": {\"type\": \"number\"}}}')\n...     data = {\"k1\": 0.9}\n...     output = tmp / \"data.json\"\n...     checksum = serialize_json(data, schema, output)\n...     assert len(checksum) == 64\n...     assert output.exists()\n</code></pre> Source code in <code>src/kgfoundry_common/serialization.py</code> <pre><code>def serialize_json(\n    obj: object,  # JSON-serializable: dict, list, str, int, float, bool, None\n    schema_path: Path,\n    output_path: Path,\n    *,\n    include_checksum: bool = True,\n    indent: int | None = 2,\n) -&gt; str:\n    \"\"\"Serialize object to JSON with schema validation and optional checksum.\n\n    Serializes a Python object to JSON format, validates it against the\n    provided JSON Schema 2020-12, and optionally writes a SHA256 checksum\n    file alongside the JSON output. Uses atomic writes to prevent corruption.\n\n    Parameters\n    ----------\n    obj : object\n        Python object to serialize. Must be JSON-serializable (dict, list,\n        str, int, float, bool, None, or nested combinations).\n    schema_path : Path\n        Path to JSON Schema 2020-12 file for validation. Must exist.\n    output_path : Path\n        Output file path for JSON data. Parent directory must exist or be\n        creatable.\n    include_checksum : bool, optional\n        If True, write a `.sha256` checksum file alongside the JSON file.\n        Defaults to True.\n    indent : int | None, optional\n        JSON indentation level. Use None for compact (minified) output.\n        Defaults to 2.\n\n    Returns\n    -------\n    str\n        SHA256 checksum of the serialized JSON (hexadecimal, 64 characters).\n        Returns the checksum even if include_checksum=False.\n\n    Raises\n    ------\n    SerializationError\n        If JSON serialization fails or file write fails.\n    SchemaValidationError\n        If the object does not conform to the schema.\n    FileNotFoundError\n        If schema file does not exist.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; import tempfile\n    &gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n    ...     tmp = Path(tmpdir)\n    ...     schema = tmp / \"schema.json\"\n    ...     schema.write_text('{\"type\": \"object\", \"properties\": {\"k1\": {\"type\": \"number\"}}}')\n    ...     data = {\"k1\": 0.9}\n    ...     output = tmp / \"data.json\"\n    ...     checksum = serialize_json(data, schema, output)\n    ...     assert len(checksum) == 64\n    ...     assert output.exists()\n    \"\"\"\n    if not schema_path.exists():\n        msg = f\"Schema file not found: {schema_path}\"\n        raise FileNotFoundError(msg)\n\n    try:\n        if isinstance(obj, Mapping):\n            validate_payload(obj, schema_path)\n        else:\n            schema_obj = _load_schema_cached(schema_path)\n            try:\n                jsonschema_validate(instance=obj, schema=schema_obj)\n            except ValidationError as exc:\n                msg = f\"Schema validation failed: {exc}\"\n                raise SchemaValidationError(msg) from exc\n    except SchemaValidationError as exc:\n        msg = f\"Schema validation failed for payload written to {output_path}: {exc}\"\n        raise SchemaValidationError(msg) from exc\n\n    try:\n        json_text: str = json.dumps(obj, indent=indent, ensure_ascii=False)\n    except (TypeError, ValueError) as exc:\n        msg = f\"Failed to serialize object to JSON: {exc}\"\n        raise SerializationError(msg) from exc\n\n    json_bytes = json_text.encode(\"utf-8\")\n    checksum = compute_checksum(json_bytes)\n\n    try:\n        atomic_write(output_path, json_text, mode=\"text\")\n    except OSError as exc:\n        msg = f\"Failed to write JSON output to {output_path}: {exc}\"\n        raise SerializationError(msg) from exc\n\n    if include_checksum:\n        checksum_path = output_path.with_suffix(output_path.suffix + \".sha256\")\n        try:\n            write_text(checksum_path, checksum)\n        except OSError as exc:\n            msg = f\"Failed to write checksum file {checksum_path}: {exc}\"\n            raise SerializationError(msg) from exc\n\n    logger.debug(\n        \"Serialized JSON\",\n        extra={\n            \"output_path\": str(output_path),\n            \"schema_path\": str(schema_path),\n            \"checksum\": checksum,\n        },\n    )\n\n    return checksum\n</code></pre>"},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_commonserializationvalidate_payload","title":"kgfoundry_common.serialization.validate_payload","text":""},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_common.serialization.validate_payload","title":"<code>kgfoundry_common.serialization.validate_payload(payload, schema_path)</code>","text":"<p>Validate a payload against a JSON Schema 2020-12.</p> <p>Loads the schema (with caching), validates the payload against it, and raises SchemaValidationError if validation fails. Used for validating JSON-serializable data structures before persistence.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>Mapping[str, object]</code> <p>Payload to validate. Must be JSON-serializable and conform to the schema structure (dict, list, or primitive types).</p> required <code>schema_path</code> <code>Path</code> <p>Path to JSON Schema 2020-12 file. Must exist and be readable.</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If schema file does not exist.</p> <code>SchemaValidationError</code> <p>If payload does not match schema constraints or if the schema itself is invalid.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     tmp = Path(tmpdir)\n...     schema = tmp / \"schema.json\"\n...     schema.write_text('{\"type\": \"object\", \"properties\": {\"k1\": {\"type\": \"number\"}}}')\n...     validate_payload({\"k1\": 0.9}, schema)\n...     validate_payload({\"k1\": \"invalid\"}, schema)\nSchemaValidationError: Schema validation failed\n</code></pre> Source code in <code>src/kgfoundry_common/serialization.py</code> <pre><code>def validate_payload(payload: Mapping[str, object], schema_path: Path) -&gt; None:\n    \"\"\"Validate a payload against a JSON Schema 2020-12.\n\n    Loads the schema (with caching), validates the payload against it, and\n    raises SchemaValidationError if validation fails. Used for validating\n    JSON-serializable data structures before persistence.\n\n    Parameters\n    ----------\n    payload : Mapping[str, object]\n        Payload to validate. Must be JSON-serializable and conform to the\n        schema structure (dict, list, or primitive types).\n    schema_path : Path\n        Path to JSON Schema 2020-12 file. Must exist and be readable.\n\n    Raises\n    ------\n    FileNotFoundError\n        If schema file does not exist.\n    SchemaValidationError\n        If payload does not match schema constraints or if the schema\n        itself is invalid.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; import tempfile\n    &gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n    ...     tmp = Path(tmpdir)\n    ...     schema = tmp / \"schema.json\"\n    ...     schema.write_text('{\"type\": \"object\", \"properties\": {\"k1\": {\"type\": \"number\"}}}')\n    ...     validate_payload({\"k1\": 0.9}, schema)\n    ...     validate_payload({\"k1\": \"invalid\"}, schema)  # doctest: +SKIP\n    SchemaValidationError: Schema validation failed\n    \"\"\"\n    if not schema_path.exists():\n        msg = f\"Schema file not found: {schema_path}\"\n        raise FileNotFoundError(msg)\n\n    schema_obj = _load_schema_cached(schema_path)\n    try:\n        jsonschema_validate(instance=payload, schema=schema_obj)\n    except ValidationError as exc:\n        msg = f\"Schema validation failed: {exc}\"\n        raise SchemaValidationError(msg) from exc\n    except SchemaError as exc:\n        msg = f\"Invalid schema: {exc}\"\n        raise SchemaValidationError(msg) from exc\n</code></pre>"},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_commonserializationverify_checksum","title":"kgfoundry_common.serialization.verify_checksum","text":""},{"location":"modules/kgfoundry_common.serialization/#kgfoundry_common.serialization.verify_checksum","title":"<code>kgfoundry_common.serialization.verify_checksum(data, expected)</code>","text":"<p>Verify SHA256 checksum matches expected value.</p> <p>Computes the SHA256 checksum of the data and compares it to the expected value. Raises an exception if they do not match.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>Binary data to verify.</p> required <code>expected</code> <code>str</code> <p>Expected hexadecimal SHA256 checksum (64 characters).</p> required <p>Raises:</p> Type Description <code>SerializationError</code> <p>If computed checksum does not match expected value. The error message includes truncated checksums for debugging.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; verify_checksum(b\"test\", compute_checksum(b\"test\"))\n&gt;&gt;&gt; verify_checksum(b\"wrong\", compute_checksum(b\"test\"))\nSerializationError: Checksum mismatch\n</code></pre> Source code in <code>src/kgfoundry_common/serialization.py</code> <pre><code>def verify_checksum(data: bytes, expected: str) -&gt; None:\n    \"\"\"Verify SHA256 checksum matches expected value.\n\n    Computes the SHA256 checksum of the data and compares it to the expected\n    value. Raises an exception if they do not match.\n\n    Parameters\n    ----------\n    data : bytes\n        Binary data to verify.\n    expected : str\n        Expected hexadecimal SHA256 checksum (64 characters).\n\n    Raises\n    ------\n    SerializationError\n        If computed checksum does not match expected value. The error message\n        includes truncated checksums for debugging.\n\n    Examples\n    --------\n    &gt;&gt;&gt; verify_checksum(b\"test\", compute_checksum(b\"test\"))\n    &gt;&gt;&gt; verify_checksum(b\"wrong\", compute_checksum(b\"test\"))  # doctest: +SKIP\n    SerializationError: Checksum mismatch\n    \"\"\"\n    actual = compute_checksum(data)\n    if actual != expected:\n        msg = f\"Checksum mismatch: expected {expected[:16]}..., got {actual[:16]}...\"\n        raise SerializationError(msg)\n</code></pre>"},{"location":"modules/kgfoundry_common.settings/","title":"kgfoundry_common.settings","text":""},{"location":"modules/kgfoundry_common.settings/#kgfoundry_commonsettings","title":"kgfoundry_common.settings","text":"<p>Typed runtime configuration with fail-fast validation</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.settings/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class FaissConfig\n    class BaseSettings\n    BaseSettings &lt;|-- FaissConfig\n    class ObservabilityConfig\n    BaseSettings &lt;|-- ObservabilityConfig\n    class RuntimeSettings\n    BaseSettings &lt;|-- RuntimeSettings\n    class SearchConfig\n    BaseSettings &lt;|-- SearchConfig\n    class SparseEmbeddingConfig\n    BaseSettings &lt;|-- SparseEmbeddingConfig\n</code></pre>"},{"location":"modules/kgfoundry_common.settings/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.settings__future__.annotationskgfoundry_common.errors.SettingsErrorkgfoundry_common.logging.get_loggerkgfoundry_common.navmap_loader.load_nav_metadatapydantic.Fieldpydantic_settings.BaseSettingspydantic_settings.SettingsConfigDicttyping.Anytyping.castkgfoundry_common.settings code <p>See the full diagram: kgfoundry_common.settings</p>"},{"location":"modules/kgfoundry_common.settings/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.settings.FaissConfig</li> <li>kgfoundry_common.settings.ObservabilityConfig</li> <li>kgfoundry_common.settings.RuntimeSettings</li> <li>kgfoundry_common.settings.load_settings</li> </ul>"},{"location":"modules/kgfoundry_common.settings/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.errors.SettingsError</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>pydantic.Field</code>, <code>pydantic_settings.BaseSettings</code>, <code>pydantic_settings.SettingsConfigDict</code>, <code>typing.Any</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.settings/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.settings/#kgfoundry_commonsettingsfaissconfig","title":"kgfoundry_common.settings.FaissConfig","text":"<p>Bases: BaseSettings</p>"},{"location":"modules/kgfoundry_common.settings/#kgfoundry_common.settings.FaissConfig","title":"<code>kgfoundry_common.settings.FaissConfig</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>FAISS index configuration (<code>KGFOUNDRY_FAISS_*</code> namespace).</p> Source code in <code>src/kgfoundry_common/settings.py</code> <pre><code>class FaissConfig(BaseSettings):\n    \"\"\"FAISS index configuration (``KGFOUNDRY_FAISS_*`` namespace).\"\"\"\n\n    model_config = SettingsConfigDict(env_prefix=\"KGFOUNDRY_FAISS_\", extra=\"forbid\")\n\n    gpu: bool = Field(default=True, description=\"Enable GPU acceleration\")\n    cuvs: bool = Field(default=True, description=\"Enable cuVS support\")\n    index_factory: str = Field(\n        default=\"OPQ64,IVF8192,PQ64\", description=\"FAISS index factory string\"\n    )\n    nprobe: int = Field(default=64, description=\"Number of probes for IVF indexes\")\n    index_path: str = Field(\n        default=\"./_indices/faiss/shard_000.idx\", description=\"FAISS index file path\"\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.settings/#kgfoundry_commonsettingsobservabilityconfig","title":"kgfoundry_common.settings.ObservabilityConfig","text":"<p>Bases: BaseSettings</p>"},{"location":"modules/kgfoundry_common.settings/#kgfoundry_common.settings.ObservabilityConfig","title":"<code>kgfoundry_common.settings.ObservabilityConfig</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Logging and telemetry toggles (<code>KGFOUNDRY_*</code> namespace).</p> Source code in <code>src/kgfoundry_common/settings.py</code> <pre><code>class ObservabilityConfig(BaseSettings):\n    \"\"\"Logging and telemetry toggles (``KGFOUNDRY_*`` namespace).\"\"\"\n\n    model_config = SettingsConfigDict(env_prefix=\"KGFOUNDRY_\", extra=\"forbid\")\n\n    log_level: str = Field(\n        default=\"INFO\", description=\"Logging level (DEBUG, INFO, WARNING, ERROR)\"\n    )\n    metrics_enabled: bool = Field(default=True, description=\"Enable Prometheus metrics export\")\n    traces_enabled: bool = Field(default=False, description=\"Enable OpenTelemetry tracing\")\n    metrics_port: int = Field(default=9090, description=\"Port for Prometheus metrics endpoint\")\n</code></pre>"},{"location":"modules/kgfoundry_common.settings/#kgfoundry_commonsettingsruntimesettings","title":"kgfoundry_common.settings.RuntimeSettings","text":"<p>Bases: BaseSettings</p>"},{"location":"modules/kgfoundry_common.settings/#kgfoundry_common.settings.RuntimeSettings","title":"<code>kgfoundry_common.settings.RuntimeSettings</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Aggregate runtime configuration loaded from environment variables.</p> Source code in <code>src/kgfoundry_common/settings.py</code> <pre><code>class RuntimeSettings(BaseSettings):\n    \"\"\"Aggregate runtime configuration loaded from environment variables.\"\"\"\n\n    model_config = SettingsConfigDict(\n        env_prefix=\"KGFOUNDRY_\",\n        env_nested_delimiter=\"__\",\n        extra=\"forbid\",\n        case_sensitive=False,\n    )\n\n    search: SearchConfig = Field(\n        default_factory=SearchConfig, description=\"Search service configuration\"\n    )\n    observability: ObservabilityConfig = Field(\n        default_factory=ObservabilityConfig, description=\"Observability configuration\"\n    )\n    sparse_embedding: SparseEmbeddingConfig = Field(\n        default_factory=SparseEmbeddingConfig,\n        description=\"Sparse embedding configuration\",\n    )\n    faiss: FaissConfig = Field(default_factory=FaissConfig, description=\"FAISS index configuration\")\n\n    def __init__(self, **overrides: object) -&gt; None:\n        \"\"\"Initialise settings with fail-fast validation.\n\n        Parameters\n        ----------\n        **overrides : object\n            Settings overrides to apply.\n\n        Raises\n        ------\n        SettingsError\n            If settings validation fails.\n        \"\"\"\n        try:\n            cast_overrides: dict[str, Any] = {\n                key: cast(\"Any\", value) for key, value in overrides.items()\n            }\n            super().__init__(**cast_overrides)\n        except Exception as exc:\n            # Convert Pydantic validation errors to SettingsError with Problem Details\n            msg = f\"Configuration validation failed: {exc}\"\n            logger.exception(\n                \"Settings validation failed\",\n                extra={\"error\": str(exc), \"error_type\": type(exc).__name__},\n            )\n            raise SettingsError(\n                msg,\n                cause=exc,\n                context={\"validation_error\": str(exc)},\n            ) from exc\n</code></pre>"},{"location":"modules/kgfoundry_common.settings/#kgfoundry_common.settings.RuntimeSettings.__init__","title":"<code>__init__(**overrides)</code>","text":"<p>Initialise settings with fail-fast validation.</p> <p>Parameters:</p> Name Type Description Default <code>**overrides</code> <code>object</code> <p>Settings overrides to apply.</p> <code>{}</code> <p>Raises:</p> Type Description <code>SettingsError</code> <p>If settings validation fails.</p> Source code in <code>src/kgfoundry_common/settings.py</code> <pre><code>def __init__(self, **overrides: object) -&gt; None:\n    \"\"\"Initialise settings with fail-fast validation.\n\n    Parameters\n    ----------\n    **overrides : object\n        Settings overrides to apply.\n\n    Raises\n    ------\n    SettingsError\n        If settings validation fails.\n    \"\"\"\n    try:\n        cast_overrides: dict[str, Any] = {\n            key: cast(\"Any\", value) for key, value in overrides.items()\n        }\n        super().__init__(**cast_overrides)\n    except Exception as exc:\n        # Convert Pydantic validation errors to SettingsError with Problem Details\n        msg = f\"Configuration validation failed: {exc}\"\n        logger.exception(\n            \"Settings validation failed\",\n            extra={\"error\": str(exc), \"error_type\": type(exc).__name__},\n        )\n        raise SettingsError(\n            msg,\n            cause=exc,\n            context={\"validation_error\": str(exc)},\n        ) from exc\n</code></pre>"},{"location":"modules/kgfoundry_common.settings/#kgfoundry_commonsettingssearchconfig","title":"kgfoundry_common.settings.SearchConfig","text":"<p>Bases: BaseSettings</p>"},{"location":"modules/kgfoundry_common.settings/#kgfoundry_common.settings.SearchConfig","title":"<code>kgfoundry_common.settings.SearchConfig</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Configuration for the hybrid search service (<code>KGFOUNDRY_SEARCH_*</code>).</p> Source code in <code>src/kgfoundry_common/settings.py</code> <pre><code>class SearchConfig(BaseSettings):\n    \"\"\"Configuration for the hybrid search service (``KGFOUNDRY_SEARCH_*``).\"\"\"\n\n    model_config = SettingsConfigDict(env_prefix=\"KGFOUNDRY_SEARCH_\", extra=\"forbid\")\n\n    api_url: str | None = Field(\n        default=None,\n        description=\"Search API base URL (required if search features are used)\",\n    )\n    k: int = Field(default=10, description=\"Default number of results to return\")\n    dense_candidates: int = Field(\n        default=200, description=\"Number of dense candidates for hybrid search\"\n    )\n    sparse_candidates: int = Field(\n        default=200, description=\"Number of sparse candidates for hybrid search\"\n    )\n    rrf_k: int = Field(default=60, description=\"Reciprocal Rank Fusion parameter\")\n    sparse_backend: str = Field(\n        default=\"lucene\", description=\"Sparse backend type ('lucene' or 'pure')\"\n    )\n    kg_boosts_direct: float = Field(default=0.08, description=\"Direct KG boost weight\")\n    kg_boosts_one_hop: float = Field(default=0.04, description=\"One-hop KG boost weight\")\n    validate_responses: bool = Field(\n        default=False, description=\"Enable response schema validation (dev/staging only)\"\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.settings/#kgfoundry_commonsettingssparseembeddingconfig","title":"kgfoundry_common.settings.SparseEmbeddingConfig","text":"<p>Bases: BaseSettings</p>"},{"location":"modules/kgfoundry_common.settings/#kgfoundry_common.settings.SparseEmbeddingConfig","title":"<code>kgfoundry_common.settings.SparseEmbeddingConfig</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Sparse embedding configuration (<code>KGFOUNDRY_SPARSE_EMBEDDING_*</code>).</p> Source code in <code>src/kgfoundry_common/settings.py</code> <pre><code>class SparseEmbeddingConfig(BaseSettings):\n    \"\"\"Sparse embedding configuration (``KGFOUNDRY_SPARSE_EMBEDDING_*``).\"\"\"\n\n    model_config = SettingsConfigDict(env_prefix=\"KGFOUNDRY_SPARSE_EMBEDDING_\", extra=\"forbid\")\n\n    bm25_index_dir: str = Field(default=\"./_indices/bm25\", description=\"BM25 index directory path\")\n    bm25_k1: float = Field(default=0.9, description=\"BM25 k1 parameter\")\n    bm25_b: float = Field(default=0.4, description=\"BM25 b parameter\")\n    splade_index_dir: str = Field(\n        default=\"./_indices/splade_impact\", description=\"SPLADE index directory path\"\n    )\n    splade_query_encoder: str = Field(\n        default=\"naver/splade-v3-distilbert\",\n        description=\"SPLADE query encoder model name\",\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.settings/#kgfoundry_commonsettingsload_settings","title":"kgfoundry_common.settings.load_settings","text":""},{"location":"modules/kgfoundry_common.settings/#kgfoundry_common.settings.load_settings","title":"<code>kgfoundry_common.settings.load_settings(**overrides)</code>","text":"<p>Load :class:<code>RuntimeSettings</code> with optional overrides.</p> <p>Parameters:</p> Name Type Description Default <code>**overrides</code> <code>object</code> <p>Settings overrides to apply.</p> <code>{}</code> <p>Returns:</p> Type Description <code>KgFoundrySettings</code> <p>Loaded settings instance.</p> <p>Raises:</p> Type Description <code>SettingsError</code> <p>If settings validation fails.</p> Source code in <code>src/kgfoundry_common/settings.py</code> <pre><code>def load_settings(**overrides: object) -&gt; KgFoundrySettings:\n    \"\"\"Load :class:`RuntimeSettings` with optional overrides.\n\n    Parameters\n    ----------\n    **overrides : object\n        Settings overrides to apply.\n\n    Returns\n    -------\n    KgFoundrySettings\n        Loaded settings instance.\n\n    Raises\n    ------\n    SettingsError\n        If settings validation fails.\n    \"\"\"\n    try:\n        return RuntimeSettings(**overrides)\n    except SettingsError:\n        # Re-raise SettingsError as-is\n        raise\n    except Exception as exc:\n        # Convert any other validation errors to SettingsError\n        msg = f\"Failed to load settings: {exc}\"\n        logger.exception(\n            \"Settings loading failed\",\n            extra={\"error\": str(exc), \"error_type\": type(exc).__name__},\n        )\n        raise SettingsError(\n            msg,\n            cause=exc,\n            context={\"validation_error\": str(exc)},\n        ) from exc\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/","title":"kgfoundry_common.subprocess_utils","text":""},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utils","title":"kgfoundry_common.subprocess_utils","text":"<p>Subprocess execution with timeouts, path sanitization, and error handling.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class SubprocessError\n    class RuntimeError\n    RuntimeError &lt;|-- SubprocessError\n    class SubprocessTimeoutError\n    class TimeoutError\n    TimeoutError &lt;|-- SubprocessTimeoutError\n    class _AllowListPolicyProtocol\n    class Protocol\n    Protocol &lt;|-- _AllowListPolicyProtocol\n    class _EnvironmentPolicyProtocol\n    Protocol &lt;|-- _EnvironmentPolicyProtocol\n    class _GetProcessRunnerCallable\n    Protocol &lt;|-- _GetProcessRunnerCallable\n    class _PopenFactory\n    Protocol &lt;|-- _PopenFactory\n    class _ProcessRunnerProtocol\n    Protocol &lt;|-- _ProcessRunnerProtocol\n    class _RunToolCallable\n    Protocol &lt;|-- _RunToolCallable\n    class _TextProcess\n    Protocol &lt;|-- _TextProcess\n    class _ToolExecutionErrorConstructor\n    Protocol &lt;|-- _ToolExecutionErrorConstructor\n    class _ToolExecutionErrorSurface\n    Protocol &lt;|-- _ToolExecutionErrorSurface\n    class _ToolRunResultProtocol\n    Protocol &lt;|-- _ToolRunResultProtocol\n    class _ToolsSurface\n    Protocol &lt;|-- _ToolsSurface\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.subprocess_utils__future__.annotationscollections.abc.Mappingcollections.abc.Sequenceimportlib.import_moduleiokgfoundry_common.navmap_loader.load_nav_metadataloggingpathlib.Pathtyping.Finaltyping.Protocoltyping.TYPE_CHECKINGtyping.castkgfoundry_common.subprocess_utils code <p>See the full diagram: kgfoundry_common.subprocess_utils</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.subprocess_utils.SubprocessError</li> <li>kgfoundry_common.subprocess_utils.SubprocessTimeoutError</li> <li>kgfoundry_common.subprocess_utils._AllowListPolicyProtocol</li> <li>kgfoundry_common.subprocess_utils._is_timeout_error</li> <li>kgfoundry_common.subprocess_utils._load_tools_surface</li> <li>kgfoundry_common.subprocess_utils.run_subprocess</li> </ul>"},{"location":"modules/kgfoundry_common.subprocess_utils/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Mapping</code>, <code>collections.abc.Sequence</code>, <code>importlib.import_module</code>, <code>io</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>logging</code>, <code>pathlib.Path</code>, <code>typing.Final</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utilssubprocesserror","title":"kgfoundry_common.subprocess_utils.SubprocessError","text":"<p>Bases: RuntimeError</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils.SubprocessError","title":"<code>kgfoundry_common.subprocess_utils.SubprocessError</code>","text":"<p>               Bases: <code>RuntimeError</code></p> <p>Raised when subprocess execution fails.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error description.</p> required <code>returncode</code> <code>int</code> <p>Exit code from subprocess.</p> <code>None</code> <code>stderr</code> <code>str</code> <p>Captured stderr output.</p> <code>None</code> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>class SubprocessError(RuntimeError):\n    \"\"\"Raised when subprocess execution fails.\n\n    Parameters\n    ----------\n    message : str\n        Error description.\n    returncode : int, optional\n        Exit code from subprocess.\n    stderr : str, optional\n        Captured stderr output.\n    \"\"\"\n\n    def __init__(\n        self, message: str, returncode: int | None = None, stderr: str | None = None\n    ) -&gt; None:\n        super().__init__(message)\n        self.returncode = returncode\n        self.stderr = stderr\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utilssubprocesstimeouterror","title":"kgfoundry_common.subprocess_utils.SubprocessTimeoutError","text":"<p>Bases: TimeoutError</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils.SubprocessTimeoutError","title":"<code>kgfoundry_common.subprocess_utils.SubprocessTimeoutError</code>","text":"<p>               Bases: <code>TimeoutError</code></p> <p>Raised when subprocess exceeds configured timeout.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error description.</p> required <code>command</code> <code>list[str] | None</code> <p>The command that timed out.</p> <code>None</code> <code>timeout_seconds</code> <code>int | None</code> <p>The timeout that was configured.</p> <code>None</code> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>class SubprocessTimeoutError(TimeoutError):\n    \"\"\"Raised when subprocess exceeds configured timeout.\n\n    Parameters\n    ----------\n    message : str\n        Error description.\n    command : list[str] | None, optional\n        The command that timed out.\n    timeout_seconds : int | None, optional\n        The timeout that was configured.\n    \"\"\"\n\n    def __init__(\n        self, message: str, command: list[str] | None = None, timeout_seconds: int | None = None\n    ) -&gt; None:\n        super().__init__(message)\n        self.command = command\n        self.timeout_seconds = timeout_seconds\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utils_allowlistpolicyprotocol","title":"kgfoundry_common.subprocess_utils._AllowListPolicyProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._AllowListPolicyProtocol","title":"<code>kgfoundry_common.subprocess_utils._AllowListPolicyProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>class _AllowListPolicyProtocol(Protocol):\n    def resolve(self, executable: str, command: Sequence[str]) -&gt; Path:\n        \"\"\"Resolve executable path using allow-list policy.\n\n        Parameters\n        ----------\n        executable : str\n            Executable name or path.\n        command : Sequence[str]\n            Full command sequence.\n\n        Returns\n        -------\n        Path\n            Resolved executable path.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._AllowListPolicyProtocol.resolve","title":"<code>resolve(executable, command)</code>","text":"<p>Resolve executable path using allow-list policy.</p> <p>Parameters:</p> Name Type Description Default <code>executable</code> <code>str</code> <p>Executable name or path.</p> required <code>command</code> <code>Sequence[str]</code> <p>Full command sequence.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Resolved executable path.</p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>def resolve(self, executable: str, command: Sequence[str]) -&gt; Path:\n    \"\"\"Resolve executable path using allow-list policy.\n\n    Parameters\n    ----------\n    executable : str\n        Executable name or path.\n    command : Sequence[str]\n        Full command sequence.\n\n    Returns\n    -------\n    Path\n        Resolved executable path.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utils_environmentpolicyprotocol","title":"kgfoundry_common.subprocess_utils._EnvironmentPolicyProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._EnvironmentPolicyProtocol","title":"<code>kgfoundry_common.subprocess_utils._EnvironmentPolicyProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>class _EnvironmentPolicyProtocol(Protocol):\n    def build(self, overrides: Mapping[str, str] | None) -&gt; Mapping[str, str]:\n        \"\"\"Build environment mapping with overrides.\n\n        Parameters\n        ----------\n        overrides : Mapping[str, str] | None, optional\n            Environment variable overrides.\n\n        Returns\n        -------\n        Mapping[str, str]\n            Environment variable mapping.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._EnvironmentPolicyProtocol.build","title":"<code>build(overrides)</code>","text":"<p>Build environment mapping with overrides.</p> <p>Parameters:</p> Name Type Description Default <code>overrides</code> <code>Mapping[str, str] | None</code> <p>Environment variable overrides.</p> required <p>Returns:</p> Type Description <code>Mapping[str, str]</code> <p>Environment variable mapping.</p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>def build(self, overrides: Mapping[str, str] | None) -&gt; Mapping[str, str]:\n    \"\"\"Build environment mapping with overrides.\n\n    Parameters\n    ----------\n    overrides : Mapping[str, str] | None, optional\n        Environment variable overrides.\n\n    Returns\n    -------\n    Mapping[str, str]\n        Environment variable mapping.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utils_getprocessrunnercallable","title":"kgfoundry_common.subprocess_utils._GetProcessRunnerCallable","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._GetProcessRunnerCallable","title":"<code>kgfoundry_common.subprocess_utils._GetProcessRunnerCallable</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>class _GetProcessRunnerCallable(Protocol):\n    def __call__(self) -&gt; _ProcessRunnerProtocol:\n        \"\"\"Get process runner instance.\n\n        Returns\n        -------\n        _ProcessRunnerProtocol\n            Process runner with allowlist and environment policies.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._GetProcessRunnerCallable.__call__","title":"<code>__call__()</code>","text":"<p>Get process runner instance.</p> <p>Returns:</p> Type Description <code>_ProcessRunnerProtocol</code> <p>Process runner with allowlist and environment policies.</p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>def __call__(self) -&gt; _ProcessRunnerProtocol:\n    \"\"\"Get process runner instance.\n\n    Returns\n    -------\n    _ProcessRunnerProtocol\n        Process runner with allowlist and environment policies.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utils_popenfactory","title":"kgfoundry_common.subprocess_utils._PopenFactory","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._PopenFactory","title":"<code>kgfoundry_common.subprocess_utils._PopenFactory</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>class _PopenFactory(Protocol):\n    def __call__(\n        self,\n        args: Sequence[str],\n        *_unsafe_args: object,\n        **_unsafe_kwargs: object,\n    ) -&gt; TextProcess:\n        \"\"\"Create subprocess instance.\n\n        Parameters\n        ----------\n        args : Sequence[str]\n            Command arguments.\n        *_unsafe_args : object\n            Additional positional arguments (unsafe, not used).\n        **_unsafe_kwargs : object\n            Additional keyword arguments (unsafe, not used).\n\n        Returns\n        -------\n        TextProcess\n            Process instance with text I/O streams.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._PopenFactory.__call__","title":"<code>__call__(args, *_unsafe_args, **_unsafe_kwargs)</code>","text":"<p>Create subprocess instance.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Sequence[str]</code> <p>Command arguments.</p> required <code>*_unsafe_args</code> <code>object</code> <p>Additional positional arguments (unsafe, not used).</p> <code>()</code> <code>**_unsafe_kwargs</code> <code>object</code> <p>Additional keyword arguments (unsafe, not used).</p> <code>{}</code> <p>Returns:</p> Type Description <code>TextProcess</code> <p>Process instance with text I/O streams.</p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>def __call__(\n    self,\n    args: Sequence[str],\n    *_unsafe_args: object,\n    **_unsafe_kwargs: object,\n) -&gt; TextProcess:\n    \"\"\"Create subprocess instance.\n\n    Parameters\n    ----------\n    args : Sequence[str]\n        Command arguments.\n    *_unsafe_args : object\n        Additional positional arguments (unsafe, not used).\n    **_unsafe_kwargs : object\n        Additional keyword arguments (unsafe, not used).\n\n    Returns\n    -------\n    TextProcess\n        Process instance with text I/O streams.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utils_processrunnerprotocol","title":"kgfoundry_common.subprocess_utils._ProcessRunnerProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._ProcessRunnerProtocol","title":"<code>kgfoundry_common.subprocess_utils._ProcessRunnerProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>class _ProcessRunnerProtocol(Protocol):\n    allowlist: _AllowListPolicyProtocol\n    environment: _EnvironmentPolicyProtocol\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utils_runtoolcallable","title":"kgfoundry_common.subprocess_utils._RunToolCallable","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._RunToolCallable","title":"<code>kgfoundry_common.subprocess_utils._RunToolCallable</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>class _RunToolCallable(Protocol):\n    def __call__(\n        self,\n        command: Sequence[str],\n        *,\n        cwd: Path | None = ...,\n        env: Mapping[str, str] | None = ...,\n        timeout: float | None = ...,\n        check: bool = ...,\n    ) -&gt; _ToolRunResultProtocol:\n        \"\"\"Execute a tool command.\n\n        Parameters\n        ----------\n        command : Sequence[str]\n            Command to execute.\n        cwd : Path | None, optional\n            Working directory for execution.\n        env : Mapping[str, str] | None, optional\n            Environment variable overrides.\n        timeout : float | None, optional\n            Maximum execution time in seconds.\n        check : bool, optional\n            Whether to raise on non-zero return code.\n\n        Returns\n        -------\n        _ToolRunResultProtocol\n            Execution result with stdout, stderr, and returncode.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._RunToolCallable.__call__","title":"<code>__call__(command, *, cwd=..., env=..., timeout=..., check=...)</code>","text":"<p>Execute a tool command.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>Sequence[str]</code> <p>Command to execute.</p> required <code>cwd</code> <code>Path | None</code> <p>Working directory for execution.</p> <code>...</code> <code>env</code> <code>Mapping[str, str] | None</code> <p>Environment variable overrides.</p> <code>...</code> <code>timeout</code> <code>float | None</code> <p>Maximum execution time in seconds.</p> <code>...</code> <code>check</code> <code>bool</code> <p>Whether to raise on non-zero return code.</p> <code>...</code> <p>Returns:</p> Type Description <code>_ToolRunResultProtocol</code> <p>Execution result with stdout, stderr, and returncode.</p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>def __call__(\n    self,\n    command: Sequence[str],\n    *,\n    cwd: Path | None = ...,\n    env: Mapping[str, str] | None = ...,\n    timeout: float | None = ...,\n    check: bool = ...,\n) -&gt; _ToolRunResultProtocol:\n    \"\"\"Execute a tool command.\n\n    Parameters\n    ----------\n    command : Sequence[str]\n        Command to execute.\n    cwd : Path | None, optional\n        Working directory for execution.\n    env : Mapping[str, str] | None, optional\n        Environment variable overrides.\n    timeout : float | None, optional\n        Maximum execution time in seconds.\n    check : bool, optional\n        Whether to raise on non-zero return code.\n\n    Returns\n    -------\n    _ToolRunResultProtocol\n        Execution result with stdout, stderr, and returncode.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utils_textprocess","title":"kgfoundry_common.subprocess_utils._TextProcess","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._TextProcess","title":"<code>kgfoundry_common.subprocess_utils._TextProcess</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol describing the streaming process surface we expose.</p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>class _TextProcess(Protocol):\n    \"\"\"Protocol describing the streaming process surface we expose.\"\"\"\n\n    stdin: io.TextIOBase | None\n    stdout: io.TextIOBase | None\n    stderr: io.TextIOBase | None\n\n    def poll(self) -&gt; int | None:\n        \"\"\"Check if process has terminated.\n\n        Returns\n        -------\n        int | None\n            Return code if process has terminated, None otherwise.\n        \"\"\"\n        ...\n\n    def wait(self, timeout: float | None = ...) -&gt; int:\n        \"\"\"Wait for process to terminate.\n\n        Parameters\n        ----------\n        timeout : float | None, optional\n            Maximum time to wait in seconds.\n\n        Returns\n        -------\n        int\n            Process return code.\n        \"\"\"\n        ...\n\n    def terminate(self) -&gt; None:\n        \"\"\"Send SIGTERM signal to process.\"\"\"\n        ...\n\n    def kill(self) -&gt; None:\n        \"\"\"Send SIGKILL signal to process.\"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._TextProcess.kill","title":"<code>kill()</code>","text":"<p>Send SIGKILL signal to process.</p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>def kill(self) -&gt; None:\n    \"\"\"Send SIGKILL signal to process.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._TextProcess.poll","title":"<code>poll()</code>","text":"<p>Check if process has terminated.</p> <p>Returns:</p> Type Description <code>int | None</code> <p>Return code if process has terminated, None otherwise.</p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>def poll(self) -&gt; int | None:\n    \"\"\"Check if process has terminated.\n\n    Returns\n    -------\n    int | None\n        Return code if process has terminated, None otherwise.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._TextProcess.terminate","title":"<code>terminate()</code>","text":"<p>Send SIGTERM signal to process.</p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>def terminate(self) -&gt; None:\n    \"\"\"Send SIGTERM signal to process.\"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._TextProcess.wait","title":"<code>wait(timeout=...)</code>","text":"<p>Wait for process to terminate.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>float | None</code> <p>Maximum time to wait in seconds.</p> <code>...</code> <p>Returns:</p> Type Description <code>int</code> <p>Process return code.</p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>def wait(self, timeout: float | None = ...) -&gt; int:\n    \"\"\"Wait for process to terminate.\n\n    Parameters\n    ----------\n    timeout : float | None, optional\n        Maximum time to wait in seconds.\n\n    Returns\n    -------\n    int\n        Process return code.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utils_toolexecutionerrorconstructor","title":"kgfoundry_common.subprocess_utils._ToolExecutionErrorConstructor","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._ToolExecutionErrorConstructor","title":"<code>kgfoundry_common.subprocess_utils._ToolExecutionErrorConstructor</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>class _ToolExecutionErrorConstructor(Protocol):\n    def __call__(self, message: str, *, command: Sequence[str], **kwargs: object) -&gt; Exception:\n        \"\"\"Create tool execution error.\n\n        Parameters\n        ----------\n        message : str\n            Error message.\n        command : Sequence[str]\n            Command that failed.\n        **kwargs : object\n            Additional error context.\n\n        Returns\n        -------\n        Exception\n            Exception instance.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._ToolExecutionErrorConstructor.__call__","title":"<code>__call__(message, *, command, **kwargs)</code>","text":"<p>Create tool execution error.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error message.</p> required <code>command</code> <code>Sequence[str]</code> <p>Command that failed.</p> required <code>**kwargs</code> <code>object</code> <p>Additional error context.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Exception</code> <p>Exception instance.</p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>def __call__(self, message: str, *, command: Sequence[str], **kwargs: object) -&gt; Exception:\n    \"\"\"Create tool execution error.\n\n    Parameters\n    ----------\n    message : str\n        Error message.\n    command : Sequence[str]\n        Command that failed.\n    **kwargs : object\n        Additional error context.\n\n    Returns\n    -------\n    Exception\n        Exception instance.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utils_toolexecutionerrorsurface","title":"kgfoundry_common.subprocess_utils._ToolExecutionErrorSurface","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._ToolExecutionErrorSurface","title":"<code>kgfoundry_common.subprocess_utils._ToolExecutionErrorSurface</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>class _ToolExecutionErrorSurface(Protocol):\n    problem: Mapping[str, object] | None\n    returncode: int | None\n    stderr: str\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utils_toolrunresultprotocol","title":"kgfoundry_common.subprocess_utils._ToolRunResultProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._ToolRunResultProtocol","title":"<code>kgfoundry_common.subprocess_utils._ToolRunResultProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>class _ToolRunResultProtocol(Protocol):\n    stdout: str\n    stderr: str\n    returncode: int\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utils_toolssurface","title":"kgfoundry_common.subprocess_utils._ToolsSurface","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._ToolsSurface","title":"<code>kgfoundry_common.subprocess_utils._ToolsSurface</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>class _ToolsSurface(Protocol):\n    ToolExecutionError: type[Exception]\n    run_tool: _RunToolCallable\n    get_process_runner: _GetProcessRunnerCallable\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utils_is_timeout_error","title":"kgfoundry_common.subprocess_utils._is_timeout_error","text":""},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._is_timeout_error","title":"<code>kgfoundry_common.subprocess_utils._is_timeout_error(error)</code>","text":"Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>def _is_timeout_error(error: _ToolExecutionErrorSurface) -&gt; bool:\n    problem = cast(\"Mapping[str, object] | None\", getattr(error, \"problem\", None))\n    if problem is not None:\n        raw_type = problem.get(\"type\")\n        if isinstance(raw_type, str) and raw_type.endswith(\"tool-timeout\"):\n            return True\n    return \"timed out\" in str(error)\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utils_load_tools_surface","title":"kgfoundry_common.subprocess_utils._load_tools_surface","text":""},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils._load_tools_surface","title":"<code>kgfoundry_common.subprocess_utils._load_tools_surface()</code>","text":"Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>def _load_tools_surface() -&gt; _ToolsSurface:\n    try:\n        module = import_module(\"tools\")\n    except ImportError as exc:\n        msg = (\n            \"The 'tools' package is required to execute subprocess utilities. \"\n            \"Install the 'kgfoundry[tools]' extra and retry.\"\n        )\n        raise RuntimeError(msg) from exc\n    return cast(\"_ToolsSurface\", module)\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utilsrun_subprocess","title":"kgfoundry_common.subprocess_utils.run_subprocess","text":""},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils.run_subprocess","title":"<code>kgfoundry_common.subprocess_utils.run_subprocess(cmd, *, timeout=None, cwd=None, env=None)</code>","text":"<p>Execute subprocess with timeout, path sanitization, and error handling.</p> <p>Parameters:</p> Name Type Description Default <code>cmd</code> <code>list[str]</code> <p>Command and arguments to execute. Command arguments are NOT shell-interpreted; each arg is literal.</p> required <code>timeout</code> <code>int | None</code> <p>Maximum execution time in seconds. If None, defaults to DEFAULT_TIMEOUT. Must be between MIN_TIMEOUT and MAX_TIMEOUT.</p> <code>None</code> <code>cwd</code> <code>Path | None</code> <p>Working directory for subprocess. If provided, will be resolved to absolute path and sanitized.</p> <code>None</code> <code>env</code> <code>Mapping[str, str] | None</code> <p>Environment variables to pass to subprocess. If None, inherits parent environment.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Captured stdout from subprocess.</p> <p>Raises:</p> Type Description <code>SubprocessTimeoutError</code> <p>If subprocess exceeds timeout.</p> <code>SubprocessError</code> <p>If subprocess exits with non-zero status.</p> <code>ValueError</code> <p>If parameters are invalid (negative timeout, etc).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; result = run_subprocess(\n...     [\"python\", \"-c\", \"print('test')\"],\n...     timeout=10,\n... )\n&gt;&gt;&gt; assert \"test\" in result\n</code></pre> Notes <p>This function does NOT use shell=True; each command element is passed literally to the OS, preventing shell injection attacks.</p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>def run_subprocess(\n    cmd: list[str],\n    *,\n    timeout: int | None = None,\n    cwd: Path | None = None,\n    env: Mapping[str, str] | None = None,\n) -&gt; str:\n    \"\"\"Execute subprocess with timeout, path sanitization, and error handling.\n\n    Parameters\n    ----------\n    cmd : list[str]\n        Command and arguments to execute.\n        Command arguments are NOT shell-interpreted; each arg is literal.\n    timeout : int | None, optional\n        Maximum execution time in seconds.\n        If None, defaults to DEFAULT_TIMEOUT.\n        Must be between MIN_TIMEOUT and MAX_TIMEOUT.\n    cwd : Path | None, optional\n        Working directory for subprocess.\n        If provided, will be resolved to absolute path and sanitized.\n    env : Mapping[str, str] | None, optional\n        Environment variables to pass to subprocess.\n        If None, inherits parent environment.\n\n    Returns\n    -------\n    str\n        Captured stdout from subprocess.\n\n    Raises\n    ------\n    SubprocessTimeoutError\n        If subprocess exceeds timeout.\n    SubprocessError\n        If subprocess exits with non-zero status.\n    ValueError\n        If parameters are invalid (negative timeout, etc).\n\n    Examples\n    --------\n    &gt;&gt;&gt; result = run_subprocess(\n    ...     [\"python\", \"-c\", \"print('test')\"],\n    ...     timeout=10,\n    ... )\n    &gt;&gt;&gt; assert \"test\" in result\n\n    Notes\n    -----\n    This function does NOT use shell=True; each command element is\n    passed literally to the OS, preventing shell injection attacks.\n    \"\"\"\n    # Normalize timeout\n    if timeout is None:\n        timeout = DEFAULT_TIMEOUT\n    if not MIN_TIMEOUT &lt;= timeout &lt;= MAX_TIMEOUT:\n        msg = f\"Timeout must be between {MIN_TIMEOUT} and {MAX_TIMEOUT}, got {timeout}\"\n        raise ValueError(msg)\n\n    # Sanitize working directory\n    if cwd is not None:\n        cwd = cwd.resolve()\n        logger.debug(\"Subprocess working directory sanitized\", extra={\"cwd\": str(cwd)})\n\n    logger.debug(\n        \"Executing subprocess\",\n        extra={\n            \"command\": \" \".join(cmd),\n            \"timeout\": timeout,\n            \"cwd\": str(cwd) if cwd else None,\n        },\n    )\n\n    effective_timeout = float(timeout)\n\n    tools_surface = _load_tools_surface()\n    tool_execution_error_type = tools_surface.ToolExecutionError\n    run_tool_impl = tools_surface.run_tool\n\n    try:\n        run_result = run_tool_impl(\n            cmd,\n            cwd=cwd,\n            env=dict(env) if env else None,\n            timeout=effective_timeout,\n            check=True,\n        )\n    except tool_execution_error_type as exc:\n        tool_error = cast(\"_ToolExecutionErrorSurface\", exc)\n        if _is_timeout_error(tool_error):\n            timeout_seconds = int(effective_timeout)\n            msg = f\"Subprocess exceeded timeout of {timeout_seconds} seconds: {' '.join(cmd)}\"\n            logger.exception(msg, extra={\"command\": \" \".join(cmd), \"timeout\": timeout_seconds})\n            raise SubprocessTimeoutError(msg, command=cmd, timeout_seconds=timeout_seconds) from exc\n\n        returncode = tool_error.returncode\n        stderr_output = tool_error.stderr or None\n        if returncode is None:\n            message = str(tool_error)\n        else:\n            message = f\"Subprocess failed with exit code {returncode}: {' '.join(cmd)}\"\n        logger.exception(\n            message,\n            extra={\n                \"command\": \" \".join(cmd),\n                \"returncode\": returncode,\n                \"stderr\": stderr_output,\n            },\n        )\n        raise SubprocessError(message, returncode=returncode, stderr=stderr_output) from exc\n    except Exception as exc:  # pragma: no cover - defensive fallback\n        msg = f\"Unexpected error executing subprocess: {exc}\"\n        logger.exception(msg, extra={\"command\": \" \".join(cmd)})\n        raise SubprocessError(msg) from exc\n\n    logger.debug(\"Subprocess completed successfully\", extra={\"returncode\": run_result.returncode})\n    return run_result.stdout\n</code></pre>"},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_commonsubprocess_utilsspawn_text_process","title":"kgfoundry_common.subprocess_utils.spawn_text_process","text":""},{"location":"modules/kgfoundry_common.subprocess_utils/#kgfoundry_common.subprocess_utils.spawn_text_process","title":"<code>kgfoundry_common.subprocess_utils.spawn_text_process(command, *, cwd=None, env=None)</code>","text":"<p>Spawn a long-lived subprocess with hardened command checks.</p> <p>The command is resolved through the shared allow-list policy to ensure the executable path is trusted, and the environment is sanitised to drop inherited state that could affect tooling deterministically.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>Sequence[str]</code> <p>Command and arguments to execute.</p> required <code>cwd</code> <code>Path | None</code> <p>Working directory for the process.</p> <code>None</code> <code>env</code> <code>Mapping[str, str] | None</code> <p>Environment variables.</p> <code>None</code> <p>Returns:</p> Type Description <code>TextProcess</code> <p>Text process instance.</p> <p>Raises:</p> Type Description <code>ToolExecutionError</code> <p>If command is empty or command validation fails.</p> Source code in <code>src/kgfoundry_common/subprocess_utils.py</code> <pre><code>def spawn_text_process(\n    command: Sequence[str],\n    *,\n    cwd: Path | None = None,\n    env: Mapping[str, str] | None = None,\n) -&gt; TextProcess:\n    \"\"\"Spawn a long-lived subprocess with hardened command checks.\n\n    The command is resolved through the shared allow-list policy to ensure the executable path is\n    trusted, and the environment is sanitised to drop inherited state that could affect tooling\n    deterministically.\n\n    Parameters\n    ----------\n    command : Sequence[str]\n        Command and arguments to execute.\n    cwd : Path | None, optional\n        Working directory for the process.\n    env : Mapping[str, str] | None, optional\n        Environment variables.\n\n    Returns\n    -------\n    TextProcess\n        Text process instance.\n\n    Raises\n    ------\n    ToolExecutionError\n        If command is empty or command validation fails.\n    \"\"\"\n    tools_surface = _load_tools_surface()\n    tool_execution_error_ctor = cast(\n        \"_ToolExecutionErrorConstructor\", tools_surface.ToolExecutionError\n    )\n    if not command:\n        msg = \"Command must contain at least one argument\"\n        raise tool_execution_error_ctor(msg, command=[])\n\n    get_runner = tools_surface.get_process_runner\n    runner = get_runner()\n\n    executable = runner.allowlist.resolve(command[0], command)\n    final_command = (str(executable), *command[1:])\n    sanitised_env = runner.environment.build(env)\n\n    return _Popen(\n        final_command,\n        stdin=_PIPE,\n        stdout=_PIPE,\n        stderr=_PIPE,\n        text=True,\n        cwd=str(cwd) if cwd else None,\n        env=dict(sanitised_env),\n    )\n</code></pre>"},{"location":"modules/kgfoundry_common.types/","title":"kgfoundry_common.types","text":""},{"location":"modules/kgfoundry_common.types/#kgfoundry_commontypes","title":"kgfoundry_common.types","text":"<p>Type aliases for kgfoundry_common.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.types/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.types__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.types code <p>See the full diagram: kgfoundry_common.types</p>"},{"location":"modules/kgfoundry_common.types/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p>"},{"location":"modules/kgfoundry_common.typing/","title":"kgfoundry_common.typing","text":""},{"location":"modules/kgfoundry_common.typing/#kgfoundry_commontyping","title":"kgfoundry_common.typing","text":"<p>Canonical typing fa\u00e7ade for kgfoundry.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.typing/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class _Comparable\n    class Protocol\n    Protocol &lt;|-- _Comparable\n</code></pre>"},{"location":"modules/kgfoundry_common.typing/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.typing__future__.annotationscollections.abc.Callablekgfoundry_common.navmap_loader.load_nav_metadatapackaging.version.parsetyping.NoReturntyping.Protocoltyping.TYPE_CHECKINGtyping.castwarningskgfoundry_common.typing code <p>See the full diagram: kgfoundry_common.typing</p>"},{"location":"modules/kgfoundry_common.typing/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.typing._Comparable</li> <li>kgfoundry_common.typing._protocol_stub</li> <li>kgfoundry_common.typing._version_gte</li> <li>kgfoundry_common.typing.gate_import</li> </ul>"},{"location":"modules/kgfoundry_common.typing/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Callable</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>packaging.version.parse</code>, <code>typing.NoReturn</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code>, <code>warnings</code></p>"},{"location":"modules/kgfoundry_common.typing/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.typing/#kgfoundry_commontyping_comparable","title":"kgfoundry_common.typing._Comparable","text":"<p>Bases: Protocol</p>"},{"location":"modules/kgfoundry_common.typing/#kgfoundry_common.typing._Comparable","title":"<code>kgfoundry_common.typing._Comparable</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/kgfoundry_common/typing/__init__.py</code> <pre><code>class _Comparable(Protocol):\n    def __lt__(self, other: _Comparable, /) -&gt; bool:\n        \"\"\"Compare less than.\n\n        Parameters\n        ----------\n        other : _Comparable\n            Other object to compare.\n        \"\"\"\n        _protocol_stub(\"__lt__\", self, other)\n\n    def __le__(self, other: _Comparable, /) -&gt; bool:\n        \"\"\"Compare less than or equal.\n\n        Parameters\n        ----------\n        other : _Comparable\n            Other object to compare.\n        \"\"\"\n        _protocol_stub(\"__le__\", self, other)\n\n    def __gt__(self, other: _Comparable, /) -&gt; bool:\n        \"\"\"Compare greater than.\n\n        Parameters\n        ----------\n        other : _Comparable\n            Other object to compare.\n        \"\"\"\n        _protocol_stub(\"__gt__\", self, other)\n\n    def __ge__(self, other: _Comparable, /) -&gt; bool:\n        \"\"\"Compare greater than or equal.\n\n        Parameters\n        ----------\n        other : _Comparable\n            Other object to compare.\n        \"\"\"\n        _protocol_stub(\"__ge__\", self, other)\n</code></pre>"},{"location":"modules/kgfoundry_common.typing/#kgfoundry_common.typing._Comparable.__ge__","title":"<code>__ge__(other)</code>","text":"<p>Compare greater than or equal.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>_Comparable</code> <p>Other object to compare.</p> required Source code in <code>src/kgfoundry_common/typing/__init__.py</code> <pre><code>def __ge__(self, other: _Comparable, /) -&gt; bool:\n    \"\"\"Compare greater than or equal.\n\n    Parameters\n    ----------\n    other : _Comparable\n        Other object to compare.\n    \"\"\"\n    _protocol_stub(\"__ge__\", self, other)\n</code></pre>"},{"location":"modules/kgfoundry_common.typing/#kgfoundry_common.typing._Comparable.__gt__","title":"<code>__gt__(other)</code>","text":"<p>Compare greater than.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>_Comparable</code> <p>Other object to compare.</p> required Source code in <code>src/kgfoundry_common/typing/__init__.py</code> <pre><code>def __gt__(self, other: _Comparable, /) -&gt; bool:\n    \"\"\"Compare greater than.\n\n    Parameters\n    ----------\n    other : _Comparable\n        Other object to compare.\n    \"\"\"\n    _protocol_stub(\"__gt__\", self, other)\n</code></pre>"},{"location":"modules/kgfoundry_common.typing/#kgfoundry_common.typing._Comparable.__le__","title":"<code>__le__(other)</code>","text":"<p>Compare less than or equal.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>_Comparable</code> <p>Other object to compare.</p> required Source code in <code>src/kgfoundry_common/typing/__init__.py</code> <pre><code>def __le__(self, other: _Comparable, /) -&gt; bool:\n    \"\"\"Compare less than or equal.\n\n    Parameters\n    ----------\n    other : _Comparable\n        Other object to compare.\n    \"\"\"\n    _protocol_stub(\"__le__\", self, other)\n</code></pre>"},{"location":"modules/kgfoundry_common.typing/#kgfoundry_common.typing._Comparable.__lt__","title":"<code>__lt__(other)</code>","text":"<p>Compare less than.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>_Comparable</code> <p>Other object to compare.</p> required Source code in <code>src/kgfoundry_common/typing/__init__.py</code> <pre><code>def __lt__(self, other: _Comparable, /) -&gt; bool:\n    \"\"\"Compare less than.\n\n    Parameters\n    ----------\n    other : _Comparable\n        Other object to compare.\n    \"\"\"\n    _protocol_stub(\"__lt__\", self, other)\n</code></pre>"},{"location":"modules/kgfoundry_common.typing/#kgfoundry_commontyping_protocol_stub","title":"kgfoundry_common.typing._protocol_stub","text":""},{"location":"modules/kgfoundry_common.typing/#kgfoundry_common.typing._protocol_stub","title":"<code>kgfoundry_common.typing._protocol_stub(method, *args)</code>","text":"<p>Raise <code>NotImplementedError</code> when a structural protocol leaks to runtime.</p> Source code in <code>src/kgfoundry_common/typing/__init__.py</code> <pre><code>def _protocol_stub(method: str, *args: object) -&gt; NoReturn:\n    \"\"\"Raise ``NotImplementedError`` when a structural protocol leaks to runtime.\"\"\"\n    message = (\n        f\"Comparable protocol method '{method}' must be implemented by the returned object. \"\n        f\"Received args={args!r}.\"\n    )\n    raise NotImplementedError(message)\n</code></pre>"},{"location":"modules/kgfoundry_common.typing/#kgfoundry_commontyping_version_gte","title":"kgfoundry_common.typing._version_gte","text":""},{"location":"modules/kgfoundry_common.typing/#kgfoundry_common.typing._version_gte","title":"<code>kgfoundry_common.typing._version_gte(installed, required)</code>","text":"<p>Check if installed version &gt;= required version.</p> <p>Parameters:</p> Name Type Description Default <code>installed</code> <code>str</code> <p>Installed version string.</p> required <code>required</code> <code>str</code> <p>Required version string.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if installed version is &gt;= required version.</p> Source code in <code>src/kgfoundry_common/typing/__init__.py</code> <pre><code>def _version_gte(installed: str, required: str) -&gt; bool:\n    \"\"\"Check if installed version &gt;= required version.\n\n    Parameters\n    ----------\n    installed : str\n        Installed version string.\n    required : str\n        Required version string.\n\n    Returns\n    -------\n    bool\n        True if installed version is &gt;= required version.\n    \"\"\"\n    if _PARSE_VERSION is None:\n        return installed &gt;= required\n    installed_version = _PARSE_VERSION(installed)\n    required_version = _PARSE_VERSION(required)\n    return installed_version &gt;= required_version\n</code></pre>"},{"location":"modules/kgfoundry_common.typing/#kgfoundry_commontypinggate_import","title":"kgfoundry_common.typing.gate_import","text":""},{"location":"modules/kgfoundry_common.typing/#kgfoundry_common.typing.gate_import","title":"<code>kgfoundry_common.typing.gate_import(module_name, purpose, min_version=None)</code>","text":"<p>Lazily import a heavy optional dependency, raising if unavailable.</p> <p>Use this when a module genuinely requires heavy dependencies at runtime, and TYPE_CHECKING guards are insufficient. The helper provides structured error messages and caches results.</p> <p>Parameters:</p> Name Type Description Default <code>module_name</code> <code>str</code> <p>Fully qualified module name (e.g., \"numpy\", \"fastapi.routing\").</p> required <code>purpose</code> <code>str</code> <p>Human-readable description of why the import is needed (used in errors).</p> required <code>min_version</code> <code>str | None</code> <p>Minimum required version (checked via version attribute).</p> <code>None</code> <p>Returns:</p> Type Description <code>object</code> <p>The imported module.</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If the module is not installed or version requirement is unmet.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; np = gate_import(\"numpy\", \"array manipulation\")\n&gt;&gt;&gt; arr = np.zeros((10,))\n</code></pre> Source code in <code>src/kgfoundry_common/typing/__init__.py</code> <pre><code>def gate_import(\n    module_name: str,\n    purpose: str,\n    min_version: str | None = None,\n) -&gt; object:\n    \"\"\"Lazily import a heavy optional dependency, raising if unavailable.\n\n    Use this when a module genuinely requires heavy dependencies at runtime,\n    and TYPE_CHECKING guards are insufficient. The helper provides structured\n    error messages and caches results.\n\n    Parameters\n    ----------\n    module_name : str\n        Fully qualified module name (e.g., \"numpy\", \"fastapi.routing\").\n    purpose : str\n        Human-readable description of why the import is needed (used in errors).\n    min_version : str | None, optional\n        Minimum required version (checked via __version__ attribute).\n\n    Returns\n    -------\n    object\n        The imported module.\n\n    Raises\n    ------\n    ImportError\n        If the module is not installed or version requirement is unmet.\n\n    Examples\n    --------\n    &gt;&gt;&gt; np = gate_import(\"numpy\", \"array manipulation\")\n    &gt;&gt;&gt; arr = np.zeros((10,))\n    \"\"\"\n    # Attempt import\n    try:\n        module = __import__(module_name, fromlist=[\"\"])\n    except ImportError as exc:\n        msg = (\n            f\"Cannot proceed with {purpose}: '{module_name}' is not installed. \"\n            f\"Install via: pip install {module_name.split('.', maxsplit=1)[0]}\"\n        )\n        raise ImportError(msg) from exc\n\n    # Check version if requested\n    if min_version is not None and hasattr(module, \"__version__\"):\n        installed: str = getattr(module, \"__version__\", \"unknown\")\n        if not _version_gte(installed, min_version):\n            msg = (\n                f\"Cannot proceed with {purpose}: '{module_name}' version \"\n                f\"{installed} &lt; {min_version} (required). \"\n                f\"Upgrade via: pip install --upgrade {module_name.split('.', maxsplit=1)[0]}\"\n            )\n            raise ImportError(msg)\n\n    return module\n</code></pre>"},{"location":"modules/kgfoundry_common.typing/#kgfoundry_commontypingresolve_faiss","title":"kgfoundry_common.typing.resolve_faiss","text":""},{"location":"modules/kgfoundry_common.typing/#kgfoundry_common.typing.resolve_faiss","title":"<code>kgfoundry_common.typing.resolve_faiss()</code>","text":"<p>Resolve and return the faiss module (deprecated).</p> <p>.. deprecated:: 0.1.0     Use <code>gate_import(\"faiss\", \"vector similarity search\")</code> instead.</p> <p>Returns:</p> Type Description <code>object</code> <p>The faiss module.</p> Notes <p>Propagates :class:<code>ImportError</code> when <code>faiss</code> is not installed.</p> Source code in <code>src/kgfoundry_common/typing/__init__.py</code> <pre><code>def resolve_faiss() -&gt; object:\n    \"\"\"Resolve and return the faiss module (deprecated).\n\n    .. deprecated:: 0.1.0\n        Use `gate_import(\"faiss\", \"vector similarity search\")` instead.\n\n    Returns\n    -------\n    object\n        The faiss module.\n\n    Notes\n    -----\n    Propagates :class:`ImportError` when ``faiss`` is not installed.\n    \"\"\"\n    warnings.warn(\n        \"resolve_faiss() is deprecated; use gate_import('faiss', ...) instead\",\n        DeprecationWarning,\n        stacklevel=2,\n    )\n    return gate_import(\"faiss\", \"vector similarity search\")\n</code></pre>"},{"location":"modules/kgfoundry_common.typing/#kgfoundry_commontypingresolve_fastapi","title":"kgfoundry_common.typing.resolve_fastapi","text":""},{"location":"modules/kgfoundry_common.typing/#kgfoundry_common.typing.resolve_fastapi","title":"<code>kgfoundry_common.typing.resolve_fastapi()</code>","text":"<p>Resolve and return the fastapi module (deprecated).</p> <p>.. deprecated:: 0.1.0     Use <code>gate_import(\"fastapi\", \"FastAPI application\")</code> instead.</p> <p>Returns:</p> Type Description <code>object</code> <p>The fastapi module.</p> Notes <p>Propagates :class:<code>ImportError</code> when <code>fastapi</code> is not installed.</p> Source code in <code>src/kgfoundry_common/typing/__init__.py</code> <pre><code>def resolve_fastapi() -&gt; object:\n    \"\"\"Resolve and return the fastapi module (deprecated).\n\n    .. deprecated:: 0.1.0\n        Use `gate_import(\"fastapi\", \"FastAPI application\")` instead.\n\n    Returns\n    -------\n    object\n        The fastapi module.\n\n    Notes\n    -----\n    Propagates :class:`ImportError` when ``fastapi`` is not installed.\n    \"\"\"\n    warnings.warn(\n        \"resolve_fastapi() is deprecated; use gate_import('fastapi', ...) instead\",\n        DeprecationWarning,\n        stacklevel=2,\n    )\n    return gate_import(\"fastapi\", \"FastAPI application\")\n</code></pre>"},{"location":"modules/kgfoundry_common.typing/#kgfoundry_commontypingresolve_numpy","title":"kgfoundry_common.typing.resolve_numpy","text":""},{"location":"modules/kgfoundry_common.typing/#kgfoundry_common.typing.resolve_numpy","title":"<code>kgfoundry_common.typing.resolve_numpy()</code>","text":"<p>Resolve and return the numpy module (deprecated).</p> <p>.. deprecated:: 0.1.0     Use <code>gate_import(\"numpy\", \"array processing\")</code> instead.</p> <p>Returns:</p> Type Description <code>object</code> <p>The numpy module.</p> Notes <p>Propagates :class:<code>ImportError</code> when <code>numpy</code> is not installed.</p> Source code in <code>src/kgfoundry_common/typing/__init__.py</code> <pre><code>def resolve_numpy() -&gt; object:\n    \"\"\"Resolve and return the numpy module (deprecated).\n\n    .. deprecated:: 0.1.0\n        Use `gate_import(\"numpy\", \"array processing\")` instead.\n\n    Returns\n    -------\n    object\n        The numpy module.\n\n    Notes\n    -----\n    Propagates :class:`ImportError` when ``numpy`` is not installed.\n    \"\"\"\n    warnings.warn(\n        \"resolve_numpy() is deprecated; use gate_import('numpy', ...) instead\",\n        DeprecationWarning,\n        stacklevel=2,\n    )\n    return gate_import(\"numpy\", \"numpy array processing\")\n</code></pre>"},{"location":"modules/kgfoundry_common.typing/#kgfoundry_commontypingsafe_get_type","title":"kgfoundry_common.typing.safe_get_type","text":""},{"location":"modules/kgfoundry_common.typing/#kgfoundry_common.typing.safe_get_type","title":"<code>kgfoundry_common.typing.safe_get_type(module_name, type_name, default=None)</code>","text":"<p>Retrieve a type from a module, returning None if unavailable.</p> <p>Use this in annotations when you want to be defensive about optional types.</p> <p>Parameters:</p> Name Type Description Default <code>module_name</code> <code>str</code> <p>Module name (e.g., \"numpy\").</p> required <code>type_name</code> <code>str</code> <p>Type/class name within the module (e.g., \"ndarray\").</p> required <code>default</code> <code>object</code> <p>Default return value if import fails (default: None).</p> <code>None</code> <p>Returns:</p> Type Description <code>object</code> <p>The type, or default if the module/type is not available.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ndarray_type = safe_get_type(\"numpy\", \"ndarray\")\n&gt;&gt;&gt; if ndarray_type is not None:\n...     pass  # Do something with the type\n</code></pre> Source code in <code>src/kgfoundry_common/typing/__init__.py</code> <pre><code>def safe_get_type(\n    module_name: str,\n    type_name: str,\n    default: object = None,\n) -&gt; object:\n    \"\"\"Retrieve a type from a module, returning None if unavailable.\n\n    Use this in annotations when you want to be defensive about optional types.\n\n    Parameters\n    ----------\n    module_name : str\n        Module name (e.g., \"numpy\").\n    type_name : str\n        Type/class name within the module (e.g., \"ndarray\").\n    default : object, optional\n        Default return value if import fails (default: None).\n\n    Returns\n    -------\n    object\n        The type, or default if the module/type is not available.\n\n    Examples\n    --------\n    &gt;&gt;&gt; ndarray_type = safe_get_type(\"numpy\", \"ndarray\")\n    &gt;&gt;&gt; if ndarray_type is not None:\n    ...     pass  # Do something with the type\n    \"\"\"\n    try:\n        module = __import__(module_name, fromlist=[type_name])\n        return getattr(module, type_name, default)\n    except (ImportError, AttributeError):\n        return default\n</code></pre>"},{"location":"modules/kgfoundry_common.vector_types/","title":"kgfoundry_common.vector_types","text":""},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_commonvector_types","title":"kgfoundry_common.vector_types","text":"<p>Typed vector contracts and validation helpers for vector ingestion.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/kgfoundry_common.vector_types/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class VectorBatch\n    class VectorValidationError\n    class ValueError\n    ValueError &lt;|-- VectorValidationError\n</code></pre>"},{"location":"modules/kgfoundry_common.vector_types/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"kgfoundry_common.vector_types__future__.annotationscollections.abc.Iterablecollections.abc.Mappingcollections.abc.Sequencedataclasses.dataclasskgfoundry_common.navmap_loader.load_nav_metadatanumpynumpy.typingtyping.Finaltyping.NewTypetyping.TYPE_CHECKINGtyping.castkgfoundry_common.vector_types code <p>See the full diagram: kgfoundry_common.vector_types</p>"},{"location":"modules/kgfoundry_common.vector_types/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>kgfoundry_common.vector_types.VectorBatch</li> <li>kgfoundry_common.vector_types.VectorValidationError</li> <li>kgfoundry_common.vector_types._coerce_vector_row</li> <li>kgfoundry_common.vector_types.assert_vector_matrix</li> <li>kgfoundry_common.vector_types.coerce_vector_batch</li> </ul>"},{"location":"modules/kgfoundry_common.vector_types/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Iterable</code>, <code>collections.abc.Mapping</code>, <code>collections.abc.Sequence</code>, <code>dataclasses.dataclass</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>numpy</code>, <code>numpy.typing</code>, <code>typing.Final</code>, <code>typing.NewType</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/kgfoundry_common.vector_types/#contents","title":"Contents","text":""},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_commonvector_typesvectorbatch","title":"kgfoundry_common.vector_types.VectorBatch","text":""},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_common.vector_types.VectorBatch","title":"<code>kgfoundry_common.vector_types.VectorBatch</code>  <code>dataclass</code>","text":"<p>Immutable collection of typed vectors with shared dimensionality.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>tuple[VectorId, ...]</code> <p>Unique identifiers associated with each vector row.</p> required <code>matrix</code> <code>VectorMatrix</code> <p>Two-dimensional <code>float32</code> matrix whose row count matches <code>ids</code>.</p> required <p>Raises:</p> Type Description <code>VectorValidationError</code> <p>If the matrix is not two dimensional, contains zero-length vectors, or the id count does not match the number of rows.</p> Source code in <code>src/kgfoundry_common/vector_types.py</code> <pre><code>@dataclass(frozen=True, slots=True)\n# [nav:anchor VectorBatch]\nclass VectorBatch:\n    \"\"\"Immutable collection of typed vectors with shared dimensionality.\n\n    Parameters\n    ----------\n    ids : tuple[VectorId, ...]\n        Unique identifiers associated with each vector row.\n    matrix : VectorMatrix\n        Two-dimensional ``float32`` matrix whose row count matches ``ids``.\n\n    Raises\n    ------\n    VectorValidationError\n        If the matrix is not two dimensional, contains zero-length vectors, or\n        the id count does not match the number of rows.\n    \"\"\"\n\n    ids: tuple[VectorId, ...]\n    matrix: VectorMatrix\n\n    def __post_init__(self) -&gt; None:\n        \"\"\"Normalise matrix representation without enforcing ids invariants.\"\"\"\n        matrix = assert_vector_matrix(self.matrix)\n        object.__setattr__(self, \"matrix\", matrix)\n\n    @property\n    def dimension(self) -&gt; int:\n        \"\"\"Return the dimensionality shared by all vectors in the batch.\"\"\"\n        return int(self.matrix.shape[1])\n\n    @property\n    def count(self) -&gt; int:\n        \"\"\"Return the number of vectors contained in the batch.\"\"\"\n        return len(self.ids)\n</code></pre>"},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_common.vector_types.VectorBatch.count","title":"<code>count</code>  <code>property</code>","text":"<p>Return the number of vectors contained in the batch.</p>"},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_common.vector_types.VectorBatch.dimension","title":"<code>dimension</code>  <code>property</code>","text":"<p>Return the dimensionality shared by all vectors in the batch.</p>"},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_common.vector_types.VectorBatch.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Normalise matrix representation without enforcing ids invariants.</p> Source code in <code>src/kgfoundry_common/vector_types.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Normalise matrix representation without enforcing ids invariants.\"\"\"\n    matrix = assert_vector_matrix(self.matrix)\n    object.__setattr__(self, \"matrix\", matrix)\n</code></pre>"},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_commonvector_typesvectorvalidationerror","title":"kgfoundry_common.vector_types.VectorValidationError","text":"<p>Bases: ValueError</p>"},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_common.vector_types.VectorValidationError","title":"<code>kgfoundry_common.vector_types.VectorValidationError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Raised when vector payloads fail dtype, shape, or schema validation.</p> Source code in <code>src/kgfoundry_common/vector_types.py</code> <pre><code>class VectorValidationError(ValueError):\n    \"\"\"Raised when vector payloads fail dtype, shape, or schema validation.\"\"\"\n\n    def __init__(self, message: str, *, errors: Sequence[str] | None = None) -&gt; None:\n        \"\"\"Initialize validation error.\n\n        Parameters\n        ----------\n        message : str\n            Error message.\n        errors : Sequence[str] | None, optional\n            List of validation error messages.\n            Defaults to None.\n        \"\"\"\n        super().__init__(message)\n        self.errors: tuple[str, ...] = tuple(errors or (message,))\n</code></pre>"},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_common.vector_types.VectorValidationError.__init__","title":"<code>__init__(message, *, errors=None)</code>","text":"<p>Initialize validation error.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error message.</p> required <code>errors</code> <code>Sequence[str] | None</code> <p>List of validation error messages. Defaults to None.</p> <code>None</code> Source code in <code>src/kgfoundry_common/vector_types.py</code> <pre><code>def __init__(self, message: str, *, errors: Sequence[str] | None = None) -&gt; None:\n    \"\"\"Initialize validation error.\n\n    Parameters\n    ----------\n    message : str\n        Error message.\n    errors : Sequence[str] | None, optional\n        List of validation error messages.\n        Defaults to None.\n    \"\"\"\n    super().__init__(message)\n    self.errors: tuple[str, ...] = tuple(errors or (message,))\n</code></pre>"},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_commonvector_types_coerce_vector_row","title":"kgfoundry_common.vector_types._coerce_vector_row","text":""},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_common.vector_types._coerce_vector_row","title":"<code>kgfoundry_common.vector_types._coerce_vector_row(vector_obj, idx)</code>","text":"<p>Return a typed row extracted from <code>vector_obj</code>.</p> <p>Parameters:</p> Name Type Description Default <code>vector_obj</code> <code>object</code> <p>Candidate vector payload.</p> required <code>idx</code> <code>int</code> <p>Zero-based index of the record, used for diagnostic messages.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>Row converted to <code>float32</code> values.</p> <p>Raises:</p> Type Description <code>VectorValidationError</code> <p>If the object cannot be converted to a one-dimensional numeric vector.</p> Source code in <code>src/kgfoundry_common/vector_types.py</code> <pre><code>def _coerce_vector_row(vector_obj: object, idx: int) -&gt; list[float]:\n    \"\"\"Return a typed row extracted from ``vector_obj``.\n\n    Parameters\n    ----------\n    vector_obj : object\n        Candidate vector payload.\n    idx : int\n        Zero-based index of the record, used for diagnostic messages.\n\n    Returns\n    -------\n    list[float]\n        Row converted to ``float32`` values.\n\n    Raises\n    ------\n    VectorValidationError\n        If the object cannot be converted to a one-dimensional numeric vector.\n    \"\"\"\n    if isinstance(vector_obj, Mapping):\n        msg = f\"Record {idx} must provide 'vector' as a sequence, not a mapping\"\n        raise VectorValidationError(msg)\n\n    try:\n        array = np.asarray(vector_obj, dtype=np.float32)\n    except (TypeError, ValueError) as exc:  # pragma: no cover - exercised in tests\n        msg = f\"Record {idx} contains non-numeric vector entries\"\n        raise VectorValidationError(msg) from exc\n\n    if array.ndim != 1:\n        msg = f\"Record {idx} vector must be one-dimensional\"\n        raise VectorValidationError(msg)\n    if array.size == 0:\n        msg = f\"Record {idx} vector must contain at least one element\"\n        raise VectorValidationError(msg)\n\n    contiguous = np.ascontiguousarray(array, dtype=np.float32)\n    return cast(\"list[float]\", contiguous.astype(np.float32, copy=False).tolist())\n</code></pre>"},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_commonvector_typesassert_vector_matrix","title":"kgfoundry_common.vector_types.assert_vector_matrix","text":""},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_common.vector_types.assert_vector_matrix","title":"<code>kgfoundry_common.vector_types.assert_vector_matrix(arr)</code>","text":"<p>Return a contiguous <code>float32</code> matrix derived from <code>arr</code>.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>object</code> <p>Candidate matrix to validate.</p> required <p>Returns:</p> Type Description <code>VectorMatrix</code> <p>Contiguous <code>float32</code> matrix with two dimensions.</p> <p>Raises:</p> Type Description <code>VectorValidationError</code> <p>If <code>arr</code> cannot be coerced to a two-dimensional <code>float32</code> matrix with a non-zero second dimension.</p> Source code in <code>src/kgfoundry_common/vector_types.py</code> <pre><code>def assert_vector_matrix(arr: object) -&gt; VectorMatrix:\n    \"\"\"Return a contiguous ``float32`` matrix derived from ``arr``.\n\n    Parameters\n    ----------\n    arr : object\n        Candidate matrix to validate.\n\n    Returns\n    -------\n    VectorMatrix\n        Contiguous ``float32`` matrix with two dimensions.\n\n    Raises\n    ------\n    VectorValidationError\n        If ``arr`` cannot be coerced to a two-dimensional ``float32`` matrix\n        with a non-zero second dimension.\n    \"\"\"\n    try:\n        matrix = np.asarray(arr, dtype=np.float32)\n    except (TypeError, ValueError) as exc:  # pragma: no cover - defensive\n        msg = \"Matrix values must be numeric\"\n        raise VectorValidationError(msg) from exc\n\n    if matrix.ndim != VECTOR_MATRIX_NDIM:\n        msg = \"Vector matrix must be two-dimensional\"\n        raise VectorValidationError(msg)\n    if matrix.shape[1] == 0:\n        msg = \"Vector dimensionality must be greater than zero\"\n        raise VectorValidationError(msg)\n\n    contiguous: VectorMatrix = np.ascontiguousarray(matrix, dtype=np.float32)\n    return contiguous\n</code></pre>"},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_commonvector_typescoerce_vector_batch","title":"kgfoundry_common.vector_types.coerce_vector_batch","text":""},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_common.vector_types.coerce_vector_batch","title":"<code>kgfoundry_common.vector_types.coerce_vector_batch(records)</code>","text":"<p>Construct a :class:<code>VectorBatch</code> from vector payload mappings.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>Iterable[Mapping[str, object]]</code> <p>Iterable of JSON-like mappings containing <code>\"key\"</code> and <code>\"vector\"</code> entries. <code>\"vector\"</code> must be a one-dimensional sequence of numbers.</p> required <p>Returns:</p> Type Description <code>VectorBatch</code> <p>Immutable batch containing unique ids and a contiguous <code>float32</code> matrix.</p> <p>Raises:</p> Type Description <code>VectorValidationError</code> <p>If a record is not a mapping, ids are missing/duplicated, vectors are empty, non-numeric, or have inconsistent dimensionality.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry_common.vector_types import coerce_vector_batch\n&gt;&gt;&gt; batch = coerce_vector_batch(\n...     [\n...         {\"key\": \"a\", \"vector\": [1, 2]},\n...         {\"key\": \"b\", \"vector\": [3, 4]},\n...     ]\n... )\n&gt;&gt;&gt; batch.matrix.dtype\ndtype('float32')\n&gt;&gt;&gt; batch.matrix.shape\n(2, 2)\n</code></pre> Source code in <code>src/kgfoundry_common/vector_types.py</code> <pre><code>def coerce_vector_batch(records: Iterable[object]) -&gt; VectorBatch:\n    \"\"\"Construct a :class:`VectorBatch` from vector payload mappings.\n\n    Parameters\n    ----------\n    records : Iterable[Mapping[str, object]]\n        Iterable of JSON-like mappings containing ``\"key\"`` and ``\"vector\"``\n        entries. ``\"vector\"`` must be a one-dimensional sequence of numbers.\n\n    Returns\n    -------\n    VectorBatch\n        Immutable batch containing unique ids and a contiguous ``float32``\n        matrix.\n\n    Raises\n    ------\n    VectorValidationError\n        If a record is not a mapping, ids are missing/duplicated, vectors are\n        empty, non-numeric, or have inconsistent dimensionality.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry_common.vector_types import coerce_vector_batch\n    &gt;&gt;&gt; batch = coerce_vector_batch(\n    ...     [\n    ...         {\"key\": \"a\", \"vector\": [1, 2]},\n    ...         {\"key\": \"b\", \"vector\": [3, 4]},\n    ...     ]\n    ... )\n    &gt;&gt;&gt; batch.matrix.dtype\n    dtype('float32')\n    &gt;&gt;&gt; batch.matrix.shape\n    (2, 2)\n    \"\"\"\n    ids: list[VectorId] = []\n    seen_ids: set[VectorId] = set()\n    vectors: list[list[float]] = []\n    expected_dim: int | None = None\n\n    for idx, record_obj in enumerate(records):\n        if not isinstance(record_obj, Mapping):\n            msg = f\"Record {idx} is missing a non-empty 'key' string\"\n            raise VectorValidationError(msg)\n        record = record_obj\n        raw_key = record.get(\"key\")\n        if not isinstance(raw_key, str) or not raw_key.strip():\n            msg = f\"Record {idx} is missing a non-empty 'key' string\"\n            raise VectorValidationError(msg)\n\n        vector_obj = record.get(\"vector\")\n        row = _coerce_vector_row(vector_obj, idx)\n\n        if expected_dim is None:\n            expected_dim = len(row)\n        elif len(row) != expected_dim:\n            msg = (\n                f\"Record {idx} has dimension {len(row)} which differs from the \"\n                f\"expected dimension {expected_dim}\"\n            )\n            raise VectorValidationError(msg)\n\n        vector_id = VectorId(raw_key)\n        if vector_id in seen_ids:\n            msg = f\"Record {idx} reuses id '{vector_id}'\"\n            raise VectorValidationError(msg)\n        seen_ids.add(vector_id)\n        ids.append(vector_id)\n        vectors.append(row)\n\n    if not ids:\n        msg = \"Vector payload must contain at least one record\"\n        raise VectorValidationError(msg)\n\n    matrix_untyped = np.asarray(vectors, dtype=np.float32)\n    matrix_contiguous: VectorMatrix = np.ascontiguousarray(matrix_untyped, dtype=np.float32)\n    return VectorBatch(ids=tuple(ids), matrix=matrix_contiguous)\n</code></pre>"},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_commonvector_typesvalidate_vector_batch","title":"kgfoundry_common.vector_types.validate_vector_batch","text":""},{"location":"modules/kgfoundry_common.vector_types/#kgfoundry_common.vector_types.validate_vector_batch","title":"<code>kgfoundry_common.vector_types.validate_vector_batch(batch)</code>","text":"<p>Return <code>batch</code> after re-validating matrix invariants.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>VectorBatch</code> <p>Candidate batch to validate.</p> required <p>Returns:</p> Type Description <code>VectorBatch</code> <p>The same batch once validation succeeds.</p> <p>Raises:</p> Type Description <code>VectorValidationError</code> <p>If the batch has mismatched ids or inconsistent vector dimensions.</p> Source code in <code>src/kgfoundry_common/vector_types.py</code> <pre><code>def validate_vector_batch(batch: VectorBatch) -&gt; VectorBatch:\n    \"\"\"Return ``batch`` after re-validating matrix invariants.\n\n    Parameters\n    ----------\n    batch : VectorBatch\n        Candidate batch to validate.\n\n    Returns\n    -------\n    VectorBatch\n        The same batch once validation succeeds.\n\n    Raises\n    ------\n    VectorValidationError\n        If the batch has mismatched ids or inconsistent vector dimensions.\n    \"\"\"\n    matrix = assert_vector_matrix(batch.matrix)\n    if matrix.shape[0] != len(batch.ids):\n        msg = (\n            \"Vector id count must match matrix row count: \"\n            f\"{len(batch.ids)} ids vs {matrix.shape[0]} rows\"\n        )\n        raise VectorValidationError(msg)\n    if matrix.shape[1] == 0:\n        msg = \"Vector dimensionality must be greater than zero\"\n        raise VectorValidationError(msg)\n    if len(set(batch.ids)) != len(batch.ids):\n        msg = \"Vector ids must be unique\"\n        raise VectorValidationError(msg)\n    return batch\n</code></pre>"},{"location":"modules/linking.calibration/","title":"linking.calibration","text":""},{"location":"modules/linking.calibration/#linkingcalibration","title":"linking.calibration","text":"<p>Placeholder calibration utilities for the linking package</p> <p>:material-source-repository: View source</p>"},{"location":"modules/linking.calibration/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"linking.calibration__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatalinking.calibration code <p>See the full diagram: linking.calibration</p>"},{"location":"modules/linking.calibration/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>linking.calibration.isotonic_calibrate</li> </ul>"},{"location":"modules/linking.calibration/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p>"},{"location":"modules/linking.calibration/#contents","title":"Contents","text":""},{"location":"modules/linking.calibration/#linkingcalibrationisotonic_calibrate","title":"linking.calibration.isotonic_calibrate","text":""},{"location":"modules/linking.calibration/#linking.calibration.isotonic_calibrate","title":"<code>linking.calibration.isotonic_calibrate(pairs)</code>","text":"<p>Return placeholder isotonic calibration parameters for linking scores.</p> <p>This function is a placeholder for future isotonic regression calibration functionality. Currently returns a dummy calibration dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>pairs</code> <code>list[tuple[float, int]]</code> <p>List of (score, label) pairs for calibration training.</p> required <p>Returns:</p> Type Description <code>dict[str, object]</code> <p>Dictionary with calibration parameters (currently placeholder).</p> Source code in <code>src/linking/calibration.py</code> <pre><code>def isotonic_calibrate(pairs: list[tuple[float, int]]) -&gt; dict[str, object]:\n    \"\"\"Return placeholder isotonic calibration parameters for linking scores.\n\n    This function is a placeholder for future isotonic regression\n    calibration functionality. Currently returns a dummy calibration\n    dictionary.\n\n    Parameters\n    ----------\n    pairs : list[tuple[float, int]]\n        List of (score, label) pairs for calibration training.\n\n    Returns\n    -------\n    dict[str, object]\n        Dictionary with calibration parameters (currently placeholder).\n    \"\"\"\n    # NOTE: fit isotonic regression parameters when calibrator is implemented\n    del pairs  # placeholder until calibration logic is wired\n    return {\"kind\": \"isotonic\", \"params\": []}\n</code></pre>"},{"location":"modules/linking.linker/","title":"linking.linker","text":""},{"location":"modules/linking.linker/#linkinglinker","title":"linking.linker","text":"<p>Linking orchestrations and scoring helpers</p> <p>:material-source-repository: View source</p>"},{"location":"modules/linking.linker/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class Linker\n</code></pre>"},{"location":"modules/linking.linker/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"linking.linker__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatalinking.linker code <p>See the full diagram: linking.linker</p>"},{"location":"modules/linking.linker/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>linking.linker.Linker</li> </ul>"},{"location":"modules/linking.linker/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p>"},{"location":"modules/linking.linker/#contents","title":"Contents","text":""},{"location":"modules/linking.linker/#linkinglinkerlinker","title":"linking.linker.Linker","text":""},{"location":"modules/linking.linker/#linking.linker.Linker","title":"<code>linking.linker.Linker</code>","text":"<p>Placeholder class for linking orchestration and scoring.</p> <p>This class serves as a placeholder for future linking functionality that orchestrates concept linking and scoring operations. Implementation details will be added later.</p> Source code in <code>src/linking/linker.py</code> <pre><code>class Linker:\n    \"\"\"Placeholder class for linking orchestration and scoring.\n\n    This class serves as a placeholder for future linking functionality that orchestrates concept\n    linking and scoring operations. Implementation details will be added later.\n    \"\"\"\n</code></pre>"},{"location":"modules/linking/","title":"linking","text":""},{"location":"modules/linking/#linking","title":"linking","text":"<p>Entity linking calibration and production pipelines</p> <p>:material-source-repository: View source</p>"},{"location":"modules/linking/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"linking__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.navmap_types.NavMaplinking code <p>See the full diagram: linking</p>"},{"location":"modules/linking/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.navmap_types.NavMap</code></p>"},{"location":"modules/observability/","title":"observability","text":""},{"location":"modules/observability/#observability","title":"observability","text":"<p>Observability metrics and instrumentation helpers</p> <p>:material-source-repository: View source</p>"},{"location":"modules/observability/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"observability__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.navmap_types.NavMapobservability code <p>See the full diagram: observability</p>"},{"location":"modules/observability/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.navmap_types.NavMap</code></p>"},{"location":"modules/observability.metrics/","title":"observability.metrics","text":""},{"location":"modules/observability.metrics/#observabilitymetrics","title":"observability.metrics","text":"<p>Prometheus metrics shared across observability surfaces.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/observability.metrics/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"observability.metrics__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.prometheus.CounterLikekgfoundry_common.prometheus.HistogramLikekgfoundry_common.prometheus.build_counterkgfoundry_common.prometheus.build_histogramtyping.TYPE_CHECKINGobservability.metrics code <p>See the full diagram: observability.metrics</p>"},{"location":"modules/observability.metrics/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.prometheus.CounterLike</code>, <code>kgfoundry_common.prometheus.HistogramLike</code>, <code>kgfoundry_common.prometheus.build_counter</code>, <code>kgfoundry_common.prometheus.build_histogram</code>, <code>typing.TYPE_CHECKING</code></p>"},{"location":"modules/ontology.catalog/","title":"ontology.catalog","text":""},{"location":"modules/ontology.catalog/#ontologycatalog","title":"ontology.catalog","text":"<p>Utility catalogue for lightweight ontology lookups.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/ontology.catalog/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class Concept\n    class OntologyCatalog\n</code></pre>"},{"location":"modules/ontology.catalog/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"ontology.catalog__future__.annotationsdataclasses.dataclasskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.problem_details.JsonValuetyping.TYPE_CHECKINGontology.catalog code <p>See the full diagram: ontology.catalog</p>"},{"location":"modules/ontology.catalog/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>ontology.catalog.Concept</li> <li>ontology.catalog.OntologyCatalog</li> </ul>"},{"location":"modules/ontology.catalog/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>dataclasses.dataclass</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.problem_details.JsonValue</code>, <code>typing.TYPE_CHECKING</code></p>"},{"location":"modules/ontology.catalog/#contents","title":"Contents","text":""},{"location":"modules/ontology.catalog/#ontologycatalogconcept","title":"ontology.catalog.Concept","text":""},{"location":"modules/ontology.catalog/#ontology.catalog.Concept","title":"<code>ontology.catalog.Concept</code>  <code>dataclass</code>","text":"<p>Knowledge graph concept representation.</p> <p>Represents a concept in the ontology catalog with an identifier and optional human-readable label.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Unique concept identifier (typically a URN).</p> required <code>label</code> <code>str | None</code> <p>Human-readable label for the concept. Defaults to None.</p> <code>None</code> Source code in <code>src/ontology/catalog.py</code> <pre><code>@dataclass\nclass Concept:\n    \"\"\"Knowledge graph concept representation.\n\n    Represents a concept in the ontology catalog with an identifier\n    and optional human-readable label.\n\n    Parameters\n    ----------\n    id : str\n        Unique concept identifier (typically a URN).\n    label : str | None, optional\n        Human-readable label for the concept. Defaults to None.\n    \"\"\"\n\n    id: str\n    label: str | None = None\n</code></pre>"},{"location":"modules/ontology.catalog/#ontologycatalogontologycatalog","title":"ontology.catalog.OntologyCatalog","text":""},{"location":"modules/ontology.catalog/#ontology.catalog.OntologyCatalog","title":"<code>ontology.catalog.OntologyCatalog</code>","text":"<p>Utility catalog for lightweight ontology lookups.</p> <p>Provides a simple in-memory catalog for querying knowledge graph concepts. Supports neighbor traversal and concept hydration.</p> <p>Parameters:</p> Name Type Description Default <code>concepts</code> <code>list[Concept]</code> <p>List of concepts to include in the catalog.</p> required Source code in <code>src/ontology/catalog.py</code> <pre><code>class OntologyCatalog:\n    \"\"\"Utility catalog for lightweight ontology lookups.\n\n    Provides a simple in-memory catalog for querying knowledge graph\n    concepts. Supports neighbor traversal and concept hydration.\n\n    Parameters\n    ----------\n    concepts : list[Concept]\n        List of concepts to include in the catalog.\n    \"\"\"\n\n    def __init__(self, concepts: list[Concept]) -&gt; None:\n        \"\"\"Initialize the ontology catalog with concepts.\n\n        Builds an internal index mapping concept IDs to concept objects\n        for fast lookup.\n\n        Parameters\n        ----------\n        concepts : list[Concept]\n            List of concepts to include in the catalog.\n        \"\"\"\n        self.by_id = {concept.id: concept for concept in concepts}\n\n    def neighbors(self, concept_id: str, depth: int = 1) -&gt; set[str]:\n        \"\"\"Return related concept identifiers up to the requested depth.\n\n        Parameters\n        ----------\n        concept_id : str\n            Concept identifier to find neighbors for.\n        depth : int, optional\n            Maximum depth to traverse. Defaults to 1.\n\n        Returns\n        -------\n        set[str]\n            Set of related concept identifiers.\n        \"\"\"\n        if depth &lt; 1:\n            return set()\n        concept = self.by_id.get(concept_id)\n        if concept is None:\n            return set()\n        # Relationship edges are not yet modelled; return the seed concept for now so the\n        # method remains total while we flesh out the backing data.\n        return {concept.id}\n\n    def hydrate(self, concept_id: str) -&gt; dict[str, JsonValue]:\n        \"\"\"Return a JSON-serialisable view of the concept metadata.\n\n        Parameters\n        ----------\n        concept_id : str\n            Concept identifier to hydrate.\n\n        Returns\n        -------\n        dict[str, JsonValue]\n            JSON-serializable dictionary of concept metadata.\n        \"\"\"\n        concept = self.by_id.get(concept_id)\n        if concept is None:\n            return {}\n        payload: dict[str, JsonValue] = {\"id\": concept.id}\n        if concept.label is not None:\n            payload[\"label\"] = concept.label\n        return payload\n</code></pre>"},{"location":"modules/ontology.catalog/#ontology.catalog.OntologyCatalog.__init__","title":"<code>__init__(concepts)</code>","text":"<p>Initialize the ontology catalog with concepts.</p> <p>Builds an internal index mapping concept IDs to concept objects for fast lookup.</p> <p>Parameters:</p> Name Type Description Default <code>concepts</code> <code>list[Concept]</code> <p>List of concepts to include in the catalog.</p> required Source code in <code>src/ontology/catalog.py</code> <pre><code>def __init__(self, concepts: list[Concept]) -&gt; None:\n    \"\"\"Initialize the ontology catalog with concepts.\n\n    Builds an internal index mapping concept IDs to concept objects\n    for fast lookup.\n\n    Parameters\n    ----------\n    concepts : list[Concept]\n        List of concepts to include in the catalog.\n    \"\"\"\n    self.by_id = {concept.id: concept for concept in concepts}\n</code></pre>"},{"location":"modules/ontology.catalog/#ontology.catalog.OntologyCatalog.hydrate","title":"<code>hydrate(concept_id)</code>","text":"<p>Return a JSON-serialisable view of the concept metadata.</p> <p>Parameters:</p> Name Type Description Default <code>concept_id</code> <code>str</code> <p>Concept identifier to hydrate.</p> required <p>Returns:</p> Type Description <code>dict[str, JsonValue]</code> <p>JSON-serializable dictionary of concept metadata.</p> Source code in <code>src/ontology/catalog.py</code> <pre><code>def hydrate(self, concept_id: str) -&gt; dict[str, JsonValue]:\n    \"\"\"Return a JSON-serialisable view of the concept metadata.\n\n    Parameters\n    ----------\n    concept_id : str\n        Concept identifier to hydrate.\n\n    Returns\n    -------\n    dict[str, JsonValue]\n        JSON-serializable dictionary of concept metadata.\n    \"\"\"\n    concept = self.by_id.get(concept_id)\n    if concept is None:\n        return {}\n    payload: dict[str, JsonValue] = {\"id\": concept.id}\n    if concept.label is not None:\n        payload[\"label\"] = concept.label\n    return payload\n</code></pre>"},{"location":"modules/ontology.catalog/#ontology.catalog.OntologyCatalog.neighbors","title":"<code>neighbors(concept_id, depth=1)</code>","text":"<p>Return related concept identifiers up to the requested depth.</p> <p>Parameters:</p> Name Type Description Default <code>concept_id</code> <code>str</code> <p>Concept identifier to find neighbors for.</p> required <code>depth</code> <code>int</code> <p>Maximum depth to traverse. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of related concept identifiers.</p> Source code in <code>src/ontology/catalog.py</code> <pre><code>def neighbors(self, concept_id: str, depth: int = 1) -&gt; set[str]:\n    \"\"\"Return related concept identifiers up to the requested depth.\n\n    Parameters\n    ----------\n    concept_id : str\n        Concept identifier to find neighbors for.\n    depth : int, optional\n        Maximum depth to traverse. Defaults to 1.\n\n    Returns\n    -------\n    set[str]\n        Set of related concept identifiers.\n    \"\"\"\n    if depth &lt; 1:\n        return set()\n    concept = self.by_id.get(concept_id)\n    if concept is None:\n        return set()\n    # Relationship edges are not yet modelled; return the seed concept for now so the\n    # method remains total while we flesh out the backing data.\n    return {concept.id}\n</code></pre>"},{"location":"modules/ontology.loader/","title":"ontology.loader","text":""},{"location":"modules/ontology.loader/#ontologyloader","title":"ontology.loader","text":"<p>Ontology ingest and caching helpers</p> <p>:material-source-repository: View source</p>"},{"location":"modules/ontology.loader/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class OntologyLoader\n</code></pre>"},{"location":"modules/ontology.loader/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"ontology.loader__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadataontology.loader code <p>See the full diagram: ontology.loader</p>"},{"location":"modules/ontology.loader/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>ontology.loader.OntologyLoader</li> </ul>"},{"location":"modules/ontology.loader/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p>"},{"location":"modules/ontology.loader/#contents","title":"Contents","text":""},{"location":"modules/ontology.loader/#ontologyloaderontologyloader","title":"ontology.loader.OntologyLoader","text":""},{"location":"modules/ontology.loader/#ontology.loader.OntologyLoader","title":"<code>ontology.loader.OntologyLoader</code>","text":"<p>Placeholder class for ontology loading functionality.</p> <p>This class serves as a placeholder for future ontology ingestion and caching helpers. Implementation details will be added later.</p> Source code in <code>src/ontology/loader.py</code> <pre><code>class OntologyLoader:\n    \"\"\"Placeholder class for ontology loading functionality.\n\n    This class serves as a placeholder for future ontology ingestion and caching helpers.\n    Implementation details will be added later.\n    \"\"\"\n</code></pre>"},{"location":"modules/ontology/","title":"ontology","text":""},{"location":"modules/ontology/#ontology","title":"ontology","text":"<p>Ontology loading and lookup helpers</p> <p>:material-source-repository: View source</p>"},{"location":"modules/ontology/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"ontology__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.navmap_types.NavMapontology code <p>See the full diagram: ontology</p>"},{"location":"modules/ontology/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.navmap_types.NavMap</code></p>"},{"location":"modules/orchestration.cli/","title":"orchestration.cli","text":""},{"location":"modules/orchestration.cli/#orchestrationcli","title":"orchestration.cli","text":"<p>Prefect command-line entrypoints for orchestration flows</p> <p>:material-source-repository: View source</p>"},{"location":"modules/orchestration.cli/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class BM25BuildConfig\n    class FaissIndexConfig\n    class _BM25Builder\n    class Protocol\n    Protocol &lt;|-- _BM25Builder\n    class _UvicornRun\n    Protocol &lt;|-- _UvicornRun\n</code></pre>"},{"location":"modules/orchestration.cli/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"orchestration.cli__future__.annotationscollections.abc.Callablecollections.abc.Iterablecollections.abc.Mappingcollections.abc.Sequencecontextlibdataclasses.dataclassimportlibjsonkgfoundry.embeddings_sparse.bm25.get_bm25kgfoundry_common.errors.ConfigurationErrorkgfoundry_common.errors.IndexBuildErrorkgfoundry_common.jsonschema_utils.Draft202012ValidatorProtocolkgfoundry_common.jsonschema_utils.ValidationErrorProtocolkgfoundry_common.jsonschema_utils.create_draft202012_validatorkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.problem_details.ProblemDetailskgfoundry_common.problem_details.build_configuration_problemkgfoundry_common.problem_details.build_problem_detailskgfoundry_common.problem_details.render_problemkgfoundry_common.schema_helpers.load_schemakgfoundry_common.types.JsonValuekgfoundry_common.vector_types.VectorBatchkgfoundry_common.vector_types.VectorValidationErrorkgfoundry_common.vector_types.coerce_vector_batchloggingorchestration.config.IndexCliConfigorchestration.flows.e2e_floworchestration.safe_picklepathlib.Pathtypertypes.ModuleTypetyping.Annotatedtyping.Protocoltyping.TYPE_CHECKINGtyping.castuuid.uuid4orchestration.cli code <p>See the full diagram: orchestration.cli</p>"},{"location":"modules/orchestration.cli/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>orchestration.cli.BM25BuildConfig</li> <li>orchestration.cli.FaissIndexConfig</li> <li>orchestration.cli._BM25Builder</li> <li>orchestration.cli._build_bm25_index</li> <li>orchestration.cli._build_vector_problem_details</li> <li>orchestration.cli._error_sort_key</li> </ul>"},{"location":"modules/orchestration.cli/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Callable</code>, <code>collections.abc.Iterable</code>, <code>collections.abc.Mapping</code>, <code>collections.abc.Sequence</code>, <code>contextlib</code>, <code>dataclasses.dataclass</code>, <code>importlib</code>, <code>json</code>, <code>kgfoundry.embeddings_sparse.bm25.get_bm25</code>, <code>kgfoundry_common.errors.ConfigurationError</code>, <code>kgfoundry_common.errors.IndexBuildError</code>, <code>kgfoundry_common.jsonschema_utils.Draft202012ValidatorProtocol</code>, <code>kgfoundry_common.jsonschema_utils.ValidationErrorProtocol</code>, <code>kgfoundry_common.jsonschema_utils.create_draft202012_validator</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.problem_details.ProblemDetails</code>, <code>kgfoundry_common.problem_details.build_configuration_problem</code>, <code>kgfoundry_common.problem_details.build_problem_details</code>, <code>kgfoundry_common.problem_details.render_problem</code>, <code>kgfoundry_common.schema_helpers.load_schema</code>, <code>kgfoundry_common.types.JsonValue</code>, <code>kgfoundry_common.vector_types.VectorBatch</code>, <code>kgfoundry_common.vector_types.VectorValidationError</code>, <code>kgfoundry_common.vector_types.coerce_vector_batch</code>, <code>logging</code>, <code>orchestration.config.IndexCliConfig</code>, <code>orchestration.flows.e2e_flow</code>, orchestration.safe_pickle, <code>pathlib.Path</code>, <code>typer</code>, <code>types.ModuleType</code>, <code>typing.Annotated</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code>, <code>uuid.uuid4</code></p>"},{"location":"modules/orchestration.cli/#related-api-operations","title":"Related API operations","text":"<p><code>cli.api</code> (orchestration-cli \u00b7 CLI Spec), <code>cli.e2e</code> (orchestration-cli \u00b7 CLI Spec), <code>cli.index_bm25</code> (orchestration-cli \u00b7 CLI Spec), <code>cli.index_faiss</code> (orchestration-cli \u00b7 CLI Spec)</p>"},{"location":"modules/orchestration.cli/#contents","title":"Contents","text":""},{"location":"modules/orchestration.cli/#orchestrationclibm25buildconfig","title":"orchestration.cli.BM25BuildConfig","text":""},{"location":"modules/orchestration.cli/#orchestration.cli.BM25BuildConfig","title":"<code>orchestration.cli.BM25BuildConfig</code>  <code>dataclass</code>","text":"<p>Configuration for BM25 index building.</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>@dataclass(frozen=True)\nclass BM25BuildConfig:\n    \"\"\"Configuration for BM25 index building.\"\"\"\n\n    chunks_path: str\n    backend: str\n    index_dir: str\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationclifaissindexconfig","title":"orchestration.cli.FaissIndexConfig","text":""},{"location":"modules/orchestration.cli/#orchestration.cli.FaissIndexConfig","title":"<code>orchestration.cli.FaissIndexConfig</code>  <code>dataclass</code>","text":"<p>Configuration for FAISS index building.</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>@dataclass(frozen=True)\nclass FaissIndexConfig:\n    \"\"\"Configuration for FAISS index building.\"\"\"\n\n    dense_vectors: str\n    index_path: str\n    factory: str\n    metric: str\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcli_bm25builder","title":"orchestration.cli._BM25Builder","text":"<p>Bases: Protocol</p>"},{"location":"modules/orchestration.cli/#orchestration.cli._BM25Builder","title":"<code>orchestration.cli._BM25Builder</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/orchestration/cli.py</code> <pre><code>class _BM25Builder(Protocol):\n    def build(self, docs: Iterable[tuple[str, dict[str, str]]]) -&gt; None:\n        \"\"\"Build BM25 index from documents.\n\n        Parameters\n        ----------\n        docs : Iterable[tuple[str, dict[str, str]]]\n            Iterable of (document_id, document_fields) tuples.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestration.cli._BM25Builder.build","title":"<code>build(docs)</code>","text":"<p>Build BM25 index from documents.</p> <p>Parameters:</p> Name Type Description Default <code>docs</code> <code>Iterable[tuple[str, dict[str, str]]]</code> <p>Iterable of (document_id, document_fields) tuples.</p> required Source code in <code>src/orchestration/cli.py</code> <pre><code>def build(self, docs: Iterable[tuple[str, dict[str, str]]]) -&gt; None:\n    \"\"\"Build BM25 index from documents.\n\n    Parameters\n    ----------\n    docs : Iterable[tuple[str, dict[str, str]]]\n        Iterable of (document_id, document_fields) tuples.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcli_uvicornrun","title":"orchestration.cli._UvicornRun","text":"<p>Bases: Protocol</p>"},{"location":"modules/orchestration.cli/#orchestration.cli._UvicornRun","title":"<code>orchestration.cli._UvicornRun</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/orchestration/cli.py</code> <pre><code>class _UvicornRun(Protocol):\n    def __call__(self, app: str, *, host: str, port: int, reload: bool = False) -&gt; None:\n        \"\"\"Run uvicorn server.\n\n        Parameters\n        ----------\n        app : str\n            Application module path.\n        host : str\n            Host to bind to.\n        port : int\n            Port to bind to.\n        reload : bool, optional\n            Whether to enable auto-reload.\n            Defaults to False.\n        \"\"\"\n        del self, app, host, port, reload\n        raise NotImplementedError\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestration.cli._UvicornRun.__call__","title":"<code>__call__(app, *, host, port, reload=False)</code>","text":"<p>Run uvicorn server.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <code>str</code> <p>Application module path.</p> required <code>host</code> <code>str</code> <p>Host to bind to.</p> required <code>port</code> <code>int</code> <p>Port to bind to.</p> required <code>reload</code> <code>bool</code> <p>Whether to enable auto-reload. Defaults to False.</p> <code>False</code> Source code in <code>src/orchestration/cli.py</code> <pre><code>def __call__(self, app: str, *, host: str, port: int, reload: bool = False) -&gt; None:\n    \"\"\"Run uvicorn server.\n\n    Parameters\n    ----------\n    app : str\n        Application module path.\n    host : str\n        Host to bind to.\n    port : int\n        Port to bind to.\n    reload : bool, optional\n        Whether to enable auto-reload.\n        Defaults to False.\n    \"\"\"\n    del self, app, host, port, reload\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcli_build_bm25_index","title":"orchestration.cli._build_bm25_index","text":""},{"location":"modules/orchestration.cli/#orchestration.cli._build_bm25_index","title":"<code>orchestration.cli._build_bm25_index(config)</code>","text":"<p>Build BM25 index from configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>BM25BuildConfig</code> <p>Build configuration.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If index building fails after attempting both backends.</p> Notes <p>Propagates :class:<code>FileNotFoundError</code>, :class:<code>TypeError</code>, and :class:<code>json.JSONDecodeError</code> from dataset loading helpers when the source data is invalid.</p> <p>Returns:</p> Type Description <code>str</code> <p>Backend identifier that successfully produced the index.</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def _build_bm25_index(config: BM25BuildConfig) -&gt; str:\n    \"\"\"Build BM25 index from configuration.\n\n    Parameters\n    ----------\n    config : BM25BuildConfig\n        Build configuration.\n\n    Raises\n    ------\n    RuntimeError\n        If index building fails after attempting both backends.\n\n    Notes\n    -----\n    Propagates :class:`FileNotFoundError`, :class:`TypeError`, and\n    :class:`json.JSONDecodeError` from dataset loading helpers when the source\n    data is invalid.\n\n    Returns\n    -------\n    str\n        Backend identifier that successfully produced the index.\n    \"\"\"\n    docs = _load_bm25_documents(config.chunks_path)\n    builder, backend_used = _instantiate_bm25_builder(config)\n\n    try:\n        builder.build(docs)\n    except RuntimeError as exc:\n        if backend_used != \"lucene\":\n            raise\n        logger.warning(\n            \"Lucene backend failed during build; retrying with pure backend\",\n            extra={\n                \"operation\": \"index_bm25\",\n                \"error\": type(exc).__name__,\n                \"backend\": backend_used,\n                \"fallback_backend\": \"pure\",\n                \"phase\": \"build\",\n            },\n            exc_info=exc,\n        )\n        fallback = cast(\n            \"_BM25Builder\",\n            get_bm25(\"pure\", config.index_dir, k1=0.9, b=0.4, load_existing=False),\n        )\n        try:\n            fallback.build(docs)\n        except Exception as fallback_exc:  # pragma: no cover - defensive fallback path\n            msg = \"Failed to build BM25 index with fallback backend\"\n            raise RuntimeError(msg) from fallback_exc\n        backend_used = \"pure\"\n    except (AttributeError, ValueError, KeyError) as exc:\n        msg = f\"Failed to build BM25 index: {exc}\"\n        raise RuntimeError(msg) from exc\n\n    return backend_used\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcli_build_vector_problem_details","title":"orchestration.cli._build_vector_problem_details","text":""},{"location":"modules/orchestration.cli/#orchestration.cli._build_vector_problem_details","title":"<code>orchestration.cli._build_vector_problem_details(*, detail, correlation_id, vector_path, errors, instance)</code>","text":"<p>Create Problem Details payload for vector ingestion failures.</p> <p>Parameters:</p> Name Type Description Default <code>detail</code> <code>str</code> <p>Human-readable error detail.</p> required <code>correlation_id</code> <code>str</code> <p>Correlation identifier for tracing.</p> required <code>vector_path</code> <code>str</code> <p>Path to the vector file that failed.</p> required <code>errors</code> <code>Sequence[str]</code> <p>Validation error messages.</p> required <code>instance</code> <code>str</code> <p>Problem instance URI.</p> required <p>Returns:</p> Type Description <code>ProblemDetails</code> <p>RFC 9457 Problem Details payload.</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def _build_vector_problem_details(\n    *,\n    detail: str,\n    correlation_id: str,\n    vector_path: str,\n    errors: Sequence[str],\n    instance: str,\n) -&gt; ProblemDetails:\n    \"\"\"Create Problem Details payload for vector ingestion failures.\n\n    Parameters\n    ----------\n    detail : str\n        Human-readable error detail.\n    correlation_id : str\n        Correlation identifier for tracing.\n    vector_path : str\n        Path to the vector file that failed.\n    errors : Sequence[str]\n        Validation error messages.\n    instance : str\n        Problem instance URI.\n\n    Returns\n    -------\n    ProblemDetails\n        RFC 9457 Problem Details payload.\n    \"\"\"\n    validation_errors = cast(\"list[JsonValue]\", list(errors))\n    errors_payload: dict[str, JsonValue] = {\n        \"schema_id\": _VECTOR_SCHEMA_ID,\n        \"vector_path\": vector_path,\n        \"validation_errors\": validation_errors,\n    }\n    problem_extensions: dict[str, JsonValue] = {\n        \"correlation_id\": correlation_id,\n        \"errors\": errors_payload,\n    }\n\n    return build_problem_details(\n        problem_type=_VECTOR_PROBLEM_TYPE,\n        title=\"Vector payload failed validation\",\n        status=422,\n        detail=detail,\n        instance=instance,\n        extensions=problem_extensions,\n    )\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcli_error_sort_key","title":"orchestration.cli._error_sort_key","text":""},{"location":"modules/orchestration.cli/#orchestration.cli._error_sort_key","title":"<code>orchestration.cli._error_sort_key(error)</code>","text":"<p>Build a sortable key for JSON Schema validation errors.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>ValidationErrorProtocol</code> <p>Validation error to extract path from.</p> required <p>Returns:</p> Type Description <code>tuple[str, ...]</code> <p>Sortable tuple of path components.</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def _error_sort_key(error: ValidationErrorProtocol) -&gt; tuple[str, ...]:\n    \"\"\"Build a sortable key for JSON Schema validation errors.\n\n    Parameters\n    ----------\n    error : ValidationErrorProtocol\n        Validation error to extract path from.\n\n    Returns\n    -------\n    tuple[str, ...]\n        Sortable tuple of path components.\n    \"\"\"\n    return tuple(str(part) for part in error.path)\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcli_extract_bm25_document","title":"orchestration.cli._extract_bm25_document","text":""},{"location":"modules/orchestration.cli/#orchestration.cli._extract_bm25_document","title":"<code>orchestration.cli._extract_bm25_document(record)</code>","text":"<p>Extract BM25 document from a record mapping.</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>Mapping[str, object]</code> <p>Record to extract from.</p> required <p>Returns:</p> Type Description <code>tuple[str, dict[str, str]] | None</code> <p>(chunk_id, fields_dict) or None if record is invalid.</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def _extract_bm25_document(record: Mapping[str, object]) -&gt; tuple[str, dict[str, str]] | None:\n    \"\"\"Extract BM25 document from a record mapping.\n\n    Parameters\n    ----------\n    record : Mapping[str, object]\n        Record to extract from.\n\n    Returns\n    -------\n    tuple[str, dict[str, str]] | None\n        (chunk_id, fields_dict) or None if record is invalid.\n    \"\"\"\n    chunk_id = record.get(\"chunk_id\")\n    if not isinstance(chunk_id, str):\n        return None\n    title = record.get(\"title\")\n    section = record.get(\"section\")\n    text = record.get(\"text\")\n    return (\n        chunk_id,\n        {\n            \"title\": title if isinstance(title, str) else \"\",\n            \"section\": section if isinstance(section, str) else \"\",\n            \"body\": text if isinstance(text, str) else \"\",\n        },\n    )\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcli_get_bm25_index_path","title":"orchestration.cli._get_bm25_index_path","text":""},{"location":"modules/orchestration.cli/#orchestration.cli._get_bm25_index_path","title":"<code>orchestration.cli._get_bm25_index_path(index_dir, backend)</code>","text":"<p>Determine BM25 index file path based on backend.</p> <p>Parameters:</p> Name Type Description Default <code>index_dir</code> <code>Path</code> <p>Base index directory.</p> required <code>backend</code> <code>str</code> <p>Backend type: \"lucene\" or \"pure\".</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Expected index file path.</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def _get_bm25_index_path(index_dir: Path, backend: str) -&gt; Path:\n    \"\"\"Determine BM25 index file path based on backend.\n\n    Parameters\n    ----------\n    index_dir : Path\n        Base index directory.\n    backend : str\n        Backend type: \"lucene\" or \"pure\".\n\n    Returns\n    -------\n    Path\n        Expected index file path.\n    \"\"\"\n    return index_dir / \"pure_bm25.pkl\" if backend == \"pure\" else index_dir / \"bm25_index\"\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcli_index_bm25_cli","title":"orchestration.cli._index_bm25_cli","text":""},{"location":"modules/orchestration.cli/#orchestration.cli._index_bm25_cli","title":"<code>orchestration.cli._index_bm25_cli(chunks_parquet, backend='lucene', index_dir='./_indices/bm25')</code>","text":"Source code in <code>src/orchestration/cli.py</code> <pre><code>def _index_bm25_cli(\n    chunks_parquet: Annotated[str, typer.Argument(..., help=\"Path to Parquet/JSONL with chunks\")],\n    backend: Annotated[str, typer.Option(help=\"lucene|pure\", show_default=True)] = \"lucene\",\n    index_dir: Annotated[\n        str,\n        typer.Option(help=\"Output index directory\", show_default=True),\n    ] = \"./_indices/bm25\",\n) -&gt; None:\n    index_bm25(chunks_parquet, backend, index_dir)\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcli_instantiate_bm25_builder","title":"orchestration.cli._instantiate_bm25_builder","text":""},{"location":"modules/orchestration.cli/#orchestration.cli._instantiate_bm25_builder","title":"<code>orchestration.cli._instantiate_bm25_builder(config)</code>","text":"<p>Instantiate a BM25 builder, falling back to pure backend if Lucene fails.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>BM25BuildConfig</code> <p>Build configuration.</p> required <p>Returns:</p> Type Description <code>tuple[_BM25Builder, str]</code> <p>(builder instance, backend identifier).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If builder instantiation fails and fallback is unavailable.</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def _instantiate_bm25_builder(config: BM25BuildConfig) -&gt; tuple[_BM25Builder, str]:\n    \"\"\"Instantiate a BM25 builder, falling back to pure backend if Lucene fails.\n\n    Parameters\n    ----------\n    config : BM25BuildConfig\n        Build configuration.\n\n    Returns\n    -------\n    tuple[_BM25Builder, str]\n        (builder instance, backend identifier).\n\n    Raises\n    ------\n    RuntimeError\n        If builder instantiation fails and fallback is unavailable.\n    \"\"\"\n    requested_backend = config.backend.strip().lower()\n    try:\n        builder = cast(\n            \"_BM25Builder\",\n            get_bm25(\n                requested_backend,\n                config.index_dir,\n                k1=0.9,\n                b=0.4,\n                load_existing=False,\n            ),\n        )\n    except RuntimeError as exc:\n        if requested_backend != \"lucene\":\n            raise\n        logger.warning(\n            \"Lucene backend unavailable during instantiation; using pure backend\",\n            extra={\n                \"operation\": \"index_bm25\",\n                \"error\": type(exc).__name__,\n                \"backend\": requested_backend,\n                \"fallback_backend\": \"pure\",\n                \"phase\": \"instantiate\",\n            },\n            exc_info=exc,\n        )\n        fallback_builder = cast(\n            \"_BM25Builder\",\n            get_bm25(\"pure\", config.index_dir, k1=0.9, b=0.4, load_existing=False),\n        )\n        return fallback_builder, \"pure\"\n    else:\n        return builder, requested_backend\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcli_load_bm25_documents","title":"orchestration.cli._load_bm25_documents","text":""},{"location":"modules/orchestration.cli/#orchestration.cli._load_bm25_documents","title":"<code>orchestration.cli._load_bm25_documents(chunks_path)</code>","text":"<p>Load BM25 documents from Parquet or JSONL file.</p> <p>Parameters:</p> Name Type Description Default <code>chunks_path</code> <code>str</code> <p>Path to Parquet or JSONL file.</p> required <p>Returns:</p> Type Description <code>list[tuple[str, dict[str, str]]]</code> <p>List of (chunk_id, fields_dict) tuples.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If dataset format is invalid.</p> Notes <p>Propagates :class:<code>FileNotFoundError</code> when the input path is missing and :class:<code>json.JSONDecodeError</code> for malformed JSON payloads in non-JSONL inputs. Invalid JSON lines in JSONL inputs are logged and skipped.</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def _load_bm25_documents(chunks_path: str) -&gt; list[tuple[str, dict[str, str]]]:\n    \"\"\"Load BM25 documents from Parquet or JSONL file.\n\n    Parameters\n    ----------\n    chunks_path : str\n        Path to Parquet or JSONL file.\n\n    Returns\n    -------\n    list[tuple[str, dict[str, str]]]\n        List of (chunk_id, fields_dict) tuples.\n\n    Raises\n    ------\n    TypeError\n        If dataset format is invalid.\n\n    Notes\n    -----\n    Propagates :class:`FileNotFoundError` when the input path is missing and\n    :class:`json.JSONDecodeError` for malformed JSON payloads in non-JSONL\n    inputs. Invalid JSON lines in JSONL inputs are logged and skipped.\n    \"\"\"\n    docs: list[tuple[str, dict[str, str]]] = []\n\n    if chunks_path.endswith(\".jsonl\"):\n        with Path(chunks_path).open(encoding=\"utf-8\") as fh:\n            for line in fh:\n                try:\n                    rec_obj: object = json.loads(line)\n                except json.JSONDecodeError as exc:\n                    logger.warning(\"Skipping invalid JSON line: %s\", exc)\n                    continue\n                if isinstance(rec_obj, Mapping):\n                    document = _extract_bm25_document(rec_obj)\n                    if document:\n                        docs.append(document)\n    else:\n        with Path(chunks_path).open(encoding=\"utf-8\") as fh:\n            raw_data: object = json.load(fh)\n        if not isinstance(raw_data, Sequence) or isinstance(raw_data, (str, bytes)):\n            msg = \"Chunk dataset must be a sequence of mapping objects\"\n            raise TypeError(msg)\n        for rec_obj in raw_data:\n            if isinstance(rec_obj, Mapping):\n                document = _extract_bm25_document(rec_obj)\n                if document:\n                    docs.append(document)\n\n    return docs\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcli_prepare_index_directory","title":"orchestration.cli._prepare_index_directory","text":""},{"location":"modules/orchestration.cli/#orchestration.cli._prepare_index_directory","title":"<code>orchestration.cli._prepare_index_directory(index_path)</code>","text":"<p>Create index output directory.</p> <p>Parameters:</p> Name Type Description Default <code>index_path</code> <code>str</code> <p>Path where index will be written.</p> required Notes <p>Propagates :class:<code>OSError</code> when directory creation fails.</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def _prepare_index_directory(index_path: str) -&gt; None:\n    \"\"\"Create index output directory.\n\n    Parameters\n    ----------\n    index_path : str\n        Path where index will be written.\n\n    Notes\n    -----\n    Propagates :class:`OSError` when directory creation fails.\n    \"\"\"\n    Path(index_path).parent.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcli_run_e2e_flow","title":"orchestration.cli._run_e2e_flow","text":""},{"location":"modules/orchestration.cli/#orchestration.cli._run_e2e_flow","title":"<code>orchestration.cli._run_e2e_flow()</code>","text":"<p>Safely invoke e2e_flow with type narrowing.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Stages from the e2e flow.</p> <p>Raises:</p> Type Description <code>Exit</code> <p>If e2e_flow is not available.</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def _run_e2e_flow() -&gt; list[str]:\n    \"\"\"Safely invoke e2e_flow with type narrowing.\n\n    Returns\n    -------\n    list[str]\n        Stages from the e2e flow.\n\n    Raises\n    ------\n    typer.Exit\n        If e2e_flow is not available.\n    \"\"\"\n    if _e2e_flow is None:\n        raise typer.Exit(code=1)\n    return _e2e_flow()  # Now properly typed via _flows_module.e2e_flow\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcli_validate_vector_payload","title":"orchestration.cli._validate_vector_payload","text":""},{"location":"modules/orchestration.cli/#orchestration.cli._validate_vector_payload","title":"<code>orchestration.cli._validate_vector_payload(payload)</code>","text":"<p>Validate vector ingestion payloads against the canonical schema.</p> <p>Parameters:</p> Name Type Description Default <code>payload</code> <code>object</code> <p>Payload to validate.</p> required <p>Raises:</p> Type Description <code>VectorValidationError</code> <p>If validation fails.</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def _validate_vector_payload(payload: object) -&gt; None:\n    \"\"\"Validate vector ingestion payloads against the canonical schema.\n\n    Parameters\n    ----------\n    payload : object\n        Payload to validate.\n\n    Raises\n    ------\n    VectorValidationError\n        If validation fails.\n    \"\"\"\n    validator = _vector_batch_validator()\n    errors_iter = validator.iter_errors(payload)\n    errors = sorted(errors_iter, key=_error_sort_key)\n    if not errors:\n        return\n\n    messages: list[str] = []\n    for error in errors[:_VECTOR_SCHEMA_ERROR_LIMIT]:\n        location = \"/\".join(str(part) for part in error.absolute_path) or \"&lt;root&gt;\"\n        messages.append(f\"{location}: {error.message}\")\n\n    if len(errors) &gt; _VECTOR_SCHEMA_ERROR_LIMIT:\n        remaining = len(errors) - _VECTOR_SCHEMA_ERROR_LIMIT\n        messages.append(f\"... {remaining} additional validation errors\")\n\n    raise VectorValidationError(messages[0], errors=messages)\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcli_vector_batch_validator","title":"orchestration.cli._vector_batch_validator","text":""},{"location":"modules/orchestration.cli/#orchestration.cli._vector_batch_validator","title":"<code>orchestration.cli._vector_batch_validator()</code>","text":"<p>Return a cached JSON Schema validator for vector ingestion payloads.</p> <p>Returns:</p> Type Description <code>Draft202012ValidatorProtocol</code> <p>Cached validator instance.</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def _vector_batch_validator() -&gt; Draft202012ValidatorProtocol:\n    \"\"\"Return a cached JSON Schema validator for vector ingestion payloads.\n\n    Returns\n    -------\n    Draft202012ValidatorProtocol\n        Cached validator instance.\n    \"\"\"\n    validator = _VECTOR_VALIDATOR_CACHE.get(\"validator\")\n    if validator is None:\n        schema = load_schema(_VECTOR_SCHEMA_PATH)\n        validator = create_draft202012_validator(cast(\"dict[str, object]\", schema))\n        _VECTOR_VALIDATOR_CACHE[\"validator\"] = validator\n    return validator\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcliapi","title":"orchestration.cli.api","text":""},{"location":"modules/orchestration.cli/#orchestration.cli.api","title":"<code>orchestration.cli.api(port=8080)</code>","text":"<p>Start FastAPI search service.</p> <p>Parameters:</p> Name Type Description Default <code>port</code> <code>int</code> <p>Port to bind to. Defaults to 8080.</p> <code>8080</code> <p>Raises:</p> Type Description <code>Exit</code> <p>If uvicorn is not available or entry point is missing (exit code 1).</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def api(port: int = 8080) -&gt; None:\n    \"\"\"Start FastAPI search service.\n\n    Parameters\n    ----------\n    port : int, optional\n        Port to bind to. Defaults to 8080.\n\n    Raises\n    ------\n    typer.Exit\n        If uvicorn is not available or entry point is missing (exit code 1).\n    \"\"\"\n    try:\n        uvicorn_module: ModuleType = importlib.import_module(\"uvicorn\")\n    except ImportError as exc:\n        typer.echo(\n            \"uvicorn is required to run the API server\",\n            err=True,\n        )\n        raise typer.Exit(code=1) from exc\n\n    module_attrs = cast(\"Mapping[str, object]\", vars(uvicorn_module))\n    run_attr = module_attrs.get(\"run\")\n    if not callable(run_attr):\n        typer.echo(\"uvicorn.run entry point not available\", err=True)\n        raise typer.Exit(code=1)\n    run_server = cast(\"_UvicornRun\", run_attr)\n    run_server(\"search_api.app:app\", host=\"127.0.0.1\", port=port, reload=False)\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationclie2e","title":"orchestration.cli.e2e","text":""},{"location":"modules/orchestration.cli/#orchestration.cli.e2e","title":"<code>orchestration.cli.e2e()</code>","text":"<p>Execute end-to-end orchestration pipeline.</p> <p>This command runs the complete e2e flow using Prefect orchestration. Requires Prefect to be installed.</p> <p>Raises:</p> Type Description <code>Exit</code> <p>If Prefect is not installed (exit code 1).</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def e2e() -&gt; None:\n    \"\"\"Execute end-to-end orchestration pipeline.\n\n    This command runs the complete e2e flow using Prefect orchestration.\n    Requires Prefect to be installed.\n\n    Raises\n    ------\n    typer.Exit\n        If Prefect is not installed (exit code 1).\n    \"\"\"\n    try:\n        stages = _run_e2e_flow()\n    except typer.Exit:\n        typer.echo(\n            \"Prefect is required for the e2e pipeline command. \"\n            \"Install it via `pip install -e '.[gpu]'` or add `prefect` manually.\",\n            err=True,\n        )\n        raise\n\n    for step in stages:\n        typer.echo(step)\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcliindex_bm25","title":"orchestration.cli.index_bm25","text":""},{"location":"modules/orchestration.cli/#orchestration.cli.index_bm25","title":"<code>orchestration.cli.index_bm25(chunks_parquet, backend='lucene', index_dir='./_indices/bm25')</code>","text":"<p>Build BM25 index from chunk data.</p> <p>This command builds a BM25 index from chunk data. The operation is idempotent: if an index already exists at the output directory, it will be rebuilt from scratch. No side effects occur beyond writing the index files.</p> <p>Parameters:</p> Name Type Description Default <code>chunks_parquet</code> <code>str</code> <p>Path to Parquet or JSONL file containing chunks.</p> required <code>backend</code> <code>str</code> <p>Backend to use: \"lucene\" or \"pure\". Defaults to \"lucene\".</p> <code>'lucene'</code> <code>index_dir</code> <code>str</code> <p>Output directory for the index. Defaults to \"./_indices/bm25\".</p> <code>'./_indices/bm25'</code> Notes <ul> <li>Idempotency: Running twice with identical inputs rebuilds the index.</li> <li>Retries: No automatic retries. On failure, check logs and re-run.</li> </ul> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the chunk dataset cannot be located.</p> <code>TypeError</code> <p>If the dataset format is invalid.</p> <code>JSONDecodeError</code> <p>If JSON chunk payloads are malformed.</p> <code>Exit</code> <p>If index building fails (exit code 1).</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def index_bm25(\n    chunks_parquet: Annotated[str, typer.Argument(..., help=\"Path to Parquet/JSONL with chunks\")],\n    backend: Annotated[str, typer.Option(help=\"lucene|pure\")] = \"lucene\",\n    index_dir: Annotated[str, typer.Option(help=\"Output index directory\")] = \"./_indices/bm25\",\n) -&gt; None:\n    \"\"\"Build BM25 index from chunk data.\n\n    This command builds a BM25 index from chunk data. The operation is\n    **idempotent**: if an index already exists at the output directory, it\n    will be rebuilt from scratch. No side effects occur beyond writing\n    the index files.\n\n    Parameters\n    ----------\n    chunks_parquet : str\n        Path to Parquet or JSONL file containing chunks.\n    backend : str, optional\n        Backend to use: \"lucene\" or \"pure\". Defaults to \"lucene\".\n    index_dir : str, optional\n        Output directory for the index. Defaults to \"./_indices/bm25\".\n\n    Notes\n    -----\n    - **Idempotency**: Running twice with identical inputs rebuilds the index.\n    - **Retries**: No automatic retries. On failure, check logs and re-run.\n\n    Raises\n    ------\n    FileNotFoundError\n        If the chunk dataset cannot be located.\n    TypeError\n        If the dataset format is invalid.\n    json.JSONDecodeError\n        If JSON chunk payloads are malformed.\n    typer.Exit\n        If index building fails (exit code 1).\n    \"\"\"\n    config = BM25BuildConfig(\n        chunks_path=chunks_parquet,\n        backend=backend,\n        index_dir=index_dir,\n    )\n\n    try:\n        _prepare_index_directory(config.index_dir)\n        logger.info(\n            \"Building BM25 index\",\n            extra={\n                \"operation\": \"index_bm25\",\n                \"backend\": backend,\n                \"chunks_path\": chunks_parquet,\n            },\n        )\n        backend_used = _build_bm25_index(config)\n        typer.echo(f\"BM25 index built at {config.index_dir} using backend={backend_used}\")\n        logger.info(\n            \"BM25 index build completed\",\n            extra={\n                \"operation\": \"index_bm25\",\n                \"backend\": backend_used,\n                \"path\": index_dir,\n                \"chunks_path\": chunks_parquet,\n            },\n        )\n    except FileNotFoundError as exc:\n        logger.exception(\n            \"Document loading failed\",\n            extra={\"operation\": \"index_bm25\", \"error\": type(exc).__name__},\n        )\n        typer.echo(f\"Error loading documents: {exc}\", err=True)\n        raise\n    except (TypeError, json.JSONDecodeError) as exc:\n        logger.exception(\n            \"Document loading failed\",\n            extra={\"operation\": \"index_bm25\", \"error\": type(exc).__name__},\n        )\n        typer.echo(f\"Error loading documents: {exc}\", err=True)\n        raise\n    except RuntimeError as exc:\n        logger.exception(\n            \"BM25 index build failed\",\n            extra={\"operation\": \"index_bm25\", \"error\": type(exc).__name__},\n        )\n        typer.echo(f\"Error building index: {exc}\", err=True)\n        raise typer.Exit(code=1) from exc\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcliindex_faiss","title":"orchestration.cli.index_faiss","text":""},{"location":"modules/orchestration.cli/#orchestration.cli.index_faiss","title":"<code>orchestration.cli.index_faiss(dense_vectors, index_path='./_indices/faiss/shard_000.idx', factory='Flat', metric='ip')</code>","text":"<p>Build FAISS index from dense vectors.</p> <p>This command builds a FAISS index from dense vector data with structured observability and comprehensive error handling. The operation is idempotent: if an index already exists at the output path, it will be rebuilt from scratch.</p> <p>Parameters:</p> Name Type Description Default <code>dense_vectors</code> <code>str</code> <p>Path to JSON file containing vectors in skeleton format. Expected format: list of {\"key\": \"id\", \"vector\": [float, ...]} objects.</p> required <code>index_path</code> <code>str</code> <p>Output path for the index file. Defaults to \"./_indices/faiss/shard_000.idx\".</p> <code>'./_indices/faiss/shard_000.idx'</code> <code>factory</code> <code>str</code> <p>FAISS factory string (e.g., \"Flat\", \"OPQ64,IVF8192,PQ64\"). Defaults to \"Flat\" for testing; production uses \"OPQ64,IVF8192,PQ64\".</p> <code>'Flat'</code> <code>metric</code> <code>str</code> <p>Metric type: \"ip\" (inner product) or \"l2\" (L2 distance). Defaults to \"ip\".</p> <code>'ip'</code> Notes <ul> <li>Idempotency: Running twice with identical inputs rebuilds the index.</li> <li>Retries: No automatic retries. On failure, check logs and re-run.</li> <li>GPU Fallback: If GPU unavailable, CPU index is built automatically.</li> </ul> Notes <p>Propagates :class:<code>typer.Exit</code> from :func:<code>run_index_faiss</code> when the index build fails.</p> <p>Examples:</p> <p>Build Flat CPU index for testing::</p> <pre><code>kgfoundry orchestration cli index_faiss vectors.json\n</code></pre> <p>Build quantized GPU index::</p> <pre><code>kgfoundry orchestration cli index_faiss vectors.json \\\\\n    --factory \"OPQ64,IVF8192,PQ64\"\n</code></pre> Source code in <code>src/orchestration/cli.py</code> <pre><code>def index_faiss(\n    dense_vectors: Annotated[\n        str, typer.Argument(..., help=\"Path to dense vectors JSON (skeleton)\")\n    ],\n    index_path: Annotated[\n        str, typer.Option(help=\"Output index (CPU .idx)\")\n    ] = \"./_indices/faiss/shard_000.idx\",\n    factory: Annotated[str, typer.Option(help=\"FAISS factory string\")] = \"Flat\",\n    metric: Annotated[str, typer.Option(help=\"Metric: 'ip' or 'l2'\")] = \"ip\",\n) -&gt; None:\n    r\"\"\"Build FAISS index from dense vectors.\n\n    This command builds a FAISS index from dense vector data with structured\n    observability and comprehensive error handling. The operation is **idempotent**:\n    if an index already exists at the output path, it will be rebuilt from scratch.\n\n    Parameters\n    ----------\n    dense_vectors : str\n        Path to JSON file containing vectors in skeleton format.\n        Expected format: list of {\"key\": \"id\", \"vector\": [float, ...]} objects.\n    index_path : str, optional\n        Output path for the index file. Defaults to \"./_indices/faiss/shard_000.idx\".\n    factory : str, optional\n        FAISS factory string (e.g., \"Flat\", \"OPQ64,IVF8192,PQ64\").\n        Defaults to \"Flat\" for testing; production uses \"OPQ64,IVF8192,PQ64\".\n    metric : str, optional\n        Metric type: \"ip\" (inner product) or \"l2\" (L2 distance).\n        Defaults to \"ip\".\n\n    Notes\n    -----\n    - **Idempotency**: Running twice with identical inputs rebuilds the index.\n    - **Retries**: No automatic retries. On failure, check logs and re-run.\n    - **GPU Fallback**: If GPU unavailable, CPU index is built automatically.\n\n    Notes\n    -----\n    Propagates :class:`typer.Exit` from :func:`run_index_faiss` when the index\n    build fails.\n\n    Examples\n    --------\n    Build Flat CPU index for testing::\n\n        kgfoundry orchestration cli index_faiss vectors.json\n\n    Build quantized GPU index::\n\n        kgfoundry orchestration cli index_faiss vectors.json \\\\\n            --factory \"OPQ64,IVF8192,PQ64\"\n    \"\"\"\n    config = IndexCliConfig(\n        dense_vectors=dense_vectors,\n        index_path=index_path,\n        factory=factory,\n        metric=metric,\n    )\n    run_index_faiss(config=config)\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationcliload_vector_batch_from_json","title":"orchestration.cli.load_vector_batch_from_json","text":""},{"location":"modules/orchestration.cli/#orchestration.cli.load_vector_batch_from_json","title":"<code>orchestration.cli.load_vector_batch_from_json(vectors_path)</code>","text":"<p>Load and validate dense vectors from JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>vectors_path</code> <code>str</code> <p>Path to JSON file containing vectors.</p> required <p>Returns:</p> Type Description <code>VectorBatch</code> <p>Validated vector batch.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the vectors file does not exist.</p> <code>VectorValidationError</code> <p>If payload validation fails.</p> Source code in <code>src/orchestration/cli.py</code> <pre><code>def load_vector_batch_from_json(vectors_path: str) -&gt; VectorBatch:\n    \"\"\"Load and validate dense vectors from JSON file.\n\n    Parameters\n    ----------\n    vectors_path : str\n        Path to JSON file containing vectors.\n\n    Returns\n    -------\n    VectorBatch\n        Validated vector batch.\n\n    Raises\n    ------\n    FileNotFoundError\n        If the vectors file does not exist.\n    VectorValidationError\n        If payload validation fails.\n    \"\"\"\n    vectors_file = Path(vectors_path)\n    if not vectors_file.exists():\n        msg = f\"Vectors file not found: {vectors_path}\"\n        raise FileNotFoundError(msg)\n\n    with vectors_file.open(\"r\", encoding=\"utf-8\") as file_obj:\n        payload: object = json.load(file_obj)\n\n    if not isinstance(payload, Sequence) or isinstance(payload, (str, bytes)):\n        msg = \"Dense vectors payload must be a sequence of mapping objects\"\n        raise VectorValidationError(msg, errors=[msg])\n\n    _validate_vector_payload(payload)\n    records = cast(\"Iterable[Mapping[str, object]]\", payload)\n    return coerce_vector_batch(records)\n</code></pre>"},{"location":"modules/orchestration.cli/#orchestrationclirun_index_faiss","title":"orchestration.cli.run_index_faiss","text":""},{"location":"modules/orchestration.cli/#orchestration.cli.run_index_faiss","title":"<code>orchestration.cli.run_index_faiss(*, config)</code>","text":"<p>Build FAISS index from dense vectors using typed configuration.</p> <p>This function builds a FAISS index from dense vector data with structured observability and comprehensive error handling. The operation is idempotent: if an index already exists at the output path, it will be rebuilt from scratch.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>IndexCliConfig</code> <p>Typed configuration with dense_vectors path, index_path, factory string, and metric type.</p> required <p>Raises:</p> Type Description <code>Exit</code> <p>On any error with exit code 1. Errors are logged with correlation ID and rendered as RFC 9457 Problem Details JSON to stderr.</p> Notes <ul> <li>Idempotency: Running twice with identical inputs rebuilds the index.</li> <li>Retries: No automatic retries. On failure, check logs and re-run.</li> <li>GPU Fallback: If GPU unavailable, CPU index is built automatically.</li> <li>Error Handling: Configuration errors are rendered as Problem Details with   correlation IDs for observability and debugging.</li> </ul> <p>Examples:</p> <p>Build Flat CPU index for testing:</p> <pre><code>&gt;&gt;&gt; from orchestration.config import IndexCliConfig\n&gt;&gt;&gt; config = IndexCliConfig(\n...     dense_vectors=\"vectors.json\",\n...     index_path=\"./_indices/faiss/shard_000.idx\",\n...     factory=\"Flat\",\n...     metric=\"ip\",\n... )\n&gt;&gt;&gt; # run_index_faiss(config=config)\n</code></pre> <p>Build quantized GPU index:</p> <pre><code>&gt;&gt;&gt; config = IndexCliConfig(\n...     dense_vectors=\"vectors.json\",\n...     index_path=\"./_indices/faiss/shard_000.idx\",\n...     factory=\"OPQ64,IVF8192,PQ64\",\n...     metric=\"ip\",\n... )\n&gt;&gt;&gt; # run_index_faiss(config=config)\n</code></pre> Source code in <code>src/orchestration/cli.py</code> <pre><code>def run_index_faiss(*, config: IndexCliConfig) -&gt; None:\n    \"\"\"Build FAISS index from dense vectors using typed configuration.\n\n    This function builds a FAISS index from dense vector data with structured\n    observability and comprehensive error handling. The operation is **idempotent**:\n    if an index already exists at the output path, it will be rebuilt from scratch.\n\n    Parameters\n    ----------\n    config : IndexCliConfig\n        Typed configuration with dense_vectors path, index_path, factory string,\n        and metric type.\n\n    Raises\n    ------\n    typer.Exit\n        On any error with exit code 1. Errors are logged with correlation ID\n        and rendered as RFC 9457 Problem Details JSON to stderr.\n\n    Notes\n    -----\n    - **Idempotency**: Running twice with identical inputs rebuilds the index.\n    - **Retries**: No automatic retries. On failure, check logs and re-run.\n    - **GPU Fallback**: If GPU unavailable, CPU index is built automatically.\n    - **Error Handling**: Configuration errors are rendered as Problem Details with\n      correlation IDs for observability and debugging.\n\n    Examples\n    --------\n    Build Flat CPU index for testing:\n\n    &gt;&gt;&gt; from orchestration.config import IndexCliConfig\n    &gt;&gt;&gt; config = IndexCliConfig(\n    ...     dense_vectors=\"vectors.json\",\n    ...     index_path=\"./_indices/faiss/shard_000.idx\",\n    ...     factory=\"Flat\",\n    ...     metric=\"ip\",\n    ... )\n    &gt;&gt;&gt; # run_index_faiss(config=config)\n\n    Build quantized GPU index:\n\n    &gt;&gt;&gt; config = IndexCliConfig(\n    ...     dense_vectors=\"vectors.json\",\n    ...     index_path=\"./_indices/faiss/shard_000.idx\",\n    ...     factory=\"OPQ64,IVF8192,PQ64\",\n    ...     metric=\"ip\",\n    ... )\n    &gt;&gt;&gt; # run_index_faiss(config=config)\n    \"\"\"\n    correlation_id = uuid4().hex\n    instance_uri = f\"urn:orchestration:index-faiss:{correlation_id}\"\n\n    try:\n        _prepare_index_directory(config.index_path)\n        batch = load_vector_batch_from_json(config.dense_vectors)\n\n        logger.info(\n            \"Building FAISS index\",\n            extra={\n                \"operation\": \"index_faiss\",\n                \"factory\": config.factory,\n                \"metric\": config.metric,\n                \"vectors\": batch.count,\n                \"dimension\": batch.dimension,\n                \"correlation_id\": correlation_id,\n            },\n        )\n\n        matrix_rows = cast(\"list[list[float]]\", batch.matrix.tolist())\n        vectors_payload: list[list[float]] = [\n            [float(component) for component in row] for row in matrix_rows\n        ]\n        index_data: dict[str, object] = {\n            \"keys\": [str(vector_id) for vector_id in batch.ids],\n            \"vectors\": vectors_payload,\n            \"factory\": config.factory,\n            \"metric\": config.metric,\n        }\n        with Path(config.index_path).open(\"wb\") as file_obj:\n            safe_pickle.dump(index_data, file_obj)\n\n        logger.info(\n            \"Index saved successfully\",\n            extra={\n                \"operation\": \"index_faiss\",\n                \"path\": config.index_path,\n                \"correlation_id\": correlation_id,\n            },\n        )\n        typer.echo(f\"FAISS index vectors stored at {config.index_path}\")\n        logger.info(\n            \"FAISS index build completed\",\n            extra={\n                \"operation\": \"index_faiss\",\n                \"path\": config.index_path,\n                \"factory\": config.factory,\n                \"metric\": config.metric,\n                \"correlation_id\": correlation_id,\n            },\n        )\n\n    except VectorValidationError as exc:\n        logger.exception(\n            \"Vector validation failed\",\n            extra={\n                \"operation\": \"index_faiss\",\n                \"error\": type(exc).__name__,\n                \"correlation_id\": correlation_id,\n            },\n        )\n        problem = _build_vector_problem_details(\n            detail=str(exc),\n            correlation_id=correlation_id,\n            vector_path=config.dense_vectors,\n            errors=exc.errors,\n            instance=instance_uri,\n        )\n        typer.echo(render_problem(problem), err=True)\n        index_error = IndexBuildError(\n            \"Vector payload failed validation\",\n            cause=exc,\n            context={\"problem\": problem, \"correlation_id\": correlation_id},\n        )\n        raise typer.Exit(code=1) from index_error\n\n    except ConfigurationError as exc:\n        logger.exception(\n            \"Configuration validation failed\",\n            extra={\n                \"operation\": \"index_faiss\",\n                \"error\": type(exc).__name__,\n                \"correlation_id\": correlation_id,\n            },\n        )\n        problem = build_configuration_problem(exc)\n        typer.echo(render_problem(problem), err=True)\n        raise typer.Exit(code=2) from exc\n\n    except (TypeError, json.JSONDecodeError, FileNotFoundError) as exc:\n        logger.exception(\n            \"Vector loading failed\",\n            extra={\n                \"operation\": \"index_faiss\",\n                \"error\": type(exc).__name__,\n                \"correlation_id\": correlation_id,\n            },\n        )\n        typer.echo(f\"Error loading vectors: {exc}\", err=True)\n        raise typer.Exit(code=1) from exc\n\n    except (OSError, ValueError, RuntimeError) as exc:\n        logger.exception(\n            \"Index save failed\",\n            extra={\n                \"operation\": \"index_faiss\",\n                \"error\": type(exc).__name__,\n                \"correlation_id\": correlation_id,\n            },\n        )\n        typer.echo(f\"Error saving index: {exc}\", err=True)\n        raise typer.Exit(code=1) from exc\n</code></pre>"},{"location":"modules/orchestration.config/","title":"orchestration.config","text":""},{"location":"modules/orchestration.config/#orchestrationconfig","title":"orchestration.config","text":"<p>Configuration models for orchestration CLI operations.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/orchestration.config/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class ArtifactValidationConfig\n    class IndexCliConfig\n</code></pre>"},{"location":"modules/orchestration.config/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"orchestration.config__future__.annotationsdataclasses.dataclasskgfoundry_common.navmap_loader.load_nav_metadataorchestration.config code <p>See the full diagram: orchestration.config</p>"},{"location":"modules/orchestration.config/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>orchestration.config.ArtifactValidationConfig</li> <li>orchestration.config.IndexCliConfig</li> </ul>"},{"location":"modules/orchestration.config/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>dataclasses.dataclass</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p>"},{"location":"modules/orchestration.config/#contents","title":"Contents","text":""},{"location":"modules/orchestration.config/#orchestrationconfigartifactvalidationconfig","title":"orchestration.config.ArtifactValidationConfig","text":""},{"location":"modules/orchestration.config/#orchestration.config.ArtifactValidationConfig","title":"<code>orchestration.config.ArtifactValidationConfig</code>  <code>dataclass</code>","text":"<p>Configuration for artifact validation operations.</p> <p>Attributes:</p> Name Type Description <code>strict_mode</code> <code>(bool, optional)</code> <p>If True, validation enforces strict schema compliance. Defaults to True.</p> <code>fail_on_warnings</code> <code>(bool, optional)</code> <p>If True, warnings are treated as validation errors. Defaults to False.</p> Notes <p>This configuration supports flexible validation policies for documentation and index artifacts.</p> Source code in <code>src/orchestration/config.py</code> <pre><code>@dataclass(frozen=True, slots=True)\n# [nav:anchor ArtifactValidationConfig]\nclass ArtifactValidationConfig:\n    \"\"\"Configuration for artifact validation operations.\n\n    Attributes\n    ----------\n    strict_mode : bool, optional\n        If True, validation enforces strict schema compliance.\n        Defaults to True.\n    fail_on_warnings : bool, optional\n        If True, warnings are treated as validation errors.\n        Defaults to False.\n\n    Notes\n    -----\n    This configuration supports flexible validation policies for documentation\n    and index artifacts.\n    \"\"\"\n\n    strict_mode: bool = True\n    fail_on_warnings: bool = False\n</code></pre>"},{"location":"modules/orchestration.config/#orchestrationconfigindexcliconfig","title":"orchestration.config.IndexCliConfig","text":""},{"location":"modules/orchestration.config/#orchestration.config.IndexCliConfig","title":"<code>orchestration.config.IndexCliConfig</code>  <code>dataclass</code>","text":"<p>Configuration for FAISS and BM25 index building CLI operations.</p> <p>Attributes:</p> Name Type Description <code>dense_vectors</code> <code>str</code> <p>Path to JSON file containing dense vectors in skeleton format.</p> <code>index_path</code> <code>str</code> <p>Output path for the built index file.</p> <code>factory</code> <code>str</code> <p>FAISS factory string (e.g., \"Flat\", \"OPQ64,IVF8192,PQ64\").</p> <code>metric</code> <code>str</code> <p>Distance metric: \"ip\" (inner product) or \"l2\" (L2 distance).</p> Notes <p>This configuration replaces positional arguments in index_faiss CLI, ensuring type safety and clear parameter documentation.</p> Source code in <code>src/orchestration/config.py</code> <pre><code>@dataclass(frozen=True, slots=True)\n# [nav:anchor IndexCliConfig]\nclass IndexCliConfig:\n    \"\"\"Configuration for FAISS and BM25 index building CLI operations.\n\n    Attributes\n    ----------\n    dense_vectors : str\n        Path to JSON file containing dense vectors in skeleton format.\n    index_path : str\n        Output path for the built index file.\n    factory : str\n        FAISS factory string (e.g., \"Flat\", \"OPQ64,IVF8192,PQ64\").\n    metric : str\n        Distance metric: \"ip\" (inner product) or \"l2\" (L2 distance).\n\n    Notes\n    -----\n    This configuration replaces positional arguments in index_faiss CLI,\n    ensuring type safety and clear parameter documentation.\n    \"\"\"\n\n    dense_vectors: str\n    index_path: str\n    factory: str\n    metric: str\n</code></pre>"},{"location":"modules/orchestration.fixture_flow/","title":"orchestration.fixture_flow","text":""},{"location":"modules/orchestration.fixture_flow/#orchestrationfixture_flow","title":"orchestration.fixture_flow","text":"<p>Prefect flows that build local fixture datasets</p> <p>:material-source-repository: View source</p>"},{"location":"modules/orchestration.fixture_flow/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"orchestration.fixture_flow__future__.annotationskgfoundry_common.models.Dockgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.parquet_io.ChunkRowkgfoundry_common.parquet_io.ParquetChunkWriterkgfoundry_common.parquet_io.ParquetVectorWriterpathlib.Pathprefect.flowprefect.taskregistry.helper.DuckDBRegistryHelpertyping.TYPE_CHECKINGorchestration.fixture_flow code <p>See the full diagram: orchestration.fixture_flow</p>"},{"location":"modules/orchestration.fixture_flow/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>orchestration.fixture_flow._fixture_pipeline_impl</li> <li>orchestration.fixture_flow._t_prepare_dirs_impl</li> <li>orchestration.fixture_flow._t_register_in_duckdb_impl</li> </ul>"},{"location":"modules/orchestration.fixture_flow/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.models.Doc</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.parquet_io.ChunkRow</code>, <code>kgfoundry_common.parquet_io.ParquetChunkWriter</code>, <code>kgfoundry_common.parquet_io.ParquetVectorWriter</code>, <code>pathlib.Path</code>, <code>prefect.flow</code>, <code>prefect.task</code>, <code>registry.helper.DuckDBRegistryHelper</code>, <code>typing.TYPE_CHECKING</code></p>"},{"location":"modules/orchestration.fixture_flow/#contents","title":"Contents","text":""},{"location":"modules/orchestration.fixture_flow/#orchestrationfixture_flow_fixture_pipeline_impl","title":"orchestration.fixture_flow._fixture_pipeline_impl","text":""},{"location":"modules/orchestration.fixture_flow/#orchestration.fixture_flow._fixture_pipeline_impl","title":"<code>orchestration.fixture_flow._fixture_pipeline_impl(root='/data', db_path='/data/catalog/catalog.duckdb')</code>","text":"<p>Execute the complete fixture pipeline flow.</p> <p>Orchestrates creation of fixture directories, writes chunk/dense/sparse parquet files, and registers everything in DuckDB registry.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>str</code> <p>Root directory for fixture data. Defaults to \"/data\".</p> <code>'/data'</code> <code>db_path</code> <code>str</code> <p>Path to DuckDB catalog database. Defaults to \"/data/catalog/catalog.duckdb\".</p> <code>'/data/catalog/catalog.duckdb'</code> <p>Returns:</p> Type Description <code>dict[str, list[str]]</code> <p>Dictionary with \"runs\" key containing list of created run IDs.</p> Source code in <code>src/orchestration/fixture_flow.py</code> <pre><code>def _fixture_pipeline_impl(\n    root: str = \"/data\", db_path: str = \"/data/catalog/catalog.duckdb\"\n) -&gt; dict[str, list[str]]:\n    \"\"\"Execute the complete fixture pipeline flow.\n\n    Orchestrates creation of fixture directories, writes chunk/dense/sparse\n    parquet files, and registers everything in DuckDB registry.\n\n    Parameters\n    ----------\n    root : str, optional\n        Root directory for fixture data. Defaults to \"/data\".\n    db_path : str, optional\n        Path to DuckDB catalog database. Defaults to \"/data/catalog/catalog.duckdb\".\n\n    Returns\n    -------\n    dict[str, list[str]]\n        Dictionary with \"runs\" key containing list of created run IDs.\n    \"\"\"\n    t_prepare_dirs(root)\n    chunks_info = t_write_fixture_chunks(f\"{root}/parquet/chunks\")\n    dense_info = t_write_fixture_dense(f\"{root}/parquet/dense\")\n    sparse_info = t_write_fixture_splade(f\"{root}/parquet/sparse\")\n    return _t_register_in_duckdb_impl(db_path, chunks_info, dense_info, sparse_info)\n</code></pre>"},{"location":"modules/orchestration.fixture_flow/#orchestrationfixture_flow_t_prepare_dirs_impl","title":"orchestration.fixture_flow._t_prepare_dirs_impl","text":""},{"location":"modules/orchestration.fixture_flow/#orchestration.fixture_flow._t_prepare_dirs_impl","title":"<code>orchestration.fixture_flow._t_prepare_dirs_impl(root)</code>","text":"<p>Prepare directory structure for fixture dataset.</p> <p>Creates necessary subdirectories for parquet outputs (dense, sparse, chunks) and catalog artifacts.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>str</code> <p>Root directory path where fixture data will be stored.</p> required <p>Returns:</p> Type Description <code>dict[str, bool]</code> <p>Status dictionary with \"ok\" key set to True.</p> Source code in <code>src/orchestration/fixture_flow.py</code> <pre><code>def _t_prepare_dirs_impl(root: str) -&gt; dict[str, bool]:\n    \"\"\"Prepare directory structure for fixture dataset.\n\n    Creates necessary subdirectories for parquet outputs (dense, sparse,\n    chunks) and catalog artifacts.\n\n    Parameters\n    ----------\n    root : str\n        Root directory path where fixture data will be stored.\n\n    Returns\n    -------\n    dict[str, bool]\n        Status dictionary with \"ok\" key set to True.\n    \"\"\"\n    path = Path(root)\n    (path / \"parquet\" / \"dense\").mkdir(parents=True, exist_ok=True)\n    (path / \"parquet\" / \"sparse\").mkdir(parents=True, exist_ok=True)\n    (path / \"parquet\" / \"chunks\").mkdir(parents=True, exist_ok=True)\n    (path / \"catalog\").mkdir(parents=True, exist_ok=True)\n    return {\"ok\": True}\n</code></pre>"},{"location":"modules/orchestration.fixture_flow/#orchestrationfixture_flow_t_register_in_duckdb_impl","title":"orchestration.fixture_flow._t_register_in_duckdb_impl","text":""},{"location":"modules/orchestration.fixture_flow/#orchestration.fixture_flow._t_register_in_duckdb_impl","title":"<code>orchestration.fixture_flow._t_register_in_duckdb_impl(db_path, chunks_info, dense_info, sparse_info)</code>","text":"<p>Register fixture datasets in DuckDB registry.</p> <p>Creates runs and datasets for chunks, dense, and sparse embeddings, then registers a fixture document.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>Path to DuckDB database file.</p> required <code>chunks_info</code> <code>tuple[str, int]</code> <p>Tuple of (chunks_dataset_path, row_count).</p> required <code>dense_info</code> <code>tuple[str, int]</code> <p>Tuple of (dense_dataset_path, row_count).</p> required <code>sparse_info</code> <code>tuple[str, int]</code> <p>Tuple of (sparse_dataset_path, row_count).</p> required <p>Returns:</p> Type Description <code>dict[str, list[str]]</code> <p>Dictionary with \"runs\" key containing list of run IDs.</p> Source code in <code>src/orchestration/fixture_flow.py</code> <pre><code>def _t_register_in_duckdb_impl(\n    db_path: str,\n    chunks_info: tuple[str, int],\n    dense_info: tuple[str, int],\n    sparse_info: tuple[str, int],\n) -&gt; dict[str, list[str]]:\n    \"\"\"Register fixture datasets in DuckDB registry.\n\n    Creates runs and datasets for chunks, dense, and sparse embeddings,\n    then registers a fixture document.\n\n    Parameters\n    ----------\n    db_path : str\n        Path to DuckDB database file.\n    chunks_info : tuple[str, int]\n        Tuple of (chunks_dataset_path, row_count).\n    dense_info : tuple[str, int]\n        Tuple of (dense_dataset_path, row_count).\n    sparse_info : tuple[str, int]\n        Tuple of (sparse_dataset_path, row_count).\n\n    Returns\n    -------\n    dict[str, list[str]]\n        Dictionary with \"runs\" key containing list of run IDs.\n    \"\"\"\n    registry = DuckDBRegistryHelper(db_path)\n    dense_run = registry.new_run(\"dense_embed\", \"Qwen3-Embedding-4B\", \"main\", {\"dim\": 2560})\n    sparse_run = registry.new_run(\"splade_encode\", \"SPLADE-v3-distilbert\", \"main\", {\"topk\": 256})\n\n    ds_chunks = registry.begin_dataset(\"chunks\", dense_run)\n    registry.commit_dataset(ds_chunks, chunks_info[0], rows=chunks_info[1])\n\n    ds_dense = registry.begin_dataset(\"dense\", dense_run)\n    registry.commit_dataset(ds_dense, dense_info[0], rows=dense_info[1])\n\n    ds_sparse = registry.begin_dataset(\"sparse\", sparse_run)\n    registry.commit_dataset(ds_sparse, sparse_info[0], rows=sparse_info[1])\n\n    registry.register_documents(\n        [\n            Doc(\n                id=\"urn:doc:fixture:0001\",\n                title=\"Fixture Doc\",\n                authors=[],\n                pdf_uri=\"/dev/null\",\n                source=\"fixture\",\n                openalex_id=None,\n                doi=None,\n                arxiv_id=None,\n                pmcid=None,\n                pub_date=None,\n                license=\"CC0\",\n                language=\"en\",\n                content_hash=\"\",\n            )\n        ]\n    )\n    registry.close_run(dense_run, success=True)\n    registry.close_run(sparse_run, success=True)\n    return {\"runs\": [dense_run, sparse_run]}\n</code></pre>"},{"location":"modules/orchestration.fixture_flow/#orchestrationfixture_flow_t_write_fixture_chunks_impl","title":"orchestration.fixture_flow._t_write_fixture_chunks_impl","text":""},{"location":"modules/orchestration.fixture_flow/#orchestration.fixture_flow._t_write_fixture_chunks_impl","title":"<code>orchestration.fixture_flow._t_write_fixture_chunks_impl(chunks_root)</code>","text":"<p>Write fixture chunk data to parquet.</p> <p>Creates a fixture dataset with a single chunk entry for testing.</p> <p>Parameters:</p> Name Type Description Default <code>chunks_root</code> <code>str</code> <p>Root directory for chunk parquet files.</p> required <p>Returns:</p> Type Description <code>tuple[str, int]</code> <p>Tuple of (dataset_root_path, row_count).</p> Source code in <code>src/orchestration/fixture_flow.py</code> <pre><code>def _t_write_fixture_chunks_impl(chunks_root: str) -&gt; tuple[str, int]:\n    \"\"\"Write fixture chunk data to parquet.\n\n    Creates a fixture dataset with a single chunk entry for testing.\n\n    Parameters\n    ----------\n    chunks_root : str\n        Root directory for chunk parquet files.\n\n    Returns\n    -------\n    tuple[str, int]\n        Tuple of (dataset_root_path, row_count).\n    \"\"\"\n    writer = ParquetChunkWriter(chunks_root, model=\"docling_hybrid\", run_id=\"fixture\")\n    rows: list[ChunkRow] = [\n        {\n            \"chunk_id\": \"urn:chunk:fixture:0-28\",\n            \"doc_id\": \"urn:doc:fixture:0001\",\n            \"section\": \"Intro\",\n            \"start_char\": 0,\n            \"end_char\": 28,\n            \"doctags_span\": {\"node_id\": \"n1\", \"start\": 0, \"end\": 28},\n            \"text\": \"Hello fixture text about LLMs\",\n            \"tokens\": 5,\n            \"created_at\": 0,\n        }\n    ]\n    dataset_root = writer.write(rows)\n    return dataset_root, len(rows)\n</code></pre>"},{"location":"modules/orchestration.fixture_flow/#orchestrationfixture_flow_t_write_fixture_dense_impl","title":"orchestration.fixture_flow._t_write_fixture_dense_impl","text":""},{"location":"modules/orchestration.fixture_flow/#orchestration.fixture_flow._t_write_fixture_dense_impl","title":"<code>orchestration.fixture_flow._t_write_fixture_dense_impl(dense_root)</code>","text":"<p>Write fixture dense embedding vectors to parquet.</p> <p>Creates a fixture dataset with a single dense embedding vector using Qwen3-Embedding-4B model.</p> <p>Parameters:</p> Name Type Description Default <code>dense_root</code> <code>str</code> <p>Root directory for dense embedding parquet files.</p> required <p>Returns:</p> Type Description <code>tuple[str, int]</code> <p>Tuple of (dataset_root_path, row_count).</p> Source code in <code>src/orchestration/fixture_flow.py</code> <pre><code>def _t_write_fixture_dense_impl(dense_root: str) -&gt; tuple[str, int]:\n    \"\"\"Write fixture dense embedding vectors to parquet.\n\n    Creates a fixture dataset with a single dense embedding vector\n    using Qwen3-Embedding-4B model.\n\n    Parameters\n    ----------\n    dense_root : str\n        Root directory for dense embedding parquet files.\n\n    Returns\n    -------\n    tuple[str, int]\n        Tuple of (dataset_root_path, row_count).\n    \"\"\"\n    writer = ParquetVectorWriter(dense_root)\n    vector = [0.0] * 2560\n    out_root = writer.write_dense(\n        \"Qwen3-Embedding-4B\", \"fixture\", 2560, [(\"urn:chunk:fixture:0-28\", vector, 1.0)], shard=0\n    )\n    return out_root, 1\n</code></pre>"},{"location":"modules/orchestration.fixture_flow/#orchestrationfixture_flow_t_write_fixture_splade_impl","title":"orchestration.fixture_flow._t_write_fixture_splade_impl","text":""},{"location":"modules/orchestration.fixture_flow/#orchestration.fixture_flow._t_write_fixture_splade_impl","title":"<code>orchestration.fixture_flow._t_write_fixture_splade_impl(sparse_root)</code>","text":"<p>Write fixture sparse SPLADE vectors to parquet.</p> <p>Creates a fixture dataset with a single sparse embedding vector using SPLADE-v3-distilbert model.</p> <p>Parameters:</p> Name Type Description Default <code>sparse_root</code> <code>str</code> <p>Root directory for sparse embedding parquet files.</p> required <p>Returns:</p> Type Description <code>tuple[str, int]</code> <p>Tuple of (dataset_root_path, row_count).</p> Source code in <code>src/orchestration/fixture_flow.py</code> <pre><code>def _t_write_fixture_splade_impl(sparse_root: str) -&gt; tuple[str, int]:\n    \"\"\"Write fixture sparse SPLADE vectors to parquet.\n\n    Creates a fixture dataset with a single sparse embedding vector\n    using SPLADE-v3-distilbert model.\n\n    Parameters\n    ----------\n    sparse_root : str\n        Root directory for sparse embedding parquet files.\n\n    Returns\n    -------\n    tuple[str, int]\n        Tuple of (dataset_root_path, row_count).\n    \"\"\"\n    writer = ParquetVectorWriter(sparse_root)\n    out_root = writer.write_splade(\n        \"SPLADE-v3-distilbert\",\n        \"fixture\",\n        [(\"urn:chunk:fixture:0-28\", [1, 7, 42], [0.3, 0.2, 0.1])],\n        shard=0,\n    )\n    return out_root, 1\n</code></pre>"},{"location":"modules/orchestration.flows/","title":"orchestration.flows","text":""},{"location":"modules/orchestration.flows/#orchestrationflows","title":"orchestration.flows","text":"<p>Prefect flow definitions for kgfoundry pipelines</p> <p>:material-source-repository: View source</p>"},{"location":"modules/orchestration.flows/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"orchestration.flows__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadataprefect.flowprefect.taskorchestration.flows code <p>See the full diagram: orchestration.flows</p>"},{"location":"modules/orchestration.flows/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>orchestration.flows._e2e_flow_impl</li> <li>orchestration.flows._t_echo_impl</li> </ul>"},{"location":"modules/orchestration.flows/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>prefect.flow</code>, <code>prefect.task</code></p>"},{"location":"modules/orchestration.flows/#contents","title":"Contents","text":""},{"location":"modules/orchestration.flows/#orchestrationflows_e2e_flow_impl","title":"orchestration.flows._e2e_flow_impl","text":""},{"location":"modules/orchestration.flows/#orchestration.flows._e2e_flow_impl","title":"<code>orchestration.flows._e2e_flow_impl()</code>","text":"<p>Execute end-to-end pipeline skeleton flow.</p> <p>Runs a sequence of echo tasks representing the complete kgfoundry pipeline stages: harvest, doctags, chunk, embed_dense, encode_splade, bm25, faiss, ontology, concept_embed, linker, and kg.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of task result strings.</p> Source code in <code>src/orchestration/flows.py</code> <pre><code>def _e2e_flow_impl() -&gt; list[str]:\n    \"\"\"Execute end-to-end pipeline skeleton flow.\n\n    Runs a sequence of echo tasks representing the complete kgfoundry\n    pipeline stages: harvest, doctags, chunk, embed_dense, encode_splade,\n    bm25, faiss, ontology, concept_embed, linker, and kg.\n\n    Returns\n    -------\n    list[str]\n        List of task result strings.\n    \"\"\"\n    return [\n        t_echo.submit(x).result()\n        for x in [\n            \"harvest\",\n            \"doctags\",\n            \"chunk\",\n            \"embed_dense\",\n            \"encode_splade\",\n            \"bm25\",\n            \"faiss\",\n            \"ontology\",\n            \"concept_embed\",\n            \"linker\",\n            \"kg\",\n        ]\n    ]\n</code></pre>"},{"location":"modules/orchestration.flows/#orchestrationflows_t_echo_impl","title":"orchestration.flows._t_echo_impl","text":""},{"location":"modules/orchestration.flows/#orchestration.flows._t_echo_impl","title":"<code>orchestration.flows._t_echo_impl(msg)</code>","text":"<p>Echo a message string.</p> <p>Simple task implementation that returns the input message unchanged. Used for testing Prefect flow orchestration.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>Message string to echo.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The input message unchanged.</p> Source code in <code>src/orchestration/flows.py</code> <pre><code>def _t_echo_impl(msg: str) -&gt; str:\n    \"\"\"Echo a message string.\n\n    Simple task implementation that returns the input message unchanged.\n    Used for testing Prefect flow orchestration.\n\n    Parameters\n    ----------\n    msg : str\n        Message string to echo.\n\n    Returns\n    -------\n    str\n        The input message unchanged.\n    \"\"\"\n    return msg\n</code></pre>"},{"location":"modules/orchestration/","title":"orchestration","text":""},{"location":"modules/orchestration/#orchestration","title":"orchestration","text":"<p>Prefect flows and CLI entrypoints for kgfoundry orchestrations</p> <p>:material-source-repository: View source</p>"},{"location":"modules/orchestration/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"orchestration__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.navmap_types.NavMaporchestration code <p>See the full diagram: orchestration</p>"},{"location":"modules/orchestration/#interfaces","title":"Interfaces","text":""},{"location":"modules/orchestration/#orchestration-cli","title":"<code>orchestration-cli</code>","text":"<ul> <li>Type: cli</li> <li>Owner: @orchestration</li> <li>Stability: beta</li> <li>Description: Primary Typer application for orchestration flows and indexing commands.</li> <li>Spec: CLI Spec</li> <li>Problem Details: schema/examples/problem_details/tool-execution-error.json</li> <li>Operations:</li> <li><code>cli.api</code> \u2014 Launch FastAPI search service.</li> <li><code>cli.e2e</code> \u2014 Execute end-to-end orchestration demo.</li> <li><code>cli.index_bm25</code> \u2014 Build BM25 index from JSON/Parquet chunks.</li> <li><code>cli.index_faiss</code> \u2014 Build FAISS index from dense vectors.</li> </ul>"},{"location":"modules/orchestration/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.navmap_types.NavMap</code></p>"},{"location":"modules/orchestration.safe_pickle/","title":"orchestration.safe_pickle","text":""},{"location":"modules/orchestration.safe_pickle/#orchestrationsafe_pickle","title":"orchestration.safe_pickle","text":"<p>Prefect flows and CLI entrypoints for kgfoundry orchestrations</p> <p>:material-source-repository: View source</p>"},{"location":"modules/orchestration.safe_pickle/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class SafeUnpickler\n    class _StdlibUnpickler\n    _StdlibUnpickler &lt;|-- SafeUnpickler\n    class UnsafePickleError\n    class ValueError\n    ValueError &lt;|-- UnsafePickleError\n    class _PickleModule\n    class Protocol\n    Protocol &lt;|-- _PickleModule\n    class _StdlibUnpickler_1\n    class _UnpicklerProtocol\n    _UnpicklerProtocol &lt;|-- _StdlibUnpickler_1\n    class _UnpicklerProtocol_1\n    Protocol &lt;|-- _UnpicklerProtocol_1\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"orchestration.safe_pickle__future__.annotationsimportlib.import_moduleloggingtyping.BinaryIOtyping.Protocoltyping.TYPE_CHECKINGtyping.castorchestration.cliorchestration.safe_pickle code <p>See the full diagram: orchestration.safe_pickle</p>"},{"location":"modules/orchestration.safe_pickle/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>orchestration.safe_pickle.SafeUnpickler</li> <li>orchestration.safe_pickle.UnsafePickleError</li> <li>orchestration.safe_pickle._PickleModule</li> <li>orchestration.safe_pickle._load_stdlib_pickle</li> <li>orchestration.safe_pickle._validate_object</li> <li>orchestration.safe_pickle.dump</li> </ul>"},{"location":"modules/orchestration.safe_pickle/#interfaces","title":"Interfaces","text":""},{"location":"modules/orchestration.safe_pickle/#orchestration-cli","title":"<code>orchestration-cli</code>","text":"<ul> <li>Type: cli</li> <li>Owner: @orchestration</li> <li>Stability: beta</li> <li>Description: Primary Typer application for orchestration flows and indexing commands.</li> <li>Spec: CLI Spec</li> <li>Problem Details: schema/examples/problem_details/tool-execution-error.json</li> <li>Operations:</li> <li><code>cli.api</code> \u2014 Launch FastAPI search service.</li> <li><code>cli.e2e</code> \u2014 Execute end-to-end orchestration demo.</li> <li><code>cli.index_bm25</code> \u2014 Build BM25 index from JSON/Parquet chunks.</li> <li><code>cli.index_faiss</code> \u2014 Build FAISS index from dense vectors.</li> </ul>"},{"location":"modules/orchestration.safe_pickle/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>importlib.import_module</code>, <code>logging</code>, <code>typing.BinaryIO</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p> <p>Imported by: orchestration.cli</p>"},{"location":"modules/orchestration.safe_pickle/#contents","title":"Contents","text":""},{"location":"modules/orchestration.safe_pickle/#orchestrationsafe_picklesafeunpickler","title":"orchestration.safe_pickle.SafeUnpickler","text":"<p>Bases: _StdlibUnpickler</p>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle.SafeUnpickler","title":"<code>orchestration.safe_pickle.SafeUnpickler</code>","text":"<p>               Bases: <code>_StdlibUnpickler</code></p> <p>Unpickler that enforces allow-list of safe types.</p> <p>This prevents arbitrary code execution by restricting deserialization to primitive types and basic containers (dict, list).</p> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>class SafeUnpickler(_StdlibUnpickler):\n    \"\"\"Unpickler that enforces allow-list of safe types.\n\n    This prevents arbitrary code execution by restricting deserialization to primitive types and\n    basic containers (dict, list).\n    \"\"\"\n\n    def __init__(\n        self,\n        file: BinaryIO,\n        *,\n        fix_imports: bool = True,\n        encoding: str = \"ASCII\",\n        errors: str = \"strict\",\n        buffers: object | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize safe unpickler with file handle.\n\n        Parameters\n        ----------\n        file : BinaryIO\n            Binary file handle to read from.\n        fix_imports : bool, optional\n            Whether to fix imports for Python 2 compatibility.\n            Defaults to True.\n        encoding : str, optional\n            Text encoding for Python 2 compatibility.\n            Defaults to \"ASCII\".\n        errors : str, optional\n            Error handling mode for encoding.\n            Defaults to \"strict\".\n        buffers : object | None, optional\n            Buffer protocol support.\n            Defaults to None.\n        \"\"\"\n        super().__init__(\n            file,\n            fix_imports=fix_imports,\n            encoding=encoding,\n            errors=errors,\n            buffers=buffers,\n        )\n\n    def find_class(self, module: str, name: str) -&gt; type:\n        \"\"\"Override find_class to enforce allow-list.\n\n        Parameters\n        ----------\n        module : str\n            Module name from pickle stream.\n        name : str\n            Class name from pickle stream.\n\n        Returns\n        -------\n        type\n            The class object.\n\n        Raises\n        ------\n        UnsafePickleError\n            If the requested class is not in the allow-list.\n        \"\"\"\n        full_name = f\"{module}.{name}\"\n        if full_name not in _ALLOWED_TYPES:\n            msg = f\"Pickle deserialization blocked: {full_name} not in allow-list\"\n            raise UnsafePickleError(msg, type_name=full_name)\n        return cast(\"type[object]\", super().find_class(module, name))\n\n    def load(self) -&gt; object:\n        \"\"\"Deserialize the payload using the hardened allow-list.\n\n        Returns\n        -------\n        object\n            Deserialized object.\n        \"\"\"\n        return super().load()\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle.SafeUnpickler.__init__","title":"<code>__init__(file, *, fix_imports=True, encoding='ASCII', errors='strict', buffers=None)</code>","text":"<p>Initialize safe unpickler with file handle.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>BinaryIO</code> <p>Binary file handle to read from.</p> required <code>fix_imports</code> <code>bool</code> <p>Whether to fix imports for Python 2 compatibility. Defaults to True.</p> <code>True</code> <code>encoding</code> <code>str</code> <p>Text encoding for Python 2 compatibility. Defaults to \"ASCII\".</p> <code>'ASCII'</code> <code>errors</code> <code>str</code> <p>Error handling mode for encoding. Defaults to \"strict\".</p> <code>'strict'</code> <code>buffers</code> <code>object | None</code> <p>Buffer protocol support. Defaults to None.</p> <code>None</code> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def __init__(\n    self,\n    file: BinaryIO,\n    *,\n    fix_imports: bool = True,\n    encoding: str = \"ASCII\",\n    errors: str = \"strict\",\n    buffers: object | None = None,\n) -&gt; None:\n    \"\"\"Initialize safe unpickler with file handle.\n\n    Parameters\n    ----------\n    file : BinaryIO\n        Binary file handle to read from.\n    fix_imports : bool, optional\n        Whether to fix imports for Python 2 compatibility.\n        Defaults to True.\n    encoding : str, optional\n        Text encoding for Python 2 compatibility.\n        Defaults to \"ASCII\".\n    errors : str, optional\n        Error handling mode for encoding.\n        Defaults to \"strict\".\n    buffers : object | None, optional\n        Buffer protocol support.\n        Defaults to None.\n    \"\"\"\n    super().__init__(\n        file,\n        fix_imports=fix_imports,\n        encoding=encoding,\n        errors=errors,\n        buffers=buffers,\n    )\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle.SafeUnpickler.find_class","title":"<code>find_class(module, name)</code>","text":"<p>Override find_class to enforce allow-list.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>str</code> <p>Module name from pickle stream.</p> required <code>name</code> <code>str</code> <p>Class name from pickle stream.</p> required <p>Returns:</p> Type Description <code>type</code> <p>The class object.</p> <p>Raises:</p> Type Description <code>UnsafePickleError</code> <p>If the requested class is not in the allow-list.</p> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def find_class(self, module: str, name: str) -&gt; type:\n    \"\"\"Override find_class to enforce allow-list.\n\n    Parameters\n    ----------\n    module : str\n        Module name from pickle stream.\n    name : str\n        Class name from pickle stream.\n\n    Returns\n    -------\n    type\n        The class object.\n\n    Raises\n    ------\n    UnsafePickleError\n        If the requested class is not in the allow-list.\n    \"\"\"\n    full_name = f\"{module}.{name}\"\n    if full_name not in _ALLOWED_TYPES:\n        msg = f\"Pickle deserialization blocked: {full_name} not in allow-list\"\n        raise UnsafePickleError(msg, type_name=full_name)\n    return cast(\"type[object]\", super().find_class(module, name))\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle.SafeUnpickler.load","title":"<code>load()</code>","text":"<p>Deserialize the payload using the hardened allow-list.</p> <p>Returns:</p> Type Description <code>object</code> <p>Deserialized object.</p> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def load(self) -&gt; object:\n    \"\"\"Deserialize the payload using the hardened allow-list.\n\n    Returns\n    -------\n    object\n        Deserialized object.\n    \"\"\"\n    return super().load()\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestrationsafe_pickleunsafepickleerror","title":"orchestration.safe_pickle.UnsafePickleError","text":"<p>Bases: ValueError</p>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle.UnsafePickleError","title":"<code>orchestration.safe_pickle.UnsafePickleError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Raised when pickle encounters disallowed types or suspicious patterns.</p> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>class UnsafePickleError(ValueError):\n    \"\"\"Raised when pickle encounters disallowed types or suspicious patterns.\"\"\"\n\n    def __init__(self, message: str, type_name: str | None = None) -&gt; None:\n        \"\"\"Initialize unsafe pickle error.\n\n        Parameters\n        ----------\n        message : str\n            Error description.\n        type_name : str | None\n            Attempted type name that was rejected.\n        \"\"\"\n        super().__init__(message)\n        self.type_name = type_name\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle.UnsafePickleError.__init__","title":"<code>__init__(message, type_name=None)</code>","text":"<p>Initialize unsafe pickle error.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error description.</p> required <code>type_name</code> <code>str | None</code> <p>Attempted type name that was rejected.</p> <code>None</code> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def __init__(self, message: str, type_name: str | None = None) -&gt; None:\n    \"\"\"Initialize unsafe pickle error.\n\n    Parameters\n    ----------\n    message : str\n        Error description.\n    type_name : str | None\n        Attempted type name that was rejected.\n    \"\"\"\n    super().__init__(message)\n    self.type_name = type_name\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestrationsafe_pickle_picklemodule","title":"orchestration.safe_pickle._PickleModule","text":"<p>Bases: Protocol</p>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle._PickleModule","title":"<code>orchestration.safe_pickle._PickleModule</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>class _PickleModule(Protocol):\n    Unpickler: type[_UnpicklerProtocol]\n\n    def dump(self, obj: object, file: BinaryIO) -&gt; None:\n        \"\"\"Serialize object to file.\n\n        Parameters\n        ----------\n        obj : object\n            Object to serialize.\n        file : BinaryIO\n            Binary file handle to write to.\n        \"\"\"\n        ...\n\n    def dumps(self, obj: object) -&gt; bytes:\n        \"\"\"Serialize object to bytes.\n\n        Parameters\n        ----------\n        obj : object\n            Object to serialize.\n\n        Returns\n        -------\n        bytes\n            Serialized object as bytes.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle._PickleModule.dump","title":"<code>dump(obj, file)</code>","text":"<p>Serialize object to file.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>Object to serialize.</p> required <code>file</code> <code>BinaryIO</code> <p>Binary file handle to write to.</p> required Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def dump(self, obj: object, file: BinaryIO) -&gt; None:\n    \"\"\"Serialize object to file.\n\n    Parameters\n    ----------\n    obj : object\n        Object to serialize.\n    file : BinaryIO\n        Binary file handle to write to.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle._PickleModule.dumps","title":"<code>dumps(obj)</code>","text":"<p>Serialize object to bytes.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>Object to serialize.</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>Serialized object as bytes.</p> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def dumps(self, obj: object) -&gt; bytes:\n    \"\"\"Serialize object to bytes.\n\n    Parameters\n    ----------\n    obj : object\n        Object to serialize.\n\n    Returns\n    -------\n    bytes\n        Serialized object as bytes.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestrationsafe_pickle_stdlibunpickler","title":"orchestration.safe_pickle._StdlibUnpickler","text":"<p>Bases: _UnpicklerProtocol</p>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle._StdlibUnpickler","title":"<code>orchestration.safe_pickle._StdlibUnpickler</code>","text":"<p>               Bases: <code>_UnpicklerProtocol</code></p> <p>Static typing shim for the stdlib Unpickler.</p> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>class _StdlibUnpickler(_UnpicklerProtocol):\n    \"\"\"Static typing shim for the stdlib Unpickler.\"\"\"\n\n    def __init__(\n        self,\n        file: BinaryIO,\n        *,\n        fix_imports: bool = ...,\n        encoding: str = ...,\n        errors: str = ...,\n        buffers: object | None = ...,\n    ) -&gt; None:\n        \"\"\"Initialize unpickler with file handle.\n\n        Parameters\n        ----------\n        file : BinaryIO\n            Binary file handle to read from.\n        fix_imports : bool, optional\n            Whether to fix imports for Python 2 compatibility.\n        encoding : str, optional\n            Text encoding for Python 2 compatibility.\n        errors : str, optional\n            Error handling mode for encoding.\n        buffers : object | None, optional\n            Buffer protocol support.\n        \"\"\"\n        ...\n\n    def load(self) -&gt; object:\n        \"\"\"Load and return unpickled object.\n\n        Returns\n        -------\n        object\n            Unpickled object from file.\n        \"\"\"\n        ...\n\n    def find_class(self, module: str, name: str) -&gt; object:\n        \"\"\"Find class by module and name.\n\n        Parameters\n        ----------\n        module : str\n            Module name.\n        name : str\n            Class name.\n\n        Returns\n        -------\n        object\n            Class object.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle._StdlibUnpickler.__init__","title":"<code>__init__(file, *, fix_imports=..., encoding=..., errors=..., buffers=...)</code>","text":"<p>Initialize unpickler with file handle.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>BinaryIO</code> <p>Binary file handle to read from.</p> required <code>fix_imports</code> <code>bool</code> <p>Whether to fix imports for Python 2 compatibility.</p> <code>...</code> <code>encoding</code> <code>str</code> <p>Text encoding for Python 2 compatibility.</p> <code>...</code> <code>errors</code> <code>str</code> <p>Error handling mode for encoding.</p> <code>...</code> <code>buffers</code> <code>object | None</code> <p>Buffer protocol support.</p> <code>...</code> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def __init__(\n    self,\n    file: BinaryIO,\n    *,\n    fix_imports: bool = ...,\n    encoding: str = ...,\n    errors: str = ...,\n    buffers: object | None = ...,\n) -&gt; None:\n    \"\"\"Initialize unpickler with file handle.\n\n    Parameters\n    ----------\n    file : BinaryIO\n        Binary file handle to read from.\n    fix_imports : bool, optional\n        Whether to fix imports for Python 2 compatibility.\n    encoding : str, optional\n        Text encoding for Python 2 compatibility.\n    errors : str, optional\n        Error handling mode for encoding.\n    buffers : object | None, optional\n        Buffer protocol support.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle._StdlibUnpickler.find_class","title":"<code>find_class(module, name)</code>","text":"<p>Find class by module and name.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>str</code> <p>Module name.</p> required <code>name</code> <code>str</code> <p>Class name.</p> required <p>Returns:</p> Type Description <code>object</code> <p>Class object.</p> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def find_class(self, module: str, name: str) -&gt; object:\n    \"\"\"Find class by module and name.\n\n    Parameters\n    ----------\n    module : str\n        Module name.\n    name : str\n        Class name.\n\n    Returns\n    -------\n    object\n        Class object.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle._StdlibUnpickler.load","title":"<code>load()</code>","text":"<p>Load and return unpickled object.</p> <p>Returns:</p> Type Description <code>object</code> <p>Unpickled object from file.</p> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def load(self) -&gt; object:\n    \"\"\"Load and return unpickled object.\n\n    Returns\n    -------\n    object\n        Unpickled object from file.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestrationsafe_pickle_unpicklerprotocol","title":"orchestration.safe_pickle._UnpicklerProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle._UnpicklerProtocol","title":"<code>orchestration.safe_pickle._UnpicklerProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>class _UnpicklerProtocol(Protocol):\n    def __init__(\n        self,\n        file: BinaryIO,\n        *,\n        fix_imports: bool = ...,\n        encoding: str = ...,\n        errors: str = ...,\n        buffers: object | None = ...,\n    ) -&gt; None:\n        \"\"\"Initialize unpickler with file handle.\n\n        Parameters\n        ----------\n        file : BinaryIO\n            Binary file handle to read from.\n        fix_imports : bool, optional\n            Whether to fix imports for Python 2 compatibility.\n        encoding : str, optional\n            Text encoding for Python 2 compatibility.\n        errors : str, optional\n            Error handling mode for encoding.\n        buffers : object | None, optional\n            Buffer protocol support.\n        \"\"\"\n        ...\n\n    def load(self) -&gt; object:\n        \"\"\"Load and return unpickled object.\n\n        Returns\n        -------\n        object\n            Unpickled object from file.\n        \"\"\"\n        ...\n\n    def find_class(self, module: str, name: str) -&gt; object:\n        \"\"\"Find class by module and name.\n\n        Parameters\n        ----------\n        module : str\n            Module name.\n        name : str\n            Class name.\n\n        Returns\n        -------\n        object\n            Class object.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle._UnpicklerProtocol.__init__","title":"<code>__init__(file, *, fix_imports=..., encoding=..., errors=..., buffers=...)</code>","text":"<p>Initialize unpickler with file handle.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>BinaryIO</code> <p>Binary file handle to read from.</p> required <code>fix_imports</code> <code>bool</code> <p>Whether to fix imports for Python 2 compatibility.</p> <code>...</code> <code>encoding</code> <code>str</code> <p>Text encoding for Python 2 compatibility.</p> <code>...</code> <code>errors</code> <code>str</code> <p>Error handling mode for encoding.</p> <code>...</code> <code>buffers</code> <code>object | None</code> <p>Buffer protocol support.</p> <code>...</code> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def __init__(\n    self,\n    file: BinaryIO,\n    *,\n    fix_imports: bool = ...,\n    encoding: str = ...,\n    errors: str = ...,\n    buffers: object | None = ...,\n) -&gt; None:\n    \"\"\"Initialize unpickler with file handle.\n\n    Parameters\n    ----------\n    file : BinaryIO\n        Binary file handle to read from.\n    fix_imports : bool, optional\n        Whether to fix imports for Python 2 compatibility.\n    encoding : str, optional\n        Text encoding for Python 2 compatibility.\n    errors : str, optional\n        Error handling mode for encoding.\n    buffers : object | None, optional\n        Buffer protocol support.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle._UnpicklerProtocol.find_class","title":"<code>find_class(module, name)</code>","text":"<p>Find class by module and name.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>str</code> <p>Module name.</p> required <code>name</code> <code>str</code> <p>Class name.</p> required <p>Returns:</p> Type Description <code>object</code> <p>Class object.</p> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def find_class(self, module: str, name: str) -&gt; object:\n    \"\"\"Find class by module and name.\n\n    Parameters\n    ----------\n    module : str\n        Module name.\n    name : str\n        Class name.\n\n    Returns\n    -------\n    object\n        Class object.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle._UnpicklerProtocol.load","title":"<code>load()</code>","text":"<p>Load and return unpickled object.</p> <p>Returns:</p> Type Description <code>object</code> <p>Unpickled object from file.</p> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def load(self) -&gt; object:\n    \"\"\"Load and return unpickled object.\n\n    Returns\n    -------\n    object\n        Unpickled object from file.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestrationsafe_pickle_load_stdlib_pickle","title":"orchestration.safe_pickle._load_stdlib_pickle","text":""},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle._load_stdlib_pickle","title":"<code>orchestration.safe_pickle._load_stdlib_pickle()</code>","text":"Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def _load_stdlib_pickle() -&gt; _PickleModule:\n    module_name = \"_pickle\"\n    return cast(\"_PickleModule\", import_module(module_name))\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestrationsafe_pickle_validate_object","title":"orchestration.safe_pickle._validate_object","text":""},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle._validate_object","title":"<code>orchestration.safe_pickle._validate_object(obj, depth=0)</code>","text":"<p>Recursively validate object contains only safe types.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>Object to validate.</p> required <code>depth</code> <code>int</code> <p>Current recursion depth (prevents infinite recursion).</p> <code>0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If object contains disallowed types or exceeds depth limit.</p> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def _validate_object(obj: object, depth: int = 0) -&gt; None:\n    \"\"\"Recursively validate object contains only safe types.\n\n    Parameters\n    ----------\n    obj : object\n        Object to validate.\n    depth : int\n        Current recursion depth (prevents infinite recursion).\n\n    Raises\n    ------\n    ValueError\n        If object contains disallowed types or exceeds depth limit.\n    \"\"\"\n    max_depth = 100\n    if depth &gt; max_depth:\n        msg = f\"Object nesting exceeds maximum depth ({max_depth})\"\n        raise ValueError(msg)\n\n    # Base case: primitives are always safe\n    if isinstance(obj, (str, int, float, bool, type(None))):\n        return\n\n    # Recursive cases: containers\n    if isinstance(obj, dict):\n        for key, value in obj.items():\n            _validate_object(key, depth + 1)\n            _validate_object(value, depth + 1)\n        return\n\n    if isinstance(obj, (list, tuple)):\n        for item in obj:\n            _validate_object(item, depth + 1)\n        return\n\n    # Reject all other types\n    msg = f\"Object type not allowed for safe pickling: {type(obj).__qualname__}\"\n    raise ValueError(msg)\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestrationsafe_pickledump","title":"orchestration.safe_pickle.dump","text":""},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle.dump","title":"<code>orchestration.safe_pickle.dump(obj, file)</code>","text":"<p>Safely pickle object to file with type validation.</p> <p>Only dict, list, tuple, and primitives (str, int, float, bool, None) are allowed to prevent arbitrary code execution during deserialization.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>object</code> <p>Object to serialize. Must be dict, list, or primitives.</p> required <code>file</code> <code>BinaryIO</code> <p>File-like object opened in binary write mode.</p> required Notes <p>Propagates :class:<code>ValueError</code> when the object contains disallowed types.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; data = {\"keys\": [\"a\", \"b\"], \"vectors\": [1.0, 2.0]}\n&gt;&gt;&gt; with tempfile.NamedTemporaryFile() as f:\n...     dump(data, f)\n</code></pre> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def dump(obj: object, file: BinaryIO) -&gt; None:\n    \"\"\"Safely pickle object to file with type validation.\n\n    Only dict, list, tuple, and primitives (str, int, float, bool, None)\n    are allowed to prevent arbitrary code execution during deserialization.\n\n    Parameters\n    ----------\n    obj : object\n        Object to serialize. Must be dict, list, or primitives.\n    file : BinaryIO\n        File-like object opened in binary write mode.\n\n    Notes\n    -----\n    Propagates :class:`ValueError` when the object contains disallowed types.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import tempfile\n    &gt;&gt;&gt; data = {\"keys\": [\"a\", \"b\"], \"vectors\": [1.0, 2.0]}\n    &gt;&gt;&gt; with tempfile.NamedTemporaryFile() as f:\n    ...     dump(data, f)\n    \"\"\"\n    _validate_object(obj)\n    _stdlib_pickle.dump(obj, file)\n</code></pre>"},{"location":"modules/orchestration.safe_pickle/#orchestrationsafe_pickleload","title":"orchestration.safe_pickle.load","text":""},{"location":"modules/orchestration.safe_pickle/#orchestration.safe_pickle.load","title":"<code>orchestration.safe_pickle.load(file)</code>","text":"<p>Safely unpickle object from file with type restrictions.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>BinaryIO</code> <p>File-like object opened in binary read mode.</p> required <p>Returns:</p> Type Description <code>object</code> <p>Deserialized object (guaranteed primitives/dict/list only).</p> Notes <p>Propagates :class:<code>UnsafePickleError</code> when the pickle stream contains disallowed types.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; data = {\"keys\": [\"a\", \"b\"], \"vectors\": [1.0, 2.0]}\n&gt;&gt;&gt; with tempfile.NamedTemporaryFile() as f:\n...     dump(data, f)\n...     f.seek(0)\n...     loaded = load(f)\n...     assert loaded == data\n</code></pre> Source code in <code>src/orchestration/safe_pickle.py</code> <pre><code>def load(file: BinaryIO) -&gt; object:\n    \"\"\"Safely unpickle object from file with type restrictions.\n\n    Parameters\n    ----------\n    file : BinaryIO\n        File-like object opened in binary read mode.\n\n    Returns\n    -------\n    object\n        Deserialized object (guaranteed primitives/dict/list only).\n\n    Notes\n    -----\n    Propagates :class:`UnsafePickleError` when the pickle stream contains\n    disallowed types.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import tempfile\n    &gt;&gt;&gt; data = {\"keys\": [\"a\", \"b\"], \"vectors\": [1.0, 2.0]}\n    &gt;&gt;&gt; with tempfile.NamedTemporaryFile() as f:\n    ...     dump(data, f)\n    ...     f.seek(0)\n    ...     loaded = load(f)\n    ...     assert loaded == data\n    \"\"\"\n    unpickler = SafeUnpickler(file)\n    loaded: object = unpickler.load()\n    return loaded\n</code></pre>"},{"location":"modules/registry.api/","title":"registry.api","text":""},{"location":"modules/registry.api/#registryapi","title":"registry.api","text":"<p>Protocol defining the registry interface</p> <p>:material-source-repository: View source</p>"},{"location":"modules/registry.api/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class Registry\n    class Protocol\n    Protocol &lt;|-- Registry\n</code></pre>"},{"location":"modules/registry.api/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"registry.api__future__.annotationscollections.abc.Mappingkgfoundry_common.models.Dockgfoundry_common.models.DoctagsAssetkgfoundry_common.navmap_loader.load_nav_metadatatyping.Protocoltyping.TYPE_CHECKINGregistry.api code <p>See the full diagram: registry.api</p>"},{"location":"modules/registry.api/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>registry.api.Registry</li> </ul>"},{"location":"modules/registry.api/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Mapping</code>, <code>kgfoundry_common.models.Doc</code>, <code>kgfoundry_common.models.DoctagsAsset</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code></p>"},{"location":"modules/registry.api/#contents","title":"Contents","text":""},{"location":"modules/registry.api/#registryapiregistry","title":"registry.api.Registry","text":"<p>Bases: Protocol</p>"},{"location":"modules/registry.api/#registry.api.Registry","title":"<code>registry.api.Registry</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol defining the registry interface for pipeline artifacts.</p> <p>This protocol defines the interface for registry implementations that store pipeline artifacts and metadata. Implementations must provide methods for managing runs, datasets, documents, doctags, and events.</p> <p>Implementations include DuckDBRegistry and DuckDBRegistryHelper.</p> Source code in <code>src/registry/api.py</code> <pre><code>class Registry(Protocol):\n    \"\"\"Protocol defining the registry interface for pipeline artifacts.\n\n    This protocol defines the interface for registry implementations that store pipeline artifacts\n    and metadata. Implementations must provide methods for managing runs, datasets, documents,\n    doctags, and events.\n\n    Implementations include DuckDBRegistry and DuckDBRegistryHelper.\n    \"\"\"\n\n    def begin_dataset(self, kind: str, run_id: str) -&gt; str:\n        \"\"\"Begin a new dataset within a run.\n\n        Creates a new dataset record associated with the specified run.\n        The dataset is initially created with an empty parquet_root; use\n        commit_dataset() to finalize it with data.\n\n        Parameters\n        ----------\n        kind : str\n            Dataset kind (e.g., \"embeddings\", \"chunks\", \"metadata\").\n        run_id : str\n            Run ID that this dataset belongs to.\n\n        Returns\n        -------\n        str\n            Unique dataset ID (UUID) for the newly created dataset.\n        \"\"\"\n        ...\n\n    def commit_dataset(self, dataset_id: str, parquet_root: str, rows: int) -&gt; None:\n        \"\"\"Commit a dataset with Parquet data location.\n\n        Finalizes a dataset by updating its parquet_root path and row count.\n        Used after Parquet files have been written to disk.\n\n        Parameters\n        ----------\n        dataset_id : str\n            Dataset ID to commit.\n        parquet_root : str\n            Root directory path where Parquet files are stored.\n        rows : int\n            Total number of rows in the dataset.\n        \"\"\"\n        ...\n\n    def rollback_dataset(self, dataset_id: str) -&gt; None:\n        \"\"\"Rollback a dataset by deleting it.\n\n        Deletes a dataset record when dataset creation fails or needs to\n        be abandoned. Use this for cleanup when errors occur.\n\n        Parameters\n        ----------\n        dataset_id : str\n            Dataset ID to rollback.\n        \"\"\"\n        ...\n\n    def insert_run(\n        self,\n        purpose: str,\n        model_id: str | None,\n        revision: str | None,\n        config: Mapping[str, object],\n    ) -&gt; str:\n        \"\"\"Create a run record and return the generated identifier.\n\n        Inserts a new run record into the registry with the specified purpose,\n        model information, and configuration. Returns a unique run ID.\n\n        Parameters\n        ----------\n        purpose : str\n            Purpose description for the run (e.g., \"embedding\", \"indexing\").\n        model_id : str | None\n            Model identifier used in this run, or None if not applicable.\n        revision : str | None\n            Model revision or version, or None if not applicable.\n        config : Mapping[str, object]\n            Run configuration dictionary (serialized as JSON).\n\n        Returns\n        -------\n        str\n            Unique run ID (UUID) for the newly created run.\n        \"\"\"\n        ...\n\n    def close_run(self, run_id: str, *, success: bool, notes: str | None = None) -&gt; None:\n        \"\"\"Close a pipeline run and record completion status.\n\n        Updates the run's finished_at timestamp and records completion status\n        with optional notes.\n\n        Parameters\n        ----------\n        run_id : str\n            Run ID to close.\n        success : bool\n            Whether the run completed successfully.\n        notes : str | None, optional\n            Optional notes about the run completion. Defaults to None.\n        \"\"\"\n        ...\n\n    def register_documents(self, docs: list[Doc]) -&gt; None:\n        \"\"\"Register document records in the registry.\n\n        Inserts or updates document records in the documents table. Each\n        document's metadata (title, authors, publication date, etc.) is\n        stored with the document ID.\n\n        Parameters\n        ----------\n        docs : list[Doc]\n            List of document objects to register. Each document must have\n            a unique doc_id.\n        \"\"\"\n        ...\n\n    def register_doctags(self, assets: list[DoctagsAsset]) -&gt; None:\n        \"\"\"Register doctags asset records in the registry.\n\n        Inserts or updates doctags asset records in the doctags table.\n        Doctags represent visual document tags generated by vision-language\n        models.\n\n        Parameters\n        ----------\n        assets : list[DoctagsAsset]\n            List of doctags asset objects to register. Each asset must have\n            doc_id, doctags_uri, and model information.\n        \"\"\"\n        ...\n\n    def emit_event(self, event_name: str, subject_id: str, payload: Mapping[str, object]) -&gt; None:\n        \"\"\"Emit a pipeline event to the registry.\n\n        Records an event in the pipeline_events table with a unique event ID,\n        event name, subject ID, and JSON payload. Used for tracking pipeline\n        operations and state changes.\n\n        Parameters\n        ----------\n        event_name : str\n            Name of the event (e.g., \"RunClosed\", \"DatasetCommitted\").\n        subject_id : str\n            ID of the subject the event relates to (e.g., run_id, dataset_id).\n        payload : Mapping[str, object]\n            Event payload dictionary (serialized as JSON).\n        \"\"\"\n        ...\n\n    def incident(self, event: str, subject_id: str, error_class: str, message: str) -&gt; None:\n        \"\"\"Record an incident emitted by registry clients.\n\n        Inserts an incident record into the incidents table for tracking\n        errors and failures in pipeline operations.\n\n        Parameters\n        ----------\n        event : str\n            Event name associated with the incident.\n        subject_id : str\n            ID of the subject the incident relates to (e.g., run_id, dataset_id).\n        error_class : str\n            Error class or exception type name.\n        message : str\n            Error message describing the incident.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/registry.api/#registry.api.Registry.begin_dataset","title":"<code>begin_dataset(kind, run_id)</code>","text":"<p>Begin a new dataset within a run.</p> <p>Creates a new dataset record associated with the specified run. The dataset is initially created with an empty parquet_root; use commit_dataset() to finalize it with data.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>Dataset kind (e.g., \"embeddings\", \"chunks\", \"metadata\").</p> required <code>run_id</code> <code>str</code> <p>Run ID that this dataset belongs to.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Unique dataset ID (UUID) for the newly created dataset.</p> Source code in <code>src/registry/api.py</code> <pre><code>def begin_dataset(self, kind: str, run_id: str) -&gt; str:\n    \"\"\"Begin a new dataset within a run.\n\n    Creates a new dataset record associated with the specified run.\n    The dataset is initially created with an empty parquet_root; use\n    commit_dataset() to finalize it with data.\n\n    Parameters\n    ----------\n    kind : str\n        Dataset kind (e.g., \"embeddings\", \"chunks\", \"metadata\").\n    run_id : str\n        Run ID that this dataset belongs to.\n\n    Returns\n    -------\n    str\n        Unique dataset ID (UUID) for the newly created dataset.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/registry.api/#registry.api.Registry.close_run","title":"<code>close_run(run_id, *, success, notes=None)</code>","text":"<p>Close a pipeline run and record completion status.</p> <p>Updates the run's finished_at timestamp and records completion status with optional notes.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>str</code> <p>Run ID to close.</p> required <code>success</code> <code>bool</code> <p>Whether the run completed successfully.</p> required <code>notes</code> <code>str | None</code> <p>Optional notes about the run completion. Defaults to None.</p> <code>None</code> Source code in <code>src/registry/api.py</code> <pre><code>def close_run(self, run_id: str, *, success: bool, notes: str | None = None) -&gt; None:\n    \"\"\"Close a pipeline run and record completion status.\n\n    Updates the run's finished_at timestamp and records completion status\n    with optional notes.\n\n    Parameters\n    ----------\n    run_id : str\n        Run ID to close.\n    success : bool\n        Whether the run completed successfully.\n    notes : str | None, optional\n        Optional notes about the run completion. Defaults to None.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/registry.api/#registry.api.Registry.commit_dataset","title":"<code>commit_dataset(dataset_id, parquet_root, rows)</code>","text":"<p>Commit a dataset with Parquet data location.</p> <p>Finalizes a dataset by updating its parquet_root path and row count. Used after Parquet files have been written to disk.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID to commit.</p> required <code>parquet_root</code> <code>str</code> <p>Root directory path where Parquet files are stored.</p> required <code>rows</code> <code>int</code> <p>Total number of rows in the dataset.</p> required Source code in <code>src/registry/api.py</code> <pre><code>def commit_dataset(self, dataset_id: str, parquet_root: str, rows: int) -&gt; None:\n    \"\"\"Commit a dataset with Parquet data location.\n\n    Finalizes a dataset by updating its parquet_root path and row count.\n    Used after Parquet files have been written to disk.\n\n    Parameters\n    ----------\n    dataset_id : str\n        Dataset ID to commit.\n    parquet_root : str\n        Root directory path where Parquet files are stored.\n    rows : int\n        Total number of rows in the dataset.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/registry.api/#registry.api.Registry.emit_event","title":"<code>emit_event(event_name, subject_id, payload)</code>","text":"<p>Emit a pipeline event to the registry.</p> <p>Records an event in the pipeline_events table with a unique event ID, event name, subject ID, and JSON payload. Used for tracking pipeline operations and state changes.</p> <p>Parameters:</p> Name Type Description Default <code>event_name</code> <code>str</code> <p>Name of the event (e.g., \"RunClosed\", \"DatasetCommitted\").</p> required <code>subject_id</code> <code>str</code> <p>ID of the subject the event relates to (e.g., run_id, dataset_id).</p> required <code>payload</code> <code>Mapping[str, object]</code> <p>Event payload dictionary (serialized as JSON).</p> required Source code in <code>src/registry/api.py</code> <pre><code>def emit_event(self, event_name: str, subject_id: str, payload: Mapping[str, object]) -&gt; None:\n    \"\"\"Emit a pipeline event to the registry.\n\n    Records an event in the pipeline_events table with a unique event ID,\n    event name, subject ID, and JSON payload. Used for tracking pipeline\n    operations and state changes.\n\n    Parameters\n    ----------\n    event_name : str\n        Name of the event (e.g., \"RunClosed\", \"DatasetCommitted\").\n    subject_id : str\n        ID of the subject the event relates to (e.g., run_id, dataset_id).\n    payload : Mapping[str, object]\n        Event payload dictionary (serialized as JSON).\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/registry.api/#registry.api.Registry.incident","title":"<code>incident(event, subject_id, error_class, message)</code>","text":"<p>Record an incident emitted by registry clients.</p> <p>Inserts an incident record into the incidents table for tracking errors and failures in pipeline operations.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>str</code> <p>Event name associated with the incident.</p> required <code>subject_id</code> <code>str</code> <p>ID of the subject the incident relates to (e.g., run_id, dataset_id).</p> required <code>error_class</code> <code>str</code> <p>Error class or exception type name.</p> required <code>message</code> <code>str</code> <p>Error message describing the incident.</p> required Source code in <code>src/registry/api.py</code> <pre><code>def incident(self, event: str, subject_id: str, error_class: str, message: str) -&gt; None:\n    \"\"\"Record an incident emitted by registry clients.\n\n    Inserts an incident record into the incidents table for tracking\n    errors and failures in pipeline operations.\n\n    Parameters\n    ----------\n    event : str\n        Event name associated with the incident.\n    subject_id : str\n        ID of the subject the incident relates to (e.g., run_id, dataset_id).\n    error_class : str\n        Error class or exception type name.\n    message : str\n        Error message describing the incident.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/registry.api/#registry.api.Registry.insert_run","title":"<code>insert_run(purpose, model_id, revision, config)</code>","text":"<p>Create a run record and return the generated identifier.</p> <p>Inserts a new run record into the registry with the specified purpose, model information, and configuration. Returns a unique run ID.</p> <p>Parameters:</p> Name Type Description Default <code>purpose</code> <code>str</code> <p>Purpose description for the run (e.g., \"embedding\", \"indexing\").</p> required <code>model_id</code> <code>str | None</code> <p>Model identifier used in this run, or None if not applicable.</p> required <code>revision</code> <code>str | None</code> <p>Model revision or version, or None if not applicable.</p> required <code>config</code> <code>Mapping[str, object]</code> <p>Run configuration dictionary (serialized as JSON).</p> required <p>Returns:</p> Type Description <code>str</code> <p>Unique run ID (UUID) for the newly created run.</p> Source code in <code>src/registry/api.py</code> <pre><code>def insert_run(\n    self,\n    purpose: str,\n    model_id: str | None,\n    revision: str | None,\n    config: Mapping[str, object],\n) -&gt; str:\n    \"\"\"Create a run record and return the generated identifier.\n\n    Inserts a new run record into the registry with the specified purpose,\n    model information, and configuration. Returns a unique run ID.\n\n    Parameters\n    ----------\n    purpose : str\n        Purpose description for the run (e.g., \"embedding\", \"indexing\").\n    model_id : str | None\n        Model identifier used in this run, or None if not applicable.\n    revision : str | None\n        Model revision or version, or None if not applicable.\n    config : Mapping[str, object]\n        Run configuration dictionary (serialized as JSON).\n\n    Returns\n    -------\n    str\n        Unique run ID (UUID) for the newly created run.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/registry.api/#registry.api.Registry.register_doctags","title":"<code>register_doctags(assets)</code>","text":"<p>Register doctags asset records in the registry.</p> <p>Inserts or updates doctags asset records in the doctags table. Doctags represent visual document tags generated by vision-language models.</p> <p>Parameters:</p> Name Type Description Default <code>assets</code> <code>list[DoctagsAsset]</code> <p>List of doctags asset objects to register. Each asset must have doc_id, doctags_uri, and model information.</p> required Source code in <code>src/registry/api.py</code> <pre><code>def register_doctags(self, assets: list[DoctagsAsset]) -&gt; None:\n    \"\"\"Register doctags asset records in the registry.\n\n    Inserts or updates doctags asset records in the doctags table.\n    Doctags represent visual document tags generated by vision-language\n    models.\n\n    Parameters\n    ----------\n    assets : list[DoctagsAsset]\n        List of doctags asset objects to register. Each asset must have\n        doc_id, doctags_uri, and model information.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/registry.api/#registry.api.Registry.register_documents","title":"<code>register_documents(docs)</code>","text":"<p>Register document records in the registry.</p> <p>Inserts or updates document records in the documents table. Each document's metadata (title, authors, publication date, etc.) is stored with the document ID.</p> <p>Parameters:</p> Name Type Description Default <code>docs</code> <code>list[Doc]</code> <p>List of document objects to register. Each document must have a unique doc_id.</p> required Source code in <code>src/registry/api.py</code> <pre><code>def register_documents(self, docs: list[Doc]) -&gt; None:\n    \"\"\"Register document records in the registry.\n\n    Inserts or updates document records in the documents table. Each\n    document's metadata (title, authors, publication date, etc.) is\n    stored with the document ID.\n\n    Parameters\n    ----------\n    docs : list[Doc]\n        List of document objects to register. Each document must have\n        a unique doc_id.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/registry.api/#registry.api.Registry.rollback_dataset","title":"<code>rollback_dataset(dataset_id)</code>","text":"<p>Rollback a dataset by deleting it.</p> <p>Deletes a dataset record when dataset creation fails or needs to be abandoned. Use this for cleanup when errors occur.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID to rollback.</p> required Source code in <code>src/registry/api.py</code> <pre><code>def rollback_dataset(self, dataset_id: str) -&gt; None:\n    \"\"\"Rollback a dataset by deleting it.\n\n    Deletes a dataset record when dataset creation fails or needs to\n    be abandoned. Use this for cleanup when errors occur.\n\n    Parameters\n    ----------\n    dataset_id : str\n        Dataset ID to rollback.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/registry.duckdb_helpers/","title":"registry.duckdb_helpers","text":""},{"location":"modules/registry.duckdb_helpers/#registryduckdb_helpers","title":"registry.duckdb_helpers","text":"<p>Typed DuckDB helper utilities for parameterized queries and logging.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/registry.duckdb_helpers/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class DuckDBQueryOptions\n</code></pre>"},{"location":"modules/registry.duckdb_helpers/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"registry.duckdb_helpers__future__.annotationscollections.abc.Iterablecollections.abc.Mappingcollections.abc.Sequencedataclasses.dataclassdataclasses.replaceduckdbduckdb.DuckDBPyConnectionkgfoundry_common.errors.RegistryErrorkgfoundry_common.logging.get_loggerkgfoundry_common.logging.with_fieldskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.observability.MetricsProviderkgfoundry_common.observability.observe_durationpathlib.Pathtimetyping.Finaltyping.TYPE_CHECKINGtyping.castregistry.duckdb_registryregistry.helperregistry.migrateregistry.duckdb_helpers code <p>See the full diagram: registry.duckdb_helpers</p>"},{"location":"modules/registry.duckdb_helpers/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>registry.duckdb_helpers.DuckDBQueryOptions</li> <li>registry.duckdb_helpers._coerce_options</li> <li>registry.duckdb_helpers._ensure_parameterized</li> <li>registry.duckdb_helpers._format_params</li> </ul>"},{"location":"modules/registry.duckdb_helpers/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Iterable</code>, <code>collections.abc.Mapping</code>, <code>collections.abc.Sequence</code>, <code>dataclasses.dataclass</code>, <code>dataclasses.replace</code>, <code>duckdb</code>, <code>duckdb.DuckDBPyConnection</code>, <code>kgfoundry_common.errors.RegistryError</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>kgfoundry_common.logging.with_fields</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.observability.MetricsProvider</code>, <code>kgfoundry_common.observability.observe_duration</code>, <code>pathlib.Path</code>, <code>time</code>, <code>typing.Final</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p> <p>Imported by: registry.duckdb_registry, registry.helper, registry.migrate</p>"},{"location":"modules/registry.duckdb_helpers/#contents","title":"Contents","text":""},{"location":"modules/registry.duckdb_helpers/#registryduckdb_helpersduckdbqueryoptions","title":"registry.duckdb_helpers.DuckDBQueryOptions","text":""},{"location":"modules/registry.duckdb_helpers/#registry.duckdb_helpers.DuckDBQueryOptions","title":"<code>registry.duckdb_helpers.DuckDBQueryOptions</code>  <code>dataclass</code>","text":"<p>Configuration for DuckDB query execution helpers.</p> Source code in <code>src/registry/duckdb_helpers.py</code> <pre><code>@dataclass(slots=True, frozen=True)\n# [nav:anchor DuckDBQueryOptions]\nclass DuckDBQueryOptions:\n    \"\"\"Configuration for DuckDB query execution helpers.\"\"\"\n\n    timeout_s: float = DEFAULT_TIMEOUT_S\n    slow_query_threshold_s: float = DEFAULT_SLOW_QUERY_THRESHOLD_S\n    operation: str = \"duckdb.execute\"\n    require_parameterized: bool | None = None\n</code></pre>"},{"location":"modules/registry.duckdb_helpers/#registryduckdb_helpers_coerce_options","title":"registry.duckdb_helpers._coerce_options","text":""},{"location":"modules/registry.duckdb_helpers/#registry.duckdb_helpers._coerce_options","title":"<code>registry.duckdb_helpers._coerce_options(options, *, operation)</code>","text":"Source code in <code>src/registry/duckdb_helpers.py</code> <pre><code>def _coerce_options(\n    options: DuckDBQueryOptions | None,\n    *,\n    operation: str,\n) -&gt; DuckDBQueryOptions:\n    if options is None:\n        return DuckDBQueryOptions(operation=operation)\n    if options.operation == operation:\n        return options\n    return replace(options, operation=operation)\n</code></pre>"},{"location":"modules/registry.duckdb_helpers/#registryduckdb_helpers_ensure_parameterized","title":"registry.duckdb_helpers._ensure_parameterized","text":""},{"location":"modules/registry.duckdb_helpers/#registry.duckdb_helpers._ensure_parameterized","title":"<code>registry.duckdb_helpers._ensure_parameterized(sql, *, require_parameterized)</code>","text":"<p>Ensure SQL query uses parameterized placeholders.</p> <p>Validates that SQL queries use parameterized placeholders (?, :name, or $n) when required. Raises RegistryError if parameterization is required but missing, preventing SQL injection vulnerabilities.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>SQL query string to validate.</p> required <code>require_parameterized</code> <code>bool</code> <p>Whether to require parameterization. If True, query must contain parameter placeholders (?, :name, or $n).</p> required <p>Raises:</p> Type Description <code>RegistryError</code> <p>If require_parameterized is True but query contains no parameter placeholders.</p> Source code in <code>src/registry/duckdb_helpers.py</code> <pre><code>def _ensure_parameterized(sql: str, *, require_parameterized: bool) -&gt; None:\n    \"\"\"Ensure SQL query uses parameterized placeholders.\n\n    Validates that SQL queries use parameterized placeholders (?, :name, or $n)\n    when required. Raises RegistryError if parameterization is required but\n    missing, preventing SQL injection vulnerabilities.\n\n    Parameters\n    ----------\n    sql : str\n        SQL query string to validate.\n    require_parameterized : bool\n        Whether to require parameterization. If True, query must contain\n        parameter placeholders (?, :name, or $n).\n\n    Raises\n    ------\n    RegistryError\n        If require_parameterized is True but query contains no parameter\n        placeholders.\n    \"\"\"\n    if not require_parameterized:\n        return\n    if \"?\" in sql or \":\" in sql or \"$\" in sql:\n        return\n    error_message = \"DuckDB query must be parameterized\"\n    raise RegistryError(\n        error_message,\n        context={\"sql_preview\": _format_sql(sql)},\n    )\n</code></pre>"},{"location":"modules/registry.duckdb_helpers/#registryduckdb_helpers_format_params","title":"registry.duckdb_helpers._format_params","text":""},{"location":"modules/registry.duckdb_helpers/#registry.duckdb_helpers._format_params","title":"<code>registry.duckdb_helpers._format_params(params)</code>","text":"<p>Format query parameters for logging preview.</p> <p>Formats query parameters for safe logging by truncating string values. Returns a dict for named parameters or a list for positional parameters.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>Params</code> <p>Query parameters (Sequence for positional, Mapping for named, or None).</p> required <p>Returns:</p> Type Description <code>object</code> <p>Formatted parameters: dict for named params, list for positional params, or empty dict if params is None.</p> Source code in <code>src/registry/duckdb_helpers.py</code> <pre><code>def _format_params(params: Params) -&gt; object:\n    \"\"\"Format query parameters for logging preview.\n\n    Formats query parameters for safe logging by truncating string values.\n    Returns a dict for named parameters or a list for positional parameters.\n\n    Parameters\n    ----------\n    params : Params\n        Query parameters (Sequence for positional, Mapping for named, or None).\n\n    Returns\n    -------\n    object\n        Formatted parameters: dict for named params, list for positional params,\n        or empty dict if params is None.\n    \"\"\"\n    if params is None:\n        return {}\n    if isinstance(params, Mapping):\n        return {str(key): _truncate_value(value) for key, value in params.items()}\n    return [_truncate_value(value) for value in params]\n</code></pre>"},{"location":"modules/registry.duckdb_helpers/#registryduckdb_helpers_format_sql","title":"registry.duckdb_helpers._format_sql","text":""},{"location":"modules/registry.duckdb_helpers/#registry.duckdb_helpers._format_sql","title":"<code>registry.duckdb_helpers._format_sql(sql)</code>","text":"<p>Format SQL query for logging preview.</p> <p>Compacts whitespace and truncates long SQL queries to MAX_SQL_PREVIEW_CHARS for safe logging. Used internally to prevent logging sensitive data or overwhelming logs with very long queries.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>SQL query string to format.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Compacted SQL string, truncated with ellipsis if longer than MAX_SQL_PREVIEW_CHARS.</p> Source code in <code>src/registry/duckdb_helpers.py</code> <pre><code>def _format_sql(sql: str) -&gt; str:\n    \"\"\"Format SQL query for logging preview.\n\n    Compacts whitespace and truncates long SQL queries to MAX_SQL_PREVIEW_CHARS\n    for safe logging. Used internally to prevent logging sensitive data or\n    overwhelming logs with very long queries.\n\n    Parameters\n    ----------\n    sql : str\n        SQL query string to format.\n\n    Returns\n    -------\n    str\n        Compacted SQL string, truncated with ellipsis if longer than\n        MAX_SQL_PREVIEW_CHARS.\n    \"\"\"\n    compact = \" \".join(sql.split())\n    if len(compact) &lt;= MAX_SQL_PREVIEW_CHARS:\n        return compact\n    return f\"{compact[:MAX_SQL_PREVIEW_CHARS]}\u2026\"\n</code></pre>"},{"location":"modules/registry.duckdb_helpers/#registryduckdb_helpers_set_timeout","title":"registry.duckdb_helpers._set_timeout","text":""},{"location":"modules/registry.duckdb_helpers/#registry.duckdb_helpers._set_timeout","title":"<code>registry.duckdb_helpers._set_timeout(conn, timeout_s)</code>","text":"<p>Set statement timeout for DuckDB connection.</p> <p>Configures the statement_timeout pragma on the connection to limit query execution time. Timeout is set in milliseconds. If timeout_s is &lt;= 0, no timeout is set.</p> <p>Parameters:</p> Name Type Description Default <code>conn</code> <code>DuckDBPyConnection</code> <p>DuckDB connection to configure.</p> required <code>timeout_s</code> <code>float</code> <p>Timeout in seconds. Must be positive to set a timeout.</p> required Source code in <code>src/registry/duckdb_helpers.py</code> <pre><code>def _set_timeout(conn: DuckDBPyConnection, timeout_s: float) -&gt; None:\n    \"\"\"Set statement timeout for DuckDB connection.\n\n    Configures the statement_timeout pragma on the connection to limit query\n    execution time. Timeout is set in milliseconds. If timeout_s is &lt;= 0,\n    no timeout is set.\n\n    Parameters\n    ----------\n    conn : DuckDBPyConnection\n        DuckDB connection to configure.\n    timeout_s : float\n        Timeout in seconds. Must be positive to set a timeout.\n    \"\"\"\n    if timeout_s &lt;= 0:\n        return\n    timeout_ms = int(timeout_s * 1000)\n    conn.execute(f\"PRAGMA statement_timeout='{timeout_ms}ms'\")\n</code></pre>"},{"location":"modules/registry.duckdb_helpers/#registryduckdb_helpers_truncate_value","title":"registry.duckdb_helpers._truncate_value","text":""},{"location":"modules/registry.duckdb_helpers/#registry.duckdb_helpers._truncate_value","title":"<code>registry.duckdb_helpers._truncate_value(value)</code>","text":"<p>Truncate string values for logging preview.</p> <p>Truncates string values longer than MAX_SQL_PREVIEW_CHARS to prevent logging sensitive data or overwhelming logs. Other types are returned unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>object</code> <p>Value to truncate (if string).</p> required <p>Returns:</p> Type Description <code>object</code> <p>Truncated string with ellipsis if longer than MAX_SQL_PREVIEW_CHARS, or original value if not a string.</p> Source code in <code>src/registry/duckdb_helpers.py</code> <pre><code>def _truncate_value(value: object) -&gt; object:\n    \"\"\"Truncate string values for logging preview.\n\n    Truncates string values longer than MAX_SQL_PREVIEW_CHARS to prevent\n    logging sensitive data or overwhelming logs. Other types are returned\n    unchanged.\n\n    Parameters\n    ----------\n    value : object\n        Value to truncate (if string).\n\n    Returns\n    -------\n    object\n        Truncated string with ellipsis if longer than MAX_SQL_PREVIEW_CHARS,\n        or original value if not a string.\n    \"\"\"\n    if isinstance(value, str) and len(value) &gt; MAX_SQL_PREVIEW_CHARS:\n        return value[:MAX_SQL_PREVIEW_CHARS] + \"\u2026\"\n    return value\n</code></pre>"},{"location":"modules/registry.duckdb_helpers/#registryduckdb_helpersconnect","title":"registry.duckdb_helpers.connect","text":""},{"location":"modules/registry.duckdb_helpers/#registry.duckdb_helpers.connect","title":"<code>registry.duckdb_helpers.connect(db_path, *, read_only=False, pragmas=None)</code>","text":"<p>Create a DuckDB connection with standard pragmas applied.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>Path | str</code> <p>Path to DuckDB database file.</p> required <code>read_only</code> <code>bool</code> <p>Whether to open in read-only mode. Defaults to False.</p> <code>False</code> <code>pragmas</code> <code>Mapping[str, object] | None</code> <p>Additional pragma settings.</p> <code>None</code> <p>Returns:</p> Type Description <code>DuckDBPyConnection</code> <p>Configured DuckDB connection.</p> Source code in <code>src/registry/duckdb_helpers.py</code> <pre><code>def connect(\n    db_path: Path | str,\n    *,\n    read_only: bool = False,\n    pragmas: Mapping[str, object] | None = None,\n) -&gt; DuckDBPyConnection:\n    \"\"\"Create a DuckDB connection with standard pragmas applied.\n\n    Parameters\n    ----------\n    db_path : Path | str\n        Path to DuckDB database file.\n    read_only : bool, optional\n        Whether to open in read-only mode. Defaults to False.\n    pragmas : Mapping[str, object] | None, optional\n        Additional pragma settings.\n\n    Returns\n    -------\n    DuckDBPyConnection\n        Configured DuckDB connection.\n    \"\"\"\n    database_path = Path(db_path)\n    if not read_only:\n        database_path.parent.mkdir(parents=True, exist_ok=True)\n    conn = duckdb.connect(str(database_path), read_only=read_only)\n    effective_pragmas: dict[str, object] = {\"threads\": DEFAULT_THREADS}\n    if pragmas:\n        effective_pragmas.update({key.lower(): value for key, value in pragmas.items()})\n    for pragma_key, value in effective_pragmas.items():\n        if isinstance(value, bool):\n            literal = \"true\" if value else \"false\"\n        elif isinstance(value, (int, float)):\n            literal = str(value)\n        else:\n            literal = f\"'{value}'\"\n        conn.execute(f\"PRAGMA {pragma_key}={literal}\")\n    return conn\n</code></pre>"},{"location":"modules/registry.duckdb_helpers/#registryduckdb_helpersexecute","title":"registry.duckdb_helpers.execute","text":""},{"location":"modules/registry.duckdb_helpers/#registry.duckdb_helpers.execute","title":"<code>registry.duckdb_helpers.execute(conn, sql, params=None, *, options=None)</code>","text":"<p>Execute a DuckDB query with parameter binding, logging, and metrics.</p> <p>Executes a SQL query with optional parameter binding, structured logging, performance metrics, and timeout enforcement. Validates parameterization when required and logs slow queries.</p> <p>Parameters:</p> Name Type Description Default <code>conn</code> <code>DuckDBPyConnection</code> <p>DuckDB connection to execute query on.</p> required <code>sql</code> <code>str</code> <p>SQL query string. Must use parameterized placeholders (?, :name, or $n) if params is provided or require_parameterized is True.</p> required <code>params</code> <code>Params</code> <p>Query parameters (Sequence for positional, Mapping for named). Defaults to None.</p> <code>None</code> <code>options</code> <code>DuckDBQueryOptions | None</code> <p>Query execution options including timeout, logging metadata, and parameter enforcement. Defaults to None (uses module defaults).</p> <code>None</code> <p>Returns:</p> Type Description <code>DuckDBPyConnection</code> <p>Connection with query result relation (use .fetchall() or .fetchone() to retrieve rows).</p> <p>Raises:</p> Type Description <code>RegistryError</code> <p>If query execution fails, parameterization is required but missing, or timeout is exceeded.</p> Source code in <code>src/registry/duckdb_helpers.py</code> <pre><code>def execute(\n    conn: DuckDBPyConnection,\n    sql: str,\n    params: Params = None,\n    *,\n    options: DuckDBQueryOptions | None = None,\n) -&gt; DuckDBPyConnection:\n    \"\"\"Execute a DuckDB query with parameter binding, logging, and metrics.\n\n    Executes a SQL query with optional parameter binding, structured logging,\n    performance metrics, and timeout enforcement. Validates parameterization\n    when required and logs slow queries.\n\n    Parameters\n    ----------\n    conn : DuckDBPyConnection\n        DuckDB connection to execute query on.\n    sql : str\n        SQL query string. Must use parameterized placeholders (?, :name, or $n)\n        if params is provided or require_parameterized is True.\n    params : Params, optional\n        Query parameters (Sequence for positional, Mapping for named).\n        Defaults to None.\n    options : DuckDBQueryOptions | None, optional\n        Query execution options including timeout, logging metadata, and\n        parameter enforcement. Defaults to None (uses module defaults).\n\n    Returns\n    -------\n    DuckDBPyConnection\n        Connection with query result relation (use .fetchall() or .fetchone()\n        to retrieve rows).\n\n    Raises\n    ------\n    RegistryError\n        If query execution fails, parameterization is required but missing,\n        or timeout is exceeded.\n    \"\"\"\n    opts = _coerce_options(options, operation=\"duckdb.execute\")\n    require_flag = (\n        params is not None if opts.require_parameterized is None else opts.require_parameterized\n    )\n    _ensure_parameterized(sql, require_parameterized=require_flag)\n\n    sql_preview = _format_sql(sql)\n    query_params = _format_params(params)\n\n    with (\n        with_fields(\n            logger,\n            component=\"registry\",\n            operation=opts.operation,\n            sql_preview=sql_preview,\n        ) as log,\n        observe_duration(metrics, opts.operation, component=\"registry\") as observer,\n    ):\n        start = time.perf_counter()\n        try:\n            _set_timeout(conn, opts.timeout_s)\n            relation = conn.execute(sql) if params is None else conn.execute(sql, params)\n        except duckdb.Error as exc:\n            observer.error()\n            log.exception(\n                \"DuckDB query failed\",\n                extra={\"params\": query_params},\n            )\n            error_message = \"DuckDB query failed\"\n            raise RegistryError(\n                error_message,\n                cause=exc,\n                context={\"sql_preview\": sql_preview, \"params\": query_params},\n            ) from exc\n        else:\n            observer.success()\n            duration = time.perf_counter() - start\n            if duration &gt;= opts.slow_query_threshold_s:\n                log.warning(\n                    \"Slow DuckDB query\",\n                    extra={\"duration_ms\": round(duration * 1000, 2), \"params\": query_params},\n                )\n            else:\n                log.debug(\n                    \"DuckDB query executed\",\n                    extra={\"duration_ms\": round(duration * 1000, 2)},\n                )\n            return relation\n</code></pre>"},{"location":"modules/registry.duckdb_helpers/#registryduckdb_helpersfetch_all","title":"registry.duckdb_helpers.fetch_all","text":""},{"location":"modules/registry.duckdb_helpers/#registry.duckdb_helpers.fetch_all","title":"<code>registry.duckdb_helpers.fetch_all(conn, sql, params=None, *, options=None)</code>","text":"<p>Execute a query and return all rows as a list of tuples.</p> <p>Executes a SQL query and returns all result rows as a list of tuples. Uses execute() internally for logging and metrics.</p> <p>Parameters:</p> Name Type Description Default <code>conn</code> <code>DuckDBPyConnection</code> <p>DuckDB connection to execute query on.</p> required <code>sql</code> <code>str</code> <p>SQL query string. Must use parameterized placeholders if params provided.</p> required <code>params</code> <code>Params</code> <p>Query parameters (Sequence for positional, Mapping for named). Defaults to None.</p> <code>None</code> <code>options</code> <code>DuckDBQueryOptions | None</code> <p>Query execution options forwarded to :func:<code>execute</code>. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[tuple[object, ...]]</code> <p>List of result rows, each row as a tuple of column values.</p> Source code in <code>src/registry/duckdb_helpers.py</code> <pre><code>def fetch_all(\n    conn: DuckDBPyConnection,\n    sql: str,\n    params: Params = None,\n    *,\n    options: DuckDBQueryOptions | None = None,\n) -&gt; list[tuple[object, ...]]:\n    \"\"\"Execute a query and return all rows as a list of tuples.\n\n    Executes a SQL query and returns all result rows as a list of tuples.\n    Uses execute() internally for logging and metrics.\n\n    Parameters\n    ----------\n    conn : DuckDBPyConnection\n        DuckDB connection to execute query on.\n    sql : str\n        SQL query string. Must use parameterized placeholders if params provided.\n    params : Params, optional\n        Query parameters (Sequence for positional, Mapping for named).\n        Defaults to None.\n    options : DuckDBQueryOptions | None, optional\n        Query execution options forwarded to :func:`execute`.\n        Defaults to None.\n\n    Returns\n    -------\n    list[tuple[object, ...]]\n        List of result rows, each row as a tuple of column values.\n    \"\"\"\n    relation = execute(\n        conn,\n        sql,\n        params,\n        options=_coerce_options(options, operation=\"duckdb.fetch_all\"),\n    )\n    raw_rows = cast(\"list[tuple[object, ...]]\", relation.fetchall())\n    typed_rows: list[tuple[object, ...]] = [tuple(row) for row in raw_rows]\n    return typed_rows\n</code></pre>"},{"location":"modules/registry.duckdb_helpers/#registryduckdb_helpersfetch_one","title":"registry.duckdb_helpers.fetch_one","text":""},{"location":"modules/registry.duckdb_helpers/#registry.duckdb_helpers.fetch_one","title":"<code>registry.duckdb_helpers.fetch_one(conn, sql, params=None, *, options=None)</code>","text":"<p>Execute a query and return the first row or None.</p> <p>Executes a SQL query and returns the first result row as a tuple, or None if no rows are returned. Uses execute() internally for logging and metrics.</p> <p>Parameters:</p> Name Type Description Default <code>conn</code> <code>DuckDBPyConnection</code> <p>DuckDB connection to execute query on.</p> required <code>sql</code> <code>str</code> <p>SQL query string. Must use parameterized placeholders if params provided.</p> required <code>params</code> <code>Params</code> <p>Query parameters (Sequence for positional, Mapping for named). Defaults to None.</p> <code>None</code> <code>options</code> <code>DuckDBQueryOptions | None</code> <p>Query execution options forwarded to :func:<code>execute</code>. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[object, ...] | None</code> <p>First result row as a tuple of column values, or None if no rows.</p> Source code in <code>src/registry/duckdb_helpers.py</code> <pre><code>def fetch_one(\n    conn: DuckDBPyConnection,\n    sql: str,\n    params: Params = None,\n    *,\n    options: DuckDBQueryOptions | None = None,\n) -&gt; tuple[object, ...] | None:\n    \"\"\"Execute a query and return the first row or None.\n\n    Executes a SQL query and returns the first result row as a tuple, or None\n    if no rows are returned. Uses execute() internally for logging and metrics.\n\n    Parameters\n    ----------\n    conn : DuckDBPyConnection\n        DuckDB connection to execute query on.\n    sql : str\n        SQL query string. Must use parameterized placeholders if params provided.\n    params : Params, optional\n        Query parameters (Sequence for positional, Mapping for named).\n        Defaults to None.\n    options : DuckDBQueryOptions | None, optional\n        Query execution options forwarded to :func:`execute`.\n        Defaults to None.\n\n    Returns\n    -------\n    tuple[object, ...] | None\n        First result row as a tuple of column values, or None if no rows.\n    \"\"\"\n    relation = execute(\n        conn,\n        sql,\n        params,\n        options=_coerce_options(options, operation=\"duckdb.fetch_one\"),\n    )\n    raw_row = cast(\"tuple[object, ...] | None\", relation.fetchone())\n    if raw_row is None:\n        return None\n    return tuple(raw_row)\n</code></pre>"},{"location":"modules/registry.duckdb_helpers/#registryduckdb_helpersvalidate_identifier","title":"registry.duckdb_helpers.validate_identifier","text":""},{"location":"modules/registry.duckdb_helpers/#registry.duckdb_helpers.validate_identifier","title":"<code>registry.duckdb_helpers.validate_identifier(identifier, allowed, *, label='identifier')</code>","text":"<p>Validate that an identifier is within an allowed set.</p> <p>Validates that an identifier string is present in the allowed set of values. Used for sanitizing table names, column names, or other database identifiers to prevent SQL injection.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str</code> <p>Identifier string to validate.</p> required <code>allowed</code> <code>Iterable[str]</code> <p>Set of allowed identifier values.</p> required <code>label</code> <code>str</code> <p>Human-readable label for error messages (e.g., \"table name\", \"column name\"). Defaults to \"identifier\".</p> <code>'identifier'</code> <p>Returns:</p> Type Description <code>str</code> <p>The validated identifier (unchanged).</p> <p>Raises:</p> Type Description <code>RegistryError</code> <p>If identifier is not in the allowed set. Error context includes the invalid identifier and sorted list of allowed values.</p> Source code in <code>src/registry/duckdb_helpers.py</code> <pre><code>def validate_identifier(\n    identifier: str,\n    allowed: Iterable[str],\n    *,\n    label: str = \"identifier\",\n) -&gt; str:\n    \"\"\"Validate that an identifier is within an allowed set.\n\n    Validates that an identifier string is present in the allowed set of values.\n    Used for sanitizing table names, column names, or other database identifiers\n    to prevent SQL injection.\n\n    Parameters\n    ----------\n    identifier : str\n        Identifier string to validate.\n    allowed : Iterable[str]\n        Set of allowed identifier values.\n    label : str, optional\n        Human-readable label for error messages (e.g., \"table name\", \"column name\").\n        Defaults to \"identifier\".\n\n    Returns\n    -------\n    str\n        The validated identifier (unchanged).\n\n    Raises\n    ------\n    RegistryError\n        If identifier is not in the allowed set. Error context includes the\n        invalid identifier and sorted list of allowed values.\n    \"\"\"\n    allowed_set = set(allowed)\n    if identifier in allowed_set:\n        return identifier\n    error_message = f\"Invalid {label}: {identifier}\"\n    raise RegistryError(\n        error_message,\n        context={label: identifier, \"allowed\": sorted(allowed_set)},\n    )\n</code></pre>"},{"location":"modules/registry.duckdb_registry/","title":"registry.duckdb_registry","text":""},{"location":"modules/registry.duckdb_registry/#registryduckdb_registry","title":"registry.duckdb_registry","text":"<p>Minimal registry wrapper storing pipeline artefacts in DuckDB.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/registry.duckdb_registry/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class DuckDBRegistry\n</code></pre>"},{"location":"modules/registry.duckdb_registry/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"registry.duckdb_registry__future__.annotationscollections.abc.Mappingduckdbjsonkgfoundry_common.models.Dockgfoundry_common.models.DoctagsAssetkgfoundry_common.navmap_loader.load_nav_metadataregistry.duckdb_helpersregistry.duckdb_helpers.DuckDBQueryOptionstyping.TYPE_CHECKINGuuidregistry.duckdb_registry code <p>See the full diagram: registry.duckdb_registry</p>"},{"location":"modules/registry.duckdb_registry/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>registry.duckdb_registry.DuckDBRegistry</li> <li>registry.duckdb_registry._execute_with_operation</li> </ul>"},{"location":"modules/registry.duckdb_registry/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Mapping</code>, <code>duckdb</code>, <code>json</code>, <code>kgfoundry_common.models.Doc</code>, <code>kgfoundry_common.models.DoctagsAsset</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, registry.duckdb_helpers, <code>registry.duckdb_helpers.DuckDBQueryOptions</code>, <code>typing.TYPE_CHECKING</code>, <code>uuid</code></p>"},{"location":"modules/registry.duckdb_registry/#contents","title":"Contents","text":""},{"location":"modules/registry.duckdb_registry/#registryduckdb_registryduckdbregistry","title":"registry.duckdb_registry.DuckDBRegistry","text":""},{"location":"modules/registry.duckdb_registry/#registry.duckdb_registry.DuckDBRegistry","title":"<code>registry.duckdb_registry.DuckDBRegistry</code>","text":"<p>DuckDB-backed implementation of the registry protocol.</p> <p>Minimal registry implementation that stores pipeline artifacts and metadata in a DuckDB database. Implements the Registry protocol for managing runs, datasets, documents, doctags, and events.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>Path to the DuckDB database file. Database will be created if it doesn't exist.</p> required Source code in <code>src/registry/duckdb_registry.py</code> <pre><code>class DuckDBRegistry:\n    \"\"\"DuckDB-backed implementation of the registry protocol.\n\n    Minimal registry implementation that stores pipeline artifacts and metadata\n    in a DuckDB database. Implements the Registry protocol for managing runs,\n    datasets, documents, doctags, and events.\n\n    Parameters\n    ----------\n    db_path : str\n        Path to the DuckDB database file. Database will be created if it\n        doesn't exist.\n    \"\"\"\n\n    def __init__(self, db_path: str) -&gt; None:\n        \"\"\"Initialize the registry with a DuckDB database path.\n\n        Opens a connection to the DuckDB database and stores it for use\n        by all registry operations. The connection is opened in read-write mode.\n\n        Parameters\n        ----------\n        db_path : str\n            Path to the DuckDB database file. Database will be created if it\n            doesn't exist.\n        \"\"\"\n        self.db_path = db_path\n        self.con = duckdb_helpers.connect(db_path, read_only=False)\n\n    def begin_dataset(self, kind: str, run_id: str) -&gt; str:\n        \"\"\"Insert a dataset placeholder row and return its identifier.\n\n        Creates a new dataset record associated with the specified run.\n        The dataset is initially created with an empty parquet_root; use\n        commit_dataset() to finalize it with data.\n\n        Parameters\n        ----------\n        kind : str\n            Dataset kind (e.g., \"embeddings\", \"chunks\", \"metadata\").\n        run_id : str\n            Run ID that this dataset belongs to.\n\n        Returns\n        -------\n        str\n            Unique dataset ID (UUID) for the newly created dataset.\n        \"\"\"\n        dataset_id = str(uuid.uuid4())\n        _execute_with_operation(\n            self.con,\n            (\n                \"INSERT INTO datasets(\"\n                \"dataset_id, kind, parquet_root, run_id, created_at\"\n                \") VALUES (?, ?, '', ?, now())\"\n            ),\n            [dataset_id, kind, run_id],\n            operation=\"registry.duckdb.begin_dataset\",\n        )\n        return dataset_id\n\n    def commit_dataset(self, dataset_id: str, parquet_root: str, rows: int) -&gt; None:\n        \"\"\"Update dataset metadata once Parquet artifacts are materialized.\n\n        Finalizes a dataset by updating its parquet_root path. The rows\n        parameter is currently unused but may be stored in the future.\n\n        Parameters\n        ----------\n        dataset_id : str\n            Dataset ID to commit.\n        parquet_root : str\n            Root directory path where Parquet files are stored.\n        rows : int\n            Total number of rows in the dataset (currently unused).\n        \"\"\"\n        del rows\n        _execute_with_operation(\n            self.con,\n            \"UPDATE datasets SET parquet_root=? WHERE dataset_id=?\",\n            [parquet_root, dataset_id],\n            operation=\"registry.duckdb.commit_dataset\",\n        )\n\n    def rollback_dataset(self, dataset_id: str) -&gt; None:\n        \"\"\"Delete a dataset placeholder if the build fails.\n\n        Removes a dataset record when dataset creation fails or needs to\n        be abandoned. Use this for cleanup when errors occur.\n\n        Parameters\n        ----------\n        dataset_id : str\n            Dataset ID to rollback.\n        \"\"\"\n        _execute_with_operation(\n            self.con,\n            \"DELETE FROM datasets WHERE dataset_id=?\",\n            [dataset_id],\n            operation=\"registry.duckdb.rollback_dataset\",\n        )\n\n    def insert_run(\n        self,\n        purpose: str,\n        model_id: str | None,\n        revision: str | None,\n        config: Mapping[str, object],\n    ) -&gt; str:\n        \"\"\"Create a run record and return the generated identifier.\n\n        Inserts a new run record into the registry with the specified purpose,\n        model information, and configuration. Returns a unique run ID.\n\n        Parameters\n        ----------\n        purpose : str\n            Purpose description for the run (e.g., \"embedding\", \"indexing\").\n        model_id : str | None\n            Model identifier used in this run, or None if not applicable.\n        revision : str | None\n            Model revision or version, or None if not applicable.\n        config : Mapping[str, object]\n            Run configuration dictionary (serialized as JSON).\n\n        Returns\n        -------\n        str\n            Unique run ID (UUID) for the newly created run.\n        \"\"\"\n        run_id = str(uuid.uuid4())\n        _execute_with_operation(\n            self.con,\n            (\n                \"INSERT INTO runs(\"\n                \"run_id, purpose, model_id, revision, started_at, config\"\n                \") VALUES (?, ?, ?, ?, now(), ?)\"\n            ),\n            [run_id, purpose, model_id, revision, json.dumps(config)],\n            operation=\"registry.duckdb.insert_run\",\n        )\n        return run_id\n\n    def close_run(self, run_id: str, *, success: bool, notes: str | None = None) -&gt; None:\n        \"\"\"Mark a run as finished and record the completion timestamp.\n\n        Updates the run's finished_at timestamp. The success and notes\n        parameters are currently unused but may be persisted in the future.\n\n        Parameters\n        ----------\n        run_id : str\n            Run ID to close.\n        success : bool\n            Whether the run completed successfully (currently unused).\n        notes : str | None, optional\n            Optional notes about the run completion (currently unused).\n            Defaults to None.\n        \"\"\"\n        _ = success  # placeholder until success flag/notes are persisted\n        _ = notes\n        _execute_with_operation(\n            self.con,\n            \"UPDATE runs SET finished_at=now() WHERE run_id=?\",\n            [run_id],\n            operation=\"registry.duckdb.close_run\",\n        )\n\n    def register_documents(self, docs: list[Doc]) -&gt; None:\n        \"\"\"Insert or update document metadata rows.\n\n        Registers document records in the documents table. Each document's\n        metadata (title, authors, publication date, etc.) is stored with\n        the document ID. Uses INSERT OR REPLACE to handle duplicates.\n\n        Parameters\n        ----------\n        docs : list[Doc]\n            List of document objects to register. Each document must have\n            a unique doc_id.\n        \"\"\"\n        for doc in docs:\n            _execute_with_operation(\n                self.con,\n                (\n                    \"INSERT OR REPLACE INTO documents(\"\n                    \"doc_id, openalex_id, doi, arxiv_id, pmcid, title, authors, \"\n                    \"pub_date, license, language, pdf_uri, source, content_hash, created_at\"\n                    \") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, now())\"\n                ),\n                [\n                    doc.id,\n                    doc.openalex_id,\n                    doc.doi,\n                    doc.arxiv_id,\n                    doc.pmcid,\n                    doc.title,\n                    json.dumps(doc.authors),\n                    doc.pub_date,\n                    doc.license,\n                    doc.language,\n                    doc.pdf_uri,\n                    doc.source,\n                    doc.content_hash,\n                ],\n                operation=\"registry.duckdb.register_documents\",\n            )\n\n    def register_doctags(self, assets: list[DoctagsAsset]) -&gt; None:\n        \"\"\"Insert or update doctags asset records.\n\n        Registers doctags asset records in the doctags table. Doctags\n        represent visual document tags generated by vision-language models.\n        Uses INSERT OR REPLACE to handle duplicates.\n\n        Parameters\n        ----------\n        assets : list[DoctagsAsset]\n            List of doctags asset objects to register. Each asset must have\n            doc_id, doctags_uri, and model information.\n        \"\"\"\n        for asset in assets:\n            _execute_with_operation(\n                self.con,\n                (\n                    \"INSERT OR REPLACE INTO doctags(\"\n                    \"doc_id, doctags_uri, pages, vlm_model, vlm_revision, avg_logprob, created_at\"\n                    \") VALUES (?, ?, ?, ?, ?, ?, now())\"\n                ),\n                [\n                    asset.doc_id,\n                    asset.doctags_uri,\n                    asset.pages,\n                    asset.vlm_model,\n                    asset.vlm_revision,\n                    asset.avg_logprob,\n                ],\n                operation=\"registry.duckdb.register_doctags\",\n            )\n\n    def emit_event(self, event_name: str, subject_id: str, payload: Mapping[str, object]) -&gt; None:\n        \"\"\"Persist an arbitrary pipeline event with structured payload.\n\n        Records an event in the pipeline_events table with a unique event ID,\n        event name, subject ID, and JSON payload. Used for tracking pipeline\n        operations and state changes.\n\n        Parameters\n        ----------\n        event_name : str\n            Name of the event (e.g., \"RunClosed\", \"DatasetCommitted\").\n        subject_id : str\n            ID of the subject the event relates to (e.g., run_id, dataset_id).\n        payload : Mapping[str, object]\n            Event payload dictionary (serialized as JSON).\n        \"\"\"\n        _execute_with_operation(\n            self.con,\n            (\n                \"INSERT INTO pipeline_events(\"\n                \"event_id, event_name, subject_id, payload, created_at\"\n                \") VALUES (gen_random_uuid(), ?, ?, ?, now())\"\n            ),\n            [event_name, subject_id, json.dumps(payload)],\n            operation=\"registry.duckdb.emit_event\",\n        )\n\n    def incident(self, event: str, subject_id: str, error_class: str, message: str) -&gt; None:\n        \"\"\"Record an incident emitted by registry clients.\n\n        Inserts an incident record into the incidents table for tracking\n        errors and failures in pipeline operations.\n\n        Parameters\n        ----------\n        event : str\n            Event name associated with the incident.\n        subject_id : str\n            ID of the subject the incident relates to (e.g., run_id, dataset_id).\n        error_class : str\n            Error class or exception type name.\n        message : str\n            Error message describing the incident.\n        \"\"\"\n        _execute_with_operation(\n            self.con,\n            (\n                \"INSERT INTO incidents(\"\n                \"id, event, subject_id, error_class, message, created_at\"\n                \") VALUES (gen_random_uuid(), ?, ?, ?, ?, now())\"\n            ),\n            [event, subject_id, error_class, message],\n            operation=\"registry.duckdb.incident\",\n        )\n</code></pre>"},{"location":"modules/registry.duckdb_registry/#registry.duckdb_registry.DuckDBRegistry.__init__","title":"<code>__init__(db_path)</code>","text":"<p>Initialize the registry with a DuckDB database path.</p> <p>Opens a connection to the DuckDB database and stores it for use by all registry operations. The connection is opened in read-write mode.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>Path to the DuckDB database file. Database will be created if it doesn't exist.</p> required Source code in <code>src/registry/duckdb_registry.py</code> <pre><code>def __init__(self, db_path: str) -&gt; None:\n    \"\"\"Initialize the registry with a DuckDB database path.\n\n    Opens a connection to the DuckDB database and stores it for use\n    by all registry operations. The connection is opened in read-write mode.\n\n    Parameters\n    ----------\n    db_path : str\n        Path to the DuckDB database file. Database will be created if it\n        doesn't exist.\n    \"\"\"\n    self.db_path = db_path\n    self.con = duckdb_helpers.connect(db_path, read_only=False)\n</code></pre>"},{"location":"modules/registry.duckdb_registry/#registry.duckdb_registry.DuckDBRegistry.begin_dataset","title":"<code>begin_dataset(kind, run_id)</code>","text":"<p>Insert a dataset placeholder row and return its identifier.</p> <p>Creates a new dataset record associated with the specified run. The dataset is initially created with an empty parquet_root; use commit_dataset() to finalize it with data.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>Dataset kind (e.g., \"embeddings\", \"chunks\", \"metadata\").</p> required <code>run_id</code> <code>str</code> <p>Run ID that this dataset belongs to.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Unique dataset ID (UUID) for the newly created dataset.</p> Source code in <code>src/registry/duckdb_registry.py</code> <pre><code>def begin_dataset(self, kind: str, run_id: str) -&gt; str:\n    \"\"\"Insert a dataset placeholder row and return its identifier.\n\n    Creates a new dataset record associated with the specified run.\n    The dataset is initially created with an empty parquet_root; use\n    commit_dataset() to finalize it with data.\n\n    Parameters\n    ----------\n    kind : str\n        Dataset kind (e.g., \"embeddings\", \"chunks\", \"metadata\").\n    run_id : str\n        Run ID that this dataset belongs to.\n\n    Returns\n    -------\n    str\n        Unique dataset ID (UUID) for the newly created dataset.\n    \"\"\"\n    dataset_id = str(uuid.uuid4())\n    _execute_with_operation(\n        self.con,\n        (\n            \"INSERT INTO datasets(\"\n            \"dataset_id, kind, parquet_root, run_id, created_at\"\n            \") VALUES (?, ?, '', ?, now())\"\n        ),\n        [dataset_id, kind, run_id],\n        operation=\"registry.duckdb.begin_dataset\",\n    )\n    return dataset_id\n</code></pre>"},{"location":"modules/registry.duckdb_registry/#registry.duckdb_registry.DuckDBRegistry.close_run","title":"<code>close_run(run_id, *, success, notes=None)</code>","text":"<p>Mark a run as finished and record the completion timestamp.</p> <p>Updates the run's finished_at timestamp. The success and notes parameters are currently unused but may be persisted in the future.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>str</code> <p>Run ID to close.</p> required <code>success</code> <code>bool</code> <p>Whether the run completed successfully (currently unused).</p> required <code>notes</code> <code>str | None</code> <p>Optional notes about the run completion (currently unused). Defaults to None.</p> <code>None</code> Source code in <code>src/registry/duckdb_registry.py</code> <pre><code>def close_run(self, run_id: str, *, success: bool, notes: str | None = None) -&gt; None:\n    \"\"\"Mark a run as finished and record the completion timestamp.\n\n    Updates the run's finished_at timestamp. The success and notes\n    parameters are currently unused but may be persisted in the future.\n\n    Parameters\n    ----------\n    run_id : str\n        Run ID to close.\n    success : bool\n        Whether the run completed successfully (currently unused).\n    notes : str | None, optional\n        Optional notes about the run completion (currently unused).\n        Defaults to None.\n    \"\"\"\n    _ = success  # placeholder until success flag/notes are persisted\n    _ = notes\n    _execute_with_operation(\n        self.con,\n        \"UPDATE runs SET finished_at=now() WHERE run_id=?\",\n        [run_id],\n        operation=\"registry.duckdb.close_run\",\n    )\n</code></pre>"},{"location":"modules/registry.duckdb_registry/#registry.duckdb_registry.DuckDBRegistry.commit_dataset","title":"<code>commit_dataset(dataset_id, parquet_root, rows)</code>","text":"<p>Update dataset metadata once Parquet artifacts are materialized.</p> <p>Finalizes a dataset by updating its parquet_root path. The rows parameter is currently unused but may be stored in the future.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID to commit.</p> required <code>parquet_root</code> <code>str</code> <p>Root directory path where Parquet files are stored.</p> required <code>rows</code> <code>int</code> <p>Total number of rows in the dataset (currently unused).</p> required Source code in <code>src/registry/duckdb_registry.py</code> <pre><code>def commit_dataset(self, dataset_id: str, parquet_root: str, rows: int) -&gt; None:\n    \"\"\"Update dataset metadata once Parquet artifacts are materialized.\n\n    Finalizes a dataset by updating its parquet_root path. The rows\n    parameter is currently unused but may be stored in the future.\n\n    Parameters\n    ----------\n    dataset_id : str\n        Dataset ID to commit.\n    parquet_root : str\n        Root directory path where Parquet files are stored.\n    rows : int\n        Total number of rows in the dataset (currently unused).\n    \"\"\"\n    del rows\n    _execute_with_operation(\n        self.con,\n        \"UPDATE datasets SET parquet_root=? WHERE dataset_id=?\",\n        [parquet_root, dataset_id],\n        operation=\"registry.duckdb.commit_dataset\",\n    )\n</code></pre>"},{"location":"modules/registry.duckdb_registry/#registry.duckdb_registry.DuckDBRegistry.emit_event","title":"<code>emit_event(event_name, subject_id, payload)</code>","text":"<p>Persist an arbitrary pipeline event with structured payload.</p> <p>Records an event in the pipeline_events table with a unique event ID, event name, subject ID, and JSON payload. Used for tracking pipeline operations and state changes.</p> <p>Parameters:</p> Name Type Description Default <code>event_name</code> <code>str</code> <p>Name of the event (e.g., \"RunClosed\", \"DatasetCommitted\").</p> required <code>subject_id</code> <code>str</code> <p>ID of the subject the event relates to (e.g., run_id, dataset_id).</p> required <code>payload</code> <code>Mapping[str, object]</code> <p>Event payload dictionary (serialized as JSON).</p> required Source code in <code>src/registry/duckdb_registry.py</code> <pre><code>def emit_event(self, event_name: str, subject_id: str, payload: Mapping[str, object]) -&gt; None:\n    \"\"\"Persist an arbitrary pipeline event with structured payload.\n\n    Records an event in the pipeline_events table with a unique event ID,\n    event name, subject ID, and JSON payload. Used for tracking pipeline\n    operations and state changes.\n\n    Parameters\n    ----------\n    event_name : str\n        Name of the event (e.g., \"RunClosed\", \"DatasetCommitted\").\n    subject_id : str\n        ID of the subject the event relates to (e.g., run_id, dataset_id).\n    payload : Mapping[str, object]\n        Event payload dictionary (serialized as JSON).\n    \"\"\"\n    _execute_with_operation(\n        self.con,\n        (\n            \"INSERT INTO pipeline_events(\"\n            \"event_id, event_name, subject_id, payload, created_at\"\n            \") VALUES (gen_random_uuid(), ?, ?, ?, now())\"\n        ),\n        [event_name, subject_id, json.dumps(payload)],\n        operation=\"registry.duckdb.emit_event\",\n    )\n</code></pre>"},{"location":"modules/registry.duckdb_registry/#registry.duckdb_registry.DuckDBRegistry.incident","title":"<code>incident(event, subject_id, error_class, message)</code>","text":"<p>Record an incident emitted by registry clients.</p> <p>Inserts an incident record into the incidents table for tracking errors and failures in pipeline operations.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>str</code> <p>Event name associated with the incident.</p> required <code>subject_id</code> <code>str</code> <p>ID of the subject the incident relates to (e.g., run_id, dataset_id).</p> required <code>error_class</code> <code>str</code> <p>Error class or exception type name.</p> required <code>message</code> <code>str</code> <p>Error message describing the incident.</p> required Source code in <code>src/registry/duckdb_registry.py</code> <pre><code>def incident(self, event: str, subject_id: str, error_class: str, message: str) -&gt; None:\n    \"\"\"Record an incident emitted by registry clients.\n\n    Inserts an incident record into the incidents table for tracking\n    errors and failures in pipeline operations.\n\n    Parameters\n    ----------\n    event : str\n        Event name associated with the incident.\n    subject_id : str\n        ID of the subject the incident relates to (e.g., run_id, dataset_id).\n    error_class : str\n        Error class or exception type name.\n    message : str\n        Error message describing the incident.\n    \"\"\"\n    _execute_with_operation(\n        self.con,\n        (\n            \"INSERT INTO incidents(\"\n            \"id, event, subject_id, error_class, message, created_at\"\n            \") VALUES (gen_random_uuid(), ?, ?, ?, ?, now())\"\n        ),\n        [event, subject_id, error_class, message],\n        operation=\"registry.duckdb.incident\",\n    )\n</code></pre>"},{"location":"modules/registry.duckdb_registry/#registry.duckdb_registry.DuckDBRegistry.insert_run","title":"<code>insert_run(purpose, model_id, revision, config)</code>","text":"<p>Create a run record and return the generated identifier.</p> <p>Inserts a new run record into the registry with the specified purpose, model information, and configuration. Returns a unique run ID.</p> <p>Parameters:</p> Name Type Description Default <code>purpose</code> <code>str</code> <p>Purpose description for the run (e.g., \"embedding\", \"indexing\").</p> required <code>model_id</code> <code>str | None</code> <p>Model identifier used in this run, or None if not applicable.</p> required <code>revision</code> <code>str | None</code> <p>Model revision or version, or None if not applicable.</p> required <code>config</code> <code>Mapping[str, object]</code> <p>Run configuration dictionary (serialized as JSON).</p> required <p>Returns:</p> Type Description <code>str</code> <p>Unique run ID (UUID) for the newly created run.</p> Source code in <code>src/registry/duckdb_registry.py</code> <pre><code>def insert_run(\n    self,\n    purpose: str,\n    model_id: str | None,\n    revision: str | None,\n    config: Mapping[str, object],\n) -&gt; str:\n    \"\"\"Create a run record and return the generated identifier.\n\n    Inserts a new run record into the registry with the specified purpose,\n    model information, and configuration. Returns a unique run ID.\n\n    Parameters\n    ----------\n    purpose : str\n        Purpose description for the run (e.g., \"embedding\", \"indexing\").\n    model_id : str | None\n        Model identifier used in this run, or None if not applicable.\n    revision : str | None\n        Model revision or version, or None if not applicable.\n    config : Mapping[str, object]\n        Run configuration dictionary (serialized as JSON).\n\n    Returns\n    -------\n    str\n        Unique run ID (UUID) for the newly created run.\n    \"\"\"\n    run_id = str(uuid.uuid4())\n    _execute_with_operation(\n        self.con,\n        (\n            \"INSERT INTO runs(\"\n            \"run_id, purpose, model_id, revision, started_at, config\"\n            \") VALUES (?, ?, ?, ?, now(), ?)\"\n        ),\n        [run_id, purpose, model_id, revision, json.dumps(config)],\n        operation=\"registry.duckdb.insert_run\",\n    )\n    return run_id\n</code></pre>"},{"location":"modules/registry.duckdb_registry/#registry.duckdb_registry.DuckDBRegistry.register_doctags","title":"<code>register_doctags(assets)</code>","text":"<p>Insert or update doctags asset records.</p> <p>Registers doctags asset records in the doctags table. Doctags represent visual document tags generated by vision-language models. Uses INSERT OR REPLACE to handle duplicates.</p> <p>Parameters:</p> Name Type Description Default <code>assets</code> <code>list[DoctagsAsset]</code> <p>List of doctags asset objects to register. Each asset must have doc_id, doctags_uri, and model information.</p> required Source code in <code>src/registry/duckdb_registry.py</code> <pre><code>def register_doctags(self, assets: list[DoctagsAsset]) -&gt; None:\n    \"\"\"Insert or update doctags asset records.\n\n    Registers doctags asset records in the doctags table. Doctags\n    represent visual document tags generated by vision-language models.\n    Uses INSERT OR REPLACE to handle duplicates.\n\n    Parameters\n    ----------\n    assets : list[DoctagsAsset]\n        List of doctags asset objects to register. Each asset must have\n        doc_id, doctags_uri, and model information.\n    \"\"\"\n    for asset in assets:\n        _execute_with_operation(\n            self.con,\n            (\n                \"INSERT OR REPLACE INTO doctags(\"\n                \"doc_id, doctags_uri, pages, vlm_model, vlm_revision, avg_logprob, created_at\"\n                \") VALUES (?, ?, ?, ?, ?, ?, now())\"\n            ),\n            [\n                asset.doc_id,\n                asset.doctags_uri,\n                asset.pages,\n                asset.vlm_model,\n                asset.vlm_revision,\n                asset.avg_logprob,\n            ],\n            operation=\"registry.duckdb.register_doctags\",\n        )\n</code></pre>"},{"location":"modules/registry.duckdb_registry/#registry.duckdb_registry.DuckDBRegistry.register_documents","title":"<code>register_documents(docs)</code>","text":"<p>Insert or update document metadata rows.</p> <p>Registers document records in the documents table. Each document's metadata (title, authors, publication date, etc.) is stored with the document ID. Uses INSERT OR REPLACE to handle duplicates.</p> <p>Parameters:</p> Name Type Description Default <code>docs</code> <code>list[Doc]</code> <p>List of document objects to register. Each document must have a unique doc_id.</p> required Source code in <code>src/registry/duckdb_registry.py</code> <pre><code>def register_documents(self, docs: list[Doc]) -&gt; None:\n    \"\"\"Insert or update document metadata rows.\n\n    Registers document records in the documents table. Each document's\n    metadata (title, authors, publication date, etc.) is stored with\n    the document ID. Uses INSERT OR REPLACE to handle duplicates.\n\n    Parameters\n    ----------\n    docs : list[Doc]\n        List of document objects to register. Each document must have\n        a unique doc_id.\n    \"\"\"\n    for doc in docs:\n        _execute_with_operation(\n            self.con,\n            (\n                \"INSERT OR REPLACE INTO documents(\"\n                \"doc_id, openalex_id, doi, arxiv_id, pmcid, title, authors, \"\n                \"pub_date, license, language, pdf_uri, source, content_hash, created_at\"\n                \") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, now())\"\n            ),\n            [\n                doc.id,\n                doc.openalex_id,\n                doc.doi,\n                doc.arxiv_id,\n                doc.pmcid,\n                doc.title,\n                json.dumps(doc.authors),\n                doc.pub_date,\n                doc.license,\n                doc.language,\n                doc.pdf_uri,\n                doc.source,\n                doc.content_hash,\n            ],\n            operation=\"registry.duckdb.register_documents\",\n        )\n</code></pre>"},{"location":"modules/registry.duckdb_registry/#registry.duckdb_registry.DuckDBRegistry.rollback_dataset","title":"<code>rollback_dataset(dataset_id)</code>","text":"<p>Delete a dataset placeholder if the build fails.</p> <p>Removes a dataset record when dataset creation fails or needs to be abandoned. Use this for cleanup when errors occur.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID to rollback.</p> required Source code in <code>src/registry/duckdb_registry.py</code> <pre><code>def rollback_dataset(self, dataset_id: str) -&gt; None:\n    \"\"\"Delete a dataset placeholder if the build fails.\n\n    Removes a dataset record when dataset creation fails or needs to\n    be abandoned. Use this for cleanup when errors occur.\n\n    Parameters\n    ----------\n    dataset_id : str\n        Dataset ID to rollback.\n    \"\"\"\n    _execute_with_operation(\n        self.con,\n        \"DELETE FROM datasets WHERE dataset_id=?\",\n        [dataset_id],\n        operation=\"registry.duckdb.rollback_dataset\",\n    )\n</code></pre>"},{"location":"modules/registry.duckdb_registry/#registryduckdb_registry_execute_with_operation","title":"registry.duckdb_registry._execute_with_operation","text":""},{"location":"modules/registry.duckdb_registry/#registry.duckdb_registry._execute_with_operation","title":"<code>registry.duckdb_registry._execute_with_operation(conn, sql, params, operation)</code>","text":"Source code in <code>src/registry/duckdb_registry.py</code> <pre><code>def _execute_with_operation(\n    conn: duckdb.DuckDBPyConnection,\n    sql: str,\n    params: duckdb_helpers.Params,\n    operation: str,\n) -&gt; None:\n    duckdb_helpers.execute(\n        conn,\n        sql,\n        params,\n        options=DuckDBQueryOptions(operation=operation),\n    )\n</code></pre>"},{"location":"modules/registry.helper/","title":"registry.helper","text":""},{"location":"modules/registry.helper/#registryhelper","title":"registry.helper","text":"<p>Helper utilities that simplify writing records into the DuckDB registry.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/registry.helper/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class DuckDBRegistryHelper\n</code></pre>"},{"location":"modules/registry.helper/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"registry.helper__future__.annotationscollections.abc.Mappingcontextlib.closingduckdb.DuckDBPyConnectionjsonkgfoundry_common.models.Dockgfoundry_common.models.DoctagsAssetkgfoundry_common.navmap_loader.load_nav_metadataregistry.duckdb_helpersregistry.duckdb_helpers.DuckDBQueryOptionstyping.TYPE_CHECKINGuuidregistry.helper code <p>See the full diagram: registry.helper</p>"},{"location":"modules/registry.helper/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>registry.helper.DuckDBRegistryHelper</li> <li>registry.helper._execute_with_operation</li> </ul>"},{"location":"modules/registry.helper/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Mapping</code>, <code>contextlib.closing</code>, <code>duckdb.DuckDBPyConnection</code>, <code>json</code>, <code>kgfoundry_common.models.Doc</code>, <code>kgfoundry_common.models.DoctagsAsset</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, registry.duckdb_helpers, <code>registry.duckdb_helpers.DuckDBQueryOptions</code>, <code>typing.TYPE_CHECKING</code>, <code>uuid</code></p>"},{"location":"modules/registry.helper/#contents","title":"Contents","text":""},{"location":"modules/registry.helper/#registryhelperduckdbregistryhelper","title":"registry.helper.DuckDBRegistryHelper","text":""},{"location":"modules/registry.helper/#registry.helper.DuckDBRegistryHelper","title":"<code>registry.helper.DuckDBRegistryHelper</code>","text":"<p>Helper class for writing records into the DuckDB registry.</p> <p>Provides convenient methods for managing runs, datasets, documents, and doctags in the DuckDB registry. All operations use parameterized queries for safety and structured logging for observability.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>Path to the DuckDB database file.</p> required Source code in <code>src/registry/helper.py</code> <pre><code>class DuckDBRegistryHelper:\n    \"\"\"Helper class for writing records into the DuckDB registry.\n\n    Provides convenient methods for managing runs, datasets, documents, and\n    doctags in the DuckDB registry. All operations use parameterized queries\n    for safety and structured logging for observability.\n\n    Parameters\n    ----------\n    db_path : str\n        Path to the DuckDB database file.\n    \"\"\"\n\n    def __init__(self, db_path: str) -&gt; None:\n        \"\"\"Initialize the registry helper with database path.\n\n        Sets up the helper with the path to the DuckDB database file.\n        The database will be created if it doesn't exist.\n\n        Parameters\n        ----------\n        db_path : str\n            Path to the DuckDB database file.\n        \"\"\"\n        self.db_path = db_path\n\n    def _connect(self) -&gt; DuckDBPyConnection:\n        \"\"\"Create a DuckDB connection for registry operations.\n\n        Opens a connection to the DuckDB database using the configured path.\n        Uses the standard connection helper with default pragmas.\n\n        Returns\n        -------\n        DuckDBPyConnection\n            Configured DuckDB connection ready for registry operations.\n        \"\"\"\n        return duckdb_helpers.connect(self.db_path)\n\n    def new_run(\n        self,\n        purpose: str,\n        model_id: str | None,\n        revision: str | None,\n        config: Mapping[str, object],\n    ) -&gt; str:\n        \"\"\"Create a new pipeline run record.\n\n        Inserts a new run record into the registry with the specified purpose,\n        model information, and configuration. Returns a unique run ID.\n\n        Parameters\n        ----------\n        purpose : str\n            Purpose description for the run (e.g., \"embedding\", \"indexing\").\n        model_id : str | None\n            Model identifier used in this run, or None if not applicable.\n        revision : str | None\n            Model revision or version, or None if not applicable.\n        config : Mapping[str, object]\n            Run configuration dictionary (serialized as JSON).\n\n        Returns\n        -------\n        str\n            Unique run ID (UUID) for the newly created run.\n        \"\"\"\n        run_id = str(uuid.uuid4())\n        with closing(self._connect()) as con:\n            _execute_with_operation(\n                con,\n                (\n                    \"INSERT INTO runs \"\n                    \"(run_id,purpose,model_id,revision,started_at,config) \"\n                    \"VALUES (?,?,?,?,CURRENT_TIMESTAMP,?)\"\n                ),\n                [run_id, purpose, model_id, revision, json.dumps(config)],\n                operation=\"registry.helper.new_run\",\n            )\n        return run_id\n\n    def close_run(self, run_id: str, *, success: bool, notes: str | None = None) -&gt; None:\n        \"\"\"Close a pipeline run and record completion status.\n\n        Updates the run's finished_at timestamp and emits a RunClosed event\n        with success status and optional notes.\n\n        Parameters\n        ----------\n        run_id : str\n            Run ID to close.\n        success : bool\n            Whether the run completed successfully.\n        notes : str | None, optional\n            Optional notes about the run completion. Defaults to None.\n        \"\"\"\n        with closing(self._connect()) as con:\n            _execute_with_operation(\n                con,\n                \"UPDATE runs SET finished_at=CURRENT_TIMESTAMP WHERE run_id=?\",\n                [run_id],\n                operation=\"registry.helper.close_run.finish\",\n            )\n            payload: dict[str, object] = {\"success\": success, \"notes\": notes or \"\"}\n            _execute_with_operation(\n                con,\n                \"INSERT INTO pipeline_events VALUES (?,?,?,?,CURRENT_TIMESTAMP)\",\n                [\n                    str(uuid.uuid4()),\n                    \"RunClosed\",\n                    run_id,\n                    json.dumps(payload),\n                ],\n                operation=\"registry.helper.close_run.event\",\n            )\n\n    def begin_dataset(self, kind: str, run_id: str) -&gt; str:\n        \"\"\"Begin a new dataset within a run.\n\n        Creates a new dataset record associated with the specified run.\n        The dataset is initially created with an empty parquet_root; use\n        commit_dataset() to finalize it with data.\n\n        Parameters\n        ----------\n        kind : str\n            Dataset kind (e.g., \"embeddings\", \"chunks\", \"metadata\").\n        run_id : str\n            Run ID that this dataset belongs to.\n\n        Returns\n        -------\n        str\n            Unique dataset ID (UUID) for the newly created dataset.\n        \"\"\"\n        dataset_id = str(uuid.uuid4())\n        with closing(self._connect()) as con:\n            _execute_with_operation(\n                con,\n                (\n                    \"INSERT INTO datasets \"\n                    \"(dataset_id,kind,parquet_root,run_id,created_at) \"\n                    \"VALUES (?,?,?,?,CURRENT_TIMESTAMP)\"\n                ),\n                [dataset_id, kind, \"\", run_id],\n                operation=\"registry.helper.begin_dataset\",\n            )\n        return dataset_id\n\n    def commit_dataset(self, dataset_id: str, parquet_root: str, rows: int) -&gt; None:\n        \"\"\"Commit a dataset with Parquet data location.\n\n        Finalizes a dataset by updating its parquet_root path and row count,\n        then emits a DatasetCommitted event.\n\n        Parameters\n        ----------\n        dataset_id : str\n            Dataset ID to commit.\n        parquet_root : str\n            Root directory path where Parquet files are stored.\n        rows : int\n            Total number of rows in the dataset.\n        \"\"\"\n        with closing(self._connect()) as con:\n            _execute_with_operation(\n                con,\n                \"UPDATE datasets SET parquet_root=? WHERE dataset_id=?\",\n                [parquet_root, dataset_id],\n                operation=\"registry.helper.commit_dataset.update\",\n            )\n            payload: dict[str, object] = {\"rows\": rows, \"root\": parquet_root}\n            _execute_with_operation(\n                con,\n                \"INSERT INTO pipeline_events VALUES (?,?,?,?,CURRENT_TIMESTAMP)\",\n                [\n                    str(uuid.uuid4()),\n                    \"DatasetCommitted\",\n                    dataset_id,\n                    json.dumps(payload),\n                ],\n                operation=\"registry.helper.commit_dataset.event\",\n            )\n\n    def rollback_dataset(self, dataset_id: str) -&gt; None:\n        \"\"\"Rollback a dataset by deleting it.\n\n        Deletes a dataset record and emits a DatasetRolledBack event.\n        Use this when a dataset creation fails or needs to be abandoned.\n\n        Parameters\n        ----------\n        dataset_id : str\n            Dataset ID to rollback.\n        \"\"\"\n        with closing(self._connect()) as con:\n            _execute_with_operation(\n                con,\n                \"DELETE FROM datasets WHERE dataset_id=?\",\n                [dataset_id],\n                operation=\"registry.helper.rollback_dataset.delete\",\n            )\n            _execute_with_operation(\n                con,\n                \"INSERT INTO pipeline_events VALUES (?,?,?,?,CURRENT_TIMESTAMP)\",\n                [str(uuid.uuid4()), \"DatasetRolledBack\", dataset_id, \"{}\"],\n                operation=\"registry.helper.rollback_dataset.event\",\n            )\n\n    def register_documents(self, docs: list[Doc]) -&gt; None:\n        \"\"\"Register document records in the registry.\n\n        Inserts or replaces document records in the documents table. Each\n        document's metadata (title, authors, publication date, etc.) is\n        stored with the document ID.\n\n        Parameters\n        ----------\n        docs : list[Doc]\n            List of document objects to register. Each document must have\n            a unique doc_id.\n        \"\"\"\n        with closing(self._connect()) as con:\n            for doc in docs:\n                authors_list = list(doc.authors) if doc.authors is not None else []\n                authors_json = json.dumps(authors_list)\n                _execute_with_operation(\n                    con,\n                    \"\"\"INSERT OR REPLACE INTO documents\n                (doc_id, openalex_id, doi, arxiv_id, pmcid, title, authors,\n                 pub_date, license, language, pdf_uri, source, content_hash, created_at)\n                VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,CURRENT_TIMESTAMP)\"\"\",\n                    [\n                        doc.id,\n                        doc.openalex_id,\n                        doc.doi,\n                        doc.arxiv_id,\n                        doc.pmcid,\n                        doc.title,\n                        authors_json,\n                        doc.pub_date,\n                        doc.license,\n                        doc.language,\n                        doc.pdf_uri,\n                        doc.source,\n                        doc.content_hash or \"\",\n                    ],\n                    operation=\"registry.helper.register_documents\",\n                )\n\n    def register_doctags(self, assets: list[DoctagsAsset]) -&gt; None:\n        \"\"\"Register doctags asset records in the registry.\n\n        Inserts or replaces doctags asset records in the doctags table.\n        Doctags represent visual document tags generated by vision-language\n        models.\n\n        Parameters\n        ----------\n        assets : list[DoctagsAsset]\n            List of doctags asset objects to register. Each asset must have\n            doc_id, doctags_uri, and model information.\n        \"\"\"\n        with closing(self._connect()) as con:\n            for asset in assets:\n                _execute_with_operation(\n                    con,\n                    (\n                        \"INSERT OR REPLACE INTO doctags(\"\n                        \"doc_id, doctags_uri, pages, vlm_model, vlm_revision, avg_logprob, created_at\"\n                        \") VALUES (?, ?, ?, ?, ?, ?, now())\"\n                    ),\n                    [\n                        asset.doc_id,\n                        asset.doctags_uri,\n                        asset.pages,\n                        asset.vlm_model,\n                        asset.vlm_revision,\n                        asset.avg_logprob,\n                    ],\n                    operation=\"registry.helper.register_doctags\",\n                )\n\n    def emit_event(self, event_name: str, subject_id: str, payload: Mapping[str, object]) -&gt; None:\n        \"\"\"Emit a pipeline event to the registry.\n\n        Records an event in the pipeline_events table with a unique event ID,\n        event name, subject ID, and JSON payload. Used for tracking pipeline\n        operations and state changes.\n\n        Parameters\n        ----------\n        event_name : str\n            Name of the event (e.g., \"RunClosed\", \"DatasetCommitted\").\n        subject_id : str\n            ID of the subject the event relates to (e.g., run_id, dataset_id).\n        payload : Mapping[str, object]\n            Event payload dictionary (serialized as JSON).\n        \"\"\"\n        with closing(self._connect()) as con:\n            payload_dict: dict[str, object] = dict(payload)\n            _execute_with_operation(\n                con,\n                \"INSERT INTO pipeline_events VALUES (?,?,?,?,CURRENT_TIMESTAMP)\",\n                [str(uuid.uuid4()), event_name, subject_id, json.dumps(payload_dict)],\n                operation=\"registry.helper.emit_event\",\n            )\n</code></pre>"},{"location":"modules/registry.helper/#registry.helper.DuckDBRegistryHelper.__init__","title":"<code>__init__(db_path)</code>","text":"<p>Initialize the registry helper with database path.</p> <p>Sets up the helper with the path to the DuckDB database file. The database will be created if it doesn't exist.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>Path to the DuckDB database file.</p> required Source code in <code>src/registry/helper.py</code> <pre><code>def __init__(self, db_path: str) -&gt; None:\n    \"\"\"Initialize the registry helper with database path.\n\n    Sets up the helper with the path to the DuckDB database file.\n    The database will be created if it doesn't exist.\n\n    Parameters\n    ----------\n    db_path : str\n        Path to the DuckDB database file.\n    \"\"\"\n    self.db_path = db_path\n</code></pre>"},{"location":"modules/registry.helper/#registry.helper.DuckDBRegistryHelper.begin_dataset","title":"<code>begin_dataset(kind, run_id)</code>","text":"<p>Begin a new dataset within a run.</p> <p>Creates a new dataset record associated with the specified run. The dataset is initially created with an empty parquet_root; use commit_dataset() to finalize it with data.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>Dataset kind (e.g., \"embeddings\", \"chunks\", \"metadata\").</p> required <code>run_id</code> <code>str</code> <p>Run ID that this dataset belongs to.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Unique dataset ID (UUID) for the newly created dataset.</p> Source code in <code>src/registry/helper.py</code> <pre><code>def begin_dataset(self, kind: str, run_id: str) -&gt; str:\n    \"\"\"Begin a new dataset within a run.\n\n    Creates a new dataset record associated with the specified run.\n    The dataset is initially created with an empty parquet_root; use\n    commit_dataset() to finalize it with data.\n\n    Parameters\n    ----------\n    kind : str\n        Dataset kind (e.g., \"embeddings\", \"chunks\", \"metadata\").\n    run_id : str\n        Run ID that this dataset belongs to.\n\n    Returns\n    -------\n    str\n        Unique dataset ID (UUID) for the newly created dataset.\n    \"\"\"\n    dataset_id = str(uuid.uuid4())\n    with closing(self._connect()) as con:\n        _execute_with_operation(\n            con,\n            (\n                \"INSERT INTO datasets \"\n                \"(dataset_id,kind,parquet_root,run_id,created_at) \"\n                \"VALUES (?,?,?,?,CURRENT_TIMESTAMP)\"\n            ),\n            [dataset_id, kind, \"\", run_id],\n            operation=\"registry.helper.begin_dataset\",\n        )\n    return dataset_id\n</code></pre>"},{"location":"modules/registry.helper/#registry.helper.DuckDBRegistryHelper.close_run","title":"<code>close_run(run_id, *, success, notes=None)</code>","text":"<p>Close a pipeline run and record completion status.</p> <p>Updates the run's finished_at timestamp and emits a RunClosed event with success status and optional notes.</p> <p>Parameters:</p> Name Type Description Default <code>run_id</code> <code>str</code> <p>Run ID to close.</p> required <code>success</code> <code>bool</code> <p>Whether the run completed successfully.</p> required <code>notes</code> <code>str | None</code> <p>Optional notes about the run completion. Defaults to None.</p> <code>None</code> Source code in <code>src/registry/helper.py</code> <pre><code>def close_run(self, run_id: str, *, success: bool, notes: str | None = None) -&gt; None:\n    \"\"\"Close a pipeline run and record completion status.\n\n    Updates the run's finished_at timestamp and emits a RunClosed event\n    with success status and optional notes.\n\n    Parameters\n    ----------\n    run_id : str\n        Run ID to close.\n    success : bool\n        Whether the run completed successfully.\n    notes : str | None, optional\n        Optional notes about the run completion. Defaults to None.\n    \"\"\"\n    with closing(self._connect()) as con:\n        _execute_with_operation(\n            con,\n            \"UPDATE runs SET finished_at=CURRENT_TIMESTAMP WHERE run_id=?\",\n            [run_id],\n            operation=\"registry.helper.close_run.finish\",\n        )\n        payload: dict[str, object] = {\"success\": success, \"notes\": notes or \"\"}\n        _execute_with_operation(\n            con,\n            \"INSERT INTO pipeline_events VALUES (?,?,?,?,CURRENT_TIMESTAMP)\",\n            [\n                str(uuid.uuid4()),\n                \"RunClosed\",\n                run_id,\n                json.dumps(payload),\n            ],\n            operation=\"registry.helper.close_run.event\",\n        )\n</code></pre>"},{"location":"modules/registry.helper/#registry.helper.DuckDBRegistryHelper.commit_dataset","title":"<code>commit_dataset(dataset_id, parquet_root, rows)</code>","text":"<p>Commit a dataset with Parquet data location.</p> <p>Finalizes a dataset by updating its parquet_root path and row count, then emits a DatasetCommitted event.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID to commit.</p> required <code>parquet_root</code> <code>str</code> <p>Root directory path where Parquet files are stored.</p> required <code>rows</code> <code>int</code> <p>Total number of rows in the dataset.</p> required Source code in <code>src/registry/helper.py</code> <pre><code>def commit_dataset(self, dataset_id: str, parquet_root: str, rows: int) -&gt; None:\n    \"\"\"Commit a dataset with Parquet data location.\n\n    Finalizes a dataset by updating its parquet_root path and row count,\n    then emits a DatasetCommitted event.\n\n    Parameters\n    ----------\n    dataset_id : str\n        Dataset ID to commit.\n    parquet_root : str\n        Root directory path where Parquet files are stored.\n    rows : int\n        Total number of rows in the dataset.\n    \"\"\"\n    with closing(self._connect()) as con:\n        _execute_with_operation(\n            con,\n            \"UPDATE datasets SET parquet_root=? WHERE dataset_id=?\",\n            [parquet_root, dataset_id],\n            operation=\"registry.helper.commit_dataset.update\",\n        )\n        payload: dict[str, object] = {\"rows\": rows, \"root\": parquet_root}\n        _execute_with_operation(\n            con,\n            \"INSERT INTO pipeline_events VALUES (?,?,?,?,CURRENT_TIMESTAMP)\",\n            [\n                str(uuid.uuid4()),\n                \"DatasetCommitted\",\n                dataset_id,\n                json.dumps(payload),\n            ],\n            operation=\"registry.helper.commit_dataset.event\",\n        )\n</code></pre>"},{"location":"modules/registry.helper/#registry.helper.DuckDBRegistryHelper.emit_event","title":"<code>emit_event(event_name, subject_id, payload)</code>","text":"<p>Emit a pipeline event to the registry.</p> <p>Records an event in the pipeline_events table with a unique event ID, event name, subject ID, and JSON payload. Used for tracking pipeline operations and state changes.</p> <p>Parameters:</p> Name Type Description Default <code>event_name</code> <code>str</code> <p>Name of the event (e.g., \"RunClosed\", \"DatasetCommitted\").</p> required <code>subject_id</code> <code>str</code> <p>ID of the subject the event relates to (e.g., run_id, dataset_id).</p> required <code>payload</code> <code>Mapping[str, object]</code> <p>Event payload dictionary (serialized as JSON).</p> required Source code in <code>src/registry/helper.py</code> <pre><code>def emit_event(self, event_name: str, subject_id: str, payload: Mapping[str, object]) -&gt; None:\n    \"\"\"Emit a pipeline event to the registry.\n\n    Records an event in the pipeline_events table with a unique event ID,\n    event name, subject ID, and JSON payload. Used for tracking pipeline\n    operations and state changes.\n\n    Parameters\n    ----------\n    event_name : str\n        Name of the event (e.g., \"RunClosed\", \"DatasetCommitted\").\n    subject_id : str\n        ID of the subject the event relates to (e.g., run_id, dataset_id).\n    payload : Mapping[str, object]\n        Event payload dictionary (serialized as JSON).\n    \"\"\"\n    with closing(self._connect()) as con:\n        payload_dict: dict[str, object] = dict(payload)\n        _execute_with_operation(\n            con,\n            \"INSERT INTO pipeline_events VALUES (?,?,?,?,CURRENT_TIMESTAMP)\",\n            [str(uuid.uuid4()), event_name, subject_id, json.dumps(payload_dict)],\n            operation=\"registry.helper.emit_event\",\n        )\n</code></pre>"},{"location":"modules/registry.helper/#registry.helper.DuckDBRegistryHelper.new_run","title":"<code>new_run(purpose, model_id, revision, config)</code>","text":"<p>Create a new pipeline run record.</p> <p>Inserts a new run record into the registry with the specified purpose, model information, and configuration. Returns a unique run ID.</p> <p>Parameters:</p> Name Type Description Default <code>purpose</code> <code>str</code> <p>Purpose description for the run (e.g., \"embedding\", \"indexing\").</p> required <code>model_id</code> <code>str | None</code> <p>Model identifier used in this run, or None if not applicable.</p> required <code>revision</code> <code>str | None</code> <p>Model revision or version, or None if not applicable.</p> required <code>config</code> <code>Mapping[str, object]</code> <p>Run configuration dictionary (serialized as JSON).</p> required <p>Returns:</p> Type Description <code>str</code> <p>Unique run ID (UUID) for the newly created run.</p> Source code in <code>src/registry/helper.py</code> <pre><code>def new_run(\n    self,\n    purpose: str,\n    model_id: str | None,\n    revision: str | None,\n    config: Mapping[str, object],\n) -&gt; str:\n    \"\"\"Create a new pipeline run record.\n\n    Inserts a new run record into the registry with the specified purpose,\n    model information, and configuration. Returns a unique run ID.\n\n    Parameters\n    ----------\n    purpose : str\n        Purpose description for the run (e.g., \"embedding\", \"indexing\").\n    model_id : str | None\n        Model identifier used in this run, or None if not applicable.\n    revision : str | None\n        Model revision or version, or None if not applicable.\n    config : Mapping[str, object]\n        Run configuration dictionary (serialized as JSON).\n\n    Returns\n    -------\n    str\n        Unique run ID (UUID) for the newly created run.\n    \"\"\"\n    run_id = str(uuid.uuid4())\n    with closing(self._connect()) as con:\n        _execute_with_operation(\n            con,\n            (\n                \"INSERT INTO runs \"\n                \"(run_id,purpose,model_id,revision,started_at,config) \"\n                \"VALUES (?,?,?,?,CURRENT_TIMESTAMP,?)\"\n            ),\n            [run_id, purpose, model_id, revision, json.dumps(config)],\n            operation=\"registry.helper.new_run\",\n        )\n    return run_id\n</code></pre>"},{"location":"modules/registry.helper/#registry.helper.DuckDBRegistryHelper.register_doctags","title":"<code>register_doctags(assets)</code>","text":"<p>Register doctags asset records in the registry.</p> <p>Inserts or replaces doctags asset records in the doctags table. Doctags represent visual document tags generated by vision-language models.</p> <p>Parameters:</p> Name Type Description Default <code>assets</code> <code>list[DoctagsAsset]</code> <p>List of doctags asset objects to register. Each asset must have doc_id, doctags_uri, and model information.</p> required Source code in <code>src/registry/helper.py</code> <pre><code>def register_doctags(self, assets: list[DoctagsAsset]) -&gt; None:\n    \"\"\"Register doctags asset records in the registry.\n\n    Inserts or replaces doctags asset records in the doctags table.\n    Doctags represent visual document tags generated by vision-language\n    models.\n\n    Parameters\n    ----------\n    assets : list[DoctagsAsset]\n        List of doctags asset objects to register. Each asset must have\n        doc_id, doctags_uri, and model information.\n    \"\"\"\n    with closing(self._connect()) as con:\n        for asset in assets:\n            _execute_with_operation(\n                con,\n                (\n                    \"INSERT OR REPLACE INTO doctags(\"\n                    \"doc_id, doctags_uri, pages, vlm_model, vlm_revision, avg_logprob, created_at\"\n                    \") VALUES (?, ?, ?, ?, ?, ?, now())\"\n                ),\n                [\n                    asset.doc_id,\n                    asset.doctags_uri,\n                    asset.pages,\n                    asset.vlm_model,\n                    asset.vlm_revision,\n                    asset.avg_logprob,\n                ],\n                operation=\"registry.helper.register_doctags\",\n            )\n</code></pre>"},{"location":"modules/registry.helper/#registry.helper.DuckDBRegistryHelper.register_documents","title":"<code>register_documents(docs)</code>","text":"<p>Register document records in the registry.</p> <p>Inserts or replaces document records in the documents table. Each document's metadata (title, authors, publication date, etc.) is stored with the document ID.</p> <p>Parameters:</p> Name Type Description Default <code>docs</code> <code>list[Doc]</code> <p>List of document objects to register. Each document must have a unique doc_id.</p> required Source code in <code>src/registry/helper.py</code> <pre><code>def register_documents(self, docs: list[Doc]) -&gt; None:\n    \"\"\"Register document records in the registry.\n\n    Inserts or replaces document records in the documents table. Each\n    document's metadata (title, authors, publication date, etc.) is\n    stored with the document ID.\n\n    Parameters\n    ----------\n    docs : list[Doc]\n        List of document objects to register. Each document must have\n        a unique doc_id.\n    \"\"\"\n    with closing(self._connect()) as con:\n        for doc in docs:\n            authors_list = list(doc.authors) if doc.authors is not None else []\n            authors_json = json.dumps(authors_list)\n            _execute_with_operation(\n                con,\n                \"\"\"INSERT OR REPLACE INTO documents\n            (doc_id, openalex_id, doi, arxiv_id, pmcid, title, authors,\n             pub_date, license, language, pdf_uri, source, content_hash, created_at)\n            VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,CURRENT_TIMESTAMP)\"\"\",\n                [\n                    doc.id,\n                    doc.openalex_id,\n                    doc.doi,\n                    doc.arxiv_id,\n                    doc.pmcid,\n                    doc.title,\n                    authors_json,\n                    doc.pub_date,\n                    doc.license,\n                    doc.language,\n                    doc.pdf_uri,\n                    doc.source,\n                    doc.content_hash or \"\",\n                ],\n                operation=\"registry.helper.register_documents\",\n            )\n</code></pre>"},{"location":"modules/registry.helper/#registry.helper.DuckDBRegistryHelper.rollback_dataset","title":"<code>rollback_dataset(dataset_id)</code>","text":"<p>Rollback a dataset by deleting it.</p> <p>Deletes a dataset record and emits a DatasetRolledBack event. Use this when a dataset creation fails or needs to be abandoned.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID to rollback.</p> required Source code in <code>src/registry/helper.py</code> <pre><code>def rollback_dataset(self, dataset_id: str) -&gt; None:\n    \"\"\"Rollback a dataset by deleting it.\n\n    Deletes a dataset record and emits a DatasetRolledBack event.\n    Use this when a dataset creation fails or needs to be abandoned.\n\n    Parameters\n    ----------\n    dataset_id : str\n        Dataset ID to rollback.\n    \"\"\"\n    with closing(self._connect()) as con:\n        _execute_with_operation(\n            con,\n            \"DELETE FROM datasets WHERE dataset_id=?\",\n            [dataset_id],\n            operation=\"registry.helper.rollback_dataset.delete\",\n        )\n        _execute_with_operation(\n            con,\n            \"INSERT INTO pipeline_events VALUES (?,?,?,?,CURRENT_TIMESTAMP)\",\n            [str(uuid.uuid4()), \"DatasetRolledBack\", dataset_id, \"{}\"],\n            operation=\"registry.helper.rollback_dataset.event\",\n        )\n</code></pre>"},{"location":"modules/registry.helper/#registryhelper_execute_with_operation","title":"registry.helper._execute_with_operation","text":""},{"location":"modules/registry.helper/#registry.helper._execute_with_operation","title":"<code>registry.helper._execute_with_operation(conn, sql, params, operation)</code>","text":"Source code in <code>src/registry/helper.py</code> <pre><code>def _execute_with_operation(\n    conn: DuckDBPyConnection,\n    sql: str,\n    params: duckdb_helpers.Params,\n    operation: str,\n) -&gt; None:\n    duckdb_helpers.execute(\n        conn,\n        sql,\n        params,\n        options=DuckDBQueryOptions(operation=operation),\n    )\n</code></pre>"},{"location":"modules/registry/","title":"registry","text":""},{"location":"modules/registry/#registry","title":"registry","text":"<p>DuckDB-backed registry APIs and helpers</p> <p>:material-source-repository: View source</p>"},{"location":"modules/registry/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"registry__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.navmap_types.NavMapregistry code <p>See the full diagram: registry</p>"},{"location":"modules/registry/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.navmap_types.NavMap</code></p>"},{"location":"modules/registry.migrate/","title":"registry.migrate","text":""},{"location":"modules/registry.migrate/#registrymigrate","title":"registry.migrate","text":"<p>Migration helpers for DuckDB registry schemas</p> <p>:material-source-repository: View source</p>"},{"location":"modules/registry.migrate/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"registry.migrate__future__.annotationsargparsecontextlib.closingkgfoundry_common.errors.RegistryErrorkgfoundry_common.navmap_loader.load_nav_metadatapathlibregistry.duckdb_helpersregistry.duckdb_helpers.DuckDBQueryOptionstyping.castregistry.migrate code <p>See the full diagram: registry.migrate</p>"},{"location":"modules/registry.migrate/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>registry.migrate.apply</li> <li>registry.migrate.main</li> </ul>"},{"location":"modules/registry.migrate/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>argparse</code>, <code>contextlib.closing</code>, <code>kgfoundry_common.errors.RegistryError</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>pathlib</code>, registry.duckdb_helpers, <code>registry.duckdb_helpers.DuckDBQueryOptions</code>, <code>typing.cast</code></p>"},{"location":"modules/registry.migrate/#contents","title":"Contents","text":""},{"location":"modules/registry.migrate/#registrymigrateapply","title":"registry.migrate.apply","text":""},{"location":"modules/registry.migrate/#registry.migrate.apply","title":"<code>registry.migrate.apply(db, migrations_dir)</code>","text":"<p>Apply migration SQL files to a DuckDB database.</p> <p>Reads all SQL files from the migrations directory in sorted order and executes them against the database. Skips errors related to missing Parquet table functions.</p> <p>Parameters:</p> Name Type Description Default <code>db</code> <code>str</code> <p>Path to DuckDB database file.</p> required <code>migrations_dir</code> <code>str</code> <p>Directory containing migration SQL files.</p> required <p>Raises:</p> Type Description <code>RegistryError</code> <p>If migrations directory does not exist or migration execution fails.</p> Source code in <code>src/registry/migrate.py</code> <pre><code>def apply(db: str, migrations_dir: str) -&gt; None:\n    \"\"\"Apply migration SQL files to a DuckDB database.\n\n    Reads all SQL files from the migrations directory in sorted order\n    and executes them against the database. Skips errors related to\n    missing Parquet table functions.\n\n    Parameters\n    ----------\n    db : str\n        Path to DuckDB database file.\n    migrations_dir : str\n        Directory containing migration SQL files.\n\n    Raises\n    ------\n    RegistryError\n        If migrations directory does not exist or migration execution fails.\n    \"\"\"\n    path = pathlib.Path(migrations_dir)\n    if not path.exists():\n        error_message = \"Migrations directory does not exist\"\n        raise RegistryError(\n            error_message,\n            context={\"migrations_dir\": str(path.resolve())},\n        )\n\n    with closing(duckdb_helpers.connect(db, pragmas={\"threads\": 4})) as con:\n        for migration in sorted(path.glob(\"*.sql\")):\n            sql = migration.read_text()\n            statements = [stmt.strip() for stmt in sql.split(\";\") if stmt.strip()]\n            for statement in statements:\n                try:\n                    duckdb_helpers.execute(\n                        con,\n                        statement,\n                        params=None,\n                        options=DuckDBQueryOptions(\n                            operation=f\"registry.migrate.{migration.stem}\",\n                            require_parameterized=False,\n                        ),\n                    )\n                except RegistryError as err:\n                    message = err.message.lower()\n                    if \"read_parquet\" in message and \"table function\" in message:\n                        continue\n                    raise\n</code></pre>"},{"location":"modules/registry.migrate/#registrymigratemain","title":"registry.migrate.main","text":""},{"location":"modules/registry.migrate/#registry.migrate.main","title":"<code>registry.migrate.main()</code>","text":"<p>CLI entrypoint for registry migration operations.</p> <p>Parses command-line arguments and executes the apply command to run migrations against a DuckDB database.</p> Source code in <code>src/registry/migrate.py</code> <pre><code>def main() -&gt; None:\n    \"\"\"CLI entrypoint for registry migration operations.\n\n    Parses command-line arguments and executes the apply command to run migrations against a DuckDB\n    database.\n    \"\"\"\n    ap = argparse.ArgumentParser()\n    sp = ap.add_subparsers(dest=\"cmd\", required=True)\n    a = sp.add_parser(\"apply\")\n    a.add_argument(\"--db\", required=True)\n    a.add_argument(\"--migrations\", required=True)\n    ns = ap.parse_args()\n    db_arg = cast(\"str\", ns.db)\n    migrations_arg = cast(\"str\", ns.migrations)\n    cmd = cast(\"str\", ns.cmd)\n    if cmd == \"apply\":\n        apply(db_arg, migrations_arg)\n</code></pre>"},{"location":"modules/search_api.app/","title":"search_api.app","text":""},{"location":"modules/search_api.app/#search_apiapp","title":"search_api.app","text":"<p>FastAPI endpoints for hybrid search with FAISS, BM25, and SPLADE</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_api.app/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class CorrelationIDMiddleware\n    class BaseHTTPMiddleware\n    BaseHTTPMiddleware &lt;|-- CorrelationIDMiddleware\n    class ResponseValidationMiddleware\n    BaseHTTPMiddleware &lt;|-- ResponseValidationMiddleware\n</code></pre>"},{"location":"modules/search_api.app/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_api.app__future__.annotationsasynciocollections.abc.Awaitablecollections.abc.Callablecollections.abc.Mappingfastapi.FastAPIfastapi.HTTPExceptionfastapi.Headerjsonkgfoundry.embeddings_sparse.bm25.LuceneBM25kgfoundry.embeddings_sparse.bm25.PurePythonBM25kgfoundry.embeddings_sparse.bm25.get_bm25kgfoundry.embeddings_sparse.splade.get_spladekgfoundry.kg_builder.mock_kg.MockKGkgfoundry_common.errors.DeserializationErrorkgfoundry_common.errors.SerializationErrorkgfoundry_common.errors.SettingsErrorkgfoundry_common.errors.VectorSearchErrorkgfoundry_common.errors.http.register_problem_details_handlerkgfoundry_common.jsonschema_utils.ValidationErrorkgfoundry_common.jsonschema_utils.ValidationErrorProtocolkgfoundry_common.jsonschema_utils.validatekgfoundry_common.logging.get_loggerkgfoundry_common.logging.set_correlation_idkgfoundry_common.logging.with_fieldskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.observability.MetricsProviderkgfoundry_common.observability.observe_durationkgfoundry_common.problem_details.JsonValuekgfoundry_common.schema_helpers.load_schemakgfoundry_common.settings.FaissConfigkgfoundry_common.settings.ObservabilityConfigkgfoundry_common.settings.RuntimeSettingskgfoundry_common.settings.SearchConfigkgfoundry_common.settings.SparseEmbeddingConfigpathlib.Pathsearch_api.fastapi_helpers.DEFAULT_TIMEOUT_SECONDSsearch_api.fastapi_helpers.typed_dependencysearch_api.fastapi_helpers.typed_middlewaresearch_api.fusion.rrf_fusesearch_api.schemas.SearchRequestsearch_api.schemas.SearchResponsesearch_api.schemas.SearchResultsearch_api.service.apply_kg_boostsstarlette.middleware.base.BaseHTTPMiddlewarestarlette.requests.Requeststarlette.responses.JSONResponsestarlette.responses.Responsestarlette.types.ASGIApptyping.Annotatedtyping.Finaltyping.TYPE_CHECKINGtyping.castuuidsearch_apisearch_api.app code <p>See the full diagram: search_api.app</p>"},{"location":"modules/search_api.app/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>search_api.app.CorrelationIDMiddleware</li> <li>search_api.app.ResponseValidationMiddleware</li> <li>search_api.app._validate_authorization_header</li> <li>search_api.app.auth</li> <li>search_api.app.graph_concepts</li> </ul>"},{"location":"modules/search_api.app/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>asyncio</code>, <code>collections.abc.Awaitable</code>, <code>collections.abc.Callable</code>, <code>collections.abc.Mapping</code>, <code>fastapi.FastAPI</code>, <code>fastapi.HTTPException</code>, <code>fastapi.Header</code>, <code>json</code>, <code>kgfoundry.embeddings_sparse.bm25.LuceneBM25</code>, <code>kgfoundry.embeddings_sparse.bm25.PurePythonBM25</code>, <code>kgfoundry.embeddings_sparse.bm25.get_bm25</code>, <code>kgfoundry.embeddings_sparse.splade.get_splade</code>, <code>kgfoundry.kg_builder.mock_kg.MockKG</code>, <code>kgfoundry_common.errors.DeserializationError</code>, <code>kgfoundry_common.errors.SerializationError</code>, <code>kgfoundry_common.errors.SettingsError</code>, <code>kgfoundry_common.errors.VectorSearchError</code>, <code>kgfoundry_common.errors.http.register_problem_details_handler</code>, <code>kgfoundry_common.jsonschema_utils.ValidationError</code>, <code>kgfoundry_common.jsonschema_utils.ValidationErrorProtocol</code>, <code>kgfoundry_common.jsonschema_utils.validate</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>kgfoundry_common.logging.set_correlation_id</code>, <code>kgfoundry_common.logging.with_fields</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.observability.MetricsProvider</code>, <code>kgfoundry_common.observability.observe_duration</code>, <code>kgfoundry_common.problem_details.JsonValue</code>, <code>kgfoundry_common.schema_helpers.load_schema</code>, <code>kgfoundry_common.settings.FaissConfig</code>, <code>kgfoundry_common.settings.ObservabilityConfig</code>, <code>kgfoundry_common.settings.RuntimeSettings</code>, <code>kgfoundry_common.settings.SearchConfig</code>, <code>kgfoundry_common.settings.SparseEmbeddingConfig</code>, <code>pathlib.Path</code>, <code>search_api.fastapi_helpers.DEFAULT_TIMEOUT_SECONDS</code>, <code>search_api.fastapi_helpers.typed_dependency</code>, <code>search_api.fastapi_helpers.typed_middleware</code>, <code>search_api.fusion.rrf_fuse</code>, <code>search_api.schemas.SearchRequest</code>, <code>search_api.schemas.SearchResponse</code>, <code>search_api.schemas.SearchResult</code>, <code>search_api.service.apply_kg_boosts</code>, <code>starlette.middleware.base.BaseHTTPMiddleware</code>, <code>starlette.requests.Request</code>, <code>starlette.responses.JSONResponse</code>, <code>starlette.responses.Response</code>, <code>starlette.types.ASGIApp</code>, <code>typing.Annotated</code>, <code>typing.Final</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code>, <code>uuid</code></p> <p>Imported by: search_api</p>"},{"location":"modules/search_api.app/#contents","title":"Contents","text":""},{"location":"modules/search_api.app/#search_apiappcorrelationidmiddleware","title":"search_api.app.CorrelationIDMiddleware","text":"<p>Bases: BaseHTTPMiddleware</p>"},{"location":"modules/search_api.app/#search_api.app.CorrelationIDMiddleware","title":"<code>search_api.app.CorrelationIDMiddleware</code>","text":"<p>               Bases: <code>BaseHTTPMiddleware</code></p> <p>Middleware to extract and set correlation ID from X-Correlation-ID header.</p> <p>Extracts correlation ID from the X-Correlation-ID HTTP header or generates a new UUID if not present. Sets the correlation ID in contextvars for async propagation and includes it in the response headers.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <code>ASGIApp</code> <p>ASGI application instance to wrap.</p> required <code>dispatch</code> <code>Callable[[Request], Awaitable[Response]] | None</code> <p>Custom dispatch function (typically None for default behavior). Defaults to None.</p> required Source code in <code>src/search_api/app.py</code> <pre><code>class CorrelationIDMiddleware(BaseHTTPMiddleware):\n    \"\"\"Middleware to extract and set correlation ID from X-Correlation-ID header.\n\n    Extracts correlation ID from the X-Correlation-ID HTTP header or generates a\n    new UUID if not present. Sets the correlation ID in contextvars for async\n    propagation and includes it in the response headers.\n\n    Parameters\n    ----------\n    app : ASGIApp\n        ASGI application instance to wrap.\n    dispatch : Callable[[StarletteRequest], Awaitable[Response]] | None, optional\n        Custom dispatch function (typically None for default behavior).\n        Defaults to None.\n    \"\"\"\n\n    HEADER_NAME: Final[str] = \"X-Correlation-ID\"\n\n    async def dispatch(\n        self,\n        request: StarletteRequest,\n        call_next: Callable[[StarletteRequest], Awaitable[Response]],\n    ) -&gt; Response:\n        \"\"\"Extract correlation ID from header or generate new one.\n\n        Checks for X-Correlation-ID header in the request. If present, uses it;\n        otherwise generates a new UUID. Sets the correlation ID in contextvars\n        and includes it in the response headers.\n\n        Parameters\n        ----------\n        request : StarletteRequest\n            HTTP request object containing headers.\n        call_next : Callable[[StarletteRequest], Awaitable[Response]]\n            Next middleware or route handler in the chain.\n\n        Returns\n        -------\n        Response\n            HTTP response with X-Correlation-ID header set.\n        \"\"\"\n        header_name = self.HEADER_NAME\n        correlation_id = request.headers.get(header_name)\n        if not correlation_id:\n            correlation_id = str(uuid.uuid4())\n        set_correlation_id(correlation_id)\n        response = await call_next(request)\n        response.headers[header_name] = correlation_id\n        return response\n</code></pre>"},{"location":"modules/search_api.app/#search_api.app.CorrelationIDMiddleware.dispatch","title":"<code>dispatch(request, call_next)</code>  <code>async</code>","text":"<p>Extract correlation ID from header or generate new one.</p> <p>Checks for X-Correlation-ID header in the request. If present, uses it; otherwise generates a new UUID. Sets the correlation ID in contextvars and includes it in the response headers.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>HTTP request object containing headers.</p> required <code>call_next</code> <code>Callable[[Request], Awaitable[Response]]</code> <p>Next middleware or route handler in the chain.</p> required <p>Returns:</p> Type Description <code>Response</code> <p>HTTP response with X-Correlation-ID header set.</p> Source code in <code>src/search_api/app.py</code> <pre><code>async def dispatch(\n    self,\n    request: StarletteRequest,\n    call_next: Callable[[StarletteRequest], Awaitable[Response]],\n) -&gt; Response:\n    \"\"\"Extract correlation ID from header or generate new one.\n\n    Checks for X-Correlation-ID header in the request. If present, uses it;\n    otherwise generates a new UUID. Sets the correlation ID in contextvars\n    and includes it in the response headers.\n\n    Parameters\n    ----------\n    request : StarletteRequest\n        HTTP request object containing headers.\n    call_next : Callable[[StarletteRequest], Awaitable[Response]]\n        Next middleware or route handler in the chain.\n\n    Returns\n    -------\n    Response\n        HTTP response with X-Correlation-ID header set.\n    \"\"\"\n    header_name = self.HEADER_NAME\n    correlation_id = request.headers.get(header_name)\n    if not correlation_id:\n        correlation_id = str(uuid.uuid4())\n    set_correlation_id(correlation_id)\n    response = await call_next(request)\n    response.headers[header_name] = correlation_id\n    return response\n</code></pre>"},{"location":"modules/search_api.app/#search_apiappresponsevalidationmiddleware","title":"search_api.app.ResponseValidationMiddleware","text":"<p>Bases: BaseHTTPMiddleware</p>"},{"location":"modules/search_api.app/#search_api.app.ResponseValidationMiddleware","title":"<code>search_api.app.ResponseValidationMiddleware</code>","text":"<p>               Bases: <code>BaseHTTPMiddleware</code></p> <p>Middleware to validate JSON responses against schema (dev/staging only).</p> <p>Validates responses against search_response.json schema when enabled. Logs validation failures and returns Problem Details (RFC 9457) on schema mismatch. Only validates JSON responses from the /search endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <code>ASGIApp</code> <p>ASGI application instance to wrap.</p> required <code>enabled</code> <code>bool</code> <p>Whether to enable response validation. Defaults to False.</p> <code>False</code> <code>schema_path</code> <code>Path | None</code> <p>Path to search_response.json schema file. If None, searches for schema/search/search_response.json relative to repo root. Defaults to None.</p> <code>None</code> Source code in <code>src/search_api/app.py</code> <pre><code>class ResponseValidationMiddleware(BaseHTTPMiddleware):\n    \"\"\"Middleware to validate JSON responses against schema (dev/staging only).\n\n    Validates responses against search_response.json schema when enabled.\n    Logs validation failures and returns Problem Details (RFC 9457) on schema\n    mismatch. Only validates JSON responses from the /search endpoint.\n\n    Parameters\n    ----------\n    app : ASGIApp\n        ASGI application instance to wrap.\n    enabled : bool, optional\n        Whether to enable response validation. Defaults to False.\n    schema_path : Path | None, optional\n        Path to search_response.json schema file. If None, searches for\n        schema/search/search_response.json relative to repo root.\n        Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: FastAPI,\n        *,\n        enabled: bool = False,\n        schema_path: Path | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize response validation middleware.\n\n        Sets up the middleware with optional schema validation. Loads the\n        JSON Schema 2020-12 from the provided path or default location.\n\n        Parameters\n        ----------\n        app : FastAPI\n            FastAPI application instance to wrap.\n        enabled : bool, optional\n            Whether to enable response validation. Defaults to False.\n        schema_path : Path | None, optional\n            Path to search_response.json schema file. If None, searches for\n            schema/search/search_response.json relative to repo root.\n            Defaults to None.\n        \"\"\"\n        super().__init__(cast(\"ASGIApp\", app))\n        self.enabled = enabled\n        if schema_path is None:\n            # Default to schema/search/search_response.json relative to repo root\n            repo_root = Path(__file__).parent.parent.parent\n            schema_path = repo_root / \"schema\" / \"search\" / \"search_response.json\"\n        self.schema_path = schema_path\n        self.schema: dict[str, JsonValue] | None = None\n        if self.enabled and self.schema_path.exists():\n            try:\n                self.schema = load_schema(self.schema_path)\n                logger.info(\n                    \"Response validation enabled\",\n                    extra={\"schema_path\": str(self.schema_path)},\n                )\n            except (FileNotFoundError, DeserializationError) as exc:\n                logger.warning(\n                    \"Failed to load response schema, validation disabled\",\n                    extra={\"schema_path\": str(self.schema_path), \"error\": str(exc)},\n                    exc_info=True,\n                )\n                self.enabled = False\n\n    async def dispatch(\n        self,\n        request: StarletteRequest,\n        call_next: Callable[[StarletteRequest], Awaitable[Response]],\n    ) -&gt; Response:\n        \"\"\"Validate response against schema if enabled.\n\n        Validates JSON responses from the /search endpoint against the loaded\n        schema. Logs validation failures and returns Problem Details (RFC 9457)\n        if validation fails.\n\n        Parameters\n        ----------\n        request : StarletteRequest\n            HTTP request object.\n        call_next : Callable[[StarletteRequest], Awaitable[Response]]\n            Next middleware or route handler in the chain.\n\n        Returns\n        -------\n        Response\n            Original response if validation passes or is disabled, or Problem\n            Details JSON response if validation fails.\n        \"\"\"\n        if not self.enabled or self.schema is None:\n            return await call_next(request)\n\n        response = await call_next(request)\n\n        # Only validate JSON responses\n        if response.media_type != \"application/json\":\n            return response\n\n        # Only validate /search endpoint responses\n        if request.url.path != \"/search\":\n            return response\n\n        # Extract response body from JSONResponse\n        try:\n            # JSONResponse has a 'body' property that contains the rendered body\n            body_buffer = response.body\n            if isinstance(body_buffer, memoryview):\n                body_bytes = body_buffer.tobytes()\n            else:\n                body_bytes = bytes(body_buffer)\n            response_body: JsonValue = json.loads(body_bytes.decode(\"utf-8\"))\n        except (json.JSONDecodeError, AttributeError) as exc:\n            with with_fields(logger, operation=\"response_validation\") as log_adapter:\n                log_adapter.warning(\n                    \"Failed to parse response body for validation\",\n                    extra={\"error\": str(exc)},\n                    exc_info=True,\n                )\n            # Return original response if parsing fails\n            return response\n\n        # Validate against schema\n        try:\n            jsonschema_validate(instance=response_body, schema=self.schema)\n        except JsonSchemaValidationError as exc:\n            with with_fields(logger, operation=\"response_validation\") as log_adapter:\n                error_details = cast(\"ValidationErrorProtocol\", exc)\n                log_adapter.exception(\n                    \"Response validation failed\",\n                    extra={\n                        \"status\": \"error\",\n                        \"validation_error\": error_details.message,\n                        \"path\": \"/\".join(str(part) for part in error_details.path),\n                    },\n                )\n            # Return Problem Details for validation failure\n            error_msg = f\"Response validation failed: {error_details.message}\"\n            problem = SerializationError(\n                error_msg,\n                cause=exc,\n                context={\n                    \"schema_path\": str(self.schema_path),\n                    \"validation_path\": \"/\".join(str(part) for part in error_details.path),\n                },\n            )\n            problem_response = JSONResponse(\n                content=problem.to_problem_details(),\n                status_code=500,\n                headers=response.headers,\n            )\n            return cast(\"Response\", problem_response)\n\n        # Return original response if validation passes\n        return response\n</code></pre>"},{"location":"modules/search_api.app/#search_api.app.ResponseValidationMiddleware.__init__","title":"<code>__init__(app, *, enabled=False, schema_path=None)</code>","text":"<p>Initialize response validation middleware.</p> <p>Sets up the middleware with optional schema validation. Loads the JSON Schema 2020-12 from the provided path or default location.</p> <p>Parameters:</p> Name Type Description Default <code>app</code> <code>FastAPI</code> <p>FastAPI application instance to wrap.</p> required <code>enabled</code> <code>bool</code> <p>Whether to enable response validation. Defaults to False.</p> <code>False</code> <code>schema_path</code> <code>Path | None</code> <p>Path to search_response.json schema file. If None, searches for schema/search/search_response.json relative to repo root. Defaults to None.</p> <code>None</code> Source code in <code>src/search_api/app.py</code> <pre><code>def __init__(\n    self,\n    app: FastAPI,\n    *,\n    enabled: bool = False,\n    schema_path: Path | None = None,\n) -&gt; None:\n    \"\"\"Initialize response validation middleware.\n\n    Sets up the middleware with optional schema validation. Loads the\n    JSON Schema 2020-12 from the provided path or default location.\n\n    Parameters\n    ----------\n    app : FastAPI\n        FastAPI application instance to wrap.\n    enabled : bool, optional\n        Whether to enable response validation. Defaults to False.\n    schema_path : Path | None, optional\n        Path to search_response.json schema file. If None, searches for\n        schema/search/search_response.json relative to repo root.\n        Defaults to None.\n    \"\"\"\n    super().__init__(cast(\"ASGIApp\", app))\n    self.enabled = enabled\n    if schema_path is None:\n        # Default to schema/search/search_response.json relative to repo root\n        repo_root = Path(__file__).parent.parent.parent\n        schema_path = repo_root / \"schema\" / \"search\" / \"search_response.json\"\n    self.schema_path = schema_path\n    self.schema: dict[str, JsonValue] | None = None\n    if self.enabled and self.schema_path.exists():\n        try:\n            self.schema = load_schema(self.schema_path)\n            logger.info(\n                \"Response validation enabled\",\n                extra={\"schema_path\": str(self.schema_path)},\n            )\n        except (FileNotFoundError, DeserializationError) as exc:\n            logger.warning(\n                \"Failed to load response schema, validation disabled\",\n                extra={\"schema_path\": str(self.schema_path), \"error\": str(exc)},\n                exc_info=True,\n            )\n            self.enabled = False\n</code></pre>"},{"location":"modules/search_api.app/#search_api.app.ResponseValidationMiddleware.dispatch","title":"<code>dispatch(request, call_next)</code>  <code>async</code>","text":"<p>Validate response against schema if enabled.</p> <p>Validates JSON responses from the /search endpoint against the loaded schema. Logs validation failures and returns Problem Details (RFC 9457) if validation fails.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>HTTP request object.</p> required <code>call_next</code> <code>Callable[[Request], Awaitable[Response]]</code> <p>Next middleware or route handler in the chain.</p> required <p>Returns:</p> Type Description <code>Response</code> <p>Original response if validation passes or is disabled, or Problem Details JSON response if validation fails.</p> Source code in <code>src/search_api/app.py</code> <pre><code>async def dispatch(\n    self,\n    request: StarletteRequest,\n    call_next: Callable[[StarletteRequest], Awaitable[Response]],\n) -&gt; Response:\n    \"\"\"Validate response against schema if enabled.\n\n    Validates JSON responses from the /search endpoint against the loaded\n    schema. Logs validation failures and returns Problem Details (RFC 9457)\n    if validation fails.\n\n    Parameters\n    ----------\n    request : StarletteRequest\n        HTTP request object.\n    call_next : Callable[[StarletteRequest], Awaitable[Response]]\n        Next middleware or route handler in the chain.\n\n    Returns\n    -------\n    Response\n        Original response if validation passes or is disabled, or Problem\n        Details JSON response if validation fails.\n    \"\"\"\n    if not self.enabled or self.schema is None:\n        return await call_next(request)\n\n    response = await call_next(request)\n\n    # Only validate JSON responses\n    if response.media_type != \"application/json\":\n        return response\n\n    # Only validate /search endpoint responses\n    if request.url.path != \"/search\":\n        return response\n\n    # Extract response body from JSONResponse\n    try:\n        # JSONResponse has a 'body' property that contains the rendered body\n        body_buffer = response.body\n        if isinstance(body_buffer, memoryview):\n            body_bytes = body_buffer.tobytes()\n        else:\n            body_bytes = bytes(body_buffer)\n        response_body: JsonValue = json.loads(body_bytes.decode(\"utf-8\"))\n    except (json.JSONDecodeError, AttributeError) as exc:\n        with with_fields(logger, operation=\"response_validation\") as log_adapter:\n            log_adapter.warning(\n                \"Failed to parse response body for validation\",\n                extra={\"error\": str(exc)},\n                exc_info=True,\n            )\n        # Return original response if parsing fails\n        return response\n\n    # Validate against schema\n    try:\n        jsonschema_validate(instance=response_body, schema=self.schema)\n    except JsonSchemaValidationError as exc:\n        with with_fields(logger, operation=\"response_validation\") as log_adapter:\n            error_details = cast(\"ValidationErrorProtocol\", exc)\n            log_adapter.exception(\n                \"Response validation failed\",\n                extra={\n                    \"status\": \"error\",\n                    \"validation_error\": error_details.message,\n                    \"path\": \"/\".join(str(part) for part in error_details.path),\n                },\n            )\n        # Return Problem Details for validation failure\n        error_msg = f\"Response validation failed: {error_details.message}\"\n        problem = SerializationError(\n            error_msg,\n            cause=exc,\n            context={\n                \"schema_path\": str(self.schema_path),\n                \"validation_path\": \"/\".join(str(part) for part in error_details.path),\n            },\n        )\n        problem_response = JSONResponse(\n            content=problem.to_problem_details(),\n            status_code=500,\n            headers=response.headers,\n        )\n        return cast(\"Response\", problem_response)\n\n    # Return original response if validation passes\n    return response\n</code></pre>"},{"location":"modules/search_api.app/#search_apiapp_validate_authorization_header","title":"search_api.app._validate_authorization_header","text":""},{"location":"modules/search_api.app/#search_api.app._validate_authorization_header","title":"<code>search_api.app._validate_authorization_header(authorization)</code>","text":"<p>Validate bearer token authentication.</p> <p>Parameters:</p> Name Type Description Default <code>authorization</code> <code>str | None</code> <p>Authorization header value.</p> required <p>Raises:</p> Type Description <code>HTTPException</code> <p>If authorization header is missing, invalid, or API key is invalid.</p> Source code in <code>src/search_api/app.py</code> <pre><code>def _validate_authorization_header(authorization: str | None) -&gt; None:\n    \"\"\"Validate bearer token authentication.\n\n    Parameters\n    ----------\n    authorization : str | None\n        Authorization header value.\n\n    Raises\n    ------\n    HTTPException\n        If authorization header is missing, invalid, or API key is invalid.\n    \"\"\"\n    if not authorization or not authorization.startswith(\"Bearer \"):\n        raise HTTPException(status_code=401, detail=\"Missing or invalid Bearer token\")\n    token = authorization.split(\" \", 1)[1]\n    if token not in API_KEYS:\n        raise HTTPException(status_code=401, detail=\"Invalid API key\")\n</code></pre>"},{"location":"modules/search_api.app/#search_apiappauth","title":"search_api.app.auth","text":""},{"location":"modules/search_api.app/#search_api.app.auth","title":"<code>search_api.app.auth(authorization)</code>  <code>async</code>","text":"<p>Validate bearer token authentication.</p> Source code in <code>src/search_api/app.py</code> <pre><code>async def auth(authorization: AuthorizationHeader) -&gt; None:\n    \"\"\"Validate bearer token authentication.\"\"\"\n    await asyncio.to_thread(_validate_authorization_header, authorization)\n</code></pre>"},{"location":"modules/search_api.app/#search_apiappgraph_concepts","title":"search_api.app.graph_concepts","text":""},{"location":"modules/search_api.app/#search_api.app.graph_concepts","title":"<code>search_api.app.graph_concepts(body, _=None)</code>","text":"<p>Retrieve knowledge graph concepts matching query.</p> <p>Returns concepts from the knowledge graph that match the query string. Searches concept labels for substring matches and returns a limited number of results. Includes structured logging and error handling.</p> <p>Parameters:</p> Name Type Description Default <code>body</code> <code>Mapping[str, JsonValue]</code> <p>Request body containing: - <code>q</code> (str): Query string to match against concept labels (case-insensitive). - <code>limit</code> (int, optional): Maximum number of concepts to return.   Defaults to 50.</p> required <code>_</code> <code>AuthDependency</code> <p>Authentication dependency (Bearer token). Injected by FastAPI. Defaults to None (handled by FastAPI dependency injection).</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, list[dict[str, str]]]</code> <p>Dictionary with \"concepts\" key containing list of concept dictionaries. Each concept has \"concept_id\" and \"label\" keys.</p> <p>Raises:</p> Type Description <code>VectorSearchError</code> <p>Returns Problem Details JSON (RFC 9457) on errors such as invalid request body or backend failures.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from search_api.app import graph_concepts\n&gt;&gt;&gt; result = graph_concepts({\"q\": \"test\", \"limit\": 10}, None)\n&gt;&gt;&gt; \"concepts\" in result\nTrue\n</code></pre> Source code in <code>src/search_api/app.py</code> <pre><code>def graph_concepts(\n    body: Mapping[str, JsonValue],\n    _: AuthDependency = None,\n) -&gt; dict[str, list[dict[str, str]]]:\n    \"\"\"Retrieve knowledge graph concepts matching query.\n\n    Returns concepts from the knowledge graph that match the query string.\n    Searches concept labels for substring matches and returns a limited number\n    of results. Includes structured logging and error handling.\n\n    Parameters\n    ----------\n    body : Mapping[str, JsonValue]\n        Request body containing:\n        - `q` (str): Query string to match against concept labels (case-insensitive).\n        - `limit` (int, optional): Maximum number of concepts to return.\n          Defaults to 50.\n    _ : AuthDependency, optional\n        Authentication dependency (Bearer token). Injected by FastAPI.\n        Defaults to None (handled by FastAPI dependency injection).\n\n    Returns\n    -------\n    dict[str, list[dict[str, str]]]\n        Dictionary with \"concepts\" key containing list of concept dictionaries.\n        Each concept has \"concept_id\" and \"label\" keys.\n\n    Raises\n    ------\n    VectorSearchError\n        Returns Problem Details JSON (RFC 9457) on errors such as invalid\n        request body or backend failures.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from search_api.app import graph_concepts\n    &gt;&gt;&gt; result = graph_concepts({\"q\": \"test\", \"limit\": 10}, None)\n    &gt;&gt;&gt; \"concepts\" in result\n    True\n    \"\"\"\n    with with_fields(logger, operation=\"graph_concepts\") as log_adapter:\n        q: str = \"\"\n        try:\n            q = str((body or {}).get(\"q\", \"\")).lower()\n            limit_raw = body.get(\"limit\", 50) if body else 50\n            try:\n                limit = int(cast(\"int | float | str\", limit_raw))\n                if limit &lt; 0:\n                    limit = 50\n            except (ValueError, TypeError):\n                limit = 50\n\n            # toy: return nodes that contain the query substring\n            concepts: list[dict[str, str]] = [\n                {\"concept_id\": c, \"label\": c}\n                for c in sorted({c for cs in kg.chunk2concepts.values() for c in cs})\n                if q in c.lower()\n            ][:limit]\n\n            log_adapter.info(\n                \"Graph concepts retrieved\", extra={\"status\": \"success\", \"count\": len(concepts)}\n            )\n        except (RuntimeError, ValueError, AttributeError, OSError) as exc:\n            error_msg = f\"Graph concepts operation failed: {exc}\"\n            # context accepts Mapping[str, object], dict[str, str] is compatible\n            context_dict: Mapping[str, object] = {\"query\": q}\n            raise VectorSearchError(error_msg, cause=exc, context=context_dict) from exc\n        else:\n            return {\"concepts\": concepts}\n</code></pre>"},{"location":"modules/search_api.app/#search_apiapphealthz","title":"search_api.app.healthz","text":""},{"location":"modules/search_api.app/#search_api.app.healthz","title":"<code>search_api.app.healthz()</code>","text":"<p>Health check endpoint.</p> <p>Returns the health status of the search API and its components (BM25, SPLADE, embeddings, knowledge graph). Used for monitoring and readiness checks.</p> <p>Returns:</p> Type Description <code>dict[str, str | dict[str, str]]</code> <p>Dictionary with \"status\" key set to \"ok\" and \"components\" key containing a dictionary mapping component names to their availability status (\"available\", \"unavailable\", or \"mocked\").</p> Source code in <code>src/search_api/app.py</code> <pre><code>def healthz() -&gt; dict[str, str | dict[str, str]]:\n    \"\"\"Health check endpoint.\n\n    Returns the health status of the search API and its components (BM25,\n    SPLADE, embeddings, knowledge graph). Used for monitoring and readiness\n    checks.\n\n    Returns\n    -------\n    dict[str, str | dict[str, str]]\n        Dictionary with \"status\" key set to \"ok\" and \"components\" key containing\n        a dictionary mapping component names to their availability status\n        (\"available\", \"unavailable\", or \"mocked\").\n    \"\"\"\n    return {\n        \"status\": \"ok\",\n        \"components\": {\n            \"bm25\": \"available\" if bm25 else \"unavailable\",\n            \"splade\": \"available\" if splade else \"unavailable\",\n            \"vllm_embeddings\": \"mocked\",\n            \"neo4j\": \"mocked\",\n        },\n    }\n</code></pre>"},{"location":"modules/search_api.app/#search_apiappsearch","title":"search_api.app.search","text":""},{"location":"modules/search_api.app/#search_api.app.search","title":"<code>search_api.app.search(req, _=None)</code>","text":"<p>Execute hybrid search query.</p> <p>Combines dense (FAISS), sparse (BM25/SPLADE), and knowledge graph signals using Reciprocal Rank Fusion and KG boosts. Returns ranked results with structured logging and metrics.</p> <p>Parameters:</p> Name Type Description Default <code>req</code> <code>SearchRequest</code> <p>Search request containing query text, k (number of results), and optional facets for filtering.</p> required <code>_</code> <code>AuthDependency</code> <p>Authentication dependency (Bearer token). Injected by FastAPI. Defaults to None (handled by FastAPI dependency injection).</p> <code>None</code> <p>Returns:</p> Type Description <code>SearchResponse</code> <p>Search results with metadata and performance metrics. Results are ranked by combined relevance scores from all search channels.</p> <p>Raises:</p> Type Description <code>VectorSearchError</code> <p>Returns Problem Details JSON (RFC 9457) on errors such as missing indexes, invalid queries, or backend failures.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from search_api.schemas import SearchRequest\n&gt;&gt;&gt; from search_api.app import search\n&gt;&gt;&gt; req = SearchRequest(query=\"vector store\", k=5)\n&gt;&gt;&gt; response = search(req, None)\n&gt;&gt;&gt; len(response.results) &lt;= 5\nTrue\n</code></pre> Source code in <code>src/search_api/app.py</code> <pre><code>def search(req: SearchRequest, _: AuthDependency = None) -&gt; SearchResponse:\n    \"\"\"Execute hybrid search query.\n\n    Combines dense (FAISS), sparse (BM25/SPLADE), and knowledge graph signals\n    using Reciprocal Rank Fusion and KG boosts. Returns ranked results with\n    structured logging and metrics.\n\n    Parameters\n    ----------\n    req : SearchRequest\n        Search request containing query text, k (number of results), and\n        optional facets for filtering.\n    _ : AuthDependency, optional\n        Authentication dependency (Bearer token). Injected by FastAPI.\n        Defaults to None (handled by FastAPI dependency injection).\n\n    Returns\n    -------\n    SearchResponse\n        Search results with metadata and performance metrics. Results are\n        ranked by combined relevance scores from all search channels.\n\n    Raises\n    ------\n    VectorSearchError\n        Returns Problem Details JSON (RFC 9457) on errors such as missing\n        indexes, invalid queries, or backend failures.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from search_api.schemas import SearchRequest\n    &gt;&gt;&gt; from search_api.app import search\n    &gt;&gt;&gt; req = SearchRequest(query=\"vector store\", k=5)\n    &gt;&gt;&gt; response = search(req, None)\n    &gt;&gt;&gt; len(response.results) &lt;= 5\n    True\n    \"\"\"\n    # Correlation ID is set by middleware, use with_fields for structured logging\n    with (\n        with_fields(logger, operation=\"search\", query=req.query, k=req.k),\n        observe_duration(metrics, \"search\", component=\"search_api\") as obs,\n    ):\n        log_adapter = logger  # Use logger directly since with_fields provides context\n        log_adapter.info(\"Search request received\", extra={\"status\": \"started\"})\n\n        try:\n            # Retrieve from each channel\n            # We don't have a query embedder here; fallback to empty or demo vector\n            dense_hits: list[tuple[str, float]] = []\n            # sparse via BM25 (preferred) and SPLADE\n            bm25_hits: list[tuple[str, float]] = []\n            if bm25:\n                try:\n                    bm25_hits = bm25.search(req.query, k=settings.search.sparse_candidates)\n                except (RuntimeError, ValueError, AttributeError, OSError) as exc:\n                    log_adapter.warning(\n                        \"BM25 search failed, falling back to empty results: %s\",\n                        exc,\n                        extra={\"status\": \"warning\"},\n                        exc_info=True,\n                    )\n                    bm25_hits = []\n            try:\n                splade_hits = (\n                    splade.search(req.query, k=settings.search.sparse_candidates) if splade else []\n                )\n            except (RuntimeError, ValueError, AttributeError, OSError) as exc:\n                log_adapter.warning(\n                    \"SPLADE search failed, falling back to empty results: %s\",\n                    exc,\n                    extra={\"status\": \"warning\"},\n                    exc_info=True,\n                )\n                splade_hits = []\n\n            # RRF fusion\n            fused = rrf_fuse([dense_hits, bm25_hits, splade_hits], k_rrf=settings.search.rrf_k)\n            # KG boosts\n            boosted = apply_kg_boosts(\n                fused,\n                req.query,\n                direct=settings.search.kg_boosts_direct,\n                one_hop=settings.search.kg_boosts_one_hop,\n            )\n\n            # Rank and craft results\n            def sort_key(item: tuple[str, float]) -&gt; float:\n                \"\"\"Sort key function for ranking results.\n\n                Parameters\n                ----------\n                item : tuple[str, float]\n                    Result tuple containing (chunk_id, score).\n\n                Returns\n                -------\n                float\n                    Score value for sorting.\n                \"\"\"\n                return item[1]\n\n            top = sorted(boosted.items(), key=sort_key, reverse=True)[: req.k]\n            results: list[SearchResult] = []\n            for chunk_id, score in top:\n                # In real system we'd hydrate title/section via DuckDB; here we echo ids\n                results.append(\n                    SearchResult(\n                        doc_id=f\"doc-of-{chunk_id}\",\n                        chunk_id=chunk_id,\n                        title=f\"Title for {chunk_id}\",\n                        section=\"Methods\",\n                        score=float(score),\n                        signals={\n                            \"rrf\": float(fused.get(chunk_id, 0.0)),\n                            \"kg_boost\": float(boosted[chunk_id] - fused.get(chunk_id, 0.0)),\n                        },\n                        spans={\"start_char\": 0, \"end_char\": 50},\n                        concepts=[\n                            {\n                                \"concept_id\": c,\n                                \"label\": c,\n                                \"match\": (\"direct\" if c in req.query else \"nearby\"),\n                            }\n                            for c in kg.linked_concepts(chunk_id)\n                        ],\n                    )\n                )\n\n            log_adapter.info(\n                \"Search completed\", extra={\"status\": \"success\", \"result_count\": len(results)}\n            )\n            obs.success()\n\n            return SearchResponse(results=results)\n        except (RuntimeError, ValueError, AttributeError, OSError) as exc:\n            obs.error()\n            # Convert to VectorSearchError for proper Problem Details handling\n            error_msg = f\"Search operation failed: {exc}\"\n            # context accepts Mapping[str, object], dict[str, str | int] is compatible\n            context_dict: Mapping[str, object] = {\"query\": req.query, \"k\": req.k}\n            raise VectorSearchError(error_msg, cause=exc, context=context_dict) from exc\n</code></pre>"},{"location":"modules/search_api.bm25_index/","title":"search_api.bm25_index","text":""},{"location":"modules/search_api.bm25_index/#search_apibm25_index","title":"search_api.bm25_index","text":"<p>Toy BM25 index backed by DuckDB parquet exports.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_api.bm25_index/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class BM25Doc\n    class BM25Index\n</code></pre>"},{"location":"modules/search_api.bm25_index/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_api.bm25_index__future__.annotationscollections.abc.Iterabledataclasses.dataclassduckdbkgfoundry_common.errors.ConfigurationErrorkgfoundry_common.errors.DeserializationErrorkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.problem_details.JsonValuekgfoundry_common.safe_pickle_v2.UnsafeSerializationErrorkgfoundry_common.safe_pickle_v2.load_unsigned_legacykgfoundry_common.serialization.deserialize_jsonkgfoundry_common.serialization.serialize_jsonmathospathlib.Pathreregistry.duckdb_helpers.fetch_allregistry.duckdb_helpers.fetch_onetyping.TYPE_CHECKINGtyping.castsearch_apisearch_api.bm25_index code <p>See the full diagram: search_api.bm25_index</p>"},{"location":"modules/search_api.bm25_index/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>search_api.bm25_index.BM25Doc</li> <li>search_api.bm25_index.BM25Index</li> <li>search_api.bm25_index._as_str</li> <li>search_api.bm25_index._validate_parquet_path</li> <li>search_api.bm25_index.toks</li> </ul>"},{"location":"modules/search_api.bm25_index/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Iterable</code>, <code>dataclasses.dataclass</code>, <code>duckdb</code>, <code>kgfoundry_common.errors.ConfigurationError</code>, <code>kgfoundry_common.errors.DeserializationError</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.problem_details.JsonValue</code>, <code>kgfoundry_common.safe_pickle_v2.UnsafeSerializationError</code>, <code>kgfoundry_common.safe_pickle_v2.load_unsigned_legacy</code>, <code>kgfoundry_common.serialization.deserialize_json</code>, <code>kgfoundry_common.serialization.serialize_json</code>, <code>math</code>, <code>os</code>, <code>pathlib.Path</code>, <code>re</code>, <code>registry.duckdb_helpers.fetch_all</code>, <code>registry.duckdb_helpers.fetch_one</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p> <p>Imported by: search_api</p>"},{"location":"modules/search_api.bm25_index/#contents","title":"Contents","text":""},{"location":"modules/search_api.bm25_index/#search_apibm25_indexbm25doc","title":"search_api.bm25_index.BM25Doc","text":""},{"location":"modules/search_api.bm25_index/#search_api.bm25_index.BM25Doc","title":"<code>search_api.bm25_index.BM25Doc</code>  <code>dataclass</code>","text":"<p>Document representation for BM25 indexing and retrieval.</p> <p>Stores term frequency statistics and document metadata for a single document chunk. Used by :class:<code>BM25Index</code> to compute BM25 relevance scores during search.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_id</code> <code>str</code> <p>Unique identifier for this document chunk.</p> required <code>doc_id</code> <code>str</code> <p>Parent document identifier that this chunk belongs to.</p> required <code>title</code> <code>str</code> <p>Document title (used for weighted term frequency in indexing).</p> required <code>section</code> <code>str</code> <p>Section name or heading where this chunk appears.</p> required <code>tf</code> <code>dict[str, float]</code> <p>Term frequency dictionary mapping token strings to their frequencies in this chunk. Title terms have weight 2.0, section terms 1.2, body terms 1.0.</p> required <code>dl</code> <code>float</code> <p>Document length (sum of all term frequencies in this chunk).</p> required See Also <p>BM25Index : BM25 index using these document representations.</p> Source code in <code>src/search_api/bm25_index.py</code> <pre><code>@dataclass\nclass BM25Doc:\n    \"\"\"Document representation for BM25 indexing and retrieval.\n\n    Stores term frequency statistics and document metadata for a single\n    document chunk. Used by :class:`BM25Index` to compute BM25 relevance scores\n    during search.\n\n    Parameters\n    ----------\n    chunk_id : str\n        Unique identifier for this document chunk.\n    doc_id : str\n        Parent document identifier that this chunk belongs to.\n    title : str\n        Document title (used for weighted term frequency in indexing).\n    section : str\n        Section name or heading where this chunk appears.\n    tf : dict[str, float]\n        Term frequency dictionary mapping token strings to their frequencies\n        in this chunk. Title terms have weight 2.0, section terms 1.2, body\n        terms 1.0.\n    dl : float\n        Document length (sum of all term frequencies in this chunk).\n\n    See Also\n    --------\n    BM25Index : BM25 index using these document representations.\n    \"\"\"\n\n    chunk_id: str\n    doc_id: str\n    title: str\n    section: str\n    tf: dict[str, float]\n    dl: float\n</code></pre>"},{"location":"modules/search_api.bm25_index/#search_apibm25_indexbm25index","title":"search_api.bm25_index.BM25Index","text":""},{"location":"modules/search_api.bm25_index/#search_api.bm25_index.BM25Index","title":"<code>search_api.bm25_index.BM25Index</code>","text":"<p>BM25 ranking function implementation for text search.</p> <p>Implements the Best Matching 25 (BM25) ranking algorithm for document retrieval. BM25 computes relevance scores based on term frequency (TF), inverse document frequency (IDF), and document length normalization.</p> <p>Parameters:</p> Name Type Description Default <code>k1</code> <code>float</code> <p>Term frequency saturation parameter. Controls how quickly term frequency saturates. Higher values allow more influence from repeated terms. Defaults to 0.9.</p> <code>0.9</code> <code>b</code> <code>float</code> <p>Document length normalization parameter. Controls the degree of length normalization. Values closer to 1.0 normalize more aggressively. Defaults to 0.4.</p> <code>0.4</code> <p>Attributes:</p> Name Type Description <code>k1</code> <code>float</code> <p>Term frequency saturation parameter.</p> <code>b</code> <code>float</code> <p>Document length normalization parameter.</p> <code>docs</code> <code>list[BM25Doc]</code> <p>List of indexed documents.</p> <code>df</code> <code>dict[str, int]</code> <p>Document frequency dictionary mapping tokens to the number of documents containing them.</p> <code>N</code> <code>int</code> <p>Total number of documents in the index.</p> <code>avgdl</code> <code>float</code> <p>Average document length across all documents.</p> Notes <p>BM25 scoring formula: :math:<code>score(D, Q) = \\sum_{t \\in Q} IDF(t) \\cdot \\frac{TF(t, D) \\cdot (k1 + 1)}{TF(t, D) + k1 \\cdot (1 - b + b \\cdot \\frac{|D|}{avgdl})}</code></p> <p>Where: - :math:<code>TF(t, D)</code> is the term frequency of term :math:<code>t</code> in document :math:<code>D</code> - :math:<code>IDF(t)</code> is the inverse document frequency of term :math:<code>t</code> - :math:<code>|D|</code> is the document length - :math:<code>avgdl</code> is the average document length</p> See Also <p>BM25Doc : Document representation used by this index. toks : Tokenization function used for indexing and queries.</p> Source code in <code>src/search_api/bm25_index.py</code> <pre><code>class BM25Index:\n    r\"\"\"BM25 ranking function implementation for text search.\n\n    Implements the Best Matching 25 (BM25) ranking algorithm for document\n    retrieval. BM25 computes relevance scores based on term frequency (TF),\n    inverse document frequency (IDF), and document length normalization.\n\n    Parameters\n    ----------\n    k1 : float, optional\n        Term frequency saturation parameter. Controls how quickly term frequency\n        saturates. Higher values allow more influence from repeated terms.\n        Defaults to 0.9.\n    b : float, optional\n        Document length normalization parameter. Controls the degree of length\n        normalization. Values closer to 1.0 normalize more aggressively.\n        Defaults to 0.4.\n\n    Attributes\n    ----------\n    k1 : float\n        Term frequency saturation parameter.\n    b : float\n        Document length normalization parameter.\n    docs : list[BM25Doc]\n        List of indexed documents.\n    df : dict[str, int]\n        Document frequency dictionary mapping tokens to the number of\n        documents containing them.\n    N : int\n        Total number of documents in the index.\n    avgdl : float\n        Average document length across all documents.\n\n    Notes\n    -----\n    BM25 scoring formula:\n    :math:`score(D, Q) = \\sum_{t \\in Q} IDF(t) \\cdot \\frac{TF(t, D) \\cdot (k1 + 1)}{TF(t, D) + k1 \\cdot (1 - b + b \\cdot \\frac{|D|}{avgdl})}`\n\n    Where:\n    - :math:`TF(t, D)` is the term frequency of term :math:`t` in document :math:`D`\n    - :math:`IDF(t)` is the inverse document frequency of term :math:`t`\n    - :math:`|D|` is the document length\n    - :math:`avgdl` is the average document length\n\n    See Also\n    --------\n    BM25Doc : Document representation used by this index.\n    toks : Tokenization function used for indexing and queries.\n    \"\"\"\n\n    def __init__(self, k1: float = 0.9, b: float = 0.4) -&gt; None:\n        \"\"\"Initialize BM25 index with scoring parameters.\n\n        Parameters\n        ----------\n        k1 : float, optional\n            Term frequency saturation parameter. Defaults to 0.9.\n        b : float, optional\n            Document length normalization parameter. Defaults to 0.4.\n        \"\"\"\n        self.k1 = k1\n        self.b = b\n        self.docs: list[BM25Doc] = []\n        self.df: dict[str, int] = {}\n        self.N = 0\n        self.avgdl = 0.0\n\n    @classmethod\n    def build_from_duckdb(cls, db_path: str) -&gt; BM25Index:\n        \"\"\"Build BM25 index from DuckDB database.\n\n        Queries a DuckDB database for the most recent chunks dataset and\n        builds a BM25 index from the parquet files. Reads chunk text, document\n        titles, and sections, then computes term frequencies and document\n        frequencies.\n\n        Parameters\n        ----------\n        db_path : str\n            Path to DuckDB database file containing datasets and documents tables.\n\n        Returns\n        -------\n        BM25Index\n            Initialized BM25 index with documents loaded from DuckDB.\n\n        Raises\n        ------\n        TypeError\n            If parquet_root value in the database is not a string.\n\n        Notes\n        -----\n        The method queries for the most recent chunks dataset ordered by\n        created_at. If no dataset is found, returns an empty index. Path\n        validation prevents path traversal attacks by ensuring resolved paths\n        are within allowed directories. Errors raised by\n        :func:`_validate_parquet_path` propagate unchanged.\n        \"\"\"\n        index = cls()\n        con = duckdb.connect(db_path)\n        try:\n            dataset = fetch_one(\n                con,\n                \"SELECT parquet_root FROM datasets \"\n                \"WHERE kind='chunks' ORDER BY created_at DESC LIMIT 1\",\n            )\n            if dataset is None:\n                return index\n            root_obj = dataset[0]\n            if not isinstance(root_obj, str):\n                msg = f\"Invalid parquet_root type: {type(root_obj)}\"\n                raise TypeError(msg)\n            # Validate and resolve path to prevent path traversal\n            # For pattern matching, we validate the root directory exists\n            root_path = _validate_parquet_path(root_obj, must_exist=True)\n            parquet_pattern = str(root_path / \"*\" / \"*.parquet\")\n            sql = \"\"\"\n                SELECT c.chunk_id, c.doc_id, coalesce(c.section,''), c.text, coalesce(d.title,'')\n                FROM read_parquet(?, union_by_name=true) AS c\n                LEFT JOIN documents d ON c.doc_id = d.doc_id\n            \"\"\"\n            raw_rows = fetch_all(con, sql, [parquet_pattern])\n            typed_rows: list[tuple[str, str, str, str, str]] = [\n                (\n                    _as_str(chunk_id_val),\n                    _as_str(doc_id_val),\n                    _as_str(section_val),\n                    _as_str(text_val),\n                    _as_str(title_val),\n                )\n                for chunk_id_val, doc_id_val, section_val, text_val, title_val in raw_rows\n            ]\n        finally:\n            con.close()\n        index._build(typed_rows)\n        return index\n\n    def _build(self, rows: Iterable[tuple[str, str, str, str, str]]) -&gt; None:\n        \"\"\"Build index from document rows.\n\n        Processes an iterable of document rows, tokenizes text fields, computes\n        term frequencies with weighted scoring (title 2.0, section 1.2, body\n        1.0), and updates document frequency statistics.\n\n        Parameters\n        ----------\n        rows : Iterable[tuple[str, str, str, str, str]]\n            Iterable of tuples containing (chunk_id, doc_id, section, body, title).\n            Each tuple represents one document chunk to index.\n\n        Notes\n        -----\n        This method clears existing index state before building. Term frequencies\n        are computed separately for title, section, and body fields with different\n        weights. The average document length (avgdl) is computed after processing\n        all rows.\n        \"\"\"\n        self.docs.clear()\n        self.df.clear()\n        dl_sum = 0.0\n        for chunk_id, doc_id, section, body, title in rows:\n            tf: dict[str, float] = {}\n            for term in toks(body or \"\"):\n                tf[term] = tf.get(term, 0.0) + 1.0\n            for term in toks(title or \"\"):\n                tf[term] = tf.get(term, 0.0) + 2.0\n            for term in toks(section or \"\"):\n                tf[term] = tf.get(term, 0.0) + 1.2\n            dl = sum(tf.values())\n            self.docs.append(\n                BM25Doc(\n                    chunk_id=chunk_id,\n                    doc_id=doc_id or \"urn:doc:fixture\",\n                    title=title or \"Fixture\",\n                    section=section or \"\",\n                    tf=tf,\n                    dl=dl,\n                )\n            )\n            dl_sum += dl\n            for term in set(tf.keys()):\n                self.df[term] = self.df.get(term, 0) + 1\n        self.N = len(self.docs)\n        self.avgdl = (dl_sum / self.N) if self.N &gt; 0 else 0.0\n\n    @classmethod\n    def from_parquet(cls, path: str, *, k1: float = 0.9, b: float = 0.4) -&gt; BM25Index:\n        \"\"\"Build BM25 index from a single parquet file.\n\n        Creates a BM25 index by reading document chunks from a parquet file.\n        Uses DuckDB to read the parquet file and extracts chunk_id, doc_id,\n        section, and text fields for indexing.\n\n        Parameters\n        ----------\n        path : str\n            Path to parquet file containing document chunks. Must exist and be\n            within allowed directories (validated to prevent path traversal).\n        k1 : float, optional\n            Term frequency saturation parameter. Defaults to 0.9.\n        b : float, optional\n            Document length normalization parameter. Defaults to 0.4.\n\n        Returns\n        -------\n        BM25Index\n            Initialized BM25 index with documents loaded from parquet file.\n\n        Notes\n        -----\n        Path validation prevents path traversal attacks. The method uses an\n        in-memory DuckDB connection to read the parquet file. Title fields are\n        not included from parquet (defaults to empty string). Errors raised by\n        :func:`_validate_parquet_path` propagate unchanged.\n        \"\"\"\n        index = cls(k1=k1, b=b)\n        con = duckdb.connect(database=\":memory:\")\n        try:\n            # Validate and resolve path to prevent path traversal\n            resolved_path = _validate_parquet_path(path)\n            sql = \"\"\"\n                SELECT chunk_id,\n                       coalesce(doc_id, chunk_id) AS doc_id,\n                       coalesce(section,'') AS section,\n                       text,\n                       '' AS title\n                FROM read_parquet(?, union_by_name=true)\n            \"\"\"\n            rows = fetch_all(con, sql, [str(resolved_path)])\n            typed_rows: list[tuple[str, str, str, str, str]] = [\n                (\n                    _as_str(chunk_id_val),\n                    _as_str(doc_id_val),\n                    _as_str(section_val),\n                    _as_str(text_val),\n                    \"\",\n                )\n                for chunk_id_val, doc_id_val, section_val, text_val, *_ in rows\n            ]\n        finally:\n            con.close()\n        index._build(typed_rows)\n        return index\n\n    def save(self, path: str) -&gt; None:\n        \"\"\"Save BM25 index metadata to JSON with schema validation and checksum.\n\n        Serializes index metadata (parameters, document frequencies, and document\n        list) to JSON format, validates it against the BM25 metadata schema, and\n        writes a SHA256 checksum file for integrity verification.\n\n        Parameters\n        ----------\n        path : str\n            Output file path for JSON metadata. A `.sha256` checksum file will\n            be written alongside it.\n\n        Notes\n        -----\n        The serialized payload includes: k1, b, N (document count), avgdl (average\n        document length), df (document frequency dictionary), and docs (list of\n        BM25Doc data dictionaries). Exceptions raised by :func:`serialize_json`\n        propagate unchanged.\n\n        Examples\n        --------\n        &gt;&gt;&gt; index = BM25Index(k1=0.9, b=0.4)\n        &gt;&gt;&gt; index.N = 100\n        &gt;&gt;&gt; index.save(\"/tmp/index.json\")\n        \"\"\"\n        path_obj = Path(path)\n        schema_path = (\n            Path(__file__).parent.parent.parent / \"schema\" / \"models\" / \"bm25_metadata.v1.json\"\n        )\n        # Convert docs to JSON-serializable format\n        docs_data = [\n            {\n                \"chunk_id\": doc.chunk_id,\n                \"doc_id\": doc.doc_id,\n                \"title\": doc.title,\n                \"section\": doc.section,\n                \"tf\": doc.tf,\n                \"dl\": doc.dl,\n            }\n            for doc in self.docs\n        ]\n        payload = {\n            \"k1\": self.k1,\n            \"b\": self.b,\n            \"N\": self.N,\n            \"avgdl\": self.avgdl,\n            \"df\": self.df,\n            \"docs\": docs_data,\n        }\n        serialize_json(payload, schema_path, path_obj)\n\n    @classmethod\n    def load(cls, path: str) -&gt; BM25Index:\n        \"\"\"Load BM25 index metadata from JSON with schema validation and checksum verification.\n\n        Deserializes index metadata from JSON, verifies the SHA256 checksum (if\n        present), validates against the BM25 metadata schema, and reconstructs\n        the index instance. Supports legacy pickle format as fallback.\n\n        Parameters\n        ----------\n        path : str\n            Path to JSON metadata file. A `.sha256` checksum file will be\n            verified if present.\n\n        Returns\n        -------\n        BM25Index\n            Reconstructed BM25 index instance with all metadata loaded.\n\n        Notes\n        -----\n        The method attempts to load from JSON first. If the file has a `.pkl`\n        extension and JSON loading fails, it falls back to legacy pickle format\n        (with validation). All document frequencies, term frequencies, and\n        document metadata are reconstructed from the payload. Exceptions raised\n        by :func:`deserialize_json` or legacy payload loaders propagate\n        unchanged.\n\n        Examples\n        --------\n        &gt;&gt;&gt; index = BM25Index.load(\"/tmp/index.json\")\n        &gt;&gt;&gt; assert index.N &gt; 0\n        \"\"\"\n        path_obj = Path(path)\n        schema_path = (\n            Path(__file__).parent.parent.parent / \"schema\" / \"models\" / \"bm25_metadata.v1.json\"\n        )\n        payload = cls._load_payload(path_obj, schema_path)\n        return cls._index_from_payload(payload)\n\n    @staticmethod\n    def _coerce_payload(raw: object) -&gt; dict[str, JsonValue]:\n        if not isinstance(raw, dict):\n            return {}\n        return cast(\"dict[str, JsonValue]\", raw)\n\n    @classmethod\n    def _load_payload(cls, metadata_path: Path, schema_path: Path) -&gt; dict[str, JsonValue]:\n        try:\n            return cls._coerce_payload(deserialize_json(metadata_path, schema_path))\n        except DeserializationError:\n            if metadata_path.suffix != \".pkl\":\n                raise\n            return cls._load_legacy_payload(metadata_path)\n\n    @classmethod\n    def _load_legacy_payload(cls, metadata_path: Path) -&gt; dict[str, JsonValue]:\n        with metadata_path.open(\"rb\") as handle:\n            try:\n                legacy_payload_raw: object = load_unsigned_legacy(handle)\n            except UnsafeSerializationError as legacy_exc:\n                message = f\"Legacy BM25 pickle failed validation: {legacy_exc}\"\n                raise DeserializationError(message) from legacy_exc\n        return cls._coerce_payload(legacy_payload_raw)\n\n    @classmethod\n    def _index_from_payload(cls, payload: dict[str, JsonValue]) -&gt; BM25Index:\n        k1_val = payload.get(\"k1\", 0.9)\n        b_val = payload.get(\"b\", 0.4)\n        index = cls(\n            k1=float(k1_val) if isinstance(k1_val, (int, float)) else 0.9,\n            b=float(b_val) if isinstance(b_val, (int, float)) else 0.4,\n        )\n        n_val = payload.get(\"N\", 0)\n        avgdl_val = payload.get(\"avgdl\", 0.0)\n        index.N = int(n_val) if isinstance(n_val, (int, float)) else 0\n        index.avgdl = float(avgdl_val) if isinstance(avgdl_val, (int, float)) else 0.0\n\n        df_val = payload.get(\"df\", {})\n        index.df = (\n            {k: int(v) if isinstance(v, (int, float)) else 0 for k, v in df_val.items()}\n            if isinstance(df_val, dict)\n            else {}\n        )\n\n        index.docs = cls._docs_from_payload(payload.get(\"docs\", []))\n        return index\n\n    @staticmethod\n    def _docs_from_payload(raw_docs: object) -&gt; list[BM25Doc]:\n        if not isinstance(raw_docs, list):\n            return []\n\n        docs: list[BM25Doc] = []\n        for entry in raw_docs:\n            if not isinstance(entry, dict):\n                continue\n            chunk_id = entry.get(\"chunk_id\", \"\")\n            doc_id = entry.get(\"doc_id\", \"\")\n            title = entry.get(\"title\", \"\")\n            section = entry.get(\"section\", \"\")\n            tf_value: object = entry.get(\"tf\", {})\n            doc_length = entry.get(\"dl\", 0.0)\n            docs.append(\n                BM25Doc(\n                    chunk_id=str(chunk_id) if isinstance(chunk_id, str) else \"\",\n                    doc_id=str(doc_id) if isinstance(doc_id, str) else \"\",\n                    title=str(title) if isinstance(title, str) else \"\",\n                    section=str(section) if isinstance(section, str) else \"\",\n                    tf=(cast(\"dict[str, float]\", tf_value) if isinstance(tf_value, dict) else {}),\n                    dl=(float(doc_length) if isinstance(doc_length, (int, float)) else 0.0),\n                )\n            )\n        return docs\n\n    def _idf(self, term: str) -&gt; float:\n        \"\"\"Compute inverse document frequency (IDF) for a term.\n\n        Calculates IDF using the formula: log((N - df + 0.5) / (df + 0.5) + 1.0)\n        where N is the total number of documents and df is the document frequency.\n\n        Parameters\n        ----------\n        term : str\n            Token string to compute IDF for.\n\n        Returns\n        -------\n        float\n            IDF score for the term. Returns 0.0 if term is not in any document\n            or if the index is empty.\n\n        Notes\n        -----\n        Uses the standard BM25 IDF formula with smoothing to avoid division by\n        zero. The 0.5 smoothing factor prevents negative IDF values for terms\n        appearing in all documents.\n        \"\"\"\n        df = self.df.get(term, 0)\n        if self.N == 0 or df == 0:\n            return 0.0\n        return math.log((self.N - df + 0.5) / (df + 0.5) + 1.0)\n\n    def search(self, query: str, k: int = 10) -&gt; list[tuple[str, float]]:\n        \"\"\"Search index and return top-k results ranked by BM25 score.\n\n        Tokenizes the query, computes BM25 relevance scores for all documents,\n        and returns the top-k results sorted by score in descending order.\n\n        Parameters\n        ----------\n        query : str\n            Search query string to tokenize and match against documents.\n        k : int, optional\n            Maximum number of results to return. Defaults to 10.\n\n        Returns\n        -------\n        list[tuple[str, float]]\n            List of (chunk_id, score) tuples sorted by score descending. Only\n            includes documents with score &gt; 0.0. Returns empty list if index is\n            empty or no documents match.\n\n        Notes\n        -----\n        BM25 scoring combines term frequency (TF), inverse document frequency\n        (IDF), and document length normalization. Documents with higher scores\n        are more relevant to the query.\n        \"\"\"\n        if self.N == 0:\n            return []\n        terms = toks(query)\n        scores = [0.0] * self.N\n        for i, doc in enumerate(self.docs):\n            score = 0.0\n            for term in terms:\n                tf = doc.tf.get(term, 0.0)\n                if tf &lt;= 0.0:\n                    continue\n                idf = self._idf(term)\n                denom = tf + self.k1 * (1.0 - self.b + self.b * (doc.dl / (self.avgdl or 1.0)))\n                score += idf * ((tf * (self.k1 + 1.0)) / denom)\n            scores[i] = score\n\n        # Explicitly type sorted callable to avoid Any\n        def key_func(item: tuple[int, float]) -&gt; float:\n            \"\"\"Extract score from (index, score) tuple for sorting.\n\n            Parameters\n            ----------\n            item : tuple[int, float]\n                Tuple of (index, score).\n\n            Returns\n            -------\n            float\n                Score value.\n            \"\"\"\n            return item[1]\n\n        ranked: list[tuple[int, float]] = sorted(enumerate(scores), key=key_func, reverse=True)\n        return [(self.docs[index].chunk_id, score) for index, score in ranked[:k] if score &gt; 0.0]\n\n    def doc(self, index: int) -&gt; BM25Doc:\n        \"\"\"Get document at the specified index.\n\n        Parameters\n        ----------\n        index : int\n            Zero-based index of the document to retrieve.\n\n        Returns\n        -------\n        BM25Doc\n            Document at the specified index.\n\n        Raises\n        ------\n        IndexError\n            If index is out of range (negative or &gt;= len(docs)).\n        \"\"\"\n        if index &lt; 0 or index &gt;= len(self.docs):\n            msg = f\"Document index {index} out of range for {len(self.docs)} documents\"\n            raise IndexError(msg)\n        return self.docs[index]\n</code></pre>"},{"location":"modules/search_api.bm25_index/#search_api.bm25_index.BM25Index.__init__","title":"<code>__init__(k1=0.9, b=0.4)</code>","text":"<p>Initialize BM25 index with scoring parameters.</p> <p>Parameters:</p> Name Type Description Default <code>k1</code> <code>float</code> <p>Term frequency saturation parameter. Defaults to 0.9.</p> <code>0.9</code> <code>b</code> <code>float</code> <p>Document length normalization parameter. Defaults to 0.4.</p> <code>0.4</code> Source code in <code>src/search_api/bm25_index.py</code> <pre><code>def __init__(self, k1: float = 0.9, b: float = 0.4) -&gt; None:\n    \"\"\"Initialize BM25 index with scoring parameters.\n\n    Parameters\n    ----------\n    k1 : float, optional\n        Term frequency saturation parameter. Defaults to 0.9.\n    b : float, optional\n        Document length normalization parameter. Defaults to 0.4.\n    \"\"\"\n    self.k1 = k1\n    self.b = b\n    self.docs: list[BM25Doc] = []\n    self.df: dict[str, int] = {}\n    self.N = 0\n    self.avgdl = 0.0\n</code></pre>"},{"location":"modules/search_api.bm25_index/#search_api.bm25_index.BM25Index.build_from_duckdb","title":"<code>build_from_duckdb(db_path)</code>  <code>classmethod</code>","text":"<p>Build BM25 index from DuckDB database.</p> <p>Queries a DuckDB database for the most recent chunks dataset and builds a BM25 index from the parquet files. Reads chunk text, document titles, and sections, then computes term frequencies and document frequencies.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>Path to DuckDB database file containing datasets and documents tables.</p> required <p>Returns:</p> Type Description <code>BM25Index</code> <p>Initialized BM25 index with documents loaded from DuckDB.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If parquet_root value in the database is not a string.</p> Notes <p>The method queries for the most recent chunks dataset ordered by created_at. If no dataset is found, returns an empty index. Path validation prevents path traversal attacks by ensuring resolved paths are within allowed directories. Errors raised by :func:<code>_validate_parquet_path</code> propagate unchanged.</p> Source code in <code>src/search_api/bm25_index.py</code> <pre><code>@classmethod\ndef build_from_duckdb(cls, db_path: str) -&gt; BM25Index:\n    \"\"\"Build BM25 index from DuckDB database.\n\n    Queries a DuckDB database for the most recent chunks dataset and\n    builds a BM25 index from the parquet files. Reads chunk text, document\n    titles, and sections, then computes term frequencies and document\n    frequencies.\n\n    Parameters\n    ----------\n    db_path : str\n        Path to DuckDB database file containing datasets and documents tables.\n\n    Returns\n    -------\n    BM25Index\n        Initialized BM25 index with documents loaded from DuckDB.\n\n    Raises\n    ------\n    TypeError\n        If parquet_root value in the database is not a string.\n\n    Notes\n    -----\n    The method queries for the most recent chunks dataset ordered by\n    created_at. If no dataset is found, returns an empty index. Path\n    validation prevents path traversal attacks by ensuring resolved paths\n    are within allowed directories. Errors raised by\n    :func:`_validate_parquet_path` propagate unchanged.\n    \"\"\"\n    index = cls()\n    con = duckdb.connect(db_path)\n    try:\n        dataset = fetch_one(\n            con,\n            \"SELECT parquet_root FROM datasets \"\n            \"WHERE kind='chunks' ORDER BY created_at DESC LIMIT 1\",\n        )\n        if dataset is None:\n            return index\n        root_obj = dataset[0]\n        if not isinstance(root_obj, str):\n            msg = f\"Invalid parquet_root type: {type(root_obj)}\"\n            raise TypeError(msg)\n        # Validate and resolve path to prevent path traversal\n        # For pattern matching, we validate the root directory exists\n        root_path = _validate_parquet_path(root_obj, must_exist=True)\n        parquet_pattern = str(root_path / \"*\" / \"*.parquet\")\n        sql = \"\"\"\n            SELECT c.chunk_id, c.doc_id, coalesce(c.section,''), c.text, coalesce(d.title,'')\n            FROM read_parquet(?, union_by_name=true) AS c\n            LEFT JOIN documents d ON c.doc_id = d.doc_id\n        \"\"\"\n        raw_rows = fetch_all(con, sql, [parquet_pattern])\n        typed_rows: list[tuple[str, str, str, str, str]] = [\n            (\n                _as_str(chunk_id_val),\n                _as_str(doc_id_val),\n                _as_str(section_val),\n                _as_str(text_val),\n                _as_str(title_val),\n            )\n            for chunk_id_val, doc_id_val, section_val, text_val, title_val in raw_rows\n        ]\n    finally:\n        con.close()\n    index._build(typed_rows)\n    return index\n</code></pre>"},{"location":"modules/search_api.bm25_index/#search_api.bm25_index.BM25Index.doc","title":"<code>doc(index)</code>","text":"<p>Get document at the specified index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Zero-based index of the document to retrieve.</p> required <p>Returns:</p> Type Description <code>BM25Doc</code> <p>Document at the specified index.</p> <p>Raises:</p> Type Description <code>IndexError</code> <p>If index is out of range (negative or &gt;= len(docs)).</p> Source code in <code>src/search_api/bm25_index.py</code> <pre><code>def doc(self, index: int) -&gt; BM25Doc:\n    \"\"\"Get document at the specified index.\n\n    Parameters\n    ----------\n    index : int\n        Zero-based index of the document to retrieve.\n\n    Returns\n    -------\n    BM25Doc\n        Document at the specified index.\n\n    Raises\n    ------\n    IndexError\n        If index is out of range (negative or &gt;= len(docs)).\n    \"\"\"\n    if index &lt; 0 or index &gt;= len(self.docs):\n        msg = f\"Document index {index} out of range for {len(self.docs)} documents\"\n        raise IndexError(msg)\n    return self.docs[index]\n</code></pre>"},{"location":"modules/search_api.bm25_index/#search_api.bm25_index.BM25Index.from_parquet","title":"<code>from_parquet(path, *, k1=0.9, b=0.4)</code>  <code>classmethod</code>","text":"<p>Build BM25 index from a single parquet file.</p> <p>Creates a BM25 index by reading document chunks from a parquet file. Uses DuckDB to read the parquet file and extracts chunk_id, doc_id, section, and text fields for indexing.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to parquet file containing document chunks. Must exist and be within allowed directories (validated to prevent path traversal).</p> required <code>k1</code> <code>float</code> <p>Term frequency saturation parameter. Defaults to 0.9.</p> <code>0.9</code> <code>b</code> <code>float</code> <p>Document length normalization parameter. Defaults to 0.4.</p> <code>0.4</code> <p>Returns:</p> Type Description <code>BM25Index</code> <p>Initialized BM25 index with documents loaded from parquet file.</p> Notes <p>Path validation prevents path traversal attacks. The method uses an in-memory DuckDB connection to read the parquet file. Title fields are not included from parquet (defaults to empty string). Errors raised by :func:<code>_validate_parquet_path</code> propagate unchanged.</p> Source code in <code>src/search_api/bm25_index.py</code> <pre><code>@classmethod\ndef from_parquet(cls, path: str, *, k1: float = 0.9, b: float = 0.4) -&gt; BM25Index:\n    \"\"\"Build BM25 index from a single parquet file.\n\n    Creates a BM25 index by reading document chunks from a parquet file.\n    Uses DuckDB to read the parquet file and extracts chunk_id, doc_id,\n    section, and text fields for indexing.\n\n    Parameters\n    ----------\n    path : str\n        Path to parquet file containing document chunks. Must exist and be\n        within allowed directories (validated to prevent path traversal).\n    k1 : float, optional\n        Term frequency saturation parameter. Defaults to 0.9.\n    b : float, optional\n        Document length normalization parameter. Defaults to 0.4.\n\n    Returns\n    -------\n    BM25Index\n        Initialized BM25 index with documents loaded from parquet file.\n\n    Notes\n    -----\n    Path validation prevents path traversal attacks. The method uses an\n    in-memory DuckDB connection to read the parquet file. Title fields are\n    not included from parquet (defaults to empty string). Errors raised by\n    :func:`_validate_parquet_path` propagate unchanged.\n    \"\"\"\n    index = cls(k1=k1, b=b)\n    con = duckdb.connect(database=\":memory:\")\n    try:\n        # Validate and resolve path to prevent path traversal\n        resolved_path = _validate_parquet_path(path)\n        sql = \"\"\"\n            SELECT chunk_id,\n                   coalesce(doc_id, chunk_id) AS doc_id,\n                   coalesce(section,'') AS section,\n                   text,\n                   '' AS title\n            FROM read_parquet(?, union_by_name=true)\n        \"\"\"\n        rows = fetch_all(con, sql, [str(resolved_path)])\n        typed_rows: list[tuple[str, str, str, str, str]] = [\n            (\n                _as_str(chunk_id_val),\n                _as_str(doc_id_val),\n                _as_str(section_val),\n                _as_str(text_val),\n                \"\",\n            )\n            for chunk_id_val, doc_id_val, section_val, text_val, *_ in rows\n        ]\n    finally:\n        con.close()\n    index._build(typed_rows)\n    return index\n</code></pre>"},{"location":"modules/search_api.bm25_index/#search_api.bm25_index.BM25Index.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load BM25 index metadata from JSON with schema validation and checksum verification.</p> <p>Deserializes index metadata from JSON, verifies the SHA256 checksum (if present), validates against the BM25 metadata schema, and reconstructs the index instance. Supports legacy pickle format as fallback.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to JSON metadata file. A <code>.sha256</code> checksum file will be verified if present.</p> required <p>Returns:</p> Type Description <code>BM25Index</code> <p>Reconstructed BM25 index instance with all metadata loaded.</p> Notes <p>The method attempts to load from JSON first. If the file has a <code>.pkl</code> extension and JSON loading fails, it falls back to legacy pickle format (with validation). All document frequencies, term frequencies, and document metadata are reconstructed from the payload. Exceptions raised by :func:<code>deserialize_json</code> or legacy payload loaders propagate unchanged.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; index = BM25Index.load(\"/tmp/index.json\")\n&gt;&gt;&gt; assert index.N &gt; 0\n</code></pre> Source code in <code>src/search_api/bm25_index.py</code> <pre><code>@classmethod\ndef load(cls, path: str) -&gt; BM25Index:\n    \"\"\"Load BM25 index metadata from JSON with schema validation and checksum verification.\n\n    Deserializes index metadata from JSON, verifies the SHA256 checksum (if\n    present), validates against the BM25 metadata schema, and reconstructs\n    the index instance. Supports legacy pickle format as fallback.\n\n    Parameters\n    ----------\n    path : str\n        Path to JSON metadata file. A `.sha256` checksum file will be\n        verified if present.\n\n    Returns\n    -------\n    BM25Index\n        Reconstructed BM25 index instance with all metadata loaded.\n\n    Notes\n    -----\n    The method attempts to load from JSON first. If the file has a `.pkl`\n    extension and JSON loading fails, it falls back to legacy pickle format\n    (with validation). All document frequencies, term frequencies, and\n    document metadata are reconstructed from the payload. Exceptions raised\n    by :func:`deserialize_json` or legacy payload loaders propagate\n    unchanged.\n\n    Examples\n    --------\n    &gt;&gt;&gt; index = BM25Index.load(\"/tmp/index.json\")\n    &gt;&gt;&gt; assert index.N &gt; 0\n    \"\"\"\n    path_obj = Path(path)\n    schema_path = (\n        Path(__file__).parent.parent.parent / \"schema\" / \"models\" / \"bm25_metadata.v1.json\"\n    )\n    payload = cls._load_payload(path_obj, schema_path)\n    return cls._index_from_payload(payload)\n</code></pre>"},{"location":"modules/search_api.bm25_index/#search_api.bm25_index.BM25Index.save","title":"<code>save(path)</code>","text":"<p>Save BM25 index metadata to JSON with schema validation and checksum.</p> <p>Serializes index metadata (parameters, document frequencies, and document list) to JSON format, validates it against the BM25 metadata schema, and writes a SHA256 checksum file for integrity verification.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Output file path for JSON metadata. A <code>.sha256</code> checksum file will be written alongside it.</p> required Notes <p>The serialized payload includes: k1, b, N (document count), avgdl (average document length), df (document frequency dictionary), and docs (list of BM25Doc data dictionaries). Exceptions raised by :func:<code>serialize_json</code> propagate unchanged.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; index = BM25Index(k1=0.9, b=0.4)\n&gt;&gt;&gt; index.N = 100\n&gt;&gt;&gt; index.save(\"/tmp/index.json\")\n</code></pre> Source code in <code>src/search_api/bm25_index.py</code> <pre><code>def save(self, path: str) -&gt; None:\n    \"\"\"Save BM25 index metadata to JSON with schema validation and checksum.\n\n    Serializes index metadata (parameters, document frequencies, and document\n    list) to JSON format, validates it against the BM25 metadata schema, and\n    writes a SHA256 checksum file for integrity verification.\n\n    Parameters\n    ----------\n    path : str\n        Output file path for JSON metadata. A `.sha256` checksum file will\n        be written alongside it.\n\n    Notes\n    -----\n    The serialized payload includes: k1, b, N (document count), avgdl (average\n    document length), df (document frequency dictionary), and docs (list of\n    BM25Doc data dictionaries). Exceptions raised by :func:`serialize_json`\n    propagate unchanged.\n\n    Examples\n    --------\n    &gt;&gt;&gt; index = BM25Index(k1=0.9, b=0.4)\n    &gt;&gt;&gt; index.N = 100\n    &gt;&gt;&gt; index.save(\"/tmp/index.json\")\n    \"\"\"\n    path_obj = Path(path)\n    schema_path = (\n        Path(__file__).parent.parent.parent / \"schema\" / \"models\" / \"bm25_metadata.v1.json\"\n    )\n    # Convert docs to JSON-serializable format\n    docs_data = [\n        {\n            \"chunk_id\": doc.chunk_id,\n            \"doc_id\": doc.doc_id,\n            \"title\": doc.title,\n            \"section\": doc.section,\n            \"tf\": doc.tf,\n            \"dl\": doc.dl,\n        }\n        for doc in self.docs\n    ]\n    payload = {\n        \"k1\": self.k1,\n        \"b\": self.b,\n        \"N\": self.N,\n        \"avgdl\": self.avgdl,\n        \"df\": self.df,\n        \"docs\": docs_data,\n    }\n    serialize_json(payload, schema_path, path_obj)\n</code></pre>"},{"location":"modules/search_api.bm25_index/#search_api.bm25_index.BM25Index.search","title":"<code>search(query, k=10)</code>","text":"<p>Search index and return top-k results ranked by BM25 score.</p> <p>Tokenizes the query, computes BM25 relevance scores for all documents, and returns the top-k results sorted by score in descending order.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query string to tokenize and match against documents.</p> required <code>k</code> <code>int</code> <p>Maximum number of results to return. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[tuple[str, float]]</code> <p>List of (chunk_id, score) tuples sorted by score descending. Only includes documents with score &gt; 0.0. Returns empty list if index is empty or no documents match.</p> Notes <p>BM25 scoring combines term frequency (TF), inverse document frequency (IDF), and document length normalization. Documents with higher scores are more relevant to the query.</p> Source code in <code>src/search_api/bm25_index.py</code> <pre><code>def search(self, query: str, k: int = 10) -&gt; list[tuple[str, float]]:\n    \"\"\"Search index and return top-k results ranked by BM25 score.\n\n    Tokenizes the query, computes BM25 relevance scores for all documents,\n    and returns the top-k results sorted by score in descending order.\n\n    Parameters\n    ----------\n    query : str\n        Search query string to tokenize and match against documents.\n    k : int, optional\n        Maximum number of results to return. Defaults to 10.\n\n    Returns\n    -------\n    list[tuple[str, float]]\n        List of (chunk_id, score) tuples sorted by score descending. Only\n        includes documents with score &gt; 0.0. Returns empty list if index is\n        empty or no documents match.\n\n    Notes\n    -----\n    BM25 scoring combines term frequency (TF), inverse document frequency\n    (IDF), and document length normalization. Documents with higher scores\n    are more relevant to the query.\n    \"\"\"\n    if self.N == 0:\n        return []\n    terms = toks(query)\n    scores = [0.0] * self.N\n    for i, doc in enumerate(self.docs):\n        score = 0.0\n        for term in terms:\n            tf = doc.tf.get(term, 0.0)\n            if tf &lt;= 0.0:\n                continue\n            idf = self._idf(term)\n            denom = tf + self.k1 * (1.0 - self.b + self.b * (doc.dl / (self.avgdl or 1.0)))\n            score += idf * ((tf * (self.k1 + 1.0)) / denom)\n        scores[i] = score\n\n    # Explicitly type sorted callable to avoid Any\n    def key_func(item: tuple[int, float]) -&gt; float:\n        \"\"\"Extract score from (index, score) tuple for sorting.\n\n        Parameters\n        ----------\n        item : tuple[int, float]\n            Tuple of (index, score).\n\n        Returns\n        -------\n        float\n            Score value.\n        \"\"\"\n        return item[1]\n\n    ranked: list[tuple[int, float]] = sorted(enumerate(scores), key=key_func, reverse=True)\n    return [(self.docs[index].chunk_id, score) for index, score in ranked[:k] if score &gt; 0.0]\n</code></pre>"},{"location":"modules/search_api.bm25_index/#search_apibm25_index_as_str","title":"search_api.bm25_index._as_str","text":""},{"location":"modules/search_api.bm25_index/#search_api.bm25_index._as_str","title":"<code>search_api.bm25_index._as_str(value)</code>","text":"Source code in <code>src/search_api/bm25_index.py</code> <pre><code>def _as_str(value: object) -&gt; str:\n    if isinstance(value, str):\n        return value\n    if value is None:\n        return \"\"\n    return str(value)\n</code></pre>"},{"location":"modules/search_api.bm25_index/#search_apibm25_index_validate_parquet_path","title":"search_api.bm25_index._validate_parquet_path","text":""},{"location":"modules/search_api.bm25_index/#search_api.bm25_index._validate_parquet_path","title":"<code>search_api.bm25_index._validate_parquet_path(path, *, allowed_roots=None, must_exist=True)</code>","text":"<p>Validate and resolve parquet path against allowlist to prevent path traversal.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to validate (may be relative or absolute).</p> required <code>allowed_roots</code> <code>list[Path] | None</code> <p>List of allowed root directories. If None, uses environment variable PARQUET_ROOT or default /data/parquet.</p> <code>None</code> <code>must_exist</code> <code>bool</code> <p>If True, require path to exist. If False, only validate it's within allowed directory. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Path</code> <p>Resolved absolute path that is within an allowed directory.</p> <p>Raises:</p> Type Description <code>ConfigurationError</code> <p>If path resolves outside allowed directories or contains invalid characters.</p> <code>ValueError</code> <p>If path cannot be resolved or (when must_exist=True) is not accessible.</p> Notes <p>This function prevents path traversal attacks by: 1. Resolving paths to absolute paths using Path.resolve() 2. Checking resolved path is within allowed root directories 3. Validating path exists and is accessible (when must_exist=True) 4. Rejecting paths with unsafe patterns (.., symlinks outside allowed roots)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; _validate_parquet_path(\"/data/parquet/chunks\", allowed_roots=[Path(\"/data/parquet\")])\nPath('/data/parquet/chunks')\n</code></pre> <pre><code>&gt;&gt;&gt; _validate_parquet_path(\"../../../etc/passwd\", allowed_roots=[Path(\"/data/parquet\")])\nTraceback (most recent call last):\n    ...\nConfigurationError: Path resolves outside allowed directories\n</code></pre> Source code in <code>src/search_api/bm25_index.py</code> <pre><code>def _validate_parquet_path(\n    path: str | Path,\n    *,\n    allowed_roots: list[Path] | None = None,\n    must_exist: bool = True,\n) -&gt; Path:\n    \"\"\"Validate and resolve parquet path against allowlist to prevent path traversal.\n\n    Parameters\n    ----------\n    path : str | Path\n        Path to validate (may be relative or absolute).\n    allowed_roots : list[Path] | None, optional\n        List of allowed root directories. If None, uses environment variable\n        PARQUET_ROOT or default /data/parquet.\n    must_exist : bool, optional\n        If True, require path to exist. If False, only validate it's within\n        allowed directory. Defaults to True.\n\n    Returns\n    -------\n    Path\n        Resolved absolute path that is within an allowed directory.\n\n    Raises\n    ------\n    ConfigurationError\n        If path resolves outside allowed directories or contains invalid characters.\n    ValueError\n        If path cannot be resolved or (when must_exist=True) is not accessible.\n\n    Notes\n    -----\n    This function prevents path traversal attacks by:\n    1. Resolving paths to absolute paths using Path.resolve()\n    2. Checking resolved path is within allowed root directories\n    3. Validating path exists and is accessible (when must_exist=True)\n    4. Rejecting paths with unsafe patterns (.., symlinks outside allowed roots)\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; _validate_parquet_path(\"/data/parquet/chunks\", allowed_roots=[Path(\"/data/parquet\")])\n    Path('/data/parquet/chunks')\n\n    &gt;&gt;&gt; _validate_parquet_path(\"../../../etc/passwd\", allowed_roots=[Path(\"/data/parquet\")])\n    Traceback (most recent call last):\n        ...\n    ConfigurationError: Path resolves outside allowed directories\n    \"\"\"\n    candidate = Path(path).expanduser()\n\n    # Resolve to absolute path to prevent path traversal\n    try:\n        resolved = candidate.resolve(strict=must_exist)\n    except (OSError, RuntimeError) as exc:\n        msg = f\"Invalid parquet path: {path}\"\n        raise ValueError(msg) from exc\n\n    # Determine allowed roots\n    if allowed_roots is None:\n        parquet_root_env = os.getenv(\"PARQUET_ROOT\", \"/data/parquet\")\n        allowed_roots = [Path(parquet_root_env).resolve()]\n\n    # Validate path is within allowed directory\n    is_allowed = False\n    for allowed_root in allowed_roots:\n        allowed_resolved = allowed_root.resolve()\n        try:\n            # Check if resolved path is within allowed root\n            resolved.relative_to(allowed_resolved)\n            is_allowed = True\n            break\n        except ValueError:\n            # Path is not relative to this allowed root, continue checking\n            continue\n\n    if not is_allowed:\n        allowed_str = \", \".join(str(root) for root in allowed_roots)\n        msg = (\n            f\"Path resolves outside allowed directories. \"\n            f\"Resolved: {resolved}, Allowed roots: {allowed_str}\"\n        )\n        raise ConfigurationError(msg)\n\n    # Verify path exists and is accessible (if required)\n    if must_exist and not resolved.exists():\n        msg = f\"Parquet path does not exist: {resolved}\"\n        raise ValueError(msg)\n\n    return resolved\n</code></pre>"},{"location":"modules/search_api.bm25_index/#search_apibm25_indextoks","title":"search_api.bm25_index.toks","text":""},{"location":"modules/search_api.bm25_index/#search_api.bm25_index.toks","title":"<code>search_api.bm25_index.toks(text)</code>","text":"<p>Extract tokens from text using word boundary regex.</p> <p>Tokenizes input text by finding all sequences of alphanumeric characters (using regex pattern <code>[A-Za-z0-9]+</code>) and converting them to lowercase. Used for BM25 indexing and query processing.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Input text to tokenize. May be empty or None (treated as empty).</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of lowercase tokens extracted from the text. Empty list if input is empty or contains no alphanumeric sequences.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; toks(\"Hello World 123\")\n['hello', 'world', '123']\n&gt;&gt;&gt; toks(\"\")\n[]\n</code></pre> Source code in <code>src/search_api/bm25_index.py</code> <pre><code>def toks(text: str) -&gt; list[str]:\n    \"\"\"Extract tokens from text using word boundary regex.\n\n    Tokenizes input text by finding all sequences of alphanumeric characters\n    (using regex pattern ``[A-Za-z0-9]+``) and converting them to lowercase.\n    Used for BM25 indexing and query processing.\n\n    Parameters\n    ----------\n    text : str\n        Input text to tokenize. May be empty or None (treated as empty).\n\n    Returns\n    -------\n    list[str]\n        List of lowercase tokens extracted from the text. Empty list if input\n        is empty or contains no alphanumeric sequences.\n\n    Examples\n    --------\n    &gt;&gt;&gt; toks(\"Hello World 123\")\n    ['hello', 'world', '123']\n    &gt;&gt;&gt; toks(\"\")\n    []\n    \"\"\"\n    # re.findall returns list[str] when pattern has no groups\n    matches: list[str] = TOKEN_RE.findall(text or \"\")\n    return [token.lower() for token in matches]\n</code></pre>"},{"location":"modules/search_api.faiss_adapter/","title":"search_api.faiss_adapter","text":""},{"location":"modules/search_api.faiss_adapter/#search_apifaiss_adapter","title":"search_api.faiss_adapter","text":"<p>FAISS adapter with typed GPU fallbacks and DuckDB persistence</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_api.faiss_adapter/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class DenseVecs\n    class FaissAdapter\n    class FaissAdapterConfig\n</code></pre>"},{"location":"modules/search_api.faiss_adapter/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_api.faiss_adapter__future__.annotationscollections.abc.Callablecollections.abc.Sequencedataclasses.dataclassduckdbimportlibkgfoundry_common.errors.IndexBuildErrorkgfoundry_common.errors.VectorSearchErrorkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.numpy_typing.FloatMatrixkgfoundry_common.numpy_typing.FloatVectorkgfoundry_common.numpy_typing.IntVectorkgfoundry_common.numpy_typing.normalize_l2kgfoundry_common.numpy_typing.topk_indicesloggingnumpynumpy.typingnumpy.typing.NDArraypathlib.Pathregistry.duckdb_helpers.fetch_allregistry.duckdb_helpers.fetch_onesearch_api.faiss_gpu.GpuContextsearch_api.faiss_gpu.clone_index_to_gpusearch_api.faiss_gpu.configure_search_parameterssearch_api.faiss_gpu.detect_gpu_contextsearch_api.types.FaissIndexProtocolsearch_api.types.FaissModuleProtocoltyping.ClassVartyping.Finaltyping.TYPE_CHECKINGtyping.TypeGuardtyping.castsearch_apisearch_api.faiss_adapter code <p>See the full diagram: search_api.faiss_adapter</p>"},{"location":"modules/search_api.faiss_adapter/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>search_api.faiss_adapter.DenseVecs</li> <li>search_api.faiss_adapter.FaissAdapter</li> <li>search_api.faiss_adapter.FaissAdapterConfig</li> <li>search_api.faiss_adapter._as_optional_str</li> <li>search_api.faiss_adapter._is_faiss_index</li> <li>search_api.faiss_adapter._load_faiss_module</li> </ul>"},{"location":"modules/search_api.faiss_adapter/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Callable</code>, <code>collections.abc.Sequence</code>, <code>dataclasses.dataclass</code>, <code>duckdb</code>, <code>importlib</code>, <code>kgfoundry_common.errors.IndexBuildError</code>, <code>kgfoundry_common.errors.VectorSearchError</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.numpy_typing.FloatMatrix</code>, <code>kgfoundry_common.numpy_typing.FloatVector</code>, <code>kgfoundry_common.numpy_typing.IntVector</code>, <code>kgfoundry_common.numpy_typing.normalize_l2</code>, <code>kgfoundry_common.numpy_typing.topk_indices</code>, <code>logging</code>, <code>numpy</code>, <code>numpy.typing</code>, <code>numpy.typing.NDArray</code>, <code>pathlib.Path</code>, <code>registry.duckdb_helpers.fetch_all</code>, <code>registry.duckdb_helpers.fetch_one</code>, <code>search_api.faiss_gpu.GpuContext</code>, <code>search_api.faiss_gpu.clone_index_to_gpu</code>, <code>search_api.faiss_gpu.configure_search_parameters</code>, <code>search_api.faiss_gpu.detect_gpu_context</code>, <code>search_api.types.FaissIndexProtocol</code>, <code>search_api.types.FaissModuleProtocol</code>, <code>typing.ClassVar</code>, <code>typing.Final</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.TypeGuard</code>, <code>typing.cast</code></p> <p>Imported by: search_api</p>"},{"location":"modules/search_api.faiss_adapter/#contents","title":"Contents","text":""},{"location":"modules/search_api.faiss_adapter/#search_apifaiss_adapterdensevecs","title":"search_api.faiss_adapter.DenseVecs","text":""},{"location":"modules/search_api.faiss_adapter/#search_api.faiss_adapter.DenseVecs","title":"<code>search_api.faiss_adapter.DenseVecs</code>  <code>dataclass</code>","text":"<p>Dense vector matrix and ID mapping used to seed FAISS indexes.</p> Source code in <code>src/search_api/faiss_adapter.py</code> <pre><code>@dataclass\n# [nav:anchor DenseVecs]\nclass DenseVecs:\n    \"\"\"Dense vector matrix and ID mapping used to seed FAISS indexes.\"\"\"\n\n    ids: list[str]\n    matrix: FloatMatrix\n</code></pre>"},{"location":"modules/search_api.faiss_adapter/#search_apifaiss_adapterfaissadapter","title":"search_api.faiss_adapter.FaissAdapter","text":""},{"location":"modules/search_api.faiss_adapter/#search_api.faiss_adapter.FaissAdapter","title":"<code>search_api.faiss_adapter.FaissAdapter</code>","text":"<p>Build FAISS indexes with optional GPU acceleration and CPU fallback.</p> Source code in <code>src/search_api/faiss_adapter.py</code> <pre><code>class FaissAdapter:\n    \"\"\"Build FAISS indexes with optional GPU acceleration and CPU fallback.\"\"\"\n\n    _CONFIG_FIELDS: ClassVar[set[str]] = {\n        \"factory\",\n        \"metric\",\n        \"nprobe\",\n        \"use_gpu\",\n        \"use_cuvs\",\n        \"gpu_devices\",\n    }\n\n    def __init__(\n        self,\n        db_path: str,\n        *,\n        config: FaissAdapterConfig | None = None,\n        **legacy_options: object,\n    ) -&gt; None:\n        \"\"\"Initialize FAISS adapter with database path and configuration.\n\n        Parameters\n        ----------\n        db_path : str\n            Path to DuckDB database file.\n        config : FaissAdapterConfig | None, optional\n            Configuration object. Defaults to None.\n        **legacy_options : object\n            Legacy keyword arguments for backward compatibility.\n        \"\"\"\n        self.db_path = db_path\n        resolved_config = self._resolve_config(config, legacy_options)\n        self.factory = resolved_config.factory\n        self.metric = resolved_config.metric\n        self.nprobe = resolved_config.nprobe\n        self.use_gpu = resolved_config.use_gpu\n        self.use_cuvs = resolved_config.use_cuvs\n        devices = resolved_config.gpu_devices or (0,)\n        self._gpu_devices = tuple(int(device) for device in devices)\n\n        self.index: FaissIndexProtocol | None = None\n        self.idmap: list[str] | None = None\n        self.vecs: DenseVecs | None = None\n\n        self._cpu_matrix: FloatMatrix | None = None\n        self._gpu_context: GpuContext | None = None\n\n    @property\n    def cpu_matrix(self) -&gt; FloatMatrix | None:\n        \"\"\"Return the CPU-resident vector matrix when available.\"\"\"\n        return self._cpu_matrix\n\n    @classmethod\n    def _resolve_config(\n        cls, config: FaissAdapterConfig | None, legacy_options: dict[str, object]\n    ) -&gt; FaissAdapterConfig:\n        cls._ensure_config_not_mixed(config, legacy_options)\n        if config is not None:\n            return config\n\n        cls._validate_legacy_keys(legacy_options)\n        if not legacy_options:\n            return FaissAdapterConfig()\n        return cls._config_from_legacy_options(legacy_options)\n\n    @classmethod\n    def _ensure_config_not_mixed(\n        cls, config: FaissAdapterConfig | None, legacy_options: dict[str, object]\n    ) -&gt; None:\n        if config is None or not legacy_options:\n            return\n        unexpected = \", \".join(sorted(legacy_options))\n        message = (\n            f\"FaissAdapter received both 'config' and individual keyword options: {unexpected}\"\n        )\n        raise TypeError(message)\n\n    @classmethod\n    def _validate_legacy_keys(cls, legacy_options: dict[str, object]) -&gt; None:\n        unexpected_keys = set(legacy_options) - cls._CONFIG_FIELDS\n        if not unexpected_keys:\n            return\n        unexpected = \", \".join(sorted(unexpected_keys))\n        message = f\"FaissAdapter got unexpected keyword arguments: {unexpected}\"\n        raise TypeError(message)\n\n    @classmethod\n    def _config_from_legacy_options(cls, legacy_options: dict[str, object]) -&gt; FaissAdapterConfig:\n        base = FaissAdapterConfig()\n        options = {\n            field: legacy_options[field] for field in cls._CONFIG_FIELDS if field in legacy_options\n        }\n        factory = cls._coerce_str(options.get(\"factory\", base.factory), \"factory\")\n        metric = cls._coerce_str(options.get(\"metric\", base.metric), \"metric\")\n        nprobe = cls._coerce_int(options.get(\"nprobe\", base.nprobe), \"nprobe\")\n        use_gpu = cls._coerce_bool(options.get(\"use_gpu\", base.use_gpu), \"use_gpu\")\n        use_cuvs = cls._coerce_bool(options.get(\"use_cuvs\", base.use_cuvs), \"use_cuvs\")\n        gpu_devices_option = options.get(\"gpu_devices\", base.gpu_devices)\n        gpu_devices = cls._coerce_gpu_devices(gpu_devices_option)\n        return FaissAdapterConfig(\n            factory=factory,\n            metric=metric,\n            nprobe=nprobe,\n            use_gpu=use_gpu,\n            use_cuvs=use_cuvs,\n            gpu_devices=gpu_devices,\n        )\n\n    @staticmethod\n    def _coerce_str(value: object, name: str) -&gt; str:\n        if isinstance(value, str):\n            return value\n        message = f\"{name} must be a string\"\n        raise TypeError(message)\n\n    @staticmethod\n    def _coerce_int(value: object, name: str) -&gt; int:\n        if isinstance(value, int):\n            return value\n        message = f\"{name} must be an integer\"\n        raise TypeError(message)\n\n    @staticmethod\n    def _coerce_bool(value: object, name: str) -&gt; bool:\n        if isinstance(value, bool):\n            return value\n        message = f\"{name} must be a boolean\"\n        raise TypeError(message)\n\n    @staticmethod\n    def _coerce_gpu_devices(value: object) -&gt; tuple[int, ...] | None:\n        if value is None:\n            return None\n        if not isinstance(value, Sequence):\n            message = \"gpu_devices must be a sequence of integers or None\"\n            raise TypeError(message)\n        return tuple(int(device) for device in value)\n\n    def build(self) -&gt; None:\n        \"\"\"Build or rebuild the FAISS index from persisted vectors.\n\n        Raises\n        ------\n        IndexBuildError\n            If index construction fails.\n\n        Notes\n        -----\n        Propagates :class:`VectorSearchError` when vector loading fails prior to\n        index construction.\n        \"\"\"\n        vectors = self._load_dense_vectors()\n        self.vecs = vectors\n        self.idmap = vectors.ids\n        self._cpu_matrix = vectors.matrix\n\n        module = faiss\n        if not HAVE_FAISS or module is None:\n            logger.debug(\"FAISS unavailable; CPU search fallback will be used\")\n            self.index = None\n            return\n        faiss_module: FaissModuleProtocol = module\n\n        try:\n            dimension = vectors.matrix.shape[1]\n            metric_type = self._resolve_metric(faiss_module)\n            factory = self.factory if dimension &gt;= MIN_FACTORY_DIMENSION else \"Flat\"\n\n            cpu_index = faiss_module.index_factory(dimension, factory, metric_type)\n\n            faiss_module.normalize_l2(vectors.matrix)\n            cpu_index.train(vectors.matrix)\n\n            id_array = cast(\"IntVector\", np.arange(len(vectors.ids), dtype=np.int64))\n            cpu_index.add_with_ids(vectors.matrix, id_array)\n\n            gpu_context = None\n            index: FaissIndexProtocol = cpu_index\n            if self.use_gpu:\n                gpu_context = detect_gpu_context(\n                    faiss_module,\n                    use_cuvs=self.use_cuvs,\n                    device_ids=self._gpu_devices,\n                )\n                if gpu_context is not None:\n                    index = clone_index_to_gpu(cpu_index, gpu_context)\n\n            configure_search_parameters(\n                faiss_module,\n                index,\n                nprobe=self.nprobe,\n                gpu_enabled=gpu_context is not None,\n            )\n        except Exception as exc:  # pragma: no cover - defensive\n            msg = f\"Failed to build FAISS index: {exc}\"\n            raise IndexBuildError(msg) from exc\n\n        if not _is_faiss_index(index):\n            msg = \"FAISS index failed protocol validation\"\n            raise IndexBuildError(msg)\n\n        self.index = index\n        self._gpu_context = gpu_context\n\n    def load_or_build(self, cpu_index_path: str | None = None) -&gt; None:\n        \"\"\"Load an existing CPU index or fall back to rebuilding from vectors.\n\n        Parameters\n        ----------\n        cpu_index_path : str | None, optional\n            Path to CPU index file.\n\n        Notes\n        -----\n        Propagates :class:`VectorSearchError` when index or vector loading\n        fails before a rebuild occurs.\n        \"\"\"\n        module = faiss\n        if module is None or not HAVE_FAISS:\n            self.build()\n            return\n        faiss_module: FaissModuleProtocol = module\n\n        if cpu_index_path:\n            index_path = Path(cpu_index_path)\n            if index_path.exists():\n                try:\n                    cpu_index = faiss_module.read_index(str(index_path))\n                    vectors = self._load_dense_vectors()\n                    self.vecs = vectors\n                    self.idmap = vectors.ids\n                    self._cpu_matrix = vectors.matrix\n\n                    gpu_context = None\n                    if self.use_gpu:\n                        gpu_context = detect_gpu_context(\n                            faiss_module,\n                            use_cuvs=self.use_cuvs,\n                            device_ids=self._gpu_devices,\n                        )\n                        if gpu_context is not None:\n                            cpu_index = clone_index_to_gpu(cpu_index, gpu_context)\n                except (\n                    RuntimeError,\n                    OSError,\n                    ValueError,\n                ) as exc:  # pragma: no cover - defensive fallback\n                    logger.warning(\n                        \"Failed to load FAISS index from %s: %s\", index_path, exc, exc_info=True\n                    )\n                else:\n                    configure_search_parameters(\n                        faiss_module,\n                        cpu_index,\n                        nprobe=self.nprobe,\n                        gpu_enabled=gpu_context is not None,\n                    )\n\n                    if not _is_faiss_index(cpu_index):\n                        logger.warning(\n                            \"Loaded FAISS index failed protocol validation; rebuilding\",\n                        )\n                    else:\n                        self.index = cpu_index\n                        self._gpu_context = gpu_context\n                        return\n\n        self.build()\n\n    def search(\n        self, query: Sequence[float] | NDArray[np.float32], k: int\n    ) -&gt; list[tuple[str, float]]:\n        \"\"\"Return the top ``k`` vector matches for ``query``.\n\n        Parameters\n        ----------\n        query : Sequence[float] | NDArray[np.float32]\n            Query vector.\n        k : int\n            Number of results to return.\n\n        Returns\n        -------\n        list[tuple[str, float]]\n            List of (doc_id, score) tuples sorted by score descending.\n\n        Raises\n        ------\n        ValueError\n            If k is not positive.\n        RuntimeError\n            If FAISS module is not available, index is not initialized, or ID map is missing.\n        \"\"\"\n        if k &lt;= 0:\n            msg = \"k must be positive\"\n            raise ValueError(msg)\n\n        query_array = cast(\"FloatMatrix\", np.asarray(query, dtype=np.float32).reshape(1, -1))\n        normalized_query = normalize_l2(query_array, axis=1)\n\n        module = faiss\n        if module is not None and HAVE_FAISS:\n            index_candidate = self._require_index()\n            if self.idmap is None:\n                msg = \"ID map not initialized\"\n                raise RuntimeError(msg)\n\n            distances_array, indices_array = index_candidate.search(normalized_query, k)\n            distance_row = cast(\"FloatVector\", distances_array[0])\n            index_row = cast(\"IntVector\", indices_array[0])\n            index_list = cast(\"list[int]\", index_row.tolist())\n            score_list = cast(\"list[float]\", distance_row.tolist())\n            results: list[tuple[str, float]] = []\n            for idx, score in zip(index_list, score_list, strict=False):\n                if idx &lt; 0 or idx &gt;= len(self.idmap):\n                    continue\n                results.append((self.idmap[idx], float(score)))\n            return results\n\n        normalized_vector = cast(\"FloatVector\", normalized_query[0])\n        return self._cpu_search(normalized_vector, k)\n\n    def save(self, index_uri: str, idmap_uri: str | None = None) -&gt; None:\n        \"\"\"Persist the index (when available) and ID mapping to disk.\n\n        Parameters\n        ----------\n        index_uri : str\n            Path where the FAISS index will be saved.\n        idmap_uri : str | None, optional\n            Path where the ID mapping will be saved. If None, defaults to ``{index_uri}.ids.npy``.\n\n        Raises\n        ------\n        RuntimeError\n            If no vectors have been loaded.\n        \"\"\"\n        if self.vecs is None:\n            msg = \"No vectors loaded; call build() before save().\"\n            raise RuntimeError(msg)\n\n        idmap_path = Path(idmap_uri or f\"{index_uri}.ids.npy\")\n        idmap_path.parent.mkdir(parents=True, exist_ok=True)\n        idmap_array: StrArray = np.asarray(self.vecs.ids, dtype=np.str_)\n        np.save(idmap_path, idmap_array)\n\n        module = faiss\n        if module is None or not HAVE_FAISS:\n            msg = \"FAISS module not available; cannot save index\"\n            raise RuntimeError(msg)\n\n        index_candidate = self._require_index()\n        module.write_index(index_candidate, index_uri)\n\n    # Internal helpers -------------------------------------------------------\n\n    def _require_index(self) -&gt; FaissIndexProtocol:\n        \"\"\"Return the initialized FAISS index or raise.\n\n        Returns\n        -------\n        FaissIndexProtocol\n            Initialized FAISS index.\n\n        Raises\n        ------\n        RuntimeError\n            If index is not initialized or fails protocol validation.\n        \"\"\"\n        index_candidate = self.index\n        if index_candidate is None:\n            msg = \"FAISS index not initialized\"\n            raise RuntimeError(msg)\n\n        if not _is_faiss_index(index_candidate):\n            msg = \"FAISS index failed protocol validation\"\n            raise RuntimeError(msg)\n\n        return index_candidate\n\n    def _cpu_search(self, query: FloatVector, k: int) -&gt; list[tuple[str, float]]:\n        \"\"\"Search using CPU fallback (inner product).\n\n        Parameters\n        ----------\n        query : FloatVector\n            Query vector.\n        k : int\n            Number of results to return.\n\n        Returns\n        -------\n        list[tuple[str, float]]\n            List of (doc_id, score) tuples sorted by score descending.\n        \"\"\"\n        cpu_matrix = self._cpu_matrix\n        idmap = self.idmap\n        if cpu_matrix is None or idmap is None:  # pragma: no cover - defensive fallback\n            return []\n\n        matrix: FloatMatrix = cpu_matrix\n        vector: FloatVector = query\n        scores_buffer: FloatVector = np.empty(matrix.shape[0], dtype=np.float32)\n        np.dot(matrix, vector, out=scores_buffer)\n        scores: FloatVector = scores_buffer\n        idmap_list: list[str] = idmap\n        score_list = cast(\"list[float]\", scores.tolist())\n        limit = min(k, scores.size)\n        if limit == 0:\n            return []\n\n        indices = topk_indices(scores, limit)\n        index_list = cast(\"list[int]\", indices.tolist())\n        return [\n            (idmap_list[idx], float(score_list[idx])) for idx in index_list if idx &lt; len(idmap_list)\n        ]\n\n    def _resolve_metric(self, module: FaissModuleProtocol) -&gt; int:\n        \"\"\"Resolve metric string to FAISS metric constant.\n\n        Parameters\n        ----------\n        module : FaissModuleProtocol\n            FAISS module instance.\n\n        Returns\n        -------\n        int\n            FAISS metric constant.\n\n        Raises\n        ------\n        ValueError\n            If metric is not recognized.\n        \"\"\"\n        metric = self.metric.lower()\n        if metric == \"ip\":\n            return module.metric_inner_product\n        if metric == \"l2\":\n            return module.metric_l2\n        msg = f\"Unsupported FAISS metric: {self.metric}\"\n        raise ValueError(msg)\n\n    def _load_dense_vectors(self) -&gt; DenseVecs:\n        \"\"\"Load dense vectors from DuckDB or Parquet.\n\n        Returns\n        -------\n        DenseVecs\n            Dense vectors container.\n\n        Raises\n        ------\n        VectorSearchError\n            If vectors cannot be loaded.\n        \"\"\"\n        candidate = Path(self.db_path)\n        if candidate.is_dir() or candidate.suffix == \".parquet\":\n            return self._load_from_parquet(candidate)\n\n        if not candidate.exists():\n            msg = f\"DuckDB registry not found: {candidate}\"\n            raise VectorSearchError(msg)\n\n        try:\n            con = duckdb.connect(str(candidate))\n        except duckdb.Error:\n            return self._load_from_parquet(candidate)\n\n        try:\n            record = fetch_one(\n                con,\n                \"SELECT parquet_root FROM dense_runs ORDER BY created_at DESC LIMIT 1\",\n            )\n        except duckdb.Error as exc:  # pragma: no cover - defensive fallback\n            msg = f\"Failed to query dense_runs: {exc}\"\n            raise VectorSearchError(msg) from exc\n        finally:\n            con.close()\n\n        if record is None:\n            msg = \"dense_runs table is empty\"\n            raise VectorSearchError(msg)\n\n        root_candidate = record[0]\n        if not isinstance(root_candidate, str):\n            msg = \"dense_runs table is empty or malformed\"\n            raise VectorSearchError(msg)\n\n        return self._load_from_parquet(Path(root_candidate))\n\n    @staticmethod\n    def _load_from_parquet(source: Path) -&gt; DenseVecs:\n        \"\"\"Load dense vectors from Parquet file.\n\n        Parameters\n        ----------\n        source : Path\n            Path to Parquet file or directory.\n\n        Returns\n        -------\n        DenseVecs\n            Dense vectors container.\n\n        Raises\n        ------\n        VectorSearchError\n            If Parquet file cannot be read or is empty.\n        \"\"\"\n        resolved = source.resolve()\n        if not resolved.exists():\n            msg = f\"Parquet source not found: {resolved}\"\n            raise VectorSearchError(msg)\n\n        con = duckdb.connect(database=\":memory:\")\n        try:\n            rows = fetch_all(\n                con,\n                \"SELECT chunk_id, vector FROM read_parquet(?, union_by_name=true)\",\n                [str(resolved)],\n            )\n        except duckdb.Error as exc:\n            msg = f\"Failed to load vectors from {resolved}: {exc}\"\n            raise VectorSearchError(msg) from exc\n        finally:\n            con.close()\n\n        if not rows:\n            msg = f\"No vectors discovered in {resolved}\"\n            raise VectorSearchError(msg)\n\n        ids: list[str] = []\n        vector_rows: list[FloatArray] = []\n        for chunk_id_val, vector_val in rows:\n            ids.append(_as_optional_str(chunk_id_val))\n            vector_array = np.asarray(vector_val, dtype=np.float32)\n            vector_rows.append(vector_array)\n\n        matrix: FloatMatrix = np.vstack(vector_rows).astype(np.float32, copy=False)\n        normalized = normalize_l2(matrix, axis=1)\n        return DenseVecs(ids=ids, matrix=normalized)\n</code></pre>"},{"location":"modules/search_api.faiss_adapter/#search_api.faiss_adapter.FaissAdapter.cpu_matrix","title":"<code>cpu_matrix</code>  <code>property</code>","text":"<p>Return the CPU-resident vector matrix when available.</p>"},{"location":"modules/search_api.faiss_adapter/#search_api.faiss_adapter.FaissAdapter.__init__","title":"<code>__init__(db_path, *, config=None, **legacy_options)</code>","text":"<p>Initialize FAISS adapter with database path and configuration.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>Path to DuckDB database file.</p> required <code>config</code> <code>FaissAdapterConfig | None</code> <p>Configuration object. Defaults to None.</p> <code>None</code> <code>**legacy_options</code> <code>object</code> <p>Legacy keyword arguments for backward compatibility.</p> <code>{}</code> Source code in <code>src/search_api/faiss_adapter.py</code> <pre><code>def __init__(\n    self,\n    db_path: str,\n    *,\n    config: FaissAdapterConfig | None = None,\n    **legacy_options: object,\n) -&gt; None:\n    \"\"\"Initialize FAISS adapter with database path and configuration.\n\n    Parameters\n    ----------\n    db_path : str\n        Path to DuckDB database file.\n    config : FaissAdapterConfig | None, optional\n        Configuration object. Defaults to None.\n    **legacy_options : object\n        Legacy keyword arguments for backward compatibility.\n    \"\"\"\n    self.db_path = db_path\n    resolved_config = self._resolve_config(config, legacy_options)\n    self.factory = resolved_config.factory\n    self.metric = resolved_config.metric\n    self.nprobe = resolved_config.nprobe\n    self.use_gpu = resolved_config.use_gpu\n    self.use_cuvs = resolved_config.use_cuvs\n    devices = resolved_config.gpu_devices or (0,)\n    self._gpu_devices = tuple(int(device) for device in devices)\n\n    self.index: FaissIndexProtocol | None = None\n    self.idmap: list[str] | None = None\n    self.vecs: DenseVecs | None = None\n\n    self._cpu_matrix: FloatMatrix | None = None\n    self._gpu_context: GpuContext | None = None\n</code></pre>"},{"location":"modules/search_api.faiss_adapter/#search_api.faiss_adapter.FaissAdapter.build","title":"<code>build()</code>","text":"<p>Build or rebuild the FAISS index from persisted vectors.</p> <p>Raises:</p> Type Description <code>IndexBuildError</code> <p>If index construction fails.</p> Notes <p>Propagates :class:<code>VectorSearchError</code> when vector loading fails prior to index construction.</p> Source code in <code>src/search_api/faiss_adapter.py</code> <pre><code>def build(self) -&gt; None:\n    \"\"\"Build or rebuild the FAISS index from persisted vectors.\n\n    Raises\n    ------\n    IndexBuildError\n        If index construction fails.\n\n    Notes\n    -----\n    Propagates :class:`VectorSearchError` when vector loading fails prior to\n    index construction.\n    \"\"\"\n    vectors = self._load_dense_vectors()\n    self.vecs = vectors\n    self.idmap = vectors.ids\n    self._cpu_matrix = vectors.matrix\n\n    module = faiss\n    if not HAVE_FAISS or module is None:\n        logger.debug(\"FAISS unavailable; CPU search fallback will be used\")\n        self.index = None\n        return\n    faiss_module: FaissModuleProtocol = module\n\n    try:\n        dimension = vectors.matrix.shape[1]\n        metric_type = self._resolve_metric(faiss_module)\n        factory = self.factory if dimension &gt;= MIN_FACTORY_DIMENSION else \"Flat\"\n\n        cpu_index = faiss_module.index_factory(dimension, factory, metric_type)\n\n        faiss_module.normalize_l2(vectors.matrix)\n        cpu_index.train(vectors.matrix)\n\n        id_array = cast(\"IntVector\", np.arange(len(vectors.ids), dtype=np.int64))\n        cpu_index.add_with_ids(vectors.matrix, id_array)\n\n        gpu_context = None\n        index: FaissIndexProtocol = cpu_index\n        if self.use_gpu:\n            gpu_context = detect_gpu_context(\n                faiss_module,\n                use_cuvs=self.use_cuvs,\n                device_ids=self._gpu_devices,\n            )\n            if gpu_context is not None:\n                index = clone_index_to_gpu(cpu_index, gpu_context)\n\n        configure_search_parameters(\n            faiss_module,\n            index,\n            nprobe=self.nprobe,\n            gpu_enabled=gpu_context is not None,\n        )\n    except Exception as exc:  # pragma: no cover - defensive\n        msg = f\"Failed to build FAISS index: {exc}\"\n        raise IndexBuildError(msg) from exc\n\n    if not _is_faiss_index(index):\n        msg = \"FAISS index failed protocol validation\"\n        raise IndexBuildError(msg)\n\n    self.index = index\n    self._gpu_context = gpu_context\n</code></pre>"},{"location":"modules/search_api.faiss_adapter/#search_api.faiss_adapter.FaissAdapter.load_or_build","title":"<code>load_or_build(cpu_index_path=None)</code>","text":"<p>Load an existing CPU index or fall back to rebuilding from vectors.</p> <p>Parameters:</p> Name Type Description Default <code>cpu_index_path</code> <code>str | None</code> <p>Path to CPU index file.</p> <code>None</code> Notes <p>Propagates :class:<code>VectorSearchError</code> when index or vector loading fails before a rebuild occurs.</p> Source code in <code>src/search_api/faiss_adapter.py</code> <pre><code>def load_or_build(self, cpu_index_path: str | None = None) -&gt; None:\n    \"\"\"Load an existing CPU index or fall back to rebuilding from vectors.\n\n    Parameters\n    ----------\n    cpu_index_path : str | None, optional\n        Path to CPU index file.\n\n    Notes\n    -----\n    Propagates :class:`VectorSearchError` when index or vector loading\n    fails before a rebuild occurs.\n    \"\"\"\n    module = faiss\n    if module is None or not HAVE_FAISS:\n        self.build()\n        return\n    faiss_module: FaissModuleProtocol = module\n\n    if cpu_index_path:\n        index_path = Path(cpu_index_path)\n        if index_path.exists():\n            try:\n                cpu_index = faiss_module.read_index(str(index_path))\n                vectors = self._load_dense_vectors()\n                self.vecs = vectors\n                self.idmap = vectors.ids\n                self._cpu_matrix = vectors.matrix\n\n                gpu_context = None\n                if self.use_gpu:\n                    gpu_context = detect_gpu_context(\n                        faiss_module,\n                        use_cuvs=self.use_cuvs,\n                        device_ids=self._gpu_devices,\n                    )\n                    if gpu_context is not None:\n                        cpu_index = clone_index_to_gpu(cpu_index, gpu_context)\n            except (\n                RuntimeError,\n                OSError,\n                ValueError,\n            ) as exc:  # pragma: no cover - defensive fallback\n                logger.warning(\n                    \"Failed to load FAISS index from %s: %s\", index_path, exc, exc_info=True\n                )\n            else:\n                configure_search_parameters(\n                    faiss_module,\n                    cpu_index,\n                    nprobe=self.nprobe,\n                    gpu_enabled=gpu_context is not None,\n                )\n\n                if not _is_faiss_index(cpu_index):\n                    logger.warning(\n                        \"Loaded FAISS index failed protocol validation; rebuilding\",\n                    )\n                else:\n                    self.index = cpu_index\n                    self._gpu_context = gpu_context\n                    return\n\n    self.build()\n</code></pre>"},{"location":"modules/search_api.faiss_adapter/#search_api.faiss_adapter.FaissAdapter.save","title":"<code>save(index_uri, idmap_uri=None)</code>","text":"<p>Persist the index (when available) and ID mapping to disk.</p> <p>Parameters:</p> Name Type Description Default <code>index_uri</code> <code>str</code> <p>Path where the FAISS index will be saved.</p> required <code>idmap_uri</code> <code>str | None</code> <p>Path where the ID mapping will be saved. If None, defaults to <code>{index_uri}.ids.npy</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If no vectors have been loaded.</p> Source code in <code>src/search_api/faiss_adapter.py</code> <pre><code>def save(self, index_uri: str, idmap_uri: str | None = None) -&gt; None:\n    \"\"\"Persist the index (when available) and ID mapping to disk.\n\n    Parameters\n    ----------\n    index_uri : str\n        Path where the FAISS index will be saved.\n    idmap_uri : str | None, optional\n        Path where the ID mapping will be saved. If None, defaults to ``{index_uri}.ids.npy``.\n\n    Raises\n    ------\n    RuntimeError\n        If no vectors have been loaded.\n    \"\"\"\n    if self.vecs is None:\n        msg = \"No vectors loaded; call build() before save().\"\n        raise RuntimeError(msg)\n\n    idmap_path = Path(idmap_uri or f\"{index_uri}.ids.npy\")\n    idmap_path.parent.mkdir(parents=True, exist_ok=True)\n    idmap_array: StrArray = np.asarray(self.vecs.ids, dtype=np.str_)\n    np.save(idmap_path, idmap_array)\n\n    module = faiss\n    if module is None or not HAVE_FAISS:\n        msg = \"FAISS module not available; cannot save index\"\n        raise RuntimeError(msg)\n\n    index_candidate = self._require_index()\n    module.write_index(index_candidate, index_uri)\n</code></pre>"},{"location":"modules/search_api.faiss_adapter/#search_api.faiss_adapter.FaissAdapter.search","title":"<code>search(query, k)</code>","text":"<p>Return the top <code>k</code> vector matches for <code>query</code>.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>Sequence[float] | NDArray[float32]</code> <p>Query vector.</p> required <code>k</code> <code>int</code> <p>Number of results to return.</p> required <p>Returns:</p> Type Description <code>list[tuple[str, float]]</code> <p>List of (doc_id, score) tuples sorted by score descending.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If k is not positive.</p> <code>RuntimeError</code> <p>If FAISS module is not available, index is not initialized, or ID map is missing.</p> Source code in <code>src/search_api/faiss_adapter.py</code> <pre><code>def search(\n    self, query: Sequence[float] | NDArray[np.float32], k: int\n) -&gt; list[tuple[str, float]]:\n    \"\"\"Return the top ``k`` vector matches for ``query``.\n\n    Parameters\n    ----------\n    query : Sequence[float] | NDArray[np.float32]\n        Query vector.\n    k : int\n        Number of results to return.\n\n    Returns\n    -------\n    list[tuple[str, float]]\n        List of (doc_id, score) tuples sorted by score descending.\n\n    Raises\n    ------\n    ValueError\n        If k is not positive.\n    RuntimeError\n        If FAISS module is not available, index is not initialized, or ID map is missing.\n    \"\"\"\n    if k &lt;= 0:\n        msg = \"k must be positive\"\n        raise ValueError(msg)\n\n    query_array = cast(\"FloatMatrix\", np.asarray(query, dtype=np.float32).reshape(1, -1))\n    normalized_query = normalize_l2(query_array, axis=1)\n\n    module = faiss\n    if module is not None and HAVE_FAISS:\n        index_candidate = self._require_index()\n        if self.idmap is None:\n            msg = \"ID map not initialized\"\n            raise RuntimeError(msg)\n\n        distances_array, indices_array = index_candidate.search(normalized_query, k)\n        distance_row = cast(\"FloatVector\", distances_array[0])\n        index_row = cast(\"IntVector\", indices_array[0])\n        index_list = cast(\"list[int]\", index_row.tolist())\n        score_list = cast(\"list[float]\", distance_row.tolist())\n        results: list[tuple[str, float]] = []\n        for idx, score in zip(index_list, score_list, strict=False):\n            if idx &lt; 0 or idx &gt;= len(self.idmap):\n                continue\n            results.append((self.idmap[idx], float(score)))\n        return results\n\n    normalized_vector = cast(\"FloatVector\", normalized_query[0])\n    return self._cpu_search(normalized_vector, k)\n</code></pre>"},{"location":"modules/search_api.faiss_adapter/#search_apifaiss_adapterfaissadapterconfig","title":"search_api.faiss_adapter.FaissAdapterConfig","text":""},{"location":"modules/search_api.faiss_adapter/#search_api.faiss_adapter.FaissAdapterConfig","title":"<code>search_api.faiss_adapter.FaissAdapterConfig</code>  <code>dataclass</code>","text":"<p>Configuration options for :class:<code>FaissAdapter</code>.</p> Source code in <code>src/search_api/faiss_adapter.py</code> <pre><code>@dataclass(slots=True, frozen=True)\nclass FaissAdapterConfig:\n    \"\"\"Configuration options for :class:`FaissAdapter`.\"\"\"\n\n    factory: str = \"OPQ64,IVF8192,PQ64\"\n    metric: str = \"ip\"\n    nprobe: int = 64\n    use_gpu: bool = True\n    use_cuvs: bool = True\n    gpu_devices: Sequence[int] | None = None\n</code></pre>"},{"location":"modules/search_api.faiss_adapter/#search_apifaiss_adapter_as_optional_str","title":"search_api.faiss_adapter._as_optional_str","text":""},{"location":"modules/search_api.faiss_adapter/#search_api.faiss_adapter._as_optional_str","title":"<code>search_api.faiss_adapter._as_optional_str(value)</code>","text":"Source code in <code>src/search_api/faiss_adapter.py</code> <pre><code>def _as_optional_str(value: object) -&gt; str:\n    if isinstance(value, str):\n        return value\n    if value is None:\n        return \"\"\n    return str(value)\n</code></pre>"},{"location":"modules/search_api.faiss_adapter/#search_apifaiss_adapter_is_faiss_index","title":"search_api.faiss_adapter._is_faiss_index","text":""},{"location":"modules/search_api.faiss_adapter/#search_api.faiss_adapter._is_faiss_index","title":"<code>search_api.faiss_adapter._is_faiss_index(candidate)</code>","text":"<p>Return True when <code>candidate</code> exposes the FAISS index protocol surface.</p> <p>Parameters:</p> Name Type Description Default <code>candidate</code> <code>object</code> <p>Candidate object to check.</p> required <p>Returns:</p> Type Description <code>TypeGuard[FaissIndexProtocol]</code> <p>True if candidate matches the protocol.</p> Source code in <code>src/search_api/faiss_adapter.py</code> <pre><code>def _is_faiss_index(candidate: object) -&gt; TypeGuard[FaissIndexProtocol]:\n    \"\"\"Return True when ``candidate`` exposes the FAISS index protocol surface.\n\n    Parameters\n    ----------\n    candidate : object\n        Candidate object to check.\n\n    Returns\n    -------\n    TypeGuard[FaissIndexProtocol]\n        True if candidate matches the protocol.\n    \"\"\"\n    if candidate is None:\n        return False\n\n    required_methods = (\"search\", \"add\", \"train\", \"add_with_ids\")\n    for method in required_methods:\n        attribute: object | None = getattr(candidate, method, None)\n        if attribute is None or not callable(attribute):\n            return False\n    return True\n</code></pre>"},{"location":"modules/search_api.faiss_adapter/#search_apifaiss_adapter_load_faiss_module","title":"search_api.faiss_adapter._load_faiss_module","text":""},{"location":"modules/search_api.faiss_adapter/#search_api.faiss_adapter._load_faiss_module","title":"<code>search_api.faiss_adapter._load_faiss_module()</code>","text":"Source code in <code>src/search_api/faiss_adapter.py</code> <pre><code>def _load_faiss_module() -&gt; FaissModuleProtocol | None:\n    try:  # pragma: no cover - optional dependency\n        module = importlib.import_module(\"faiss\")\n    except (\n        ImportError,\n        AttributeError,\n        OSError,\n        RuntimeError,\n    ) as exc:  # pragma: no cover - optional dependency\n        logger.debug(\"FAISS import failed: %s\", exc, exc_info=True)\n        return None\n    return cast(\"FaissModuleProtocol\", module)\n</code></pre>"},{"location":"modules/search_api.faiss_adapter/#search_apifaiss_adapter_load_libcuvs","title":"search_api.faiss_adapter._load_libcuvs","text":""},{"location":"modules/search_api.faiss_adapter/#search_api.faiss_adapter._load_libcuvs","title":"<code>search_api.faiss_adapter._load_libcuvs()</code>","text":"Source code in <code>src/search_api/faiss_adapter.py</code> <pre><code>def _load_libcuvs() -&gt; LoadLibraryFn | None:\n    module_names = (\"libcuvs\", \"libcuvs_cu13\")\n    module = None\n    for name in module_names:\n        try:\n            module = importlib.import_module(name)\n        except (ImportError, ModuleNotFoundError):  # pragma: no cover - optional dependency\n            continue\n        except (RuntimeError, OSError):  # pragma: no cover - optional dependency\n            logger.debug(\"Failed to import %s: runtime error\", name)\n            continue\n        else:\n            break\n\n    if module is None:\n        return None\n\n    if hasattr(module, \"load_library\"):\n        candidate: object = module.load_library\n        if callable(candidate):\n            return cast(\"LoadLibraryFn\", candidate)\n    return None\n</code></pre>"},{"location":"modules/search_api.faiss_gpu/","title":"search_api.faiss_gpu","text":""},{"location":"modules/search_api.faiss_gpu/#search_apifaiss_gpu","title":"search_api.faiss_gpu","text":"<p>Typed helpers for working with FAISS GPU bindings.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_api.faiss_gpu/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class GpuContext\n</code></pre>"},{"location":"modules/search_api.faiss_gpu/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_api.faiss_gpu__future__.annotationscollections.abc.Callablecollections.abc.Sequencedataclasses.dataclasskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.sequence_guards.first_or_errorkgfoundry_common.sequence_guards.first_or_error_multi_deviceloggingsearch_api.types.FaissIndexProtocolsearch_api.types.FaissModuleProtocolsearch_api.types.GpuClonerOptionsProtocolsearch_api.types.GpuResourcesProtocoltyping.TYPE_CHECKINGtyping.castsearch_api.faiss_gpu code <p>See the full diagram: search_api.faiss_gpu</p>"},{"location":"modules/search_api.faiss_gpu/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>search_api.faiss_gpu.GpuContext</li> <li>search_api.faiss_gpu.clone_index_to_gpu</li> <li>search_api.faiss_gpu.configure_search_parameters</li> <li>search_api.faiss_gpu.detect_gpu_context</li> </ul>"},{"location":"modules/search_api.faiss_gpu/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Callable</code>, <code>collections.abc.Sequence</code>, <code>dataclasses.dataclass</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.sequence_guards.first_or_error</code>, <code>kgfoundry_common.sequence_guards.first_or_error_multi_device</code>, <code>logging</code>, <code>search_api.types.FaissIndexProtocol</code>, <code>search_api.types.FaissModuleProtocol</code>, <code>search_api.types.GpuClonerOptionsProtocol</code>, <code>search_api.types.GpuResourcesProtocol</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/search_api.faiss_gpu/#contents","title":"Contents","text":""},{"location":"modules/search_api.faiss_gpu/#search_apifaiss_gpugpucontext","title":"search_api.faiss_gpu.GpuContext","text":""},{"location":"modules/search_api.faiss_gpu/#search_api.faiss_gpu.GpuContext","title":"<code>search_api.faiss_gpu.GpuContext</code>  <code>dataclass</code>","text":"<p>Container describing GPU resources associated with a FAISS module.</p> Source code in <code>src/search_api/faiss_gpu.py</code> <pre><code>@dataclass(frozen=True)\n# [nav:anchor GpuContext]\nclass GpuContext:\n    \"\"\"Container describing GPU resources associated with a FAISS module.\"\"\"\n\n    module: FaissModuleProtocol\n    resources: GpuResourcesProtocol\n    options: GpuClonerOptionsProtocol | None\n    device_ids: tuple[int, ...]\n</code></pre>"},{"location":"modules/search_api.faiss_gpu/#search_apifaiss_gpuclone_index_to_gpu","title":"search_api.faiss_gpu.clone_index_to_gpu","text":""},{"location":"modules/search_api.faiss_gpu/#search_api.faiss_gpu.clone_index_to_gpu","title":"<code>search_api.faiss_gpu.clone_index_to_gpu(index, context)</code>","text":"<p>Clone <code>index</code> onto GPU hardware described by <code>context</code>.</p> <p>If GPU helpers are unavailable or cloning fails, the original CPU index is returned. All exceptions are caught and logged at debug level so callers can emit typed Problem Details without leaking driver internals to clients.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>FaissIndexProtocol</code> <p>CPU index to clone.</p> required <code>context</code> <code>GpuContext</code> <p>GPU context for cloning.</p> required <p>Returns:</p> Type Description <code>FaissIndexProtocol</code> <p>GPU index if cloning succeeds, otherwise the original CPU index.</p> Source code in <code>src/search_api/faiss_gpu.py</code> <pre><code>def clone_index_to_gpu(index: FaissIndexProtocol, context: GpuContext) -&gt; FaissIndexProtocol:\n    \"\"\"Clone ``index`` onto GPU hardware described by ``context``.\n\n    If GPU helpers are unavailable or cloning fails, the original CPU index is returned. All\n    exceptions are caught and logged at debug level so callers can emit typed Problem Details\n    without leaking driver internals to clients.\n\n    Parameters\n    ----------\n    index : FaissIndexProtocol\n        CPU index to clone.\n    context : GpuContext\n        GPU context for cloning.\n\n    Returns\n    -------\n    FaissIndexProtocol\n        GPU index if cloning succeeds, otherwise the original CPU index.\n    \"\"\"\n    module = context.module\n    devices = context.device_ids\n    options = context.options\n\n    try:\n        if len(devices) &gt; 1:\n            multi_clone_raw = cast(\n                \"object | None\", getattr(module, \"index_cpu_to_gpu_multiple\", None)\n            )\n            if multi_clone_raw is not None:\n                multi_clone = cast(\n                    \"Callable[[GpuResourcesProtocol, Sequence[int], FaissIndexProtocol, GpuClonerOptionsProtocol | None], list[FaissIndexProtocol]]\",\n                    multi_clone_raw,\n                )\n                gpu_indices = multi_clone(context.resources, list(devices), index, options)\n                if gpu_indices:\n                    return first_or_error_multi_device(\n                        gpu_indices, context=\"gpu_indices_from_multi_clone\"\n                    )\n\n        clone_raw = cast(\"object | None\", getattr(module, \"index_cpu_to_gpu\", None))\n        if clone_raw is None:\n            return index\n\n        if options is not None:\n            clone = cast(\n                \"Callable[[GpuResourcesProtocol, int, FaissIndexProtocol, GpuClonerOptionsProtocol], FaissIndexProtocol]\",\n                clone_raw,\n            )\n            return clone(\n                context.resources,\n                first_or_error(devices, context=\"device_ids_single_clone\"),\n                index,\n                options,\n            )\n\n        clone_without_options = cast(\n            \"Callable[[GpuResourcesProtocol, int, FaissIndexProtocol], FaissIndexProtocol]\",\n            clone_raw,\n        )\n        return clone_without_options(\n            context.resources,\n            first_or_error(devices, context=\"device_ids_no_options\"),\n            index,\n        )\n    except (RuntimeError, OSError, ValueError) as exc:  # pragma: no cover - defensive fallback\n        logger.debug(\"FAISS GPU cloning failed: %s\", exc, exc_info=True)\n        return index\n</code></pre>"},{"location":"modules/search_api.faiss_gpu/#search_apifaiss_gpuconfigure_search_parameters","title":"search_api.faiss_gpu.configure_search_parameters","text":""},{"location":"modules/search_api.faiss_gpu/#search_api.faiss_gpu.configure_search_parameters","title":"<code>search_api.faiss_gpu.configure_search_parameters(module, index, *, nprobe, gpu_enabled)</code>","text":"<p>Apply FAISS search parameters (such as <code>nprobe</code>) to <code>index</code>.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>FaissModuleProtocol</code> <p>FAISS module to query for parameter space helpers.</p> required <code>index</code> <code>FaissIndexProtocol</code> <p>Index to configure.</p> required <code>nprobe</code> <code>int</code> <p>Number of inverted lists to probe during search.</p> required <code>gpu_enabled</code> <code>bool</code> <p>Whether the index runs on GPU (selects GPU or CPU parameter space).</p> required Source code in <code>src/search_api/faiss_gpu.py</code> <pre><code>def configure_search_parameters(\n    module: FaissModuleProtocol,\n    index: FaissIndexProtocol,\n    *,\n    nprobe: int,\n    gpu_enabled: bool,\n) -&gt; None:\n    \"\"\"Apply FAISS search parameters (such as ``nprobe``) to ``index``.\n\n    Parameters\n    ----------\n    module : FaissModuleProtocol\n        FAISS module to query for parameter space helpers.\n    index : FaissIndexProtocol\n        Index to configure.\n    nprobe : int\n        Number of inverted lists to probe during search.\n    gpu_enabled : bool\n        Whether the index runs on GPU (selects GPU or CPU parameter space).\n    \"\"\"\n    params_name = \"GpuParameterSpace\" if gpu_enabled else \"ParameterSpace\"\n    params_ctor_raw = cast(\"object | None\", getattr(module, params_name, None))\n    if params_ctor_raw is None:\n        return\n\n    params_ctor = cast(\"Callable[[], object]\", params_ctor_raw)\n    params = params_ctor()\n    setter_raw = cast(\"object | None\", getattr(params, \"set_index_parameter\", None))\n    if setter_raw is None:\n        return\n\n    setter = cast(\"Callable[[FaissIndexProtocol, str, object], None]\", setter_raw)\n    try:\n        setter(index, \"nprobe\", nprobe)\n    except (\n        RuntimeError,\n        AttributeError,\n        ValueError,\n    ) as exc:  # pragma: no cover - defensive fallback\n        logger.debug(\"Unable to configure FAISS parameter 'nprobe': %s\", exc, exc_info=True)\n</code></pre>"},{"location":"modules/search_api.faiss_gpu/#search_apifaiss_gpudetect_gpu_context","title":"search_api.faiss_gpu.detect_gpu_context","text":""},{"location":"modules/search_api.faiss_gpu/#search_api.faiss_gpu.detect_gpu_context","title":"<code>search_api.faiss_gpu.detect_gpu_context(module, *, use_cuvs=True, device_ids=None)</code>","text":"<p>Return a :class:<code>GpuContext</code> when GPU helpers are available.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>FaissModuleProtocol</code> <p>FAISS module previously imported (may be CPU-only).</p> required <code>use_cuvs</code> <code>bool</code> <p>Whether to request cuVS acceleration when the module exposes the <code>GpuClonerOptions</code> flag. Defaults to <code>True</code>.</p> <code>True</code> <code>device_ids</code> <code>Sequence[int] | None</code> <p>Specific GPU device IDs to target. Defaults to <code>(0,)</code> when omitted.</p> <code>None</code> <p>Returns:</p> Type Description <code>GpuContext | None</code> <p>GPU context if GPU helpers are available, None otherwise.</p> Source code in <code>src/search_api/faiss_gpu.py</code> <pre><code>def detect_gpu_context(\n    module: FaissModuleProtocol,\n    *,\n    use_cuvs: bool = True,\n    device_ids: Sequence[int] | None = None,\n) -&gt; GpuContext | None:\n    \"\"\"Return a :class:`GpuContext` when GPU helpers are available.\n\n    Parameters\n    ----------\n    module : FaissModuleProtocol\n        FAISS module previously imported (may be CPU-only).\n    use_cuvs : bool, optional\n        Whether to request cuVS acceleration when the module exposes the\n        ``GpuClonerOptions`` flag. Defaults to ``True``.\n    device_ids : Sequence[int] | None, optional\n        Specific GPU device IDs to target. Defaults to ``(0,)`` when omitted.\n\n    Returns\n    -------\n    GpuContext | None\n        GPU context if GPU helpers are available, None otherwise.\n    \"\"\"\n    standard_gpu_resources_raw = cast(\n        \"object | None\", getattr(module, \"StandardGpuResources\", None)\n    )\n    if standard_gpu_resources_raw is None:\n        return None\n\n    resources_ctor = cast(\"Callable[[], GpuResourcesProtocol]\", standard_gpu_resources_raw)\n    resources = resources_ctor()\n\n    options_ctor_raw = cast(\"object | None\", getattr(module, \"GpuClonerOptions\", None))\n    options: GpuClonerOptionsProtocol | None = None\n    if options_ctor_raw is not None:\n        options_ctor = cast(\"Callable[[], GpuClonerOptionsProtocol]\", options_ctor_raw)\n        options = options_ctor()\n        if hasattr(options, \"use_cuvs\"):\n            options.use_cuvs = bool(use_cuvs)\n\n    devices = tuple(int(device) for device in device_ids) if device_ids else (0,)\n\n    return GpuContext(module=module, resources=resources, options=options, device_ids=devices)\n</code></pre>"},{"location":"modules/search_api.fastapi_helpers/","title":"search_api.fastapi_helpers","text":""},{"location":"modules/search_api.fastapi_helpers/#search_apifastapi_helpers","title":"search_api.fastapi_helpers","text":"<p>Expose the typed FastAPI helpers surfaced by the search API layer.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_api.fastapi_helpers/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_api.fastapi_helpers__future__.annotationskgfoundry_common.fastapi_helpers.DEFAULT_TIMEOUT_SECONDSkgfoundry_common.fastapi_helpers.typed_dependencykgfoundry_common.fastapi_helpers.typed_exception_handlerkgfoundry_common.fastapi_helpers.typed_middlewarekgfoundry_common.navmap_loader.load_nav_metadatasearch_api.fastapi_helpers code <p>See the full diagram: search_api.fastapi_helpers</p>"},{"location":"modules/search_api.fastapi_helpers/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.fastapi_helpers.DEFAULT_TIMEOUT_SECONDS</code>, <code>kgfoundry_common.fastapi_helpers.typed_dependency</code>, <code>kgfoundry_common.fastapi_helpers.typed_exception_handler</code>, <code>kgfoundry_common.fastapi_helpers.typed_middleware</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p>"},{"location":"modules/search_api.fixture_index/","title":"search_api.fixture_index","text":""},{"location":"modules/search_api.fixture_index/#search_apifixture_index","title":"search_api.fixture_index","text":"<p>In-memory fixture index used for tests and tutorials</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_api.fixture_index/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class FixtureDoc\n    class FixtureIndex\n</code></pre>"},{"location":"modules/search_api.fixture_index/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_api.fixture_index__future__.annotationscollections.abc.Iteratorcollections.abc.Sequencedataclasses.dataclassduckdbkgfoundry_common.navmap_loader.load_nav_metadatamathpathlib.Pathreregistry.duckdb_helpers.fetch_allregistry.duckdb_helpers.fetch_onetyping.TYPE_CHECKINGsearch_apisearch_api.fixture_index code <p>See the full diagram: search_api.fixture_index</p>"},{"location":"modules/search_api.fixture_index/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>search_api.fixture_index.FixtureDoc</li> <li>search_api.fixture_index.FixtureIndex</li> <li>search_api.fixture_index._as_str</li> <li>search_api.fixture_index.tokenize</li> </ul>"},{"location":"modules/search_api.fixture_index/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Iterator</code>, <code>collections.abc.Sequence</code>, <code>dataclasses.dataclass</code>, <code>duckdb</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>math</code>, <code>pathlib.Path</code>, <code>re</code>, <code>registry.duckdb_helpers.fetch_all</code>, <code>registry.duckdb_helpers.fetch_one</code>, <code>typing.TYPE_CHECKING</code></p> <p>Imported by: search_api</p>"},{"location":"modules/search_api.fixture_index/#contents","title":"Contents","text":""},{"location":"modules/search_api.fixture_index/#search_apifixture_indexfixturedoc","title":"search_api.fixture_index.FixtureDoc","text":""},{"location":"modules/search_api.fixture_index/#search_api.fixture_index.FixtureDoc","title":"<code>search_api.fixture_index.FixtureDoc</code>  <code>dataclass</code>","text":"<p>Document fixture for test and tutorial use.</p> <p>Represents a document chunk loaded from the fixture index. Contains metadata and text content for search testing and demonstrations.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_id</code> <code>str</code> <p>Unique identifier for the chunk.</p> required <code>doc_id</code> <code>str</code> <p>Document identifier that this chunk belongs to.</p> required <code>title</code> <code>str</code> <p>Title of the document.</p> required <code>section</code> <code>str</code> <p>Section name or identifier within the document.</p> required <code>text</code> <code>str</code> <p>Text content of the chunk.</p> required Source code in <code>src/search_api/fixture_index.py</code> <pre><code>@dataclass\nclass FixtureDoc:\n    \"\"\"Document fixture for test and tutorial use.\n\n    Represents a document chunk loaded from the fixture index. Contains\n    metadata and text content for search testing and demonstrations.\n\n    Parameters\n    ----------\n    chunk_id : str\n        Unique identifier for the chunk.\n    doc_id : str\n        Document identifier that this chunk belongs to.\n    title : str\n        Title of the document.\n    section : str\n        Section name or identifier within the document.\n    text : str\n        Text content of the chunk.\n    \"\"\"\n\n    chunk_id: str\n    doc_id: str\n    title: str\n    section: str\n    text: str\n</code></pre>"},{"location":"modules/search_api.fixture_index/#search_apifixture_indexfixtureindex","title":"search_api.fixture_index.FixtureIndex","text":""},{"location":"modules/search_api.fixture_index/#search_api.fixture_index.FixtureIndex","title":"<code>search_api.fixture_index.FixtureIndex</code>","text":"<p>In-memory fixture index for tests and tutorials.</p> <p>Simple in-memory search index that loads document chunks from a DuckDB catalog and builds term frequency (TF) and document frequency (DF) indexes for basic text search. Used primarily for testing and tutorials.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>str</code> <p>Root directory path for data files. Defaults to \"/data\".</p> <code>'/data'</code> <code>db_path</code> <code>str</code> <p>Path to DuckDB catalog database file. Defaults to \"/data/catalog/catalog.duckdb\".</p> <code>'/data/catalog/catalog.duckdb'</code> Source code in <code>src/search_api/fixture_index.py</code> <pre><code>class FixtureIndex:\n    \"\"\"In-memory fixture index for tests and tutorials.\n\n    Simple in-memory search index that loads document chunks from a DuckDB\n    catalog and builds term frequency (TF) and document frequency (DF)\n    indexes for basic text search. Used primarily for testing and tutorials.\n\n    Parameters\n    ----------\n    root : str, optional\n        Root directory path for data files. Defaults to \"/data\".\n    db_path : str, optional\n        Path to DuckDB catalog database file. Defaults to\n        \"/data/catalog/catalog.duckdb\".\n    \"\"\"\n\n    def __init__(self, root: str = \"/data\", db_path: str = \"/data/catalog/catalog.duckdb\") -&gt; None:\n        \"\"\"Initialize the fixture index and load documents from DuckDB.\n\n        Connects to the DuckDB catalog, loads the latest chunks dataset,\n        and builds the lexical index (TF/DF structures) for search.\n\n        Parameters\n        ----------\n        root : str, optional\n            Root directory path for data files. Defaults to \"/data\".\n        db_path : str, optional\n            Path to DuckDB catalog database file. Defaults to\n            \"/data/catalog/catalog.duckdb\".\n        \"\"\"\n        self.root = Path(root)\n        self.db_path = db_path\n        self.docs: list[FixtureDoc] = []\n        self.df: dict[str, int] = {}\n        self.tf: list[dict[str, int]] = []\n        self._load_from_duckdb()\n\n    def _load_from_duckdb(self) -&gt; None:\n        \"\"\"Load documents from DuckDB catalog.\n\n        Connects to the DuckDB database, finds the latest chunks dataset, and loads all document\n        chunks into memory. Then builds the lexical index for search.\n        \"\"\"\n        db_file = Path(self.db_path)\n        if not db_file.exists():\n            return\n\n        with duckdb.connect(str(db_file)) as connection:\n            root_path = self._latest_chunks_root(connection)\n            if root_path is None:\n                return\n            for doc in self._iter_fixture_docs(connection, root_path):\n                self.docs.append(doc)\n\n        self._build_lex()\n\n    @staticmethod\n    def _latest_chunks_root(connection: duckdb.DuckDBPyConnection) -&gt; Path | None:\n        dataset_row = fetch_one(\n            connection,\n            \"\"\"\n              SELECT parquet_root FROM datasets\n              WHERE kind='chunks'\n              ORDER BY created_at DESC\n              LIMIT 1\n            \"\"\",\n        )\n        if dataset_row is None:\n            return None\n        parquet_root = dataset_row[0]\n        if not isinstance(parquet_root, str):\n            msg = f\"Invalid parquet_root type: {type(parquet_root)}\"\n            raise TypeError(msg)\n        return Path(parquet_root)\n\n    @staticmethod\n    def _iter_fixture_docs(\n        connection: duckdb.DuckDBPyConnection, root_path: Path\n    ) -&gt; Iterator[FixtureDoc]:\n        parquet_pattern = str(root_path / \"*\" / \"*.parquet\")\n        rows: Sequence[tuple[object, ...]] = fetch_all(\n            connection,\n            \"\"\"\n                SELECT c.chunk_id, c.doc_id, coalesce(c.section,''), c.text,\n                       coalesce(d.title,'') AS title\n                FROM read_parquet(?, union_by_name=true) AS c\n                LEFT JOIN documents d ON c.doc_id = d.doc_id\n            \"\"\",\n            [parquet_pattern],\n        )\n        for chunk_id_val, doc_id_val, section_val, text_val, title_val in rows:\n            chunk_id = _as_str(chunk_id_val)\n            doc_id = _as_str(doc_id_val)\n            section = _as_str(section_val)\n            text = _as_str(text_val)\n            title = _as_str(title_val)\n            yield FixtureDoc(\n                chunk_id=chunk_id,\n                doc_id=doc_id or \"urn:doc:fixture\",\n                title=title or \"Fixture\",\n                section=section or \"\",\n                text=text or \"\",\n            )\n\n    def _build_lex(self) -&gt; None:\n        \"\"\"Build lexical index (TF/DF structures) from loaded documents.\n\n        Computes term frequency (TF) for each document and document frequency (DF) for each token\n        across all documents. Sets self.N to the total number of documents.\n        \"\"\"\n        self.tf.clear()\n        self.df.clear()\n        for doc in self.docs:\n            tokens = tokenize(doc.text)\n            tf_counts: dict[str, int] = {}\n            for token in tokens:\n                tf_counts[token] = tf_counts.get(token, 0) + 1\n            self.tf.append(tf_counts)\n            for token in set(tokens):\n                self.df[token] = self.df.get(token, 0) + 1\n        self.N = len(self.docs)\n\n    def search(self, query: str, k: int = 10) -&gt; list[tuple[int, float]]:\n        \"\"\"Search documents using TF-IDF scoring.\n\n        Tokenizes the query and scores each document using TF-IDF (term\n        frequency-inverse document frequency). Returns top-k results sorted\n        by relevance score.\n\n        Parameters\n        ----------\n        query : str\n            Search query text.\n        k : int, optional\n            Number of top results to return. Defaults to 10.\n\n        Returns\n        -------\n        list[tuple[int, float]]\n            List of (document_index, score) tuples sorted by score descending.\n            Only documents with score &gt; 0 are included.\n        \"\"\"\n        if not hasattr(self, \"N\") or self.N == 0:\n            return []\n        qtoks = tokenize(query)\n        if not qtoks:\n            return []\n        scores = [0.0] * self.N\n        for i, tf in enumerate(self.tf):\n            score = 0.0\n            for token in qtoks:\n                if token not in self.df:\n                    continue\n                idf = math.log((self.N + 1) / (self.df[token] + 0.5) + 1.0)\n                score += idf * tf.get(token, 0)\n            scores[i] = score\n\n        # Explicitly type sorted callable to avoid Any\n        def key_func(item: tuple[int, float]) -&gt; float:\n            \"\"\"Extract score from (index, score) tuple for sorting.\n\n            Parameters\n            ----------\n            item : tuple[int, float]\n                Tuple of (index, score).\n\n            Returns\n            -------\n            float\n                Score value.\n            \"\"\"\n            return item[1]\n\n        ranked: list[tuple[int, float]] = sorted(enumerate(scores), key=key_func, reverse=True)\n        return [(index, score) for index, score in ranked[:k] if score &gt; 0.0]\n\n    def doc(self, index: int) -&gt; FixtureDoc:\n        \"\"\"Get document by index.\n\n        Retrieves the document at the specified index from the loaded\n        documents list.\n\n        Parameters\n        ----------\n        index : int\n            Document index (0-based).\n\n        Returns\n        -------\n        FixtureDoc\n            Document fixture at the specified index.\n        \"\"\"\n        return self.docs[index]\n</code></pre>"},{"location":"modules/search_api.fixture_index/#search_api.fixture_index.FixtureIndex.__init__","title":"<code>__init__(root='/data', db_path='/data/catalog/catalog.duckdb')</code>","text":"<p>Initialize the fixture index and load documents from DuckDB.</p> <p>Connects to the DuckDB catalog, loads the latest chunks dataset, and builds the lexical index (TF/DF structures) for search.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>str</code> <p>Root directory path for data files. Defaults to \"/data\".</p> <code>'/data'</code> <code>db_path</code> <code>str</code> <p>Path to DuckDB catalog database file. Defaults to \"/data/catalog/catalog.duckdb\".</p> <code>'/data/catalog/catalog.duckdb'</code> Source code in <code>src/search_api/fixture_index.py</code> <pre><code>def __init__(self, root: str = \"/data\", db_path: str = \"/data/catalog/catalog.duckdb\") -&gt; None:\n    \"\"\"Initialize the fixture index and load documents from DuckDB.\n\n    Connects to the DuckDB catalog, loads the latest chunks dataset,\n    and builds the lexical index (TF/DF structures) for search.\n\n    Parameters\n    ----------\n    root : str, optional\n        Root directory path for data files. Defaults to \"/data\".\n    db_path : str, optional\n        Path to DuckDB catalog database file. Defaults to\n        \"/data/catalog/catalog.duckdb\".\n    \"\"\"\n    self.root = Path(root)\n    self.db_path = db_path\n    self.docs: list[FixtureDoc] = []\n    self.df: dict[str, int] = {}\n    self.tf: list[dict[str, int]] = []\n    self._load_from_duckdb()\n</code></pre>"},{"location":"modules/search_api.fixture_index/#search_api.fixture_index.FixtureIndex.doc","title":"<code>doc(index)</code>","text":"<p>Get document by index.</p> <p>Retrieves the document at the specified index from the loaded documents list.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Document index (0-based).</p> required <p>Returns:</p> Type Description <code>FixtureDoc</code> <p>Document fixture at the specified index.</p> Source code in <code>src/search_api/fixture_index.py</code> <pre><code>def doc(self, index: int) -&gt; FixtureDoc:\n    \"\"\"Get document by index.\n\n    Retrieves the document at the specified index from the loaded\n    documents list.\n\n    Parameters\n    ----------\n    index : int\n        Document index (0-based).\n\n    Returns\n    -------\n    FixtureDoc\n        Document fixture at the specified index.\n    \"\"\"\n    return self.docs[index]\n</code></pre>"},{"location":"modules/search_api.fixture_index/#search_api.fixture_index.FixtureIndex.search","title":"<code>search(query, k=10)</code>","text":"<p>Search documents using TF-IDF scoring.</p> <p>Tokenizes the query and scores each document using TF-IDF (term frequency-inverse document frequency). Returns top-k results sorted by relevance score.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query text.</p> required <code>k</code> <code>int</code> <p>Number of top results to return. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[tuple[int, float]]</code> <p>List of (document_index, score) tuples sorted by score descending. Only documents with score &gt; 0 are included.</p> Source code in <code>src/search_api/fixture_index.py</code> <pre><code>def search(self, query: str, k: int = 10) -&gt; list[tuple[int, float]]:\n    \"\"\"Search documents using TF-IDF scoring.\n\n    Tokenizes the query and scores each document using TF-IDF (term\n    frequency-inverse document frequency). Returns top-k results sorted\n    by relevance score.\n\n    Parameters\n    ----------\n    query : str\n        Search query text.\n    k : int, optional\n        Number of top results to return. Defaults to 10.\n\n    Returns\n    -------\n    list[tuple[int, float]]\n        List of (document_index, score) tuples sorted by score descending.\n        Only documents with score &gt; 0 are included.\n    \"\"\"\n    if not hasattr(self, \"N\") or self.N == 0:\n        return []\n    qtoks = tokenize(query)\n    if not qtoks:\n        return []\n    scores = [0.0] * self.N\n    for i, tf in enumerate(self.tf):\n        score = 0.0\n        for token in qtoks:\n            if token not in self.df:\n                continue\n            idf = math.log((self.N + 1) / (self.df[token] + 0.5) + 1.0)\n            score += idf * tf.get(token, 0)\n        scores[i] = score\n\n    # Explicitly type sorted callable to avoid Any\n    def key_func(item: tuple[int, float]) -&gt; float:\n        \"\"\"Extract score from (index, score) tuple for sorting.\n\n        Parameters\n        ----------\n        item : tuple[int, float]\n            Tuple of (index, score).\n\n        Returns\n        -------\n        float\n            Score value.\n        \"\"\"\n        return item[1]\n\n    ranked: list[tuple[int, float]] = sorted(enumerate(scores), key=key_func, reverse=True)\n    return [(index, score) for index, score in ranked[:k] if score &gt; 0.0]\n</code></pre>"},{"location":"modules/search_api.fixture_index/#search_apifixture_index_as_str","title":"search_api.fixture_index._as_str","text":""},{"location":"modules/search_api.fixture_index/#search_api.fixture_index._as_str","title":"<code>search_api.fixture_index._as_str(value)</code>","text":"Source code in <code>src/search_api/fixture_index.py</code> <pre><code>def _as_str(value: object) -&gt; str:\n    if isinstance(value, str):\n        return value\n    if value is None:\n        return \"\"\n    return str(value)\n</code></pre>"},{"location":"modules/search_api.fixture_index/#search_apifixture_indextokenize","title":"search_api.fixture_index.tokenize","text":""},{"location":"modules/search_api.fixture_index/#search_api.fixture_index.tokenize","title":"<code>search_api.fixture_index.tokenize(text)</code>","text":"<p>Tokenize text into lowercase alphanumeric tokens.</p> <p>Extracts alphanumeric sequences from the input text and converts them to lowercase. Uses a regex pattern to match alphanumeric characters.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Input text to tokenize. Empty strings are handled gracefully.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of lowercase alphanumeric tokens extracted from the text.</p> Source code in <code>src/search_api/fixture_index.py</code> <pre><code>def tokenize(text: str) -&gt; list[str]:\n    \"\"\"Tokenize text into lowercase alphanumeric tokens.\n\n    Extracts alphanumeric sequences from the input text and converts them\n    to lowercase. Uses a regex pattern to match alphanumeric characters.\n\n    Parameters\n    ----------\n    text : str\n        Input text to tokenize. Empty strings are handled gracefully.\n\n    Returns\n    -------\n    list[str]\n        List of lowercase alphanumeric tokens extracted from the text.\n    \"\"\"\n    # re.findall returns list[str] when pattern has no groups\n    matches: list[str] = TOKEN_RE.findall(text or \"\")\n    return [token.lower() for token in matches]\n</code></pre>"},{"location":"modules/search_api.fusion/","title":"search_api.fusion","text":""},{"location":"modules/search_api.fusion/#search_apifusion","title":"search_api.fusion","text":"<p>Reciprocal rank fusion helpers for combining retrieval signals</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_api.fusion/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_api.fusion__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatasearch_apisearch_api.fusion code <p>See the full diagram: search_api.fusion</p>"},{"location":"modules/search_api.fusion/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>search_api.fusion.rrf_fuse</li> </ul>"},{"location":"modules/search_api.fusion/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code></p> <p>Imported by: search_api</p>"},{"location":"modules/search_api.fusion/#contents","title":"Contents","text":""},{"location":"modules/search_api.fusion/#search_apifusionrrf_fuse","title":"search_api.fusion.rrf_fuse","text":""},{"location":"modules/search_api.fusion/#search_api.fusion.rrf_fuse","title":"<code>search_api.fusion.rrf_fuse(rankers, k_rrf=60)</code>","text":"<p>Fuse multiple ranked lists using Reciprocal Rank Fusion (RRF).</p> <p>Combines multiple ranked lists into a single fused ranking by summing reciprocal rank scores across all lists. Items appearing in multiple lists receive higher scores.</p> <p>Parameters:</p> Name Type Description Default <code>rankers</code> <code>list[list[tuple[str, float]]]</code> <p>List of ranked lists, where each inner list contains (item_id, score) tuples sorted by score (descending).</p> required <code>k_rrf</code> <code>int</code> <p>RRF constant used to dampen the contribution of lower ranks. Defaults to 60.</p> <code>60</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>Dictionary mapping item IDs to their fused RRF scores.</p> Source code in <code>src/search_api/fusion.py</code> <pre><code>def rrf_fuse(rankers: list[list[tuple[str, float]]], k_rrf: int = 60) -&gt; dict[str, float]:\n    \"\"\"Fuse multiple ranked lists using Reciprocal Rank Fusion (RRF).\n\n    Combines multiple ranked lists into a single fused ranking by summing\n    reciprocal rank scores across all lists. Items appearing in multiple\n    lists receive higher scores.\n\n    Parameters\n    ----------\n    rankers : list[list[tuple[str, float]]]\n        List of ranked lists, where each inner list contains (item_id, score)\n        tuples sorted by score (descending).\n    k_rrf : int, optional\n        RRF constant used to dampen the contribution of lower ranks.\n        Defaults to 60.\n\n    Returns\n    -------\n    dict[str, float]\n        Dictionary mapping item IDs to their fused RRF scores.\n    \"\"\"\n    agg: dict[str, float] = {}\n    for ranked in rankers:\n        for r, (key, _score) in enumerate(ranked, start=1):\n            agg[key] = agg.get(key, 0.0) + 1.0 / (k_rrf + r)\n    return agg\n</code></pre>"},{"location":"modules/search_api.kg_mock/","title":"search_api.kg_mock","text":""},{"location":"modules/search_api.kg_mock/#search_apikg_mock","title":"search_api.kg_mock","text":"<p>Mock knowledge graph helpers used by the search API</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_api.kg_mock/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class ConceptMeta\n    class TypedDict\n    TypedDict &lt;|-- ConceptMeta\n</code></pre>"},{"location":"modules/search_api.kg_mock/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_api.kg_mock__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatatyping.Finaltyping.TypedDictsearch_apisearch_api.kg_mock code <p>See the full diagram: search_api.kg_mock</p>"},{"location":"modules/search_api.kg_mock/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>search_api.kg_mock.ConceptMeta</li> <li>search_api.kg_mock.detect_query_concepts</li> <li>search_api.kg_mock.kg_boost</li> <li>search_api.kg_mock.linked_concepts_for_text</li> </ul>"},{"location":"modules/search_api.kg_mock/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>typing.Final</code>, <code>typing.TypedDict</code></p> <p>Imported by: search_api</p>"},{"location":"modules/search_api.kg_mock/#contents","title":"Contents","text":""},{"location":"modules/search_api.kg_mock/#search_apikg_mockconceptmeta","title":"search_api.kg_mock.ConceptMeta","text":"<p>Bases: TypedDict</p>"},{"location":"modules/search_api.kg_mock/#search_api.kg_mock.ConceptMeta","title":"<code>search_api.kg_mock.ConceptMeta</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Metadata for knowledge graph concepts.</p> <p>TypedDict representing concept metadata with label and keywords. Used by mock knowledge graph functions for concept matching.</p> <p>Parameters:</p> Name Type Description Default <code>label</code> <code>str</code> <p>Human-readable concept label.</p> required <code>keywords</code> <code>list[str]</code> <p>List of keywords that match this concept.</p> required Source code in <code>src/search_api/kg_mock.py</code> <pre><code>class ConceptMeta(TypedDict):\n    \"\"\"Metadata for knowledge graph concepts.\n\n    TypedDict representing concept metadata with label and keywords.\n    Used by mock knowledge graph functions for concept matching.\n\n    Parameters\n    ----------\n    label : str\n        Human-readable concept label.\n    keywords : list[str]\n        List of keywords that match this concept.\n    \"\"\"\n\n    label: str\n    keywords: list[str]\n</code></pre>"},{"location":"modules/search_api.kg_mock/#search_apikg_mockdetect_query_concepts","title":"search_api.kg_mock.detect_query_concepts","text":""},{"location":"modules/search_api.kg_mock/#search_api.kg_mock.detect_query_concepts","title":"<code>search_api.kg_mock.detect_query_concepts(query)</code>","text":"<p>Detect knowledge graph concepts mentioned in a query.</p> <p>Searches for concept keywords in the query text and returns matching concept IDs from the mock knowledge graph.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Query text to analyze for concept mentions.</p> required <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of concept IDs that match keywords in the query.</p> Source code in <code>src/search_api/kg_mock.py</code> <pre><code>def detect_query_concepts(query: str) -&gt; set[str]:\n    \"\"\"Detect knowledge graph concepts mentioned in a query.\n\n    Searches for concept keywords in the query text and returns matching\n    concept IDs from the mock knowledge graph.\n\n    Parameters\n    ----------\n    query : str\n        Query text to analyze for concept mentions.\n\n    Returns\n    -------\n    set[str]\n        Set of concept IDs that match keywords in the query.\n    \"\"\"\n    lowered = query.lower()\n    hits: set[str] = set()\n    for concept_id, meta in CONCEPTS.items():\n        if any(keyword in lowered for keyword in meta[\"keywords\"]):\n            hits.add(concept_id)\n    return hits\n</code></pre>"},{"location":"modules/search_api.kg_mock/#search_apikg_mockkg_boost","title":"search_api.kg_mock.kg_boost","text":""},{"location":"modules/search_api.kg_mock/#search_api.kg_mock.kg_boost","title":"<code>search_api.kg_mock.kg_boost(query_concepts, chunk_concepts, direct=0.08, one_hop=0.04)</code>","text":"<p>Calculate knowledge graph boost score for a chunk.</p> <p>Computes a boost score based on concept overlap between query and chunk. Returns direct boost if there are direct concept matches, otherwise 0.0. The one_hop parameter is reserved for future graph traversal heuristics.</p> <p>Parameters:</p> Name Type Description Default <code>query_concepts</code> <code>list[str]</code> <p>List of concept IDs extracted from the query.</p> required <code>chunk_concepts</code> <code>list[str]</code> <p>List of concept IDs linked to the chunk.</p> required <code>direct</code> <code>float</code> <p>Boost amount for direct concept matches. Defaults to 0.08.</p> <code>0.08</code> <code>one_hop</code> <code>float</code> <p>Boost amount for one-hop concept matches (currently unused). Defaults to 0.04.</p> <code>0.04</code> <p>Returns:</p> Type Description <code>float</code> <p>Boost score (direct if concepts overlap, otherwise 0.0).</p> Source code in <code>src/search_api/kg_mock.py</code> <pre><code>def kg_boost(\n    query_concepts: list[str],\n    chunk_concepts: list[str],\n    direct: float = 0.08,\n    one_hop: float = 0.04,\n) -&gt; float:\n    \"\"\"Calculate knowledge graph boost score for a chunk.\n\n    Computes a boost score based on concept overlap between query and chunk.\n    Returns direct boost if there are direct concept matches, otherwise 0.0.\n    The one_hop parameter is reserved for future graph traversal heuristics.\n\n    Parameters\n    ----------\n    query_concepts : list[str]\n        List of concept IDs extracted from the query.\n    chunk_concepts : list[str]\n        List of concept IDs linked to the chunk.\n    direct : float, optional\n        Boost amount for direct concept matches. Defaults to 0.08.\n    one_hop : float, optional\n        Boost amount for one-hop concept matches (currently unused).\n        Defaults to 0.04.\n\n    Returns\n    -------\n    float\n        Boost score (direct if concepts overlap, otherwise 0.0).\n    \"\"\"\n    _ = one_hop  # placeholder for future graph traversal heuristics\n    return direct if set(query_concepts) &amp; set(chunk_concepts) else 0.0\n</code></pre>"},{"location":"modules/search_api.kg_mock/#search_apikg_mocklinked_concepts_for_text","title":"search_api.kg_mock.linked_concepts_for_text","text":""},{"location":"modules/search_api.kg_mock/#search_api.kg_mock.linked_concepts_for_text","title":"<code>search_api.kg_mock.linked_concepts_for_text(text)</code>","text":"<p>Find knowledge graph concepts linked to text content.</p> <p>Searches for concept keywords in the text and returns matching concept IDs from the mock knowledge graph.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text content to analyze for concept mentions.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of concept IDs that match keywords in the text.</p> Source code in <code>src/search_api/kg_mock.py</code> <pre><code>def linked_concepts_for_text(text: str) -&gt; list[str]:\n    \"\"\"Find knowledge graph concepts linked to text content.\n\n    Searches for concept keywords in the text and returns matching\n    concept IDs from the mock knowledge graph.\n\n    Parameters\n    ----------\n    text : str\n        Text content to analyze for concept mentions.\n\n    Returns\n    -------\n    list[str]\n        List of concept IDs that match keywords in the text.\n    \"\"\"\n    lowered = text.lower()\n    hits = []\n    for concept_id, meta in CONCEPTS.items():\n        if any(keyword in lowered for keyword in meta[\"keywords\"]):\n            hits.append(concept_id)\n    return hits\n</code></pre>"},{"location":"modules/search_api/","title":"search_api","text":""},{"location":"modules/search_api/#search_api","title":"search_api","text":"<p>Search service endpoints and retrieval adapters</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_api/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_api__future__.annotationsimportlib.import_modulekgfoundry_common.navmap_loader.load_nav_metadatasearch_api.appsearch_api.bm25_indexsearch_api.faiss_adaptersearch_api.fixture_indexsearch_api.fusionsearch_api.kg_mocksearch_api.schemassearch_api.servicesearch_api.splade_indexsearch_api.typessystypes.ModuleTypetyping.TYPE_CHECKINGsearch_api code <p>See the full diagram: search_api</p>"},{"location":"modules/search_api/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>search_api.dir</li> <li>search_api.getattr</li> <li>search_api._load</li> </ul>"},{"location":"modules/search_api/#interfaces","title":"Interfaces","text":""},{"location":"modules/search_api/#search-http","title":"<code>search-http</code>","text":"<ul> <li>Type: http</li> <li>Owner: @search-api</li> <li>Stability: experimental</li> <li>Description: FastAPI application exposing search operations via the public HTTP API.</li> <li>Spec: HTTP API</li> <li>Problem Details: schema/examples/problem_details/search-missing-index.json, schema/examples/problem_details/search-gpu-unavailable.json</li> </ul>"},{"location":"modules/search_api/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>importlib.import_module</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, search_api.app, search_api.bm25_index, search_api.faiss_adapter, search_api.fixture_index, search_api.fusion, search_api.kg_mock, search_api.schemas, search_api.service, search_api.splade_index, search_api.types, <code>sys</code>, <code>types.ModuleType</code>, <code>typing.TYPE_CHECKING</code></p>"},{"location":"modules/search_api/#contents","title":"Contents","text":""},{"location":"modules/search_api/#search_apidir","title":"search_api.dir","text":""},{"location":"modules/search_api/#search_api.__dir__","title":"<code>search_api.__dir__()</code>","text":"Source code in <code>src/search_api/__init__.py</code> <pre><code>def __dir__() -&gt; list[str]:\n    return sorted(set(__all__))\n</code></pre>"},{"location":"modules/search_api/#search_apigetattr","title":"search_api.getattr","text":""},{"location":"modules/search_api/#search_api.__getattr__","title":"<code>search_api.__getattr__(name)</code>","text":"Source code in <code>src/search_api/__init__.py</code> <pre><code>def __getattr__(name: str) -&gt; ModuleType:\n    if name not in _ALIASES:\n        message = f\"module {__name__!r} has no attribute {name!r}\"\n        raise AttributeError(message)\n    return _load(name)\n</code></pre>"},{"location":"modules/search_api/#search_api_load","title":"search_api._load","text":""},{"location":"modules/search_api/#search_api._load","title":"<code>search_api._load(name)</code>","text":"Source code in <code>src/search_api/__init__.py</code> <pre><code>def _load(name: str) -&gt; ModuleType:\n    module = import_module(_ALIASES[name])\n    sys.modules[f\"{__name__}.{name}\"] = module\n    return module\n</code></pre>"},{"location":"modules/search_api.schemas/","title":"search_api.schemas","text":""},{"location":"modules/search_api.schemas/#search_apischemas","title":"search_api.schemas","text":"<p>Pydantic models used by the search API</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_api.schemas/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class SearchRequest\n    class BaseModel\n    BaseModel &lt;|-- SearchRequest\n    class SearchResponse\n    BaseModel &lt;|-- SearchResponse\n    class SearchResult\n    BaseModel &lt;|-- SearchResult\n</code></pre>"},{"location":"modules/search_api.schemas/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_api.schemas__future__.annotationsimportlibkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.pydantic.BaseModelkgfoundry_common.types.JsonValuepydantic.ConfigDictpydantic.Fieldtyping.TYPE_CHECKINGsearch_apisearch_api.schemas code <p>See the full diagram: search_api.schemas</p>"},{"location":"modules/search_api.schemas/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>search_api.schemas.SearchRequest</li> <li>search_api.schemas.SearchResponse</li> <li>search_api.schemas.SearchResult</li> </ul>"},{"location":"modules/search_api.schemas/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>importlib</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.pydantic.BaseModel</code>, <code>kgfoundry_common.types.JsonValue</code>, <code>pydantic.ConfigDict</code>, <code>pydantic.Field</code>, <code>typing.TYPE_CHECKING</code></p> <p>Imported by: search_api</p>"},{"location":"modules/search_api.schemas/#contents","title":"Contents","text":""},{"location":"modules/search_api.schemas/#search_apischemassearchrequest","title":"search_api.schemas.SearchRequest","text":"<p>Bases: BaseModel</p>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchRequest","title":"<code>search_api.schemas.SearchRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Search API request model.</p> <p>Pydantic model for search API requests. Validates query parameters and request structure according to the search API schema.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query text. Must be non-empty (min_length=1).</p> required <code>k</code> <code>int</code> <p>Number of results to return. Defaults to 10.</p> required <code>filters</code> <code>dict[str, object] | None</code> <p>Optional filters to apply to search results. Defaults to None.</p> required <code>explain</code> <code>bool</code> <p>Whether to include explanation metadata in results. Defaults to False.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from kgfoundry_common.schema_helpers import assert_model_roundtrip\n&gt;&gt;&gt; example_path = (\n...     Path(__file__).parent.parent.parent\n...     / \"schema\"\n...     / \"examples\"\n...     / \"search_api\"\n...     / \"search_request.v1.json\"\n... )\n&gt;&gt;&gt; assert_model_roundtrip(SearchRequest, example_path)\n</code></pre> Source code in <code>src/search_api/schemas.py</code> <pre><code>class SearchRequest(BaseModel):\n    \"\"\"Search API request model.\n\n    Pydantic model for search API requests. Validates query parameters\n    and request structure according to the search API schema.\n\n    Parameters\n    ----------\n    query : str\n        Search query text. Must be non-empty (min_length=1).\n    k : int, optional\n        Number of results to return. Defaults to 10.\n    filters : dict[str, object] | None, optional\n        Optional filters to apply to search results. Defaults to None.\n    explain : bool, optional\n        Whether to include explanation metadata in results. Defaults to False.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; from kgfoundry_common.schema_helpers import assert_model_roundtrip\n    &gt;&gt;&gt; example_path = (\n    ...     Path(__file__).parent.parent.parent\n    ...     / \"schema\"\n    ...     / \"examples\"\n    ...     / \"search_api\"\n    ...     / \"search_request.v1.json\"\n    ... )\n    &gt;&gt;&gt; assert_model_roundtrip(SearchRequest, example_path)\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n\n    query: str = Field(min_length=1)\n    k: int = 10\n    filters: dict[str, JsonValue] | None = None\n    explain: bool = False\n</code></pre>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchRequest.__init__","title":"<code>__init__(**data)</code>","text":"<p>Populate the model from keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>**data</code> <code>Any</code> <p>Keyword arguments forwarded to the underlying Pydantic model constructor.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def __init__(self, **data: object) -&gt; None:\n    \"\"\"Populate the model from keyword arguments.\n\n    Parameters\n    ----------\n    **data : Any\n        Keyword arguments forwarded to the underlying Pydantic model\n        constructor.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchRequest.model_dump","title":"<code>model_dump(**model_dump_kwargs)</code>","text":"<p>Return the dictionary representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump(self, **model_dump_kwargs: object) -&gt; dict[str, object]:\n    \"\"\"Return the dictionary representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump`.\n    \"\"\"\n    del self, model_dump_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchRequest.model_dump_json","title":"<code>model_dump_json(**model_dump_json_kwargs)</code>","text":"<p>Return the JSON representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_json_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump_json</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump_json(self, **model_dump_json_kwargs: object) -&gt; str:\n    \"\"\"Return the JSON representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_json_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump_json`.\n    \"\"\"\n    del self, model_dump_json_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchRequest.model_validate","title":"<code>model_validate(obj)</code>  <code>classmethod</code>","text":"<p>Validate <code>obj</code> using the underlying Pydantic implementation.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Instance or mapping to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to forbid coercion during validation. Defaults to <code>None</code> (defer to Pydantic).</p> required <code>extra</code> <code>ExtraValues | None</code> <p>Strategy for handling extra keys. Defaults to <code>None</code> (use model configuration).</p> required <code>from_attributes</code> <code>bool | None</code> <p>Allow attribute-based population when <code>obj</code> is not a mapping. Defaults to <code>None</code> (follow model configuration).</p> required <code>context</code> <code>Any | None</code> <p>Context data available to validators. Defaults to <code>None</code>.</p> required <code>by_alias</code> <code>bool | None</code> <p>Interpret alias names when reading <code>obj</code>. Defaults to <code>None</code> (inherit from configuration).</p> required <code>by_name</code> <code>bool | None</code> <p>Permit field-name based population alongside aliases. Defaults to <code>None</code>.</p> required Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>@classmethod\ndef model_validate(cls, obj: object, /) -&gt; Self:\n    \"\"\"Validate ``obj`` using the underlying Pydantic implementation.\n\n    Parameters\n    ----------\n    obj : Any\n        Instance or mapping to validate.\n    strict : bool | None, optional\n        Whether to forbid coercion during validation.\n        Defaults to ``None`` (defer to Pydantic).\n    extra : ExtraValues | None, optional\n        Strategy for handling extra keys.\n        Defaults to ``None`` (use model configuration).\n    from_attributes : bool | None, optional\n        Allow attribute-based population when ``obj`` is not a mapping.\n        Defaults to ``None`` (follow model configuration).\n    context : Any | None, optional\n        Context data available to validators.\n        Defaults to ``None``.\n    by_alias : bool | None, optional\n        Interpret alias names when reading ``obj``.\n        Defaults to ``None`` (inherit from configuration).\n    by_name : bool | None, optional\n        Permit field-name based population alongside aliases.\n        Defaults to ``None``.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/search_api.schemas/#search_apischemassearchresponse","title":"search_api.schemas.SearchResponse","text":"<p>Bases: BaseModel</p>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchResponse","title":"<code>search_api.schemas.SearchResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Search API response containing results.</p> <p>Response envelope for search API endpoints. Contains a list of search results with optional metadata.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>list[SearchResult]</code> <p>List of search results, ordered by relevance score descending. Defaults to empty list.</p> required Source code in <code>src/search_api/schemas.py</code> <pre><code>class SearchResponse(BaseModel):\n    \"\"\"Search API response containing results.\n\n    Response envelope for search API endpoints. Contains a list of\n    search results with optional metadata.\n\n    Parameters\n    ----------\n    results : list[SearchResult]\n        List of search results, ordered by relevance score descending.\n        Defaults to empty list.\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n\n    results: list[SearchResult] = Field(default_factory=list)\n</code></pre>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchResponse.__init__","title":"<code>__init__(**data)</code>","text":"<p>Populate the model from keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>**data</code> <code>Any</code> <p>Keyword arguments forwarded to the underlying Pydantic model constructor.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def __init__(self, **data: object) -&gt; None:\n    \"\"\"Populate the model from keyword arguments.\n\n    Parameters\n    ----------\n    **data : Any\n        Keyword arguments forwarded to the underlying Pydantic model\n        constructor.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchResponse.model_dump","title":"<code>model_dump(**model_dump_kwargs)</code>","text":"<p>Return the dictionary representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump(self, **model_dump_kwargs: object) -&gt; dict[str, object]:\n    \"\"\"Return the dictionary representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump`.\n    \"\"\"\n    del self, model_dump_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchResponse.model_dump_json","title":"<code>model_dump_json(**model_dump_json_kwargs)</code>","text":"<p>Return the JSON representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_json_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump_json</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump_json(self, **model_dump_json_kwargs: object) -&gt; str:\n    \"\"\"Return the JSON representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_json_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump_json`.\n    \"\"\"\n    del self, model_dump_json_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchResponse.model_validate","title":"<code>model_validate(obj)</code>  <code>classmethod</code>","text":"<p>Validate <code>obj</code> using the underlying Pydantic implementation.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Instance or mapping to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to forbid coercion during validation. Defaults to <code>None</code> (defer to Pydantic).</p> required <code>extra</code> <code>ExtraValues | None</code> <p>Strategy for handling extra keys. Defaults to <code>None</code> (use model configuration).</p> required <code>from_attributes</code> <code>bool | None</code> <p>Allow attribute-based population when <code>obj</code> is not a mapping. Defaults to <code>None</code> (follow model configuration).</p> required <code>context</code> <code>Any | None</code> <p>Context data available to validators. Defaults to <code>None</code>.</p> required <code>by_alias</code> <code>bool | None</code> <p>Interpret alias names when reading <code>obj</code>. Defaults to <code>None</code> (inherit from configuration).</p> required <code>by_name</code> <code>bool | None</code> <p>Permit field-name based population alongside aliases. Defaults to <code>None</code>.</p> required Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>@classmethod\ndef model_validate(cls, obj: object, /) -&gt; Self:\n    \"\"\"Validate ``obj`` using the underlying Pydantic implementation.\n\n    Parameters\n    ----------\n    obj : Any\n        Instance or mapping to validate.\n    strict : bool | None, optional\n        Whether to forbid coercion during validation.\n        Defaults to ``None`` (defer to Pydantic).\n    extra : ExtraValues | None, optional\n        Strategy for handling extra keys.\n        Defaults to ``None`` (use model configuration).\n    from_attributes : bool | None, optional\n        Allow attribute-based population when ``obj`` is not a mapping.\n        Defaults to ``None`` (follow model configuration).\n    context : Any | None, optional\n        Context data available to validators.\n        Defaults to ``None``.\n    by_alias : bool | None, optional\n        Interpret alias names when reading ``obj``.\n        Defaults to ``None`` (inherit from configuration).\n    by_name : bool | None, optional\n        Permit field-name based population alongside aliases.\n        Defaults to ``None``.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/search_api.schemas/#search_apischemassearchresult","title":"search_api.schemas.SearchResult","text":"<p>Bases: BaseModel</p>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchResult","title":"<code>search_api.schemas.SearchResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Search result model.</p> <p>Pydantic model representing a single search result. Contains document and chunk identifiers, metadata, relevance score, and optional signals, spans, and concept links.</p> <p>Parameters:</p> Name Type Description Default <code>doc_id</code> <code>str</code> <p>Document identifier.</p> required <code>chunk_id</code> <code>str</code> <p>Chunk identifier within the document.</p> required <code>title</code> <code>str</code> <p>Document title.</p> required <code>section</code> <code>str</code> <p>Section name or identifier within the document.</p> required <code>score</code> <code>float</code> <p>Relevance score for this result.</p> required <code>signals</code> <code>dict[str, float]</code> <p>Dictionary of signal scores (e.g., \"dense\", \"sparse\", \"kg\"). Defaults to empty dictionary.</p> required <code>spans</code> <code>dict[str, int]</code> <p>Dictionary of character span information. Defaults to empty dictionary.</p> required <code>concepts</code> <code>list[dict[str, str]]</code> <p>List of linked concept dictionaries. Defaults to empty list.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from kgfoundry_common.schema_helpers import assert_model_roundtrip\n&gt;&gt;&gt; example_path = (\n...     Path(__file__).parent.parent.parent\n...     / \"schema\"\n...     / \"examples\"\n...     / \"search_api\"\n...     / \"search_result.v1.json\"\n... )\n&gt;&gt;&gt; assert_model_roundtrip(SearchResult, example_path)\n</code></pre> Source code in <code>src/search_api/schemas.py</code> <pre><code>class SearchResult(BaseModel):\n    \"\"\"Search result model.\n\n    Pydantic model representing a single search result. Contains document\n    and chunk identifiers, metadata, relevance score, and optional signals,\n    spans, and concept links.\n\n    Parameters\n    ----------\n    doc_id : str\n        Document identifier.\n    chunk_id : str\n        Chunk identifier within the document.\n    title : str\n        Document title.\n    section : str\n        Section name or identifier within the document.\n    score : float\n        Relevance score for this result.\n    signals : dict[str, float], optional\n        Dictionary of signal scores (e.g., \"dense\", \"sparse\", \"kg\").\n        Defaults to empty dictionary.\n    spans : dict[str, int], optional\n        Dictionary of character span information. Defaults to empty dictionary.\n    concepts : list[dict[str, str]], optional\n        List of linked concept dictionaries. Defaults to empty list.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pathlib import Path\n    &gt;&gt;&gt; from kgfoundry_common.schema_helpers import assert_model_roundtrip\n    &gt;&gt;&gt; example_path = (\n    ...     Path(__file__).parent.parent.parent\n    ...     / \"schema\"\n    ...     / \"examples\"\n    ...     / \"search_api\"\n    ...     / \"search_result.v1.json\"\n    ... )\n    &gt;&gt;&gt; assert_model_roundtrip(SearchResult, example_path)\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n\n    doc_id: str\n    chunk_id: str\n    title: str\n    section: str\n    score: float\n    signals: dict[str, float] = Field(default_factory=dict)\n    spans: dict[str, int] = Field(default_factory=dict)\n    concepts: list[dict[str, str]] = Field(default_factory=list)\n</code></pre>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchResult.__init__","title":"<code>__init__(**data)</code>","text":"<p>Populate the model from keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>**data</code> <code>Any</code> <p>Keyword arguments forwarded to the underlying Pydantic model constructor.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def __init__(self, **data: object) -&gt; None:\n    \"\"\"Populate the model from keyword arguments.\n\n    Parameters\n    ----------\n    **data : Any\n        Keyword arguments forwarded to the underlying Pydantic model\n        constructor.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchResult.model_dump","title":"<code>model_dump(**model_dump_kwargs)</code>","text":"<p>Return the dictionary representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump(self, **model_dump_kwargs: object) -&gt; dict[str, object]:\n    \"\"\"Return the dictionary representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump`.\n    \"\"\"\n    del self, model_dump_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchResult.model_dump_json","title":"<code>model_dump_json(**model_dump_json_kwargs)</code>","text":"<p>Return the JSON representation produced by Pydantic.</p> <p>Parameters:</p> Name Type Description Default <code>**model_dump_json_kwargs</code> <code>dict[str, object]</code> <p>Keyword arguments forwarded to :meth:<code>pydantic.BaseModel.model_dump_json</code>.</p> <code>{}</code> Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>def model_dump_json(self, **model_dump_json_kwargs: object) -&gt; str:\n    \"\"\"Return the JSON representation produced by Pydantic.\n\n    Parameters\n    ----------\n    **model_dump_json_kwargs : dict[str, object]\n        Keyword arguments forwarded to :meth:`pydantic.BaseModel.model_dump_json`.\n    \"\"\"\n    del self, model_dump_json_kwargs\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/search_api.schemas/#search_api.schemas.SearchResult.model_validate","title":"<code>model_validate(obj)</code>  <code>classmethod</code>","text":"<p>Validate <code>obj</code> using the underlying Pydantic implementation.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Instance or mapping to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to forbid coercion during validation. Defaults to <code>None</code> (defer to Pydantic).</p> required <code>extra</code> <code>ExtraValues | None</code> <p>Strategy for handling extra keys. Defaults to <code>None</code> (use model configuration).</p> required <code>from_attributes</code> <code>bool | None</code> <p>Allow attribute-based population when <code>obj</code> is not a mapping. Defaults to <code>None</code> (follow model configuration).</p> required <code>context</code> <code>Any | None</code> <p>Context data available to validators. Defaults to <code>None</code>.</p> required <code>by_alias</code> <code>bool | None</code> <p>Interpret alias names when reading <code>obj</code>. Defaults to <code>None</code> (inherit from configuration).</p> required <code>by_name</code> <code>bool | None</code> <p>Permit field-name based population alongside aliases. Defaults to <code>None</code>.</p> required Source code in <code>src/kgfoundry_common/pydantic.py</code> <pre><code>@classmethod\ndef model_validate(cls, obj: object, /) -&gt; Self:\n    \"\"\"Validate ``obj`` using the underlying Pydantic implementation.\n\n    Parameters\n    ----------\n    obj : Any\n        Instance or mapping to validate.\n    strict : bool | None, optional\n        Whether to forbid coercion during validation.\n        Defaults to ``None`` (defer to Pydantic).\n    extra : ExtraValues | None, optional\n        Strategy for handling extra keys.\n        Defaults to ``None`` (use model configuration).\n    from_attributes : bool | None, optional\n        Allow attribute-based population when ``obj`` is not a mapping.\n        Defaults to ``None`` (follow model configuration).\n    context : Any | None, optional\n        Context data available to validators.\n        Defaults to ``None``.\n    by_alias : bool | None, optional\n        Interpret alias names when reading ``obj``.\n        Defaults to ``None`` (inherit from configuration).\n    by_name : bool | None, optional\n        Permit field-name based population alongside aliases.\n        Defaults to ``None``.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"modules/search_api.service/","title":"search_api.service","text":""},{"location":"modules/search_api.service/#search_apiservice","title":"search_api.service","text":"<p>Search orchestration helpers that combine retrieval backends</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_api.service/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_api.service__future__.annotationscollections.abc.Mappingkgfoundry_common.logging.get_loggerkgfoundry_common.logging.with_fieldskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.observability.MetricsProviderkgfoundry_common.observability.observe_durationkgfoundry_common.problem_details.JsonValuesearch_api.types.AgentSearchResponsesearch_api.types.VectorSearchResultTypedDicttimetyping.TYPE_CHECKINGsearch_apisearch_api.service code <p>See the full diagram: search_api.service</p>"},{"location":"modules/search_api.service/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>search_api.service.apply_kg_boosts</li> <li>search_api.service.mmr_deduplicate</li> <li>search_api.service.rrf_fuse</li> </ul>"},{"location":"modules/search_api.service/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Mapping</code>, <code>kgfoundry_common.logging.get_logger</code>, <code>kgfoundry_common.logging.with_fields</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.observability.MetricsProvider</code>, <code>kgfoundry_common.observability.observe_duration</code>, <code>kgfoundry_common.problem_details.JsonValue</code>, <code>search_api.types.AgentSearchResponse</code>, <code>search_api.types.VectorSearchResultTypedDict</code>, <code>time</code>, <code>typing.TYPE_CHECKING</code></p> <p>Imported by: search_api</p>"},{"location":"modules/search_api.service/#contents","title":"Contents","text":""},{"location":"modules/search_api.service/#search_apiserviceapply_kg_boosts","title":"search_api.service.apply_kg_boosts","text":""},{"location":"modules/search_api.service/#search_api.service.apply_kg_boosts","title":"<code>search_api.service.apply_kg_boosts(cands, query, direct=0.08, one_hop=0.04, *, kg_concepts=None)</code>","text":"<p>Apply knowledge graph boosts to candidate scores.</p> <p>Boosts scores for candidates that have direct or one-hop concept matches with the query. If kg_concepts is None, returns candidates unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>cands</code> <code>dict[str, float]</code> <p>Dictionary mapping candidate IDs to base scores.</p> required <code>query</code> <code>str</code> <p>Query text (used to extract concept mentions).</p> required <code>direct</code> <code>float</code> <p>Boost amount for direct concept matches. Defaults to 0.08.</p> <code>0.08</code> <code>one_hop</code> <code>float</code> <p>Boost amount for one-hop concept matches. Defaults to 0.04.</p> <code>0.04</code> <code>kg_concepts</code> <code>Mapping[str, set[str]] | None</code> <p>Mapping from candidate IDs to sets of concept IDs. If None, no boosts are applied. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>Dictionary mapping candidate IDs to boosted scores.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; cands = {\"doc1\": 0.8, \"doc2\": 0.7}\n&gt;&gt;&gt; boosted = apply_kg_boosts(cands, \"test query\", kg_concepts={\"doc1\": {\"C:42\"}})\n&gt;&gt;&gt; boosted[\"doc1\"] &gt; cands[\"doc1\"]\nTrue\n</code></pre> Source code in <code>src/search_api/service.py</code> <pre><code>def apply_kg_boosts(\n    cands: dict[str, float],\n    query: str,\n    direct: float = 0.08,\n    one_hop: float = 0.04,\n    *,\n    kg_concepts: Mapping[str, set[str]] | None = None,\n) -&gt; dict[str, float]:\n    \"\"\"Apply knowledge graph boosts to candidate scores.\n\n    Boosts scores for candidates that have direct or one-hop concept matches\n    with the query. If kg_concepts is None, returns candidates unchanged.\n\n    Parameters\n    ----------\n    cands : dict[str, float]\n        Dictionary mapping candidate IDs to base scores.\n    query : str\n        Query text (used to extract concept mentions).\n    direct : float, optional\n        Boost amount for direct concept matches. Defaults to 0.08.\n    one_hop : float, optional\n        Boost amount for one-hop concept matches. Defaults to 0.04.\n    kg_concepts : Mapping[str, set[str]] | None, optional\n        Mapping from candidate IDs to sets of concept IDs.\n        If None, no boosts are applied. Defaults to None.\n\n    Returns\n    -------\n    dict[str, float]\n        Dictionary mapping candidate IDs to boosted scores.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cands = {\"doc1\": 0.8, \"doc2\": 0.7}\n    &gt;&gt;&gt; boosted = apply_kg_boosts(cands, \"test query\", kg_concepts={\"doc1\": {\"C:42\"}})\n    &gt;&gt;&gt; boosted[\"doc1\"] &gt; cands[\"doc1\"]\n    True\n    \"\"\"\n    with with_fields(logger, operation=\"apply_kg_boosts\", query=query[:50]):\n        if kg_concepts is None:\n            logger.debug(\"No KG concepts provided, skipping boosts\")\n            return cands\n\n        # Extract concept mentions from query (simplified)\n        q_concepts: set[str] = set()\n        for word in query.lower().split():\n            if word.startswith(\"concept\"):\n                q_concepts.add(f\"C:{word.replace('concept', '')}\")\n\n        boosted = dict(cands)\n        boost_count = 0\n        for cand_id, base_score in cands.items():\n            linked = kg_concepts.get(cand_id, set())\n            boost = 0.0\n            if linked &amp; q_concepts:\n                boost += direct\n            else:\n                for concept in linked:\n                    # Simplified one-hop check (would need full KG graph)\n                    if concept in q_concepts:\n                        boost += one_hop\n                        break\n            if boost &gt; 0:\n                boost_count += 1\n            boosted[cand_id] = base_score + boost\n\n        logger.debug(\n            \"KG boosts applied\",\n            extra={\"boosted_count\": boost_count, \"total_candidates\": len(cands)},\n        )\n        return boosted\n</code></pre>"},{"location":"modules/search_api.service/#search_apiservicemmr_deduplicate","title":"search_api.service.mmr_deduplicate","text":""},{"location":"modules/search_api.service/#search_api.service.mmr_deduplicate","title":"<code>search_api.service.mmr_deduplicate(results, lambda_mmr=0.7)</code>","text":"<p>Deduplicate results using Maximal Marginal Relevance (MMR).</p> <p>Removes duplicate items while preserving diversity. Currently returns results unchanged; full MMR implementation requires document embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>list[tuple[str, float]]</code> <p>List of (item_id, score) tuples, sorted by score descending.</p> required <code>lambda_mmr</code> <code>float</code> <p>MMR lambda parameter (0.0 = pure relevance, 1.0 = pure diversity). Defaults to 0.7.</p> <code>0.7</code> <p>Returns:</p> Type Description <code>list[tuple[str, float]]</code> <p>Deduplicated list of (item_id, score) tuples.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; results = [(\"doc1\", 0.9), (\"doc2\", 0.8), (\"doc1\", 0.7)]\n&gt;&gt;&gt; deduped = mmr_deduplicate(results)\n&gt;&gt;&gt; len(deduped) &lt;= len(results)\nTrue\n</code></pre> Source code in <code>src/search_api/service.py</code> <pre><code>def mmr_deduplicate(\n    results: list[tuple[str, float]], lambda_mmr: float = 0.7\n) -&gt; list[tuple[str, float]]:\n    \"\"\"Deduplicate results using Maximal Marginal Relevance (MMR).\n\n    Removes duplicate items while preserving diversity. Currently returns\n    results unchanged; full MMR implementation requires document embeddings.\n\n    Parameters\n    ----------\n    results : list[tuple[str, float]]\n        List of (item_id, score) tuples, sorted by score descending.\n    lambda_mmr : float, optional\n        MMR lambda parameter (0.0 = pure relevance, 1.0 = pure diversity).\n        Defaults to 0.7.\n\n    Returns\n    -------\n    list[tuple[str, float]]\n        Deduplicated list of (item_id, score) tuples.\n\n    Examples\n    --------\n    &gt;&gt;&gt; results = [(\"doc1\", 0.9), (\"doc2\", 0.8), (\"doc1\", 0.7)]\n    &gt;&gt;&gt; deduped = mmr_deduplicate(results)\n    &gt;&gt;&gt; len(deduped) &lt;= len(results)\n    True\n    \"\"\"\n    with with_fields(logger, operation=\"mmr_deduplicate\", lambda_mmr=lambda_mmr):\n        # Simple deduplication (full MMR requires document embeddings)\n        seen: set[str] = set()\n        deduped: list[tuple[str, float]] = []\n        for item_id, score in results:\n            if item_id not in seen:\n                seen.add(item_id)\n                deduped.append((item_id, score))\n\n        logger.debug(\n            \"MMR deduplication completed\",\n            extra={\"original_count\": len(results), \"deduped_count\": len(deduped)},\n        )\n        return deduped\n</code></pre>"},{"location":"modules/search_api.service/#search_apiservicerrf_fuse","title":"search_api.service.rrf_fuse","text":""},{"location":"modules/search_api.service/#search_api.service.rrf_fuse","title":"<code>search_api.service.rrf_fuse(rankers, k_rrf=60)</code>","text":"<p>Fuse multiple ranked lists using Reciprocal Rank Fusion (RRF).</p> <p>Combines multiple ranked lists into a single ranked list using RRF scoring. Each item's score is the sum of 1 / (k_rrf + rank) across all rankers.</p> <p>Parameters:</p> Name Type Description Default <code>rankers</code> <code>list[list[tuple[str, float]]]</code> <p>List of ranked lists, where each list contains (item_id, score) tuples.</p> required <code>k_rrf</code> <code>int</code> <p>RRF constant parameter (higher = more weight to top ranks). Defaults to 60.</p> <code>60</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>Dictionary mapping item IDs to fused RRF scores.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dense = [(\"doc1\", 0.9), (\"doc2\", 0.8)]\n&gt;&gt;&gt; sparse = [(\"doc2\", 0.85), (\"doc1\", 0.75)]\n&gt;&gt;&gt; fused = rrf_fuse([dense, sparse], k_rrf=60)\n&gt;&gt;&gt; \"doc1\" in fused and \"doc2\" in fused\nTrue\n</code></pre> Source code in <code>src/search_api/service.py</code> <pre><code>def rrf_fuse(rankers: list[list[tuple[str, float]]], k_rrf: int = 60) -&gt; dict[str, float]:\n    \"\"\"Fuse multiple ranked lists using Reciprocal Rank Fusion (RRF).\n\n    Combines multiple ranked lists into a single ranked list using RRF scoring.\n    Each item's score is the sum of 1 / (k_rrf + rank) across all rankers.\n\n    Parameters\n    ----------\n    rankers : list[list[tuple[str, float]]]\n        List of ranked lists, where each list contains (item_id, score) tuples.\n    k_rrf : int, optional\n        RRF constant parameter (higher = more weight to top ranks).\n        Defaults to 60.\n\n    Returns\n    -------\n    dict[str, float]\n        Dictionary mapping item IDs to fused RRF scores.\n\n    Examples\n    --------\n    &gt;&gt;&gt; dense = [(\"doc1\", 0.9), (\"doc2\", 0.8)]\n    &gt;&gt;&gt; sparse = [(\"doc2\", 0.85), (\"doc1\", 0.75)]\n    &gt;&gt;&gt; fused = rrf_fuse([dense, sparse], k_rrf=60)\n    &gt;&gt;&gt; \"doc1\" in fused and \"doc2\" in fused\n    True\n    \"\"\"\n    with with_fields(logger, operation=\"rrf_fuse\", k_rrf=k_rrf, num_rankers=len(rankers)):\n        scores: dict[str, float] = {}\n        for ranked in rankers:\n            for rank, (item_id, _score) in enumerate(ranked, start=1):\n                scores[item_id] = scores.get(item_id, 0.0) + 1.0 / (k_rrf + rank)\n        logger.debug(\"RRF fusion completed\", extra={\"num_items\": len(scores)})\n        return scores\n</code></pre>"},{"location":"modules/search_api.service/#search_apiservicesearch_service","title":"search_api.service.search_service","text":""},{"location":"modules/search_api.service/#search_api.service.search_service","title":"<code>search_api.service.search_service(results, *, metrics=None)</code>","text":"<p>Create typed search response from results.</p> <p>Wraps search results in an AgentSearchResponse envelope with metadata and metrics. Includes structured logging and duration tracking.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>list[VectorSearchResultTypedDict]</code> <p>List of typed search results.</p> required <code>metrics</code> <code>MetricsProvider | None</code> <p>Metrics provider for recording search metrics. If None, uses default provider. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>AgentSearchResponse</code> <p>Typed search response with results and metadata.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from search_api.types import VectorSearchResultTypedDict\n&gt;&gt;&gt; results: list[VectorSearchResultTypedDict] = [\n...     {\n...         \"symbol_id\": \"py:test.Foo\",\n...         \"score\": 0.9,\n...         \"lexical_score\": 0.8,\n...         \"vector_score\": 0.9,\n...         \"package\": \"test\",\n...         \"module\": \"test\",\n...         \"qname\": \"Foo\",\n...         \"kind\": \"class\",\n...         \"anchor\": {\"start_line\": 1},\n...         \"metadata\": {},\n...     }\n... ]\n&gt;&gt;&gt; response = search_service(results)\n&gt;&gt;&gt; response[\"total\"] == len(results)\nTrue\n</code></pre> Source code in <code>src/search_api/service.py</code> <pre><code>def search_service(\n    results: list[VectorSearchResultTypedDict],\n    *,\n    metrics: MetricsProvider | None = None,\n) -&gt; AgentSearchResponse:\n    \"\"\"Create typed search response from results.\n\n    Wraps search results in an AgentSearchResponse envelope with metadata\n    and metrics. Includes structured logging and duration tracking.\n\n    Parameters\n    ----------\n    results : list[VectorSearchResultTypedDict]\n        List of typed search results.\n    metrics : MetricsProvider | None, optional\n        Metrics provider for recording search metrics.\n        If None, uses default provider. Defaults to None.\n\n    Returns\n    -------\n    AgentSearchResponse\n        Typed search response with results and metadata.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from search_api.types import VectorSearchResultTypedDict\n    &gt;&gt;&gt; results: list[VectorSearchResultTypedDict] = [\n    ...     {\n    ...         \"symbol_id\": \"py:test.Foo\",\n    ...         \"score\": 0.9,\n    ...         \"lexical_score\": 0.8,\n    ...         \"vector_score\": 0.9,\n    ...         \"package\": \"test\",\n    ...         \"module\": \"test\",\n    ...         \"qname\": \"Foo\",\n    ...         \"kind\": \"class\",\n    ...         \"anchor\": {\"start_line\": 1},\n    ...         \"metadata\": {},\n    ...     }\n    ... ]\n    &gt;&gt;&gt; response = search_service(results)\n    &gt;&gt;&gt; response[\"total\"] == len(results)\n    True\n    \"\"\"\n    active_metrics = metrics or MetricsProvider.default()\n    start_time = time.time()\n\n    with (\n        with_fields(logger, operation=\"search_service\") as log_adapter,\n        observe_duration(active_metrics, \"search\", component=\"search_api\") as obs,\n    ):\n        try:\n            took_ms = int((time.time() - start_time) * 1000)\n            metadata: Mapping[str, JsonValue] = {\n                \"backend\": \"search_api\",\n                \"result_count\": len(results),\n            }\n            response: AgentSearchResponse = {\n                \"results\": results,\n                \"total\": len(results),\n                \"took_ms\": took_ms,\n                \"metadata\": metadata,\n            }\n\n            log_adapter.info(\n                \"Search service completed\",\n                extra={\n                    \"status\": \"success\",\n                    \"result_count\": len(results),\n                    \"took_ms\": took_ms,\n                },\n            )\n            obs.success()\n        except Exception as exc:\n            log_adapter.exception(\"Search service failed\", exc_info=exc)\n            obs.error()\n            raise\n        else:\n            return response\n</code></pre>"},{"location":"modules/search_api.splade_index/","title":"search_api.splade_index","text":""},{"location":"modules/search_api.splade_index/#search_apisplade_index","title":"search_api.splade_index","text":"<p>Example SPLADE index used in the search API fixtures</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_api.splade_index/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class SpladeDoc\n    class SpladeIndex\n</code></pre>"},{"location":"modules/search_api.splade_index/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_api.splade_index__future__.annotationscollections.abc.Sequencedataclasses.dataclassduckdbkgfoundry_common.navmap_loader.load_nav_metadatapathlib.Pathretyping.Finaltyping.TYPE_CHECKINGsearch_apisearch_api.splade_index code <p>See the full diagram: search_api.splade_index</p>"},{"location":"modules/search_api.splade_index/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>search_api.splade_index.SpladeDoc</li> <li>search_api.splade_index.SpladeIndex</li> <li>search_api.splade_index.tok</li> </ul>"},{"location":"modules/search_api.splade_index/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Sequence</code>, <code>dataclasses.dataclass</code>, <code>duckdb</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>pathlib.Path</code>, <code>re</code>, <code>typing.Final</code>, <code>typing.TYPE_CHECKING</code></p> <p>Imported by: search_api</p>"},{"location":"modules/search_api.splade_index/#contents","title":"Contents","text":""},{"location":"modules/search_api.splade_index/#search_apisplade_indexspladedoc","title":"search_api.splade_index.SpladeDoc","text":""},{"location":"modules/search_api.splade_index/#search_api.splade_index.SpladeDoc","title":"<code>search_api.splade_index.SpladeDoc</code>  <code>dataclass</code>","text":"<p>Document fixture for SPLADE index.</p> <p>Represents a document chunk loaded from the SPLADE index. Contains metadata and text content for sparse retrieval testing and demonstrations.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_id</code> <code>str</code> <p>Unique identifier for the chunk.</p> required <code>doc_id</code> <code>str</code> <p>Document identifier that this chunk belongs to.</p> required <code>section</code> <code>str</code> <p>Section name or identifier within the document.</p> required <code>text</code> <code>str</code> <p>Text content of the chunk.</p> required Source code in <code>src/search_api/splade_index.py</code> <pre><code>@dataclass\nclass SpladeDoc:\n    \"\"\"Document fixture for SPLADE index.\n\n    Represents a document chunk loaded from the SPLADE index. Contains\n    metadata and text content for sparse retrieval testing and demonstrations.\n\n    Parameters\n    ----------\n    chunk_id : str\n        Unique identifier for the chunk.\n    doc_id : str\n        Document identifier that this chunk belongs to.\n    section : str\n        Section name or identifier within the document.\n    text : str\n        Text content of the chunk.\n    \"\"\"\n\n    chunk_id: str\n    doc_id: str\n    section: str\n    text: str\n</code></pre>"},{"location":"modules/search_api.splade_index/#search_apisplade_indexspladeindex","title":"search_api.splade_index.SpladeIndex","text":""},{"location":"modules/search_api.splade_index/#search_api.splade_index.SpladeIndex","title":"<code>search_api.splade_index.SpladeIndex</code>","text":"<p>In-memory SPLADE index for tests and tutorials.</p> <p>Simple in-memory search index that loads document chunks from a DuckDB catalog and builds document frequency (DF) indexes for sparse retrieval. Used primarily for testing and tutorials as an example SPLADE index.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>Path to DuckDB catalog database file.</p> required <code>chunks_dataset_root</code> <code>str | None</code> <p>Optional override path to chunks dataset root. If None, uses the latest chunks dataset from the catalog. Defaults to None.</p> <code>None</code> <code>sparse_root</code> <code>str | None</code> <p>Optional sparse embeddings root (retained for interface compatibility). Currently unused. Defaults to None.</p> <code>None</code> Source code in <code>src/search_api/splade_index.py</code> <pre><code>class SpladeIndex:\n    \"\"\"In-memory SPLADE index for tests and tutorials.\n\n    Simple in-memory search index that loads document chunks from a DuckDB\n    catalog and builds document frequency (DF) indexes for sparse retrieval.\n    Used primarily for testing and tutorials as an example SPLADE index.\n\n    Parameters\n    ----------\n    db_path : str\n        Path to DuckDB catalog database file.\n    chunks_dataset_root : str | None, optional\n        Optional override path to chunks dataset root. If None, uses the\n        latest chunks dataset from the catalog. Defaults to None.\n    sparse_root : str | None, optional\n        Optional sparse embeddings root (retained for interface compatibility).\n        Currently unused. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        db_path: str,\n        chunks_dataset_root: str | None = None,\n        sparse_root: str | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the SPLADE index and load documents from DuckDB.\n\n        Connects to the DuckDB catalog, loads document chunks from the\n        specified or latest chunks dataset, and builds the document frequency\n        index for search.\n\n        Parameters\n        ----------\n        db_path : str\n            Path to DuckDB catalog database file.\n        chunks_dataset_root : str | None, optional\n            Optional override path to chunks dataset root. If None, uses the\n            latest chunks dataset from the catalog. Defaults to None.\n        sparse_root : str | None, optional\n            Optional sparse embeddings root (retained for interface compatibility).\n            Currently unused. Defaults to None.\n        \"\"\"\n        _ = sparse_root  # retained for interface compatibility\n        self.db_path = db_path\n        self.docs: list[SpladeDoc] = []\n        self.df: dict[str, int] = {}\n        self.N = 0\n        self._load(chunks_dataset_root)\n\n    def _load(self, chunks_root: str | None) -&gt; None:\n        if not Path(self.db_path).exists():\n            return\n\n        connection: duckdb.DuckDBPyConnection = duckdb.connect(self.db_path)\n        try:\n            root = self._resolve_chunks_root(connection, chunks_root)\n            rows = self._read_chunk_rows(connection, root) if root is not None else []\n        finally:\n            connection.close()\n\n        self._populate_docs(rows)\n        self._recompute_document_frequencies()\n\n    @staticmethod\n    def _resolve_chunks_root(\n        connection: duckdb.DuckDBPyConnection, override: str | None\n    ) -&gt; str | None:\n        if override:\n            return override\n        dataset: tuple[object, ...] | None = connection.execute(\n            \"SELECT parquet_root FROM datasets WHERE kind='chunks' ORDER BY created_at DESC LIMIT 1\"\n        ).fetchone()\n        if dataset is None:\n            return None\n        root_obj = dataset[0]\n        if not isinstance(root_obj, str):\n            msg = f\"Invalid parquet_root type: {type(root_obj)}\"\n            raise TypeError(msg)\n        return root_obj\n\n    @staticmethod\n    def _read_chunk_rows(\n        connection: duckdb.DuckDBPyConnection, root: str\n    ) -&gt; list[tuple[object, object, object, object]]:\n        root_path = Path(root)\n        parquet_pattern = str(root_path / \"*\" / \"*.parquet\")\n        sql = \"\"\"\n            SELECT c.chunk_id, c.doc_id, coalesce(c.section,''), c.text\n            FROM read_parquet(?, union_by_name=true) AS c\n        \"\"\"\n        raw_rows: Sequence[tuple[object, ...]] = connection.execute(\n            sql, [parquet_pattern]\n        ).fetchall()\n        typed_rows: list[tuple[object, object, object, object]] = []\n        for row in raw_rows:\n            if len(row) &lt; PARQUET_ROW_WIDTH:\n                continue\n            chunk_id_val, doc_id_val, section_val, text_val = row[:PARQUET_ROW_WIDTH]\n            typed_rows.append((chunk_id_val, doc_id_val, section_val, text_val))\n        return typed_rows\n\n    def _populate_docs(self, rows: list[tuple[object, object, object, object]]) -&gt; None:\n        for chunk_id_val, doc_id_val, section_val, text_val in rows:\n            doc = SpladeDoc(\n                chunk_id=str(chunk_id_val),\n                doc_id=str(doc_id_val) or \"urn:doc:fixture\",\n                section=str(section_val),\n                text=str(text_val) or \"\",\n            )\n            self.docs.append(doc)\n\n    def _recompute_document_frequencies(self) -&gt; None:\n        self.N = len(self.docs)\n        self.df.clear()\n        for doc in self.docs:\n            for term in set(tok(doc.text)):\n                self.df[term] = self.df.get(term, 0) + 1\n\n    def search(self, query: str, k: int = 10) -&gt; list[tuple[int, float]]:\n        \"\"\"Search documents using TF-IDF scoring.\n\n        Tokenizes the query and scores each document using TF-IDF (term\n        frequency-inverse document frequency). Returns top-k results sorted\n        by relevance score.\n\n        Parameters\n        ----------\n        query : str\n            Search query text.\n        k : int, optional\n            Number of top results to return. Defaults to 10.\n\n        Returns\n        -------\n        list[tuple[int, float]]\n            List of (document_index, score) tuples sorted by score descending.\n            Only documents with score &gt; 0 are included.\n        \"\"\"\n        if self.N == 0:\n            return []\n        terms = tok(query)\n        if not terms:\n            return []\n        scores = [0.0] * self.N\n        for index, doc in enumerate(self.docs):\n            term_freq: dict[str, int] = {}\n            for term in tok(doc.text):\n                term_freq[term] = term_freq.get(term, 0) + 1\n            score = 0.0\n            for term in terms:\n                if term in self.df:\n                    idf = (self.N + 1) / (self.df[term] + 0.5)\n                    score += term_freq.get(term, 0) * idf\n            scores[index] = score\n\n        # Explicitly type sorted callable to avoid Any\n        def key_func(item: tuple[int, float]) -&gt; float:\n            \"\"\"Extract score from (index, score) tuple for sorting.\n\n            Parameters\n            ----------\n            item : tuple[int, float]\n                Tuple of (index, score).\n\n            Returns\n            -------\n            float\n                Score value.\n            \"\"\"\n            return item[1]\n\n        ranked: list[tuple[int, float]] = sorted(enumerate(scores), key=key_func, reverse=True)\n        return [(idx, value) for idx, value in ranked[:k] if value &gt; 0.0]\n\n    def doc(self, index: int) -&gt; SpladeDoc:\n        \"\"\"Get document by index.\n\n        Retrieves the document at the specified index from the loaded\n        documents list.\n\n        Parameters\n        ----------\n        index : int\n            Document index (0-based).\n\n        Returns\n        -------\n        SpladeDoc\n            Document fixture at the specified index.\n        \"\"\"\n        return self.docs[index]\n</code></pre>"},{"location":"modules/search_api.splade_index/#search_api.splade_index.SpladeIndex.__init__","title":"<code>__init__(db_path, chunks_dataset_root=None, sparse_root=None)</code>","text":"<p>Initialize the SPLADE index and load documents from DuckDB.</p> <p>Connects to the DuckDB catalog, loads document chunks from the specified or latest chunks dataset, and builds the document frequency index for search.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>Path to DuckDB catalog database file.</p> required <code>chunks_dataset_root</code> <code>str | None</code> <p>Optional override path to chunks dataset root. If None, uses the latest chunks dataset from the catalog. Defaults to None.</p> <code>None</code> <code>sparse_root</code> <code>str | None</code> <p>Optional sparse embeddings root (retained for interface compatibility). Currently unused. Defaults to None.</p> <code>None</code> Source code in <code>src/search_api/splade_index.py</code> <pre><code>def __init__(\n    self,\n    db_path: str,\n    chunks_dataset_root: str | None = None,\n    sparse_root: str | None = None,\n) -&gt; None:\n    \"\"\"Initialize the SPLADE index and load documents from DuckDB.\n\n    Connects to the DuckDB catalog, loads document chunks from the\n    specified or latest chunks dataset, and builds the document frequency\n    index for search.\n\n    Parameters\n    ----------\n    db_path : str\n        Path to DuckDB catalog database file.\n    chunks_dataset_root : str | None, optional\n        Optional override path to chunks dataset root. If None, uses the\n        latest chunks dataset from the catalog. Defaults to None.\n    sparse_root : str | None, optional\n        Optional sparse embeddings root (retained for interface compatibility).\n        Currently unused. Defaults to None.\n    \"\"\"\n    _ = sparse_root  # retained for interface compatibility\n    self.db_path = db_path\n    self.docs: list[SpladeDoc] = []\n    self.df: dict[str, int] = {}\n    self.N = 0\n    self._load(chunks_dataset_root)\n</code></pre>"},{"location":"modules/search_api.splade_index/#search_api.splade_index.SpladeIndex.doc","title":"<code>doc(index)</code>","text":"<p>Get document by index.</p> <p>Retrieves the document at the specified index from the loaded documents list.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Document index (0-based).</p> required <p>Returns:</p> Type Description <code>SpladeDoc</code> <p>Document fixture at the specified index.</p> Source code in <code>src/search_api/splade_index.py</code> <pre><code>def doc(self, index: int) -&gt; SpladeDoc:\n    \"\"\"Get document by index.\n\n    Retrieves the document at the specified index from the loaded\n    documents list.\n\n    Parameters\n    ----------\n    index : int\n        Document index (0-based).\n\n    Returns\n    -------\n    SpladeDoc\n        Document fixture at the specified index.\n    \"\"\"\n    return self.docs[index]\n</code></pre>"},{"location":"modules/search_api.splade_index/#search_api.splade_index.SpladeIndex.search","title":"<code>search(query, k=10)</code>","text":"<p>Search documents using TF-IDF scoring.</p> <p>Tokenizes the query and scores each document using TF-IDF (term frequency-inverse document frequency). Returns top-k results sorted by relevance score.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query text.</p> required <code>k</code> <code>int</code> <p>Number of top results to return. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[tuple[int, float]]</code> <p>List of (document_index, score) tuples sorted by score descending. Only documents with score &gt; 0 are included.</p> Source code in <code>src/search_api/splade_index.py</code> <pre><code>def search(self, query: str, k: int = 10) -&gt; list[tuple[int, float]]:\n    \"\"\"Search documents using TF-IDF scoring.\n\n    Tokenizes the query and scores each document using TF-IDF (term\n    frequency-inverse document frequency). Returns top-k results sorted\n    by relevance score.\n\n    Parameters\n    ----------\n    query : str\n        Search query text.\n    k : int, optional\n        Number of top results to return. Defaults to 10.\n\n    Returns\n    -------\n    list[tuple[int, float]]\n        List of (document_index, score) tuples sorted by score descending.\n        Only documents with score &gt; 0 are included.\n    \"\"\"\n    if self.N == 0:\n        return []\n    terms = tok(query)\n    if not terms:\n        return []\n    scores = [0.0] * self.N\n    for index, doc in enumerate(self.docs):\n        term_freq: dict[str, int] = {}\n        for term in tok(doc.text):\n            term_freq[term] = term_freq.get(term, 0) + 1\n        score = 0.0\n        for term in terms:\n            if term in self.df:\n                idf = (self.N + 1) / (self.df[term] + 0.5)\n                score += term_freq.get(term, 0) * idf\n        scores[index] = score\n\n    # Explicitly type sorted callable to avoid Any\n    def key_func(item: tuple[int, float]) -&gt; float:\n        \"\"\"Extract score from (index, score) tuple for sorting.\n\n        Parameters\n        ----------\n        item : tuple[int, float]\n            Tuple of (index, score).\n\n        Returns\n        -------\n        float\n            Score value.\n        \"\"\"\n        return item[1]\n\n    ranked: list[tuple[int, float]] = sorted(enumerate(scores), key=key_func, reverse=True)\n    return [(idx, value) for idx, value in ranked[:k] if value &gt; 0.0]\n</code></pre>"},{"location":"modules/search_api.splade_index/#search_apisplade_indextok","title":"search_api.splade_index.tok","text":""},{"location":"modules/search_api.splade_index/#search_api.splade_index.tok","title":"<code>search_api.splade_index.tok(text)</code>","text":"<p>Tokenize text into lowercase alphanumeric tokens.</p> <p>Extracts alphanumeric sequences from the input text and converts them to lowercase. Uses a regex pattern to match alphanumeric characters.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Input text to tokenize. Empty strings are handled gracefully.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of lowercase alphanumeric tokens extracted from the text.</p> Source code in <code>src/search_api/splade_index.py</code> <pre><code>def tok(text: str) -&gt; list[str]:\n    \"\"\"Tokenize text into lowercase alphanumeric tokens.\n\n    Extracts alphanumeric sequences from the input text and converts them\n    to lowercase. Uses a regex pattern to match alphanumeric characters.\n\n    Parameters\n    ----------\n    text : str\n        Input text to tokenize. Empty strings are handled gracefully.\n\n    Returns\n    -------\n    list[str]\n        List of lowercase alphanumeric tokens extracted from the text.\n    \"\"\"\n    # re.findall returns list[str] when pattern has no groups\n    matches: list[str] = TOKEN.findall(text or \"\")\n    return [token.lower() for token in matches]\n</code></pre>"},{"location":"modules/search_api.types/","title":"search_api.types","text":""},{"location":"modules/search_api.types/#search_apitypes","title":"search_api.types","text":"<p>Vector search protocols and typed result structures</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_api.types/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class AgentSearchQuery\n    class AgentSearchResponse\n    class TypedDict\n    TypedDict &lt;|-- AgentSearchResponse\n    class BM25IndexProtocol\n    class Protocol\n    Protocol &lt;|-- BM25IndexProtocol\n    class FaissIndexProtocol\n    Protocol &lt;|-- FaissIndexProtocol\n    class FaissModuleProtocol\n    Protocol &lt;|-- FaissModuleProtocol\n    class GpuClonerOptionsProtocol\n    Protocol &lt;|-- GpuClonerOptionsProtocol\n    class GpuResourcesProtocol\n    Protocol &lt;|-- GpuResourcesProtocol\n    class SpladeEncoderProtocol\n    Protocol &lt;|-- SpladeEncoderProtocol\n    class VectorSearchResult\n    class VectorSearchResultTypedDict\n    TypedDict &lt;|-- VectorSearchResultTypedDict\n    class _FaissModuleAdapter\n    class _LegacyFaissModule\n    Protocol &lt;|-- _LegacyFaissModule\n</code></pre>"},{"location":"modules/search_api.types/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_api.types__future__.annotationscollections.abc.Callablecollections.abc.Mappingcollections.abc.Sequencecontextlib.suppressdataclasses.dataclasskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.problem_details.JsonValuenumpynumpy.typingnumpy.typing.NDArrayoperator.attrgettertyping.Protocoltyping.TYPE_CHECKINGtyping.TypedDicttyping.castsearch_apisearch_api.types code <p>See the full diagram: search_api.types</p>"},{"location":"modules/search_api.types/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>search_api.types.AgentSearchQuery</li> <li>search_api.types.AgentSearchResponse</li> <li>search_api.types.BM25IndexProtocol</li> <li>search_api.types._labels_or_default</li> <li>search_api.types._legacy_index_flat_ip</li> <li>search_api.types._legacy_index_id_map2</li> </ul>"},{"location":"modules/search_api.types/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Callable</code>, <code>collections.abc.Mapping</code>, <code>collections.abc.Sequence</code>, <code>contextlib.suppress</code>, <code>dataclasses.dataclass</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.problem_details.JsonValue</code>, <code>numpy</code>, <code>numpy.typing</code>, <code>numpy.typing.NDArray</code>, <code>operator.attrgetter</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.TypedDict</code>, <code>typing.cast</code></p> <p>Imported by: search_api</p>"},{"location":"modules/search_api.types/#contents","title":"Contents","text":""},{"location":"modules/search_api.types/#search_apitypesagentsearchquery","title":"search_api.types.AgentSearchQuery","text":""},{"location":"modules/search_api.types/#search_api.types.AgentSearchQuery","title":"<code>search_api.types.AgentSearchQuery</code>  <code>dataclass</code>","text":"<p>Query parameters for agent catalog search operations.</p> <p>This dataclass represents a search query with typed fields for query text, result count, filtering facets, and explanation flags. All fields are validated at construction time.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query text (tokenized and normalized internally). Cannot be empty.</p> required <code>k</code> <code>int</code> <p>Maximum number of results to return. Must be positive. Defaults to 10.</p> <code>10</code> <code>facets</code> <code>Mapping[str, str] | None</code> <p>Optional facet filters for narrowing search results. Common facets include: package, module, kind, stability, deprecated. Values are matched exactly (case-sensitive). Defaults to None.</p> <code>None</code> <code>explain</code> <code>bool</code> <p>Whether to include explanation metadata in results. When True, results include detailed scoring breakdowns and match highlights. Defaults to False.</p> <code>False</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry.search_api.types import AgentSearchQuery\n&gt;&gt;&gt; query = AgentSearchQuery(\n...     query=\"vector store\",\n...     k=10,\n...     facets={\"package\": \"search_api\"},\n...     explain=True,\n... )\n&gt;&gt;&gt; assert query.k == 10\n&gt;&gt;&gt; assert query.facets[\"package\"] == \"search_api\"\n</code></pre> Source code in <code>src/search_api/types.py</code> <pre><code>@dataclass(frozen=True, slots=True)\n# [nav:anchor AgentSearchQuery]\nclass AgentSearchQuery:\n    \"\"\"Query parameters for agent catalog search operations.\n\n    This dataclass represents a search query with typed fields for query text,\n    result count, filtering facets, and explanation flags. All fields are\n    validated at construction time.\n\n    Parameters\n    ----------\n    query : str\n        Search query text (tokenized and normalized internally). Cannot be empty.\n    k : int, optional\n        Maximum number of results to return. Must be positive.\n        Defaults to 10.\n    facets : Mapping[str, str] | None, optional\n        Optional facet filters for narrowing search results. Common facets include:\n        package, module, kind, stability, deprecated. Values are matched exactly\n        (case-sensitive). Defaults to None.\n    explain : bool, optional\n        Whether to include explanation metadata in results. When True, results include\n        detailed scoring breakdowns and match highlights. Defaults to False.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry.search_api.types import AgentSearchQuery\n    &gt;&gt;&gt; query = AgentSearchQuery(\n    ...     query=\"vector store\",\n    ...     k=10,\n    ...     facets={\"package\": \"search_api\"},\n    ...     explain=True,\n    ... )\n    &gt;&gt;&gt; assert query.k == 10\n    &gt;&gt;&gt; assert query.facets[\"package\"] == \"search_api\"\n    \"\"\"\n\n    query: str\n    \"\"\"Search query text (tokenized and normalized internally).\"\"\"\n\n    k: int = 10\n    \"\"\"Maximum number of results to return.\n\n    Must be positive and typically bounded (e.g., 1 &lt;= k &lt;= 100).\n    \"\"\"\n\n    facets: Mapping[str, str] | None = None\n    \"\"\"Optional facet filters for narrowing search results.\n\n    Common facets include: package, module, kind, stability, deprecated.\n    Values are matched exactly (case-sensitive).\n    \"\"\"\n\n    explain: bool = False\n    \"\"\"Whether to include explanation metadata in results.\n\n    When True, results include detailed scoring breakdowns and match highlights for debugging and\n    transparency.\n    \"\"\"\n\n    def __post_init__(self) -&gt; None:\n        \"\"\"Validate query parameters.\n\n        Ensures query text is non-empty and k is positive. Called automatically\n        by dataclass after initialization.\n\n        Raises\n        ------\n        ValueError\n            If query is empty or k is not positive.\n        \"\"\"\n        if not self.query.strip():\n            msg = \"Query text cannot be empty\"\n            raise ValueError(msg)\n        if self.k &lt;= 0:\n            msg = f\"k must be positive, got {self.k}\"\n            raise ValueError(msg)\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.AgentSearchQuery.explain","title":"<code>explain = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to include explanation metadata in results.</p> <p>When True, results include detailed scoring breakdowns and match highlights for debugging and transparency.</p>"},{"location":"modules/search_api.types/#search_api.types.AgentSearchQuery.facets","title":"<code>facets = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Optional facet filters for narrowing search results.</p> <p>Common facets include: package, module, kind, stability, deprecated. Values are matched exactly (case-sensitive).</p>"},{"location":"modules/search_api.types/#search_api.types.AgentSearchQuery.k","title":"<code>k = 10</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Maximum number of results to return.</p> <p>Must be positive and typically bounded (e.g., 1 &lt;= k &lt;= 100).</p>"},{"location":"modules/search_api.types/#search_api.types.AgentSearchQuery.query","title":"<code>query</code>  <code>instance-attribute</code>","text":"<p>Search query text (tokenized and normalized internally).</p>"},{"location":"modules/search_api.types/#search_api.types.AgentSearchQuery.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Validate query parameters.</p> <p>Ensures query text is non-empty and k is positive. Called automatically by dataclass after initialization.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If query is empty or k is not positive.</p> Source code in <code>src/search_api/types.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Validate query parameters.\n\n    Ensures query text is non-empty and k is positive. Called automatically\n    by dataclass after initialization.\n\n    Raises\n    ------\n    ValueError\n        If query is empty or k is not positive.\n    \"\"\"\n    if not self.query.strip():\n        msg = \"Query text cannot be empty\"\n        raise ValueError(msg)\n    if self.k &lt;= 0:\n        msg = f\"k must be positive, got {self.k}\"\n        raise ValueError(msg)\n</code></pre>"},{"location":"modules/search_api.types/#search_apitypesagentsearchresponse","title":"search_api.types.AgentSearchResponse","text":"<p>Bases: TypedDict</p>"},{"location":"modules/search_api.types/#search_api.types.AgentSearchResponse","title":"<code>search_api.types.AgentSearchResponse</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>TypedDict representation of agent catalog search response.</p> <p>This TypedDict represents a complete search response from the agent catalog with results, metadata, and performance metrics. Used for JSON serialization and API responses.</p> <p>Attributes:</p> Name Type Description <code>results</code> <code>list[VectorSearchResultTypedDict]</code> <p>List of search results, sorted by score descending.</p> <code>total</code> <code>int</code> <p>Total number of results (may exceed len(results) if truncated).</p> <code>took_ms</code> <code>int</code> <p>Query execution time in milliseconds.</p> <code>metadata</code> <code>Mapping[str, JsonValue]</code> <p>Response metadata (alpha, backend, query_info, etc.).</p> Source code in <code>src/search_api/types.py</code> <pre><code>class AgentSearchResponse(TypedDict, total=True):\n    \"\"\"TypedDict representation of agent catalog search response.\n\n    This TypedDict represents a complete search response from the agent catalog\n    with results, metadata, and performance metrics. Used for JSON serialization\n    and API responses.\n\n    Attributes\n    ----------\n    results : list[VectorSearchResultTypedDict]\n        List of search results, sorted by score descending.\n    total : int\n        Total number of results (may exceed len(results) if truncated).\n    took_ms : int\n        Query execution time in milliseconds.\n    metadata : Mapping[str, JsonValue]\n        Response metadata (alpha, backend, query_info, etc.).\n    \"\"\"\n\n    results: list[VectorSearchResultTypedDict]\n    \"\"\"List of search results, sorted by score descending.\"\"\"\n\n    total: int\n    \"\"\"Total number of results (may exceed len(results) if truncated).\"\"\"\n\n    took_ms: int\n    \"\"\"Query execution time in milliseconds.\"\"\"\n\n    metadata: Mapping[str, JsonValue]\n    \"\"\"Response metadata (alpha, backend, query_info, etc.).\"\"\"\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.AgentSearchResponse.metadata","title":"<code>metadata</code>  <code>instance-attribute</code>","text":"<p>Response metadata (alpha, backend, query_info, etc.).</p>"},{"location":"modules/search_api.types/#search_api.types.AgentSearchResponse.results","title":"<code>results</code>  <code>instance-attribute</code>","text":"<p>List of search results, sorted by score descending.</p>"},{"location":"modules/search_api.types/#search_api.types.AgentSearchResponse.took_ms","title":"<code>took_ms</code>  <code>instance-attribute</code>","text":"<p>Query execution time in milliseconds.</p>"},{"location":"modules/search_api.types/#search_api.types.AgentSearchResponse.total","title":"<code>total</code>  <code>instance-attribute</code>","text":"<p>Total number of results (may exceed len(results) if truncated).</p>"},{"location":"modules/search_api.types/#search_apitypesbm25indexprotocol","title":"search_api.types.BM25IndexProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/search_api.types/#search_api.types.BM25IndexProtocol","title":"<code>search_api.types.BM25IndexProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for BM25 lexical search index implementations.</p> <p>BM25 indexes provide term-frequency based lexical search over document collections. This protocol defines the interface required for BM25-based search operations.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry.search_api.types import BM25IndexProtocol\n&gt;&gt;&gt; class MyBM25Index:\n...     def search(self, query: str, k: int = 10) -&gt; list[tuple[str, float]]:\n...         # Return (doc_id, score) tuples\n...         return [(\"doc1\", 0.95), (\"doc2\", 0.87)]\n&gt;&gt;&gt; index: BM25IndexProtocol = MyBM25Index()\n&gt;&gt;&gt; results = index.search(\"search query\", k=5)\n&gt;&gt;&gt; assert len(results) &lt;= 5\n</code></pre> Source code in <code>src/search_api/types.py</code> <pre><code>class BM25IndexProtocol(Protocol):\n    \"\"\"Protocol for BM25 lexical search index implementations.\n\n    BM25 indexes provide term-frequency based lexical search over document\n    collections. This protocol defines the interface required for BM25-based\n    search operations.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry.search_api.types import BM25IndexProtocol\n    &gt;&gt;&gt; class MyBM25Index:\n    ...     def search(self, query: str, k: int = 10) -&gt; list[tuple[str, float]]:\n    ...         # Return (doc_id, score) tuples\n    ...         return [(\"doc1\", 0.95), (\"doc2\", 0.87)]\n    &gt;&gt;&gt; index: BM25IndexProtocol = MyBM25Index()\n    &gt;&gt;&gt; results = index.search(\"search query\", k=5)\n    &gt;&gt;&gt; assert len(results) &lt;= 5\n    \"\"\"\n\n    def search(self, query: str, k: int = 10) -&gt; list[tuple[str, float]]:\n        \"\"\"Search the index for documents matching the query.\n\n        Searches the BM25 index for documents matching the query string.\n        Returns top-k results sorted by relevance score.\n\n        Parameters\n        ----------\n        query : str\n            Search query string (will be tokenized internally).\n        k : int, optional\n            Maximum number of results to return. Defaults to 10.\n\n        Returns\n        -------\n        list[tuple[str, float]]\n            List of (document_id, score) tuples, sorted by score descending.\n            Scores are BM25 relevance scores (higher is better).\n\n        Raises\n        ------\n        RuntimeError\n            If the index has not been built or loaded.\n        ValueError\n            If the query is empty or invalid.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.BM25IndexProtocol.search","title":"<code>search(query, k=10)</code>","text":"<p>Search the index for documents matching the query.</p> <p>Searches the BM25 index for documents matching the query string. Returns top-k results sorted by relevance score.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query string (will be tokenized internally).</p> required <code>k</code> <code>int</code> <p>Maximum number of results to return. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>list[tuple[str, float]]</code> <p>List of (document_id, score) tuples, sorted by score descending. Scores are BM25 relevance scores (higher is better).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the index has not been built or loaded.</p> <code>ValueError</code> <p>If the query is empty or invalid.</p> Source code in <code>src/search_api/types.py</code> <pre><code>def search(self, query: str, k: int = 10) -&gt; list[tuple[str, float]]:\n    \"\"\"Search the index for documents matching the query.\n\n    Searches the BM25 index for documents matching the query string.\n    Returns top-k results sorted by relevance score.\n\n    Parameters\n    ----------\n    query : str\n        Search query string (will be tokenized internally).\n    k : int, optional\n        Maximum number of results to return. Defaults to 10.\n\n    Returns\n    -------\n    list[tuple[str, float]]\n        List of (document_id, score) tuples, sorted by score descending.\n        Scores are BM25 relevance scores (higher is better).\n\n    Raises\n    ------\n    RuntimeError\n        If the index has not been built or loaded.\n    ValueError\n        If the query is empty or invalid.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/search_api.types/#search_apitypesfaissindexprotocol","title":"search_api.types.FaissIndexProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/search_api.types/#search_api.types.FaissIndexProtocol","title":"<code>search_api.types.FaissIndexProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for FAISS-compatible vector indexes.</p> <p>This protocol defines the minimum interface required for vector search operations. Implementations may support additional features (GPU acceleration, quantization, etc.) but must satisfy these core methods.</p> <p>Performance expectations: - <code>add()</code>: O(n) where n is the number of vectors; may require training first - <code>search()</code>: O(k * log(n)) for approximate indexes; O(n) for exact search - Indexes are typically trained before adding vectors (not shown in protocol)</p> <p>Concurrency notes: - Index operations are not thread-safe; serialize access from multiple threads - GPU indexes may block the calling thread during kernel execution - For async code, run index operations in thread pools to avoid blocking</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from kgfoundry.search_api.types import FaissIndexProtocol, VectorArray\n&gt;&gt;&gt; class SimpleIndex:\n...     def add(self, vectors: VectorArray) -&gt; None:\n...         self._vectors = vectors\n...\n...     def search(\n...         self, vectors: VectorArray, k: int\n...     ) -&gt; tuple[NDArray[np.float32], NDArray[np.int64]]:\n...         # Simple inner product search\n...         scores = vectors @ self._vectors.T\n...         indices = np.argsort(-scores, axis=1)[:, :k]\n...         distances = np.take_along_axis(scores, indices, axis=1)\n...         return distances.astype(np.float32), indices.astype(np.int64)\n&gt;&gt;&gt; idx: FaissIndexProtocol = SimpleIndex()\n</code></pre> Source code in <code>src/search_api/types.py</code> <pre><code>class FaissIndexProtocol(Protocol):\n    \"\"\"Protocol for FAISS-compatible vector indexes.\n\n    This protocol defines the minimum interface required for vector search\n    operations. Implementations may support additional features (GPU acceleration,\n    quantization, etc.) but must satisfy these core methods.\n\n    Performance expectations:\n    - `add()`: O(n) where n is the number of vectors; may require training first\n    - `search()`: O(k * log(n)) for approximate indexes; O(n) for exact search\n    - Indexes are typically trained before adding vectors (not shown in protocol)\n\n    Concurrency notes:\n    - Index operations are not thread-safe; serialize access from multiple threads\n    - GPU indexes may block the calling thread during kernel execution\n    - For async code, run index operations in thread pools to avoid blocking\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from kgfoundry.search_api.types import FaissIndexProtocol, VectorArray\n    &gt;&gt;&gt; class SimpleIndex:\n    ...     def add(self, vectors: VectorArray) -&gt; None:\n    ...         self._vectors = vectors\n    ...\n    ...     def search(\n    ...         self, vectors: VectorArray, k: int\n    ...     ) -&gt; tuple[NDArray[np.float32], NDArray[np.int64]]:\n    ...         # Simple inner product search\n    ...         scores = vectors @ self._vectors.T\n    ...         indices = np.argsort(-scores, axis=1)[:, :k]\n    ...         distances = np.take_along_axis(scores, indices, axis=1)\n    ...         return distances.astype(np.float32), indices.astype(np.int64)\n    &gt;&gt;&gt; idx: FaissIndexProtocol = SimpleIndex()\n    \"\"\"\n\n    def add(self, vectors: VectorArray) -&gt; None:\n        \"\"\"Add vectors to the index.\n\n        Adds vectors to the index for future search operations. Vectors must\n        match the index dimension and be normalized to unit length for\n        inner-product search.\n\n        Parameters\n        ----------\n        vectors : VectorArray\n            Array of shape (n_vectors, dimension) with float32 dtype.\n            Vectors should be normalized to unit length for inner-product search.\n\n        Raises\n        ------\n        RuntimeError\n            If index has not been trained (for trainable indexes).\n        ValueError\n            If vector dimensions do not match index configuration.\n        \"\"\"\n        ...\n\n    def search(self, vectors: VectorArray, k: int) -&gt; tuple[NDArray[np.float32], NDArray[np.int64]]:\n        \"\"\"Search for nearest neighbors.\n\n        Searches the index for the k nearest neighbors of each query vector.\n        Returns similarity scores and indices for the top-k matches.\n\n        Parameters\n        ----------\n        vectors : VectorArray\n            Query vectors of shape (n_queries, dimension) with float32 dtype.\n            Must be normalized to unit length for inner-product search.\n        k : int\n            Number of nearest neighbors to return per query.\n\n        Returns\n        -------\n        tuple[NDArray[np.float32], NDArray[np.int64]]\n            Tuple of (distances, indices) where:\n            - distances: shape (n_queries, k) with similarity scores (higher is better for IP)\n            - indices: shape (n_queries, k) with vector indices in the index\n\n        Notes\n        -----\n        - For inner-product metrics, higher scores indicate better matches\n        - Invalid indices (no match) are typically represented as -1\n        - Search performance depends on index type (exact vs approximate)\n        \"\"\"\n        ...\n\n    def train(self, vectors: VectorArray) -&gt; None:\n        \"\"\"Train the index with sample vectors (optional method).\n\n        Some FAISS indexes (e.g., quantized indexes) require training before\n        adding vectors. This method is optional - not all indexes support it.\n\n        Parameters\n        ----------\n        vectors : VectorArray\n            Training vectors of shape (n_train, dimension) with float32 dtype.\n\n        Notes\n        -----\n        - Flat indexes (exact search) do not require training\n        - Quantized indexes (IVF, PQ) require training before add()\n        - Calling train() on a non-trainable index is a no-op\n        \"\"\"\n        ...\n\n    def add_with_ids(self, vectors: VectorArray, ids: IndexArray) -&gt; None:\n        \"\"\"Add vectors with explicit IDs (optional method).\n\n        Some FAISS indexes support adding vectors with explicit IDs rather than\n        sequential indices. This method is optional - not all indexes support it.\n\n        Parameters\n        ----------\n        vectors : VectorArray\n            Vectors to add, shape (n_vectors, dimension) with float32 dtype.\n        ids : IndexArray\n            Explicit IDs for each vector, shape (n_vectors,) with int64 dtype.\n\n        Notes\n        -----\n        - IndexIDMap2 wrapper enables add_with_ids for any base index\n        - If not supported, use add() which assigns sequential IDs\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.FaissIndexProtocol.add","title":"<code>add(vectors)</code>","text":"<p>Add vectors to the index.</p> <p>Adds vectors to the index for future search operations. Vectors must match the index dimension and be normalized to unit length for inner-product search.</p> <p>Parameters:</p> Name Type Description Default <code>vectors</code> <code>VectorArray</code> <p>Array of shape (n_vectors, dimension) with float32 dtype. Vectors should be normalized to unit length for inner-product search.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If index has not been trained (for trainable indexes).</p> <code>ValueError</code> <p>If vector dimensions do not match index configuration.</p> Source code in <code>src/search_api/types.py</code> <pre><code>def add(self, vectors: VectorArray) -&gt; None:\n    \"\"\"Add vectors to the index.\n\n    Adds vectors to the index for future search operations. Vectors must\n    match the index dimension and be normalized to unit length for\n    inner-product search.\n\n    Parameters\n    ----------\n    vectors : VectorArray\n        Array of shape (n_vectors, dimension) with float32 dtype.\n        Vectors should be normalized to unit length for inner-product search.\n\n    Raises\n    ------\n    RuntimeError\n        If index has not been trained (for trainable indexes).\n    ValueError\n        If vector dimensions do not match index configuration.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.FaissIndexProtocol.add_with_ids","title":"<code>add_with_ids(vectors, ids)</code>","text":"<p>Add vectors with explicit IDs (optional method).</p> <p>Some FAISS indexes support adding vectors with explicit IDs rather than sequential indices. This method is optional - not all indexes support it.</p> <p>Parameters:</p> Name Type Description Default <code>vectors</code> <code>VectorArray</code> <p>Vectors to add, shape (n_vectors, dimension) with float32 dtype.</p> required <code>ids</code> <code>IndexArray</code> <p>Explicit IDs for each vector, shape (n_vectors,) with int64 dtype.</p> required Notes <ul> <li>IndexIDMap2 wrapper enables add_with_ids for any base index</li> <li>If not supported, use add() which assigns sequential IDs</li> </ul> Source code in <code>src/search_api/types.py</code> <pre><code>def add_with_ids(self, vectors: VectorArray, ids: IndexArray) -&gt; None:\n    \"\"\"Add vectors with explicit IDs (optional method).\n\n    Some FAISS indexes support adding vectors with explicit IDs rather than\n    sequential indices. This method is optional - not all indexes support it.\n\n    Parameters\n    ----------\n    vectors : VectorArray\n        Vectors to add, shape (n_vectors, dimension) with float32 dtype.\n    ids : IndexArray\n        Explicit IDs for each vector, shape (n_vectors,) with int64 dtype.\n\n    Notes\n    -----\n    - IndexIDMap2 wrapper enables add_with_ids for any base index\n    - If not supported, use add() which assigns sequential IDs\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.FaissIndexProtocol.search","title":"<code>search(vectors, k)</code>","text":"<p>Search for nearest neighbors.</p> <p>Searches the index for the k nearest neighbors of each query vector. Returns similarity scores and indices for the top-k matches.</p> <p>Parameters:</p> Name Type Description Default <code>vectors</code> <code>VectorArray</code> <p>Query vectors of shape (n_queries, dimension) with float32 dtype. Must be normalized to unit length for inner-product search.</p> required <code>k</code> <code>int</code> <p>Number of nearest neighbors to return per query.</p> required <p>Returns:</p> Type Description <code>tuple[NDArray[float32], NDArray[int64]]</code> <p>Tuple of (distances, indices) where: - distances: shape (n_queries, k) with similarity scores (higher is better for IP) - indices: shape (n_queries, k) with vector indices in the index</p> Notes <ul> <li>For inner-product metrics, higher scores indicate better matches</li> <li>Invalid indices (no match) are typically represented as -1</li> <li>Search performance depends on index type (exact vs approximate)</li> </ul> Source code in <code>src/search_api/types.py</code> <pre><code>def search(self, vectors: VectorArray, k: int) -&gt; tuple[NDArray[np.float32], NDArray[np.int64]]:\n    \"\"\"Search for nearest neighbors.\n\n    Searches the index for the k nearest neighbors of each query vector.\n    Returns similarity scores and indices for the top-k matches.\n\n    Parameters\n    ----------\n    vectors : VectorArray\n        Query vectors of shape (n_queries, dimension) with float32 dtype.\n        Must be normalized to unit length for inner-product search.\n    k : int\n        Number of nearest neighbors to return per query.\n\n    Returns\n    -------\n    tuple[NDArray[np.float32], NDArray[np.int64]]\n        Tuple of (distances, indices) where:\n        - distances: shape (n_queries, k) with similarity scores (higher is better for IP)\n        - indices: shape (n_queries, k) with vector indices in the index\n\n    Notes\n    -----\n    - For inner-product metrics, higher scores indicate better matches\n    - Invalid indices (no match) are typically represented as -1\n    - Search performance depends on index type (exact vs approximate)\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.FaissIndexProtocol.train","title":"<code>train(vectors)</code>","text":"<p>Train the index with sample vectors (optional method).</p> <p>Some FAISS indexes (e.g., quantized indexes) require training before adding vectors. This method is optional - not all indexes support it.</p> <p>Parameters:</p> Name Type Description Default <code>vectors</code> <code>VectorArray</code> <p>Training vectors of shape (n_train, dimension) with float32 dtype.</p> required Notes <ul> <li>Flat indexes (exact search) do not require training</li> <li>Quantized indexes (IVF, PQ) require training before add()</li> <li>Calling train() on a non-trainable index is a no-op</li> </ul> Source code in <code>src/search_api/types.py</code> <pre><code>def train(self, vectors: VectorArray) -&gt; None:\n    \"\"\"Train the index with sample vectors (optional method).\n\n    Some FAISS indexes (e.g., quantized indexes) require training before\n    adding vectors. This method is optional - not all indexes support it.\n\n    Parameters\n    ----------\n    vectors : VectorArray\n        Training vectors of shape (n_train, dimension) with float32 dtype.\n\n    Notes\n    -----\n    - Flat indexes (exact search) do not require training\n    - Quantized indexes (IVF, PQ) require training before add()\n    - Calling train() on a non-trainable index is a no-op\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/search_api.types/#search_apitypesfaissmoduleprotocol","title":"search_api.types.FaissModuleProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/search_api.types/#search_api.types.FaissModuleProtocol","title":"<code>search_api.types.FaissModuleProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for FAISS module surface used by adapters.</p> <p>This protocol describes the subset of FAISS API used by kgfoundry adapters. It enables type checking and allows fallback implementations (e.g., <code>_SimpleFaissModule</code>) to satisfy the protocol.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry.search_api.types import FaissModuleProtocol, FaissIndexProtocol\n&gt;&gt;&gt; class MockFaissModule:\n...     METRIC_INNER_PRODUCT = 1\n...\n...     def IndexFlatIP(self, dimension: int) -&gt; FaissIndexProtocol: ...\n...     def write_index(self, index: FaissIndexProtocol, path: str) -&gt; None: ...\n...     def read_index(self, path: str) -&gt; FaissIndexProtocol: ...\n...     def normalize_L2(self, vectors: VectorArray) -&gt; None: ...\n&gt;&gt;&gt; module: FaissModuleProtocol = MockFaissModule()\n</code></pre> Source code in <code>src/search_api/types.py</code> <pre><code>class FaissModuleProtocol(Protocol):\n    \"\"\"Protocol for FAISS module surface used by adapters.\n\n    This protocol describes the subset of FAISS API used by kgfoundry\n    adapters. It enables type checking and allows fallback implementations\n    (e.g., `_SimpleFaissModule`) to satisfy the protocol.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry.search_api.types import FaissModuleProtocol, FaissIndexProtocol\n    &gt;&gt;&gt; class MockFaissModule:\n    ...     METRIC_INNER_PRODUCT = 1\n    ...\n    ...     def IndexFlatIP(self, dimension: int) -&gt; FaissIndexProtocol: ...\n    ...     def write_index(self, index: FaissIndexProtocol, path: str) -&gt; None: ...\n    ...     def read_index(self, path: str) -&gt; FaissIndexProtocol: ...\n    ...     def normalize_L2(self, vectors: VectorArray) -&gt; None: ...\n    &gt;&gt;&gt; module: FaissModuleProtocol = MockFaissModule()\n    \"\"\"\n\n    metric_inner_product: int\n    \"\"\"Constant for inner-product metric (used with index_factory).\"\"\"\n\n    metric_l2: int\n    \"\"\"Constant for L2 distance metric (used with index_factory).\"\"\"\n\n    index_flat_ip: Callable[[int], FaissIndexProtocol]\n    \"\"\"Create a flat inner-product index.\"\"\"\n\n    def index_factory(self, dimension: int, factory_string: str, metric: int) -&gt; FaissIndexProtocol:\n        \"\"\"Create an index from a factory string.\n\n        Constructs a FAISS index using a factory string description. Factory\n        strings describe index configuration (e.g., \"IVF8192,PQ64\" for\n        quantized indexes).\n\n        Parameters\n        ----------\n        dimension : int\n            Vector dimension.\n        factory_string : str\n            Factory description (e.g., \"IVF8192,PQ64\" for quantized index).\n        metric : int\n            Metric type (METRIC_INNER_PRODUCT or METRIC_L2).\n\n        Returns\n        -------\n        FaissIndexProtocol\n            Configured index instance.\n\n        Examples\n        --------\n        &gt;&gt;&gt; # Create quantized index for large-scale search\n        &gt;&gt;&gt; index = faiss.index_factory(2560, \"OPQ64,IVF8192,PQ64\", faiss.METRIC_INNER_PRODUCT)\n        \"\"\"\n        ...\n\n    index_id_map2: Callable[[FaissIndexProtocol], FaissIndexProtocol]\n    \"\"\"Wrap an index with 64-bit ID mapping.\"\"\"\n\n    def write_index(self, index: FaissIndexProtocol, path: str) -&gt; None:\n        \"\"\"Persist an index to disk.\n\n        Serializes a FAISS index to disk for later loading. The index format\n        is FAISS-specific and not human-readable.\n\n        Parameters\n        ----------\n        index : FaissIndexProtocol\n            Index instance to save.\n        path : str\n            File path for the persisted index.\n\n        Raises\n        ------\n        OSError\n            If the file cannot be written.\n        \"\"\"\n        ...\n\n    def read_index(self, path: str) -&gt; FaissIndexProtocol:\n        \"\"\"Load an index from disk.\n\n        Deserializes a FAISS index from disk. The index must have been saved\n        using write_index() with a compatible FAISS version.\n\n        Parameters\n        ----------\n        path : str\n            File path to the persisted index.\n\n        Returns\n        -------\n        FaissIndexProtocol\n            Loaded index instance.\n\n        Raises\n        ------\n        FileNotFoundError\n            If the index file does not exist.\n        OSError\n            If the file cannot be read or is corrupted.\n        \"\"\"\n        ...\n\n    normalize_l2: Callable[[VectorArray], None]\n    \"\"\"Normalize vectors to unit length in-place.\"\"\"\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.FaissModuleProtocol.index_flat_ip","title":"<code>index_flat_ip</code>  <code>instance-attribute</code>","text":"<p>Create a flat inner-product index.</p>"},{"location":"modules/search_api.types/#search_api.types.FaissModuleProtocol.index_id_map2","title":"<code>index_id_map2</code>  <code>instance-attribute</code>","text":"<p>Wrap an index with 64-bit ID mapping.</p>"},{"location":"modules/search_api.types/#search_api.types.FaissModuleProtocol.metric_inner_product","title":"<code>metric_inner_product</code>  <code>instance-attribute</code>","text":"<p>Constant for inner-product metric (used with index_factory).</p>"},{"location":"modules/search_api.types/#search_api.types.FaissModuleProtocol.metric_l2","title":"<code>metric_l2</code>  <code>instance-attribute</code>","text":"<p>Constant for L2 distance metric (used with index_factory).</p>"},{"location":"modules/search_api.types/#search_api.types.FaissModuleProtocol.normalize_l2","title":"<code>normalize_l2</code>  <code>instance-attribute</code>","text":"<p>Normalize vectors to unit length in-place.</p>"},{"location":"modules/search_api.types/#search_api.types.FaissModuleProtocol.index_factory","title":"<code>index_factory(dimension, factory_string, metric)</code>","text":"<p>Create an index from a factory string.</p> <p>Constructs a FAISS index using a factory string description. Factory strings describe index configuration (e.g., \"IVF8192,PQ64\" for quantized indexes).</p> <p>Parameters:</p> Name Type Description Default <code>dimension</code> <code>int</code> <p>Vector dimension.</p> required <code>factory_string</code> <code>str</code> <p>Factory description (e.g., \"IVF8192,PQ64\" for quantized index).</p> required <code>metric</code> <code>int</code> <p>Metric type (METRIC_INNER_PRODUCT or METRIC_L2).</p> required <p>Returns:</p> Type Description <code>FaissIndexProtocol</code> <p>Configured index instance.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Create quantized index for large-scale search\n&gt;&gt;&gt; index = faiss.index_factory(2560, \"OPQ64,IVF8192,PQ64\", faiss.METRIC_INNER_PRODUCT)\n</code></pre> Source code in <code>src/search_api/types.py</code> <pre><code>def index_factory(self, dimension: int, factory_string: str, metric: int) -&gt; FaissIndexProtocol:\n    \"\"\"Create an index from a factory string.\n\n    Constructs a FAISS index using a factory string description. Factory\n    strings describe index configuration (e.g., \"IVF8192,PQ64\" for\n    quantized indexes).\n\n    Parameters\n    ----------\n    dimension : int\n        Vector dimension.\n    factory_string : str\n        Factory description (e.g., \"IVF8192,PQ64\" for quantized index).\n    metric : int\n        Metric type (METRIC_INNER_PRODUCT or METRIC_L2).\n\n    Returns\n    -------\n    FaissIndexProtocol\n        Configured index instance.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # Create quantized index for large-scale search\n    &gt;&gt;&gt; index = faiss.index_factory(2560, \"OPQ64,IVF8192,PQ64\", faiss.METRIC_INNER_PRODUCT)\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.FaissModuleProtocol.read_index","title":"<code>read_index(path)</code>","text":"<p>Load an index from disk.</p> <p>Deserializes a FAISS index from disk. The index must have been saved using write_index() with a compatible FAISS version.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>File path to the persisted index.</p> required <p>Returns:</p> Type Description <code>FaissIndexProtocol</code> <p>Loaded index instance.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the index file does not exist.</p> <code>OSError</code> <p>If the file cannot be read or is corrupted.</p> Source code in <code>src/search_api/types.py</code> <pre><code>def read_index(self, path: str) -&gt; FaissIndexProtocol:\n    \"\"\"Load an index from disk.\n\n    Deserializes a FAISS index from disk. The index must have been saved\n    using write_index() with a compatible FAISS version.\n\n    Parameters\n    ----------\n    path : str\n        File path to the persisted index.\n\n    Returns\n    -------\n    FaissIndexProtocol\n        Loaded index instance.\n\n    Raises\n    ------\n    FileNotFoundError\n        If the index file does not exist.\n    OSError\n        If the file cannot be read or is corrupted.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.FaissModuleProtocol.write_index","title":"<code>write_index(index, path)</code>","text":"<p>Persist an index to disk.</p> <p>Serializes a FAISS index to disk for later loading. The index format is FAISS-specific and not human-readable.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>FaissIndexProtocol</code> <p>Index instance to save.</p> required <code>path</code> <code>str</code> <p>File path for the persisted index.</p> required <p>Raises:</p> Type Description <code>OSError</code> <p>If the file cannot be written.</p> Source code in <code>src/search_api/types.py</code> <pre><code>def write_index(self, index: FaissIndexProtocol, path: str) -&gt; None:\n    \"\"\"Persist an index to disk.\n\n    Serializes a FAISS index to disk for later loading. The index format\n    is FAISS-specific and not human-readable.\n\n    Parameters\n    ----------\n    index : FaissIndexProtocol\n        Index instance to save.\n    path : str\n        File path for the persisted index.\n\n    Raises\n    ------\n    OSError\n        If the file cannot be written.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/search_api.types/#search_apitypesgpucloneroptionsprotocol","title":"search_api.types.GpuClonerOptionsProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/search_api.types/#search_api.types.GpuClonerOptionsProtocol","title":"<code>search_api.types.GpuClonerOptionsProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for FAISS GPU cloner options.</p> <p>This protocol describes the GpuClonerOptions interface used when cloning CPU indexes to GPU. The <code>use_cuvs</code> attribute controls cuVS acceleration.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry.search_api.types import GpuClonerOptionsProtocol\n&gt;&gt;&gt; class MockGpuClonerOptions:\n...     use_cuvs: bool = False\n&gt;&gt;&gt; options: GpuClonerOptionsProtocol = MockGpuClonerOptions()\n&gt;&gt;&gt; options.use_cuvs = True\n</code></pre> Source code in <code>src/search_api/types.py</code> <pre><code>class GpuClonerOptionsProtocol(Protocol):\n    \"\"\"Protocol for FAISS GPU cloner options.\n\n    This protocol describes the GpuClonerOptions interface used when cloning\n    CPU indexes to GPU. The `use_cuvs` attribute controls cuVS acceleration.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry.search_api.types import GpuClonerOptionsProtocol\n    &gt;&gt;&gt; class MockGpuClonerOptions:\n    ...     use_cuvs: bool = False\n    &gt;&gt;&gt; options: GpuClonerOptionsProtocol = MockGpuClonerOptions()\n    &gt;&gt;&gt; options.use_cuvs = True\n    \"\"\"\n\n    use_cuvs: bool\n    \"\"\"Enable cuVS acceleration for GPU operations (default: False).\"\"\"\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.GpuClonerOptionsProtocol.use_cuvs","title":"<code>use_cuvs</code>  <code>instance-attribute</code>","text":"<p>Enable cuVS acceleration for GPU operations (default: False).</p>"},{"location":"modules/search_api.types/#search_apitypesgpuresourcesprotocol","title":"search_api.types.GpuResourcesProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/search_api.types/#search_api.types.GpuResourcesProtocol","title":"<code>search_api.types.GpuResourcesProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for FAISS GPU resources.</p> <p>This protocol describes the StandardGpuResources interface used for GPU index operations. Implementations manage GPU memory and resources.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry.search_api.types import GpuResourcesProtocol\n&gt;&gt;&gt; class MockGpuResources:\n...     def __init__(self) -&gt; None:\n...         pass\n&gt;&gt;&gt; resources: GpuResourcesProtocol = MockGpuResources()\n</code></pre> Source code in <code>src/search_api/types.py</code> <pre><code>class GpuResourcesProtocol(Protocol):\n    \"\"\"Protocol for FAISS GPU resources.\n\n    This protocol describes the StandardGpuResources interface used for GPU\n    index operations. Implementations manage GPU memory and resources.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry.search_api.types import GpuResourcesProtocol\n    &gt;&gt;&gt; class MockGpuResources:\n    ...     def __init__(self) -&gt; None:\n    ...         pass\n    &gt;&gt;&gt; resources: GpuResourcesProtocol = MockGpuResources()\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize GPU resources.\n\n        Sets up GPU memory management and resource allocation for FAISS GPU operations.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.GpuResourcesProtocol.__init__","title":"<code>__init__()</code>","text":"<p>Initialize GPU resources.</p> <p>Sets up GPU memory management and resource allocation for FAISS GPU operations.</p> Source code in <code>src/search_api/types.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize GPU resources.\n\n    Sets up GPU memory management and resource allocation for FAISS GPU operations.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/search_api.types/#search_apitypesspladeencoderprotocol","title":"search_api.types.SpladeEncoderProtocol","text":"<p>Bases: Protocol</p>"},{"location":"modules/search_api.types/#search_api.types.SpladeEncoderProtocol","title":"<code>search_api.types.SpladeEncoderProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for SPLADE encoder implementations.</p> <p>SPLADE (Sparse Lexical and Expansion) encoders transform text into sparse vector representations suitable for semantic search. This protocol defines the interface required for SPLADE-based search operations.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry.search_api.types import SpladeEncoderProtocol, VectorArray\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; class MySpladeEncoder:\n...     def encode(self, texts: Sequence[str]) -&gt; VectorArray:\n...         # Return sparse vectors for input texts\n...         return np.array([[0.1, 0.0, 0.5]], dtype=np.float32)\n&gt;&gt;&gt; encoder: SpladeEncoderProtocol = MySpladeEncoder()\n&gt;&gt;&gt; vecs = encoder.encode([\"query text\"])\n&gt;&gt;&gt; assert vecs.shape[0] == 1\n</code></pre> Source code in <code>src/search_api/types.py</code> <pre><code>class SpladeEncoderProtocol(Protocol):\n    \"\"\"Protocol for SPLADE encoder implementations.\n\n    SPLADE (Sparse Lexical and Expansion) encoders transform text into\n    sparse vector representations suitable for semantic search. This protocol\n    defines the interface required for SPLADE-based search operations.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry.search_api.types import SpladeEncoderProtocol, VectorArray\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; class MySpladeEncoder:\n    ...     def encode(self, texts: Sequence[str]) -&gt; VectorArray:\n    ...         # Return sparse vectors for input texts\n    ...         return np.array([[0.1, 0.0, 0.5]], dtype=np.float32)\n    &gt;&gt;&gt; encoder: SpladeEncoderProtocol = MySpladeEncoder()\n    &gt;&gt;&gt; vecs = encoder.encode([\"query text\"])\n    &gt;&gt;&gt; assert vecs.shape[0] == 1\n    \"\"\"\n\n    def encode(self, texts: Sequence[str]) -&gt; VectorArray:\n        \"\"\"Encode text sequences into sparse vector representations.\n\n        Transforms input text sequences into sparse vectors suitable for\n        semantic search. Vectors are typically sparse (many zeros) and\n        represent term importance in the vocabulary.\n\n        Parameters\n        ----------\n        texts : Sequence[str]\n            Input text sequences to encode.\n\n        Returns\n        -------\n        VectorArray\n            Sparse vector array of shape (len(texts), vocab_size) with float32 dtype.\n            Vectors are typically sparse (many zeros) and represent term importance.\n\n        Raises\n        ------\n        RuntimeError\n            If the encoder model fails to load or encode.\n        ValueError\n            If input texts are invalid or exceed maximum sequence length.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.SpladeEncoderProtocol.encode","title":"<code>encode(texts)</code>","text":"<p>Encode text sequences into sparse vector representations.</p> <p>Transforms input text sequences into sparse vectors suitable for semantic search. Vectors are typically sparse (many zeros) and represent term importance in the vocabulary.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <code>Sequence[str]</code> <p>Input text sequences to encode.</p> required <p>Returns:</p> Type Description <code>VectorArray</code> <p>Sparse vector array of shape (len(texts), vocab_size) with float32 dtype. Vectors are typically sparse (many zeros) and represent term importance.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the encoder model fails to load or encode.</p> <code>ValueError</code> <p>If input texts are invalid or exceed maximum sequence length.</p> Source code in <code>src/search_api/types.py</code> <pre><code>def encode(self, texts: Sequence[str]) -&gt; VectorArray:\n    \"\"\"Encode text sequences into sparse vector representations.\n\n    Transforms input text sequences into sparse vectors suitable for\n    semantic search. Vectors are typically sparse (many zeros) and\n    represent term importance in the vocabulary.\n\n    Parameters\n    ----------\n    texts : Sequence[str]\n        Input text sequences to encode.\n\n    Returns\n    -------\n    VectorArray\n        Sparse vector array of shape (len(texts), vocab_size) with float32 dtype.\n        Vectors are typically sparse (many zeros) and represent term importance.\n\n    Raises\n    ------\n    RuntimeError\n        If the encoder model fails to load or encode.\n    ValueError\n        If input texts are invalid or exceed maximum sequence length.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/search_api.types/#search_apitypesvectorsearchresult","title":"search_api.types.VectorSearchResult","text":""},{"location":"modules/search_api.types/#search_api.types.VectorSearchResult","title":"<code>search_api.types.VectorSearchResult</code>  <code>dataclass</code>","text":"<p>Typed result from vector search operations.</p> <p>This dataclass represents a single search result with typed fields and performance metadata. Results are immutable to prevent accidental modification.</p> <p>Parameters:</p> Name Type Description Default <code>doc_id</code> <code>str</code> <p>Document identifier (URN format, e.g., \"urn:doc:abc123\").</p> required <code>chunk_id</code> <code>str</code> <p>Chunk identifier within the document (e.g., \"urn:chunk:abc123:0-500\").</p> required <code>score</code> <code>float</code> <p>Final relevance score combining multiple signals (higher is better).</p> required <code>vector_score</code> <code>float</code> <p>Raw vector similarity score from FAISS search (inner product or L2).</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from kgfoundry.search_api.types import VectorSearchResult\n&gt;&gt;&gt; result = VectorSearchResult(\n...     doc_id=\"urn:doc:abc123\",\n...     chunk_id=\"urn:chunk:abc123:0-500\",\n...     score=0.95,\n...     vector_score=0.95,\n... )\n&gt;&gt;&gt; assert result.score == 0.95\n</code></pre> Source code in <code>src/search_api/types.py</code> <pre><code>@dataclass(frozen=True, slots=True)\n# [nav:anchor VectorSearchResult]\nclass VectorSearchResult:\n    \"\"\"Typed result from vector search operations.\n\n    This dataclass represents a single search result with typed fields\n    and performance metadata. Results are immutable to prevent accidental\n    modification.\n\n    Parameters\n    ----------\n    doc_id : str\n        Document identifier (URN format, e.g., \"urn:doc:abc123\").\n    chunk_id : str\n        Chunk identifier within the document (e.g., \"urn:chunk:abc123:0-500\").\n    score : float\n        Final relevance score combining multiple signals (higher is better).\n    vector_score : float\n        Raw vector similarity score from FAISS search (inner product or L2).\n\n    Examples\n    --------\n    &gt;&gt;&gt; from kgfoundry.search_api.types import VectorSearchResult\n    &gt;&gt;&gt; result = VectorSearchResult(\n    ...     doc_id=\"urn:doc:abc123\",\n    ...     chunk_id=\"urn:chunk:abc123:0-500\",\n    ...     score=0.95,\n    ...     vector_score=0.95,\n    ... )\n    &gt;&gt;&gt; assert result.score == 0.95\n    \"\"\"\n\n    doc_id: str\n    \"\"\"Document identifier (URN format).\"\"\"\n\n    chunk_id: str\n    \"\"\"Chunk identifier within the document.\"\"\"\n\n    score: float\n    \"\"\"Final relevance score (may combine multiple signals).\"\"\"\n\n    vector_score: float\n    \"\"\"Raw vector similarity score (inner product or L2 distance).\"\"\"\n\n    def __post_init__(self) -&gt; None:\n        \"\"\"Validate result fields.\n\n        This method is called automatically by dataclass after initialization. For frozen\n        dataclasses, fields cannot be modified, so validation is limited to type checking (enforced\n        by the type checker).\n        \"\"\"\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResult.chunk_id","title":"<code>chunk_id</code>  <code>instance-attribute</code>","text":"<p>Chunk identifier within the document.</p>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResult.doc_id","title":"<code>doc_id</code>  <code>instance-attribute</code>","text":"<p>Document identifier (URN format).</p>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResult.score","title":"<code>score</code>  <code>instance-attribute</code>","text":"<p>Final relevance score (may combine multiple signals).</p>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResult.vector_score","title":"<code>vector_score</code>  <code>instance-attribute</code>","text":"<p>Raw vector similarity score (inner product or L2 distance).</p>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResult.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Validate result fields.</p> <p>This method is called automatically by dataclass after initialization. For frozen dataclasses, fields cannot be modified, so validation is limited to type checking (enforced by the type checker).</p> Source code in <code>src/search_api/types.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Validate result fields.\n\n    This method is called automatically by dataclass after initialization. For frozen\n    dataclasses, fields cannot be modified, so validation is limited to type checking (enforced\n    by the type checker).\n    \"\"\"\n</code></pre>"},{"location":"modules/search_api.types/#search_apitypesvectorsearchresulttypeddict","title":"search_api.types.VectorSearchResultTypedDict","text":"<p>Bases: TypedDict</p>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResultTypedDict","title":"<code>search_api.types.VectorSearchResultTypedDict</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>TypedDict representation of vector search results.</p> <p>This TypedDict represents a search result from the agent catalog with symbol metadata, relevance scores, and source anchors. Used for JSON serialization and API responses.</p> <p>Attributes:</p> Name Type Description <code>symbol_id</code> <code>str</code> <p>Fully qualified symbol identifier (e.g., 'py:module.Class.method').</p> <code>score</code> <code>float</code> <p>Final relevance score combining lexical and vector signals.</p> <code>lexical_score</code> <code>float</code> <p>BM25 lexical search score (0.0 to 1.0).</p> <code>vector_score</code> <code>float</code> <p>Vector similarity score from dense/sparse search (0.0 to 1.0).</p> <code>package</code> <code>str</code> <p>Package name containing the symbol.</p> <code>module</code> <code>str</code> <p>Module name containing the symbol.</p> <code>qname</code> <code>str</code> <p>Qualified name of the symbol within its module.</p> <code>kind</code> <code>str</code> <p>Symbol kind (e.g., 'class', 'function', 'module').</p> <code>anchor</code> <code>Mapping[str, int | None]</code> <p>Source anchor metadata (start_line, end_line, etc.).</p> <code>metadata</code> <code>Mapping[str, JsonValue]</code> <p>Additional metadata (stability, deprecated, summary, etc.).</p> Source code in <code>src/search_api/types.py</code> <pre><code>class VectorSearchResultTypedDict(TypedDict, total=True):\n    \"\"\"TypedDict representation of vector search results.\n\n    This TypedDict represents a search result from the agent catalog with\n    symbol metadata, relevance scores, and source anchors. Used for JSON\n    serialization and API responses.\n\n    Attributes\n    ----------\n    symbol_id : str\n        Fully qualified symbol identifier (e.g., 'py:module.Class.method').\n    score : float\n        Final relevance score combining lexical and vector signals.\n    lexical_score : float\n        BM25 lexical search score (0.0 to 1.0).\n    vector_score : float\n        Vector similarity score from dense/sparse search (0.0 to 1.0).\n    package : str\n        Package name containing the symbol.\n    module : str\n        Module name containing the symbol.\n    qname : str\n        Qualified name of the symbol within its module.\n    kind : str\n        Symbol kind (e.g., 'class', 'function', 'module').\n    anchor : Mapping[str, int | None]\n        Source anchor metadata (start_line, end_line, etc.).\n    metadata : Mapping[str, JsonValue]\n        Additional metadata (stability, deprecated, summary, etc.).\n    \"\"\"\n\n    symbol_id: str\n    \"\"\"Fully qualified symbol identifier (e.g., 'py:module.Class.method').\"\"\"\n\n    score: float\n    \"\"\"Final relevance score combining lexical and vector signals.\"\"\"\n\n    lexical_score: float\n    \"\"\"BM25 lexical search score (0.0 to 1.0).\"\"\"\n\n    vector_score: float\n    \"\"\"Vector similarity score from dense/sparse search (0.0 to 1.0).\"\"\"\n\n    package: str\n    \"\"\"Package name containing the symbol.\"\"\"\n\n    module: str\n    \"\"\"Module name containing the symbol.\"\"\"\n\n    qname: str\n    \"\"\"Qualified name of the symbol within its module.\"\"\"\n\n    kind: str\n    \"\"\"Symbol kind (e.g., 'class', 'function', 'module').\"\"\"\n\n    anchor: Mapping[str, int | None]\n    \"\"\"Source anchor metadata (start_line, end_line, etc.).\"\"\"\n\n    metadata: Mapping[str, JsonValue]\n    \"\"\"Additional metadata (stability, deprecated, summary, etc.).\"\"\"\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResultTypedDict.anchor","title":"<code>anchor</code>  <code>instance-attribute</code>","text":"<p>Source anchor metadata (start_line, end_line, etc.).</p>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResultTypedDict.kind","title":"<code>kind</code>  <code>instance-attribute</code>","text":"<p>Symbol kind (e.g., 'class', 'function', 'module').</p>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResultTypedDict.lexical_score","title":"<code>lexical_score</code>  <code>instance-attribute</code>","text":"<p>BM25 lexical search score (0.0 to 1.0).</p>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResultTypedDict.metadata","title":"<code>metadata</code>  <code>instance-attribute</code>","text":"<p>Additional metadata (stability, deprecated, summary, etc.).</p>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResultTypedDict.module","title":"<code>module</code>  <code>instance-attribute</code>","text":"<p>Module name containing the symbol.</p>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResultTypedDict.package","title":"<code>package</code>  <code>instance-attribute</code>","text":"<p>Package name containing the symbol.</p>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResultTypedDict.qname","title":"<code>qname</code>  <code>instance-attribute</code>","text":"<p>Qualified name of the symbol within its module.</p>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResultTypedDict.score","title":"<code>score</code>  <code>instance-attribute</code>","text":"<p>Final relevance score combining lexical and vector signals.</p>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResultTypedDict.symbol_id","title":"<code>symbol_id</code>  <code>instance-attribute</code>","text":"<p>Fully qualified symbol identifier (e.g., 'py:module.Class.method').</p>"},{"location":"modules/search_api.types/#search_api.types.VectorSearchResultTypedDict.vector_score","title":"<code>vector_score</code>  <code>instance-attribute</code>","text":"<p>Vector similarity score from dense/sparse search (0.0 to 1.0).</p>"},{"location":"modules/search_api.types/#search_apitypes_faissmoduleadapter","title":"search_api.types._FaissModuleAdapter","text":""},{"location":"modules/search_api.types/#search_api.types._FaissModuleAdapter","title":"<code>search_api.types._FaissModuleAdapter</code>","text":"<p>Adapter that exposes PEP 8 method names for FAISS modules.</p> Source code in <code>src/search_api/types.py</code> <pre><code>class _FaissModuleAdapter:\n    \"\"\"Adapter that exposes PEP 8 method names for FAISS modules.\"\"\"\n\n    def __init__(self, module: _LegacyFaissModule) -&gt; None:\n        \"\"\"Initialize adapter with legacy FAISS module.\n\n        Parameters\n        ----------\n        module : _LegacyFaissModule\n            Legacy FAISS module with UPPER_CASE names.\n        \"\"\"\n        self._module = module\n\n    @property\n    def metric_inner_product(self) -&gt; int:\n        \"\"\"Return inner product metric constant.\"\"\"\n        return self._module.METRIC_INNER_PRODUCT\n\n    @property\n    def metric_l2(self) -&gt; int:\n        \"\"\"Return L2 metric constant.\"\"\"\n        return self._module.METRIC_L2\n\n    def index_flat_ip(self, dimension: int) -&gt; FaissIndexProtocol:\n        \"\"\"Create flat inner product index.\n\n        Parameters\n        ----------\n        dimension : int\n            Vector dimension.\n\n        Returns\n        -------\n        FaissIndexProtocol\n            FAISS index instance.\n        \"\"\"\n        constructor = _legacy_index_flat_ip(self._module)\n        return constructor(dimension)\n\n    def index_factory(self, dimension: int, factory_string: str, metric: int) -&gt; FaissIndexProtocol:\n        \"\"\"Create index from factory string.\n\n        Parameters\n        ----------\n        dimension : int\n            Vector dimension.\n        factory_string : str\n            Factory description string.\n        metric : int\n            Distance metric constant.\n\n        Returns\n        -------\n        FaissIndexProtocol\n            FAISS index instance.\n        \"\"\"\n        return self._module.index_factory(dimension, factory_string, metric)\n\n    def index_id_map2(self, index: FaissIndexProtocol) -&gt; FaissIndexProtocol:\n        \"\"\"Wrap index with 64-bit ID mapping.\n\n        Parameters\n        ----------\n        index : FaissIndexProtocol\n            Base index to wrap.\n\n        Returns\n        -------\n        FaissIndexProtocol\n            Index with ID mapping.\n        \"\"\"\n        wrapper = _legacy_index_id_map2(self._module)\n        return wrapper(index)\n\n    def write_index(self, index: FaissIndexProtocol, path: str) -&gt; None:\n        \"\"\"Write index to disk.\n\n        Parameters\n        ----------\n        index : FaissIndexProtocol\n            Index to serialize.\n        path : str\n            Output file path.\n        \"\"\"\n        self._module.write_index(index, path)\n\n    def read_index(self, path: str) -&gt; FaissIndexProtocol:\n        \"\"\"Read index from disk.\n\n        Parameters\n        ----------\n        path : str\n            Input file path.\n\n        Returns\n        -------\n        FaissIndexProtocol\n            Loaded index instance.\n        \"\"\"\n        return self._module.read_index(path)\n\n    def normalize_l2(self, vectors: VectorArray) -&gt; None:\n        \"\"\"Normalize vectors to unit length in-place.\n\n        Parameters\n        ----------\n        vectors : VectorArray\n            Vector array to normalize (modified in-place).\n        \"\"\"\n        normalizer = _legacy_normalize_l2(self._module)\n        normalizer(vectors)\n\n    def __getattr__(self, name: str) -&gt; object:\n        \"\"\"Get attribute with legacy name fallback.\n\n        Parameters\n        ----------\n        name : str\n            Attribute name.\n\n        Returns\n        -------\n        object\n            Attribute value from module.\n        \"\"\"\n        if name == \"METRIC_INNER_PRODUCT\":\n            return self.metric_inner_product\n        if name == \"METRIC_L2\":\n            return self.metric_l2\n        if name == \"IndexFlatIP\":\n            return self.index_flat_ip\n        if name == \"IndexIDMap2\":\n            return self.index_id_map2\n        if name == \"normalize_L2\":\n            return self.normalize_l2\n        return cast(\"object\", getattr(self._module, name))\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types._FaissModuleAdapter.metric_inner_product","title":"<code>metric_inner_product</code>  <code>property</code>","text":"<p>Return inner product metric constant.</p>"},{"location":"modules/search_api.types/#search_api.types._FaissModuleAdapter.metric_l2","title":"<code>metric_l2</code>  <code>property</code>","text":"<p>Return L2 metric constant.</p>"},{"location":"modules/search_api.types/#search_api.types._FaissModuleAdapter.__getattr__","title":"<code>__getattr__(name)</code>","text":"<p>Get attribute with legacy name fallback.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Attribute name.</p> required <p>Returns:</p> Type Description <code>object</code> <p>Attribute value from module.</p> Source code in <code>src/search_api/types.py</code> <pre><code>def __getattr__(self, name: str) -&gt; object:\n    \"\"\"Get attribute with legacy name fallback.\n\n    Parameters\n    ----------\n    name : str\n        Attribute name.\n\n    Returns\n    -------\n    object\n        Attribute value from module.\n    \"\"\"\n    if name == \"METRIC_INNER_PRODUCT\":\n        return self.metric_inner_product\n    if name == \"METRIC_L2\":\n        return self.metric_l2\n    if name == \"IndexFlatIP\":\n        return self.index_flat_ip\n    if name == \"IndexIDMap2\":\n        return self.index_id_map2\n    if name == \"normalize_L2\":\n        return self.normalize_l2\n    return cast(\"object\", getattr(self._module, name))\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types._FaissModuleAdapter.__init__","title":"<code>__init__(module)</code>","text":"<p>Initialize adapter with legacy FAISS module.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>_LegacyFaissModule</code> <p>Legacy FAISS module with UPPER_CASE names.</p> required Source code in <code>src/search_api/types.py</code> <pre><code>def __init__(self, module: _LegacyFaissModule) -&gt; None:\n    \"\"\"Initialize adapter with legacy FAISS module.\n\n    Parameters\n    ----------\n    module : _LegacyFaissModule\n        Legacy FAISS module with UPPER_CASE names.\n    \"\"\"\n    self._module = module\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types._FaissModuleAdapter.index_factory","title":"<code>index_factory(dimension, factory_string, metric)</code>","text":"<p>Create index from factory string.</p> <p>Parameters:</p> Name Type Description Default <code>dimension</code> <code>int</code> <p>Vector dimension.</p> required <code>factory_string</code> <code>str</code> <p>Factory description string.</p> required <code>metric</code> <code>int</code> <p>Distance metric constant.</p> required <p>Returns:</p> Type Description <code>FaissIndexProtocol</code> <p>FAISS index instance.</p> Source code in <code>src/search_api/types.py</code> <pre><code>def index_factory(self, dimension: int, factory_string: str, metric: int) -&gt; FaissIndexProtocol:\n    \"\"\"Create index from factory string.\n\n    Parameters\n    ----------\n    dimension : int\n        Vector dimension.\n    factory_string : str\n        Factory description string.\n    metric : int\n        Distance metric constant.\n\n    Returns\n    -------\n    FaissIndexProtocol\n        FAISS index instance.\n    \"\"\"\n    return self._module.index_factory(dimension, factory_string, metric)\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types._FaissModuleAdapter.index_flat_ip","title":"<code>index_flat_ip(dimension)</code>","text":"<p>Create flat inner product index.</p> <p>Parameters:</p> Name Type Description Default <code>dimension</code> <code>int</code> <p>Vector dimension.</p> required <p>Returns:</p> Type Description <code>FaissIndexProtocol</code> <p>FAISS index instance.</p> Source code in <code>src/search_api/types.py</code> <pre><code>def index_flat_ip(self, dimension: int) -&gt; FaissIndexProtocol:\n    \"\"\"Create flat inner product index.\n\n    Parameters\n    ----------\n    dimension : int\n        Vector dimension.\n\n    Returns\n    -------\n    FaissIndexProtocol\n        FAISS index instance.\n    \"\"\"\n    constructor = _legacy_index_flat_ip(self._module)\n    return constructor(dimension)\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types._FaissModuleAdapter.index_id_map2","title":"<code>index_id_map2(index)</code>","text":"<p>Wrap index with 64-bit ID mapping.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>FaissIndexProtocol</code> <p>Base index to wrap.</p> required <p>Returns:</p> Type Description <code>FaissIndexProtocol</code> <p>Index with ID mapping.</p> Source code in <code>src/search_api/types.py</code> <pre><code>def index_id_map2(self, index: FaissIndexProtocol) -&gt; FaissIndexProtocol:\n    \"\"\"Wrap index with 64-bit ID mapping.\n\n    Parameters\n    ----------\n    index : FaissIndexProtocol\n        Base index to wrap.\n\n    Returns\n    -------\n    FaissIndexProtocol\n        Index with ID mapping.\n    \"\"\"\n    wrapper = _legacy_index_id_map2(self._module)\n    return wrapper(index)\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types._FaissModuleAdapter.normalize_l2","title":"<code>normalize_l2(vectors)</code>","text":"<p>Normalize vectors to unit length in-place.</p> <p>Parameters:</p> Name Type Description Default <code>vectors</code> <code>VectorArray</code> <p>Vector array to normalize (modified in-place).</p> required Source code in <code>src/search_api/types.py</code> <pre><code>def normalize_l2(self, vectors: VectorArray) -&gt; None:\n    \"\"\"Normalize vectors to unit length in-place.\n\n    Parameters\n    ----------\n    vectors : VectorArray\n        Vector array to normalize (modified in-place).\n    \"\"\"\n    normalizer = _legacy_normalize_l2(self._module)\n    normalizer(vectors)\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types._FaissModuleAdapter.read_index","title":"<code>read_index(path)</code>","text":"<p>Read index from disk.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Input file path.</p> required <p>Returns:</p> Type Description <code>FaissIndexProtocol</code> <p>Loaded index instance.</p> Source code in <code>src/search_api/types.py</code> <pre><code>def read_index(self, path: str) -&gt; FaissIndexProtocol:\n    \"\"\"Read index from disk.\n\n    Parameters\n    ----------\n    path : str\n        Input file path.\n\n    Returns\n    -------\n    FaissIndexProtocol\n        Loaded index instance.\n    \"\"\"\n    return self._module.read_index(path)\n</code></pre>"},{"location":"modules/search_api.types/#search_api.types._FaissModuleAdapter.write_index","title":"<code>write_index(index, path)</code>","text":"<p>Write index to disk.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>FaissIndexProtocol</code> <p>Index to serialize.</p> required <code>path</code> <code>str</code> <p>Output file path.</p> required Source code in <code>src/search_api/types.py</code> <pre><code>def write_index(self, index: FaissIndexProtocol, path: str) -&gt; None:\n    \"\"\"Write index to disk.\n\n    Parameters\n    ----------\n    index : FaissIndexProtocol\n        Index to serialize.\n    path : str\n        Output file path.\n    \"\"\"\n    self._module.write_index(index, path)\n</code></pre>"},{"location":"modules/search_api.types/#search_apitypes_legacyfaissmodule","title":"search_api.types._LegacyFaissModule","text":"<p>Bases: Protocol</p>"},{"location":"modules/search_api.types/#search_api.types._LegacyFaissModule","title":"<code>search_api.types._LegacyFaissModule</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Subset of the legacy FAISS module surface used by the adapter.</p> Source code in <code>src/search_api/types.py</code> <pre><code>class _LegacyFaissModule(Protocol):\n    \"\"\"Subset of the legacy FAISS module surface used by the adapter.\"\"\"\n\n    METRIC_INNER_PRODUCT: int\n    METRIC_L2: int\n\n    index_factory: Callable[[int, str, int], FaissIndexProtocol]\n    write_index: Callable[[FaissIndexProtocol, str], None]\n    read_index: Callable[[str], FaissIndexProtocol]\n</code></pre>"},{"location":"modules/search_api.types/#search_apitypes_labels_or_default","title":"search_api.types._labels_or_default","text":""},{"location":"modules/search_api.types/#search_api.types._labels_or_default","title":"<code>search_api.types._labels_or_default(labelnames)</code>","text":"Source code in <code>src/search_api/types.py</code> <pre><code>def _labels_or_default(labelnames: Sequence[str] | None) -&gt; Sequence[str]:\n    return tuple(labelnames) if labelnames is not None else ()\n</code></pre>"},{"location":"modules/search_api.types/#search_apitypes_legacy_index_flat_ip","title":"search_api.types._legacy_index_flat_ip","text":""},{"location":"modules/search_api.types/#search_api.types._legacy_index_flat_ip","title":"<code>search_api.types._legacy_index_flat_ip(module)</code>","text":"Source code in <code>src/search_api/types.py</code> <pre><code>def _legacy_index_flat_ip(module: _LegacyFaissModule) -&gt; Callable[[int], FaissIndexProtocol]:\n    attr_any: object = attrgetter(\"IndexFlatIP\")(module)\n    if not callable(attr_any):  # pragma: no cover - defensive guard for type checkers\n        msg = \"Legacy FAISS module attribute 'IndexFlatIP' must be callable\"\n        raise TypeError(msg)\n    return cast(\"Callable[[int], FaissIndexProtocol]\", attr_any)\n</code></pre>"},{"location":"modules/search_api.types/#search_apitypes_legacy_index_id_map2","title":"search_api.types._legacy_index_id_map2","text":""},{"location":"modules/search_api.types/#search_api.types._legacy_index_id_map2","title":"<code>search_api.types._legacy_index_id_map2(module)</code>","text":"Source code in <code>src/search_api/types.py</code> <pre><code>def _legacy_index_id_map2(\n    module: _LegacyFaissModule,\n) -&gt; Callable[[FaissIndexProtocol], FaissIndexProtocol]:\n    attr_any: object = attrgetter(\"IndexIDMap2\")(module)\n    if not callable(attr_any):  # pragma: no cover - defensive guard for type checkers\n        msg = \"Legacy FAISS module attribute 'IndexIDMap2' must be callable\"\n        raise TypeError(msg)\n    return cast(\"Callable[[FaissIndexProtocol], FaissIndexProtocol]\", attr_any)\n</code></pre>"},{"location":"modules/search_api.types/#search_apitypes_legacy_normalize_l2","title":"search_api.types._legacy_normalize_l2","text":""},{"location":"modules/search_api.types/#search_api.types._legacy_normalize_l2","title":"<code>search_api.types._legacy_normalize_l2(module)</code>","text":"Source code in <code>src/search_api/types.py</code> <pre><code>def _legacy_normalize_l2(module: _LegacyFaissModule) -&gt; Callable[[VectorArray], None]:\n    attr_any: object = attrgetter(\"normalize_L2\")(module)\n    if not callable(attr_any):  # pragma: no cover - defensive guard for type checkers\n        msg = \"Legacy FAISS module attribute 'normalize_L2' must be callable\"\n        raise TypeError(msg)\n    return cast(\"Callable[[VectorArray], None]\", attr_any)\n</code></pre>"},{"location":"modules/search_api.types/#search_apitypeswrap_faiss_module","title":"search_api.types.wrap_faiss_module","text":""},{"location":"modules/search_api.types/#search_api.types.wrap_faiss_module","title":"<code>search_api.types.wrap_faiss_module(module)</code>","text":"<p>Return a :class:<code>FaissModuleProtocol</code> with PEP 8 method names.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>object</code> <p>FAISS module to wrap.</p> required <p>Returns:</p> Type Description <code>FaissModuleProtocol</code> <p>Wrapped module conforming to protocol.</p> Source code in <code>src/search_api/types.py</code> <pre><code>def wrap_faiss_module(module: object) -&gt; FaissModuleProtocol:\n    \"\"\"Return a :class:`FaissModuleProtocol` with PEP 8 method names.\n\n    Parameters\n    ----------\n    module : object\n        FAISS module to wrap.\n\n    Returns\n    -------\n    FaissModuleProtocol\n        Wrapped module conforming to protocol.\n    \"\"\"\n    required_attributes = (\n        \"index_flat_ip\",\n        \"index_factory\",\n        \"index_id_map2\",\n        \"write_index\",\n        \"read_index\",\n        \"normalize_l2\",\n    )\n    if all(hasattr(module, attribute) for attribute in required_attributes):\n        return cast(\"FaissModuleProtocol\", module)\n    legacy_module = cast(\"_LegacyFaissModule\", module)\n    return cast(\"FaissModuleProtocol\", _FaissModuleAdapter(legacy_module))\n</code></pre>"},{"location":"modules/search_api.vectorstore_factory/","title":"search_api.vectorstore_factory","text":""},{"location":"modules/search_api.vectorstore_factory/#search_apivectorstore_factory","title":"search_api.vectorstore_factory","text":"<p>Dependency-injected factory for FAISS vectorstore adapters with observability.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_api.vectorstore_factory/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class FaissAdapterSettings\n    class FaissVectorstoreFactory\n</code></pre>"},{"location":"modules/search_api.vectorstore_factory/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_api.vectorstore_factory__future__.annotationsdataclasses.dataclassdataclasses.fieldkgfoundry_common.errors.IndexBuildErrorkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.prometheus.CounterLikekgfoundry_common.prometheus.HistogramLikekgfoundry_common.prometheus.build_counterkgfoundry_common.prometheus.build_histogramloggingsearch_api.faiss_adapter.FaissAdaptertimetyping.Finaltyping.TYPE_CHECKINGsearch_api.vectorstore_factory code <p>See the full diagram: search_api.vectorstore_factory</p>"},{"location":"modules/search_api.vectorstore_factory/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>search_api.vectorstore_factory.FaissAdapterSettings</li> <li>search_api.vectorstore_factory.FaissVectorstoreFactory</li> <li>search_api.vectorstore_factory._ingestion_extra</li> <li>search_api.vectorstore_factory._observe_metrics</li> </ul>"},{"location":"modules/search_api.vectorstore_factory/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>dataclasses.dataclass</code>, <code>dataclasses.field</code>, <code>kgfoundry_common.errors.IndexBuildError</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.prometheus.CounterLike</code>, <code>kgfoundry_common.prometheus.HistogramLike</code>, <code>kgfoundry_common.prometheus.build_counter</code>, <code>kgfoundry_common.prometheus.build_histogram</code>, <code>logging</code>, <code>search_api.faiss_adapter.FaissAdapter</code>, <code>time</code>, <code>typing.Final</code>, <code>typing.TYPE_CHECKING</code></p>"},{"location":"modules/search_api.vectorstore_factory/#contents","title":"Contents","text":""},{"location":"modules/search_api.vectorstore_factory/#search_apivectorstore_factoryfaissadaptersettings","title":"search_api.vectorstore_factory.FaissAdapterSettings","text":""},{"location":"modules/search_api.vectorstore_factory/#search_api.vectorstore_factory.FaissAdapterSettings","title":"<code>search_api.vectorstore_factory.FaissAdapterSettings</code>  <code>dataclass</code>","text":"<p>Configuration for FAISS adapter instances.</p> <p>This immutable dataclass captures all parameters needed to construct a FaissAdapter with consistent defaults and validation.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>Path to DuckDB registry or Parquet vector file.</p> required <code>index_path</code> <code>str</code> <p>Path where the built index will be saved.</p> required <code>factory</code> <code>str</code> <p>FAISS factory string (e.g., \"OPQ64,IVF8192,PQ64\"). Defaults to \"Flat\".</p> <code>'Flat'</code> <code>metric</code> <code>str</code> <p>Metric type: \"ip\" (inner product) or \"l2\" (L2 distance). Defaults to \"ip\".</p> <code>'ip'</code> <code>nprobe</code> <code>int</code> <p>IVF search parameter. Defaults to 64.</p> <code>DEFAULT_NPROBE</code> <code>use_gpu</code> <code>bool</code> <p>Enable GPU acceleration. Defaults to True.</p> <code>True</code> <code>use_cuvs</code> <code>bool</code> <p>Enable cuVS acceleration. Defaults to True.</p> <code>True</code> <code>gpu_devices</code> <code>tuple[int, ...]</code> <p>GPU device IDs. Defaults to (0,).</p> <code>(lambda: (0,))()</code> <code>timeout_seconds</code> <code>int</code> <p>Build operation timeout. Defaults to 3600.</p> <code>DEFAULT_INDEX_TIMEOUT_SECONDS</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If metric is not \"ip\" or \"l2\".</p> Source code in <code>src/search_api/vectorstore_factory.py</code> <pre><code>@dataclass(frozen=True, slots=True)\n# [nav:anchor FaissAdapterSettings]\nclass FaissAdapterSettings:\n    \"\"\"Configuration for FAISS adapter instances.\n\n    This immutable dataclass captures all parameters needed to construct\n    a FaissAdapter with consistent defaults and validation.\n\n    Parameters\n    ----------\n    db_path : str\n        Path to DuckDB registry or Parquet vector file.\n    index_path : str\n        Path where the built index will be saved.\n    factory : str, optional\n        FAISS factory string (e.g., \"OPQ64,IVF8192,PQ64\"). Defaults to \"Flat\".\n    metric : str, optional\n        Metric type: \"ip\" (inner product) or \"l2\" (L2 distance). Defaults to \"ip\".\n    nprobe : int, optional\n        IVF search parameter. Defaults to 64.\n    use_gpu : bool, optional\n        Enable GPU acceleration. Defaults to True.\n    use_cuvs : bool, optional\n        Enable cuVS acceleration. Defaults to True.\n    gpu_devices : tuple[int, ...], optional\n        GPU device IDs. Defaults to (0,).\n    timeout_seconds : int, optional\n        Build operation timeout. Defaults to 3600.\n\n    Raises\n    ------\n    ValueError\n        If metric is not \"ip\" or \"l2\".\n    \"\"\"\n\n    db_path: str\n    index_path: str\n    factory: str = \"Flat\"\n    metric: str = \"ip\"\n    nprobe: int = DEFAULT_NPROBE\n    use_gpu: bool = True\n    use_cuvs: bool = True\n    gpu_devices: tuple[int, ...] = field(default_factory=lambda: (0,))\n    timeout_seconds: int = DEFAULT_INDEX_TIMEOUT_SECONDS\n\n    def __post_init__(self) -&gt; None:\n        \"\"\"Validate settings.\n\n        Raises\n        ------\n        ValueError\n            If ``metric`` is not one of ``{\"ip\", \"l2\"}``.\n        \"\"\"\n        if self.metric not in VALID_METRICS:\n            msg = f\"metric must be 'ip' or 'l2', got {self.metric!r}\"\n            raise ValueError(msg)\n</code></pre>"},{"location":"modules/search_api.vectorstore_factory/#search_api.vectorstore_factory.FaissAdapterSettings.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Validate settings.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>metric</code> is not one of <code>{\"ip\", \"l2\"}</code>.</p> Source code in <code>src/search_api/vectorstore_factory.py</code> <pre><code>def __post_init__(self) -&gt; None:\n    \"\"\"Validate settings.\n\n    Raises\n    ------\n    ValueError\n        If ``metric`` is not one of ``{\"ip\", \"l2\"}``.\n    \"\"\"\n    if self.metric not in VALID_METRICS:\n        msg = f\"metric must be 'ip' or 'l2', got {self.metric!r}\"\n        raise ValueError(msg)\n</code></pre>"},{"location":"modules/search_api.vectorstore_factory/#search_apivectorstore_factoryfaissvectorstorefactory","title":"search_api.vectorstore_factory.FaissVectorstoreFactory","text":""},{"location":"modules/search_api.vectorstore_factory/#search_api.vectorstore_factory.FaissVectorstoreFactory","title":"<code>search_api.vectorstore_factory.FaissVectorstoreFactory</code>  <code>dataclass</code>","text":"<p>Factory for building FAISS adapters with observability and error handling.</p> <p>This factory manages the lifecycle of FAISS adapter instances, emitting structured logs, Prometheus metrics, and Problem Details on error.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>FaissAdapterSettings</code> <p>Configuration for adapter instances.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from search_api.vectorstore_factory import FaissAdapterSettings, FaissVectorstoreFactory\n&gt;&gt;&gt; settings = FaissAdapterSettings(db_path=\"vectors.db\", index_path=\"index.idx\")\n&gt;&gt;&gt; factory = FaissVectorstoreFactory(settings)\n</code></pre> Source code in <code>src/search_api/vectorstore_factory.py</code> <pre><code>@dataclass(slots=True)\n# [nav:anchor FaissVectorstoreFactory]\nclass FaissVectorstoreFactory:\n    \"\"\"Factory for building FAISS adapters with observability and error handling.\n\n    This factory manages the lifecycle of FAISS adapter instances, emitting\n    structured logs, Prometheus metrics, and Problem Details on error.\n\n    Parameters\n    ----------\n    settings : FaissAdapterSettings\n        Configuration for adapter instances.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from search_api.vectorstore_factory import FaissAdapterSettings, FaissVectorstoreFactory\n    &gt;&gt;&gt; settings = FaissAdapterSettings(db_path=\"vectors.db\", index_path=\"index.idx\")\n    &gt;&gt;&gt; factory = FaissVectorstoreFactory(settings)\n    \"\"\"\n\n    settings: FaissAdapterSettings\n\n    def build_adapter(self) -&gt; FaissAdapter:\n        \"\"\"Build and return a configured FAISS adapter.\n\n        Returns\n        -------\n        FaissAdapter\n            Configured FaissAdapter instance.\n\n        Raises\n        ------\n        IndexBuildError\n            If adapter construction fails.\n        \"\"\"\n        logger.debug(\n            \"Building FAISS adapter\",\n            extra={\n                \"operation\": \"build_adapter\",\n                \"factory\": self.settings.factory,\n                \"metric\": self.settings.metric,\n                \"gpu_enabled\": self.settings.use_gpu,\n            },\n        )\n\n        try:\n            return FaissAdapter(\n                db_path=self.settings.db_path,\n                factory=self.settings.factory,\n                metric=self.settings.metric,\n                nprobe=self.settings.nprobe,\n                use_gpu=self.settings.use_gpu,\n                use_cuvs=self.settings.use_cuvs,\n                gpu_devices=list(self.settings.gpu_devices),\n            )\n        except Exception as exc:\n            msg = f\"Failed to construct FAISS adapter: {exc}\"\n            raise IndexBuildError(msg) from exc\n\n    def build_index(self, *, correlation_id: str | None = None) -&gt; FaissAdapter:\n        \"\"\"Build a FAISS index with timeout enforcement.\n\n        Returns\n        -------\n        FaissAdapter\n            Configured FaissAdapter with built index.\n\n        Raises\n        ------\n        IndexBuildError\n            If build exceeds timeout or fails.\n\n        Parameters\n        ----------\n        correlation_id : str | None, optional\n            Correlation identifier propagated to logs and metrics. Defaults to ``None``.\n        \"\"\"\n        adapter = self.build_adapter()\n        start_time = time.monotonic()\n        operation = \"build\"\n\n        logger.info(\n            \"Starting FAISS index build\",\n            extra={\n                \"operation\": \"index_build\",\n                \"index_path\": self.settings.index_path,\n                \"timeout_seconds\": self.settings.timeout_seconds,\n                \"stage\": _METRIC_STAGE_LABEL,\n                \"correlation_id\": correlation_id,\n            },\n        )\n\n        try:\n            adapter.build()\n        except Exception as exc:\n            elapsed = time.monotonic() - start_time\n            logger.exception(\n                \"FAISS index build failed\",\n                extra={\n                    \"operation\": \"index_build\",\n                    \"status\": \"error\",\n                    \"duration_seconds\": elapsed,\n                    \"error_type\": type(exc).__name__,\n                    \"stage\": _METRIC_STAGE_LABEL,\n                    \"correlation_id\": correlation_id,\n                },\n            )\n            _observe_metrics(operation, \"error\", elapsed)\n            msg = f\"Failed to build FAISS index: {exc}\"\n            raise IndexBuildError(msg, cause=exc) from exc\n\n        elapsed = time.monotonic() - start_time\n\n        if elapsed &gt; self.settings.timeout_seconds:\n            msg = f\"Index build exceeded timeout: {elapsed:.1f}s &gt; {self.settings.timeout_seconds}s\"\n            raise IndexBuildError(msg)\n\n        vector_count = len(adapter.idmap) if adapter.idmap else 0\n        matrix = adapter.cpu_matrix\n        vector_dimension = matrix.shape[1] if matrix is not None else None\n        logger.info(\n            \"FAISS index build completed\",\n            extra={\n                \"operation\": \"index_build\",\n                \"status\": \"success\",\n                \"duration_seconds\": elapsed,\n                \"vector_count\": vector_count,\n                \"vector_dimension\": vector_dimension,\n                \"stage\": _METRIC_STAGE_LABEL,\n                \"correlation_id\": correlation_id,\n            },\n        )\n        _observe_metrics(operation, \"success\", elapsed)\n\n        return adapter\n\n    def load_or_build(\n        self, cpu_index_path: str | None = None, *, correlation_id: str | None = None\n    ) -&gt; FaissAdapter:\n        \"\"\"Load an existing index or build from scratch.\n\n        Parameters\n        ----------\n        cpu_index_path : str | None, optional\n            Path to existing CPU-format index. If provided and exists, will\n            be loaded instead of rebuilding.\n        correlation_id : str | None, optional\n            Correlation identifier propagated to logs and metrics. Defaults to ``None``.\n\n        Returns\n        -------\n        FaissAdapter\n            Configured FaissAdapter with index ready for search.\n\n        Raises\n        ------\n        IndexBuildError\n            If loading or building fails.\n        \"\"\"\n        adapter = self.build_adapter()\n\n        operation = \"load_or_build\"\n        start_time = time.monotonic()\n        logger.info(\n            \"Loading or building FAISS index\",\n            extra={\n                \"operation\": \"load_or_build\",\n                \"cpu_index_path\": cpu_index_path,\n                \"stage\": _METRIC_STAGE_LABEL,\n                \"correlation_id\": correlation_id,\n            },\n        )\n\n        try:\n            adapter.load_or_build(cpu_index_path=cpu_index_path)\n        except Exception as exc:\n            logger.exception(\n                \"Index load or build failed\",\n                extra={\n                    \"operation\": \"load_or_build\",\n                    \"status\": \"error\",\n                    \"error_type\": type(exc).__name__,\n                    \"stage\": _METRIC_STAGE_LABEL,\n                    \"correlation_id\": correlation_id,\n                },\n            )\n            msg = f\"Failed to load or build FAISS index: {exc}\"\n            raise IndexBuildError(msg) from exc\n\n        elapsed = time.monotonic() - start_time\n        logger.info(\n            \"Index load or build completed\",\n            extra={\n                \"operation\": \"load_or_build\",\n                \"status\": \"success\",\n                \"duration_seconds\": elapsed,\n                \"stage\": _METRIC_STAGE_LABEL,\n                \"correlation_id\": correlation_id,\n            },\n        )\n        _observe_metrics(operation, \"success\", elapsed)\n        return adapter\n\n    @staticmethod\n    def save_index(\n        adapter: FaissAdapter,\n        index_uri: str,\n        idmap_uri: str | None = None,\n        *,\n        correlation_id: str | None = None,\n    ) -&gt; None:\n        \"\"\"Save adapter index and ID mapping to disk.\n\n        Parameters\n        ----------\n        adapter : FaissAdapter\n            FaissAdapter instance with built index.\n        index_uri : str\n            Path where index will be saved.\n        idmap_uri : str | None, optional\n            Path where ID mapping will be saved.\n        correlation_id : str | None, optional\n            Correlation identifier propagated to logs and metrics. Defaults to ``None``.\n\n        Notes\n        -----\n        Propagates exceptions raised by :meth:`FaissAdapter.save` (for example\n        I/O errors or FAISS errors). Callers should handle these according to\n        their error-handling strategy.\n        \"\"\"\n        logger.info(\n            \"Saving FAISS index\",\n            extra={\n                \"operation\": \"save_index\",\n                \"index_uri\": index_uri,\n                \"idmap_uri\": idmap_uri,\n                \"stage\": _METRIC_STAGE_LABEL,\n                \"correlation_id\": correlation_id,\n            },\n        )\n\n        start_time = time.monotonic()\n        operation = \"save\"\n        try:\n            adapter.save(index_uri, idmap_uri)\n        except Exception as exc:\n            logger.exception(\n                \"Index save failed\",\n                extra={\n                    \"operation\": \"save_index\",\n                    \"status\": \"error\",\n                    \"error_type\": type(exc).__name__,\n                    \"stage\": _METRIC_STAGE_LABEL,\n                    \"correlation_id\": correlation_id,\n                },\n            )\n            elapsed = time.monotonic() - start_time\n            _observe_metrics(operation, \"error\", elapsed)\n            raise\n\n        elapsed = time.monotonic() - start_time\n        logger.info(\n            \"Index saved successfully\",\n            extra={\n                \"operation\": \"save_index\",\n                \"status\": \"success\",\n                \"duration_seconds\": elapsed,\n                \"stage\": _METRIC_STAGE_LABEL,\n                \"correlation_id\": correlation_id,\n            },\n        )\n        _observe_metrics(operation, \"success\", elapsed)\n</code></pre>"},{"location":"modules/search_api.vectorstore_factory/#search_api.vectorstore_factory.FaissVectorstoreFactory.build_adapter","title":"<code>build_adapter()</code>","text":"<p>Build and return a configured FAISS adapter.</p> <p>Returns:</p> Type Description <code>FaissAdapter</code> <p>Configured FaissAdapter instance.</p> <p>Raises:</p> Type Description <code>IndexBuildError</code> <p>If adapter construction fails.</p> Source code in <code>src/search_api/vectorstore_factory.py</code> <pre><code>def build_adapter(self) -&gt; FaissAdapter:\n    \"\"\"Build and return a configured FAISS adapter.\n\n    Returns\n    -------\n    FaissAdapter\n        Configured FaissAdapter instance.\n\n    Raises\n    ------\n    IndexBuildError\n        If adapter construction fails.\n    \"\"\"\n    logger.debug(\n        \"Building FAISS adapter\",\n        extra={\n            \"operation\": \"build_adapter\",\n            \"factory\": self.settings.factory,\n            \"metric\": self.settings.metric,\n            \"gpu_enabled\": self.settings.use_gpu,\n        },\n    )\n\n    try:\n        return FaissAdapter(\n            db_path=self.settings.db_path,\n            factory=self.settings.factory,\n            metric=self.settings.metric,\n            nprobe=self.settings.nprobe,\n            use_gpu=self.settings.use_gpu,\n            use_cuvs=self.settings.use_cuvs,\n            gpu_devices=list(self.settings.gpu_devices),\n        )\n    except Exception as exc:\n        msg = f\"Failed to construct FAISS adapter: {exc}\"\n        raise IndexBuildError(msg) from exc\n</code></pre>"},{"location":"modules/search_api.vectorstore_factory/#search_api.vectorstore_factory.FaissVectorstoreFactory.build_index","title":"<code>build_index(*, correlation_id=None)</code>","text":"<p>Build a FAISS index with timeout enforcement.</p> <p>Returns:</p> Type Description <code>FaissAdapter</code> <p>Configured FaissAdapter with built index.</p> <p>Raises:</p> Type Description <code>IndexBuildError</code> <p>If build exceeds timeout or fails.</p> <p>Parameters:</p> Name Type Description Default <code>correlation_id</code> <code>str | None</code> <p>Correlation identifier propagated to logs and metrics. Defaults to <code>None</code>.</p> <code>None</code> Source code in <code>src/search_api/vectorstore_factory.py</code> <pre><code>def build_index(self, *, correlation_id: str | None = None) -&gt; FaissAdapter:\n    \"\"\"Build a FAISS index with timeout enforcement.\n\n    Returns\n    -------\n    FaissAdapter\n        Configured FaissAdapter with built index.\n\n    Raises\n    ------\n    IndexBuildError\n        If build exceeds timeout or fails.\n\n    Parameters\n    ----------\n    correlation_id : str | None, optional\n        Correlation identifier propagated to logs and metrics. Defaults to ``None``.\n    \"\"\"\n    adapter = self.build_adapter()\n    start_time = time.monotonic()\n    operation = \"build\"\n\n    logger.info(\n        \"Starting FAISS index build\",\n        extra={\n            \"operation\": \"index_build\",\n            \"index_path\": self.settings.index_path,\n            \"timeout_seconds\": self.settings.timeout_seconds,\n            \"stage\": _METRIC_STAGE_LABEL,\n            \"correlation_id\": correlation_id,\n        },\n    )\n\n    try:\n        adapter.build()\n    except Exception as exc:\n        elapsed = time.monotonic() - start_time\n        logger.exception(\n            \"FAISS index build failed\",\n            extra={\n                \"operation\": \"index_build\",\n                \"status\": \"error\",\n                \"duration_seconds\": elapsed,\n                \"error_type\": type(exc).__name__,\n                \"stage\": _METRIC_STAGE_LABEL,\n                \"correlation_id\": correlation_id,\n            },\n        )\n        _observe_metrics(operation, \"error\", elapsed)\n        msg = f\"Failed to build FAISS index: {exc}\"\n        raise IndexBuildError(msg, cause=exc) from exc\n\n    elapsed = time.monotonic() - start_time\n\n    if elapsed &gt; self.settings.timeout_seconds:\n        msg = f\"Index build exceeded timeout: {elapsed:.1f}s &gt; {self.settings.timeout_seconds}s\"\n        raise IndexBuildError(msg)\n\n    vector_count = len(adapter.idmap) if adapter.idmap else 0\n    matrix = adapter.cpu_matrix\n    vector_dimension = matrix.shape[1] if matrix is not None else None\n    logger.info(\n        \"FAISS index build completed\",\n        extra={\n            \"operation\": \"index_build\",\n            \"status\": \"success\",\n            \"duration_seconds\": elapsed,\n            \"vector_count\": vector_count,\n            \"vector_dimension\": vector_dimension,\n            \"stage\": _METRIC_STAGE_LABEL,\n            \"correlation_id\": correlation_id,\n        },\n    )\n    _observe_metrics(operation, \"success\", elapsed)\n\n    return adapter\n</code></pre>"},{"location":"modules/search_api.vectorstore_factory/#search_api.vectorstore_factory.FaissVectorstoreFactory.load_or_build","title":"<code>load_or_build(cpu_index_path=None, *, correlation_id=None)</code>","text":"<p>Load an existing index or build from scratch.</p> <p>Parameters:</p> Name Type Description Default <code>cpu_index_path</code> <code>str | None</code> <p>Path to existing CPU-format index. If provided and exists, will be loaded instead of rebuilding.</p> <code>None</code> <code>correlation_id</code> <code>str | None</code> <p>Correlation identifier propagated to logs and metrics. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>FaissAdapter</code> <p>Configured FaissAdapter with index ready for search.</p> <p>Raises:</p> Type Description <code>IndexBuildError</code> <p>If loading or building fails.</p> Source code in <code>src/search_api/vectorstore_factory.py</code> <pre><code>def load_or_build(\n    self, cpu_index_path: str | None = None, *, correlation_id: str | None = None\n) -&gt; FaissAdapter:\n    \"\"\"Load an existing index or build from scratch.\n\n    Parameters\n    ----------\n    cpu_index_path : str | None, optional\n        Path to existing CPU-format index. If provided and exists, will\n        be loaded instead of rebuilding.\n    correlation_id : str | None, optional\n        Correlation identifier propagated to logs and metrics. Defaults to ``None``.\n\n    Returns\n    -------\n    FaissAdapter\n        Configured FaissAdapter with index ready for search.\n\n    Raises\n    ------\n    IndexBuildError\n        If loading or building fails.\n    \"\"\"\n    adapter = self.build_adapter()\n\n    operation = \"load_or_build\"\n    start_time = time.monotonic()\n    logger.info(\n        \"Loading or building FAISS index\",\n        extra={\n            \"operation\": \"load_or_build\",\n            \"cpu_index_path\": cpu_index_path,\n            \"stage\": _METRIC_STAGE_LABEL,\n            \"correlation_id\": correlation_id,\n        },\n    )\n\n    try:\n        adapter.load_or_build(cpu_index_path=cpu_index_path)\n    except Exception as exc:\n        logger.exception(\n            \"Index load or build failed\",\n            extra={\n                \"operation\": \"load_or_build\",\n                \"status\": \"error\",\n                \"error_type\": type(exc).__name__,\n                \"stage\": _METRIC_STAGE_LABEL,\n                \"correlation_id\": correlation_id,\n            },\n        )\n        msg = f\"Failed to load or build FAISS index: {exc}\"\n        raise IndexBuildError(msg) from exc\n\n    elapsed = time.monotonic() - start_time\n    logger.info(\n        \"Index load or build completed\",\n        extra={\n            \"operation\": \"load_or_build\",\n            \"status\": \"success\",\n            \"duration_seconds\": elapsed,\n            \"stage\": _METRIC_STAGE_LABEL,\n            \"correlation_id\": correlation_id,\n        },\n    )\n    _observe_metrics(operation, \"success\", elapsed)\n    return adapter\n</code></pre>"},{"location":"modules/search_api.vectorstore_factory/#search_api.vectorstore_factory.FaissVectorstoreFactory.save_index","title":"<code>save_index(adapter, index_uri, idmap_uri=None, *, correlation_id=None)</code>  <code>staticmethod</code>","text":"<p>Save adapter index and ID mapping to disk.</p> <p>Parameters:</p> Name Type Description Default <code>adapter</code> <code>FaissAdapter</code> <p>FaissAdapter instance with built index.</p> required <code>index_uri</code> <code>str</code> <p>Path where index will be saved.</p> required <code>idmap_uri</code> <code>str | None</code> <p>Path where ID mapping will be saved.</p> <code>None</code> <code>correlation_id</code> <code>str | None</code> <p>Correlation identifier propagated to logs and metrics. Defaults to <code>None</code>.</p> <code>None</code> Notes <p>Propagates exceptions raised by :meth:<code>FaissAdapter.save</code> (for example I/O errors or FAISS errors). Callers should handle these according to their error-handling strategy.</p> Source code in <code>src/search_api/vectorstore_factory.py</code> <pre><code>@staticmethod\ndef save_index(\n    adapter: FaissAdapter,\n    index_uri: str,\n    idmap_uri: str | None = None,\n    *,\n    correlation_id: str | None = None,\n) -&gt; None:\n    \"\"\"Save adapter index and ID mapping to disk.\n\n    Parameters\n    ----------\n    adapter : FaissAdapter\n        FaissAdapter instance with built index.\n    index_uri : str\n        Path where index will be saved.\n    idmap_uri : str | None, optional\n        Path where ID mapping will be saved.\n    correlation_id : str | None, optional\n        Correlation identifier propagated to logs and metrics. Defaults to ``None``.\n\n    Notes\n    -----\n    Propagates exceptions raised by :meth:`FaissAdapter.save` (for example\n    I/O errors or FAISS errors). Callers should handle these according to\n    their error-handling strategy.\n    \"\"\"\n    logger.info(\n        \"Saving FAISS index\",\n        extra={\n            \"operation\": \"save_index\",\n            \"index_uri\": index_uri,\n            \"idmap_uri\": idmap_uri,\n            \"stage\": _METRIC_STAGE_LABEL,\n            \"correlation_id\": correlation_id,\n        },\n    )\n\n    start_time = time.monotonic()\n    operation = \"save\"\n    try:\n        adapter.save(index_uri, idmap_uri)\n    except Exception as exc:\n        logger.exception(\n            \"Index save failed\",\n            extra={\n                \"operation\": \"save_index\",\n                \"status\": \"error\",\n                \"error_type\": type(exc).__name__,\n                \"stage\": _METRIC_STAGE_LABEL,\n                \"correlation_id\": correlation_id,\n            },\n        )\n        elapsed = time.monotonic() - start_time\n        _observe_metrics(operation, \"error\", elapsed)\n        raise\n\n    elapsed = time.monotonic() - start_time\n    logger.info(\n        \"Index saved successfully\",\n        extra={\n            \"operation\": \"save_index\",\n            \"status\": \"success\",\n            \"duration_seconds\": elapsed,\n            \"stage\": _METRIC_STAGE_LABEL,\n            \"correlation_id\": correlation_id,\n        },\n    )\n    _observe_metrics(operation, \"success\", elapsed)\n</code></pre>"},{"location":"modules/search_api.vectorstore_factory/#search_apivectorstore_factory_ingestion_extra","title":"search_api.vectorstore_factory._ingestion_extra","text":""},{"location":"modules/search_api.vectorstore_factory/#search_api.vectorstore_factory._ingestion_extra","title":"<code>search_api.vectorstore_factory._ingestion_extra(*, correlation_id=None, **extra_fields)</code>","text":"Source code in <code>src/search_api/vectorstore_factory.py</code> <pre><code>def _ingestion_extra(\n    *, correlation_id: str | None = None, **extra_fields: object\n) -&gt; dict[str, object]:\n    base = dict(extra_fields)\n    if correlation_id:\n        base[\"correlation_id\"] = correlation_id\n    base.setdefault(\"stage\", _METRIC_STAGE_LABEL)\n    return base\n</code></pre>"},{"location":"modules/search_api.vectorstore_factory/#search_apivectorstore_factory_observe_metrics","title":"search_api.vectorstore_factory._observe_metrics","text":""},{"location":"modules/search_api.vectorstore_factory/#search_api.vectorstore_factory._observe_metrics","title":"<code>search_api.vectorstore_factory._observe_metrics(operation, status, duration_seconds)</code>","text":"Source code in <code>src/search_api/vectorstore_factory.py</code> <pre><code>def _observe_metrics(operation: str, status: str, duration_seconds: float) -&gt; None:\n    labels = {\"stage\": _METRIC_STAGE_LABEL, \"operation\": operation, \"status\": status}\n    _BUILD_COUNTER.labels(**labels).inc()\n    _BUILD_DURATION.labels(stage=_METRIC_STAGE_LABEL, operation=operation).observe(duration_seconds)\n</code></pre>"},{"location":"modules/search_client.client/","title":"search_client.client","text":""},{"location":"modules/search_client.client/#search_clientclient","title":"search_client.client","text":"<p>Lightweight client wrapper around the kgfoundry Search API</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_client.client/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class KGFoundryClient\n    class RequestsHttp\n    class SupportsHttp\n    SupportsHttp &lt;|-- RequestsHttp\n    class SupportsHttp_1\n    class Protocol\n    Protocol &lt;|-- SupportsHttp_1\n    class SupportsResponse\n    Protocol &lt;|-- SupportsResponse\n</code></pre>"},{"location":"modules/search_client.client/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_client.client__future__.annotationscollections.abc.Mappingkgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.problem_details.JsonValuerequeststyping.Finaltyping.Protocoltyping.TYPE_CHECKINGtyping.castsearch_client.client code <p>See the full diagram: search_client.client</p>"},{"location":"modules/search_client.client/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>search_client.client.KGFoundryClient</li> <li>search_client.client.RequestsHttp</li> <li>search_client.client.SupportsHttp</li> </ul>"},{"location":"modules/search_client.client/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Mapping</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.problem_details.JsonValue</code>, <code>requests</code>, <code>typing.Final</code>, <code>typing.Protocol</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/search_client.client/#contents","title":"Contents","text":""},{"location":"modules/search_client.client/#search_clientclientkgfoundryclient","title":"search_client.client.KGFoundryClient","text":""},{"location":"modules/search_client.client/#search_client.client.KGFoundryClient","title":"<code>search_client.client.KGFoundryClient</code>","text":"<p>High-level client for the kgfoundry Search API.</p> <p>Provides a convenient interface for interacting with the kgfoundry Search API, including search, health checks, and knowledge graph concept queries. Supports authentication via API keys and configurable timeouts.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>Base URL of the Search API service. Defaults to \"http://localhost:8080\".</p> <code>'http://localhost:8080'</code> <code>api_key</code> <code>str | None</code> <p>API key for Bearer token authentication. Defaults to None (no auth).</p> <code>None</code> <code>timeout</code> <code>float</code> <p>Default request timeout in seconds. Defaults to 30.0.</p> <code>30.0</code> <code>http</code> <code>SupportsHttp | None</code> <p>HTTP adapter implementation. If None, uses RequestsHttp. Defaults to None.</p> <code>None</code> Source code in <code>src/search_client/client.py</code> <pre><code>class KGFoundryClient:\n    \"\"\"High-level client for the kgfoundry Search API.\n\n    Provides a convenient interface for interacting with the kgfoundry Search API,\n    including search, health checks, and knowledge graph concept queries. Supports\n    authentication via API keys and configurable timeouts.\n\n    Parameters\n    ----------\n    base_url : str, optional\n        Base URL of the Search API service. Defaults to \"http://localhost:8080\".\n    api_key : str | None, optional\n        API key for Bearer token authentication. Defaults to None (no auth).\n    timeout : float, optional\n        Default request timeout in seconds. Defaults to 30.0.\n    http : SupportsHttp | None, optional\n        HTTP adapter implementation. If None, uses RequestsHttp.\n        Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        base_url: str = \"http://localhost:8080\",\n        api_key: str | None = None,\n        timeout: float = 30.0,\n        http: SupportsHttp | None = None,\n    ) -&gt; None:\n        \"\"\"Instantiate the client with connection details.\n\n        Initializes the client with API endpoint, authentication, and timeout\n        configuration. The base_url is normalized by removing trailing slashes.\n\n        Parameters\n        ----------\n        base_url : str, optional\n            Base URL of the Search API service. Defaults to \"http://localhost:8080\".\n        api_key : str | None, optional\n            API key for Bearer token authentication. Defaults to None (no auth).\n        timeout : float, optional\n            Default request timeout in seconds. Defaults to 30.0.\n        http : SupportsHttp | None, optional\n            HTTP adapter implementation. If None, uses RequestsHttp.\n            Defaults to None.\n        \"\"\"\n        self.base_url = base_url.rstrip(\"/\")\n        self.api_key = api_key\n        self.timeout = timeout\n        self._http: SupportsHttp = http or _DEFAULT_HTTP\n\n    def _headers(self) -&gt; dict[str, str]:\n        \"\"\"Build default headers for authenticated requests.\n\n        Constructs HTTP headers for requests, including Content-Type and\n        Authorization (if API key is configured).\n\n        Returns\n        -------\n        dict[str, str]\n            Header dictionary including Content-Type and Authorization (if API key\n            is configured).\n        \"\"\"\n        headers = {\"Content-Type\": \"application/json\"}\n        if self.api_key:\n            headers[\"Authorization\"] = f\"Bearer {self.api_key}\"\n        return headers\n\n    def healthz(self) -&gt; JsonValue:\n        \"\"\"Fetch the service health endpoint.\n\n        Queries the /healthz endpoint to check service availability and\n        component status.\n\n        Returns\n        -------\n        JsonValue\n            JSON payload describing service health, including component\n            availability status.\n\n        Notes\n        -----\n        Propagates :class:`requests.HTTPError` when the API responds with a\n        non-success status code.\n        \"\"\"\n        response = self._http.get(f\"{self.base_url}/healthz\", timeout=self.timeout)\n        response.raise_for_status()\n        return response.json()\n\n    def search(\n        self,\n        query: str,\n        k: int = 10,\n        filters: dict[str, JsonValue] | None = None,\n        *,\n        explain: bool = False,\n    ) -&gt; JsonValue:\n        \"\"\"Execute a semantic search request.\n\n        Performs a hybrid search query combining dense (FAISS), sparse (BM25/SPLADE),\n        and knowledge graph signals. Returns ranked results with optional explanation\n        metadata.\n\n        Parameters\n        ----------\n        query : str\n            Search query text.\n        k : int, optional\n            Maximum number of results to return. Defaults to 10.\n        filters : dict[str, JsonValue] | None, optional\n            Optional facet filters for narrowing search results. Defaults to None.\n        explain : bool, optional\n            Whether to include explanation metadata in results. Defaults to False.\n\n        Returns\n        -------\n        JsonValue\n            JSON response containing the ranked search results with metadata.\n\n        Notes\n        -----\n        Propagates :class:`requests.HTTPError` when the API responds with a\n        non-success status code.\n        \"\"\"\n        filters_payload: dict[str, JsonValue] = filters.copy() if filters is not None else {}\n        payload: dict[str, JsonValue] = {\n            \"query\": query,\n            \"k\": k,\n            \"filters\": filters_payload,\n            \"explain\": explain,\n        }\n        response = self._http.post(\n            f\"{self.base_url}/search\",\n            json=payload,\n            headers=self._headers(),\n            timeout=self.timeout,\n        )\n        response.raise_for_status()\n        return response.json()\n\n    def concepts(self, q: str, limit: int = 50) -&gt; JsonValue:\n        \"\"\"Retrieve graph concepts that match the provided query string.\n\n        Queries the knowledge graph for concepts matching the query string.\n        Returns concept IDs and labels.\n\n        Parameters\n        ----------\n        q : str\n            Query string to match against concept labels (case-insensitive).\n        limit : int, optional\n            Maximum number of concepts to return. Defaults to 50.\n\n        Returns\n        -------\n        JsonValue\n            JSON response containing matching concepts with concept_id and label\n            fields.\n\n        Notes\n        -----\n        Propagates :class:`requests.HTTPError` when the API responds with a\n        non-success status code.\n        \"\"\"\n        body: dict[str, JsonValue] = {\"q\": q, \"limit\": limit}\n        response = self._http.post(\n            f\"{self.base_url}/graph/concepts\",\n            json=body,\n            headers=self._headers(),\n            timeout=self.timeout,\n        )\n        response.raise_for_status()\n        return response.json()\n</code></pre>"},{"location":"modules/search_client.client/#search_client.client.KGFoundryClient.__init__","title":"<code>__init__(base_url='http://localhost:8080', api_key=None, timeout=30.0, http=None)</code>","text":"<p>Instantiate the client with connection details.</p> <p>Initializes the client with API endpoint, authentication, and timeout configuration. The base_url is normalized by removing trailing slashes.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>Base URL of the Search API service. Defaults to \"http://localhost:8080\".</p> <code>'http://localhost:8080'</code> <code>api_key</code> <code>str | None</code> <p>API key for Bearer token authentication. Defaults to None (no auth).</p> <code>None</code> <code>timeout</code> <code>float</code> <p>Default request timeout in seconds. Defaults to 30.0.</p> <code>30.0</code> <code>http</code> <code>SupportsHttp | None</code> <p>HTTP adapter implementation. If None, uses RequestsHttp. Defaults to None.</p> <code>None</code> Source code in <code>src/search_client/client.py</code> <pre><code>def __init__(\n    self,\n    base_url: str = \"http://localhost:8080\",\n    api_key: str | None = None,\n    timeout: float = 30.0,\n    http: SupportsHttp | None = None,\n) -&gt; None:\n    \"\"\"Instantiate the client with connection details.\n\n    Initializes the client with API endpoint, authentication, and timeout\n    configuration. The base_url is normalized by removing trailing slashes.\n\n    Parameters\n    ----------\n    base_url : str, optional\n        Base URL of the Search API service. Defaults to \"http://localhost:8080\".\n    api_key : str | None, optional\n        API key for Bearer token authentication. Defaults to None (no auth).\n    timeout : float, optional\n        Default request timeout in seconds. Defaults to 30.0.\n    http : SupportsHttp | None, optional\n        HTTP adapter implementation. If None, uses RequestsHttp.\n        Defaults to None.\n    \"\"\"\n    self.base_url = base_url.rstrip(\"/\")\n    self.api_key = api_key\n    self.timeout = timeout\n    self._http: SupportsHttp = http or _DEFAULT_HTTP\n</code></pre>"},{"location":"modules/search_client.client/#search_client.client.KGFoundryClient.concepts","title":"<code>concepts(q, limit=50)</code>","text":"<p>Retrieve graph concepts that match the provided query string.</p> <p>Queries the knowledge graph for concepts matching the query string. Returns concept IDs and labels.</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>str</code> <p>Query string to match against concept labels (case-insensitive).</p> required <code>limit</code> <code>int</code> <p>Maximum number of concepts to return. Defaults to 50.</p> <code>50</code> <p>Returns:</p> Type Description <code>JsonValue</code> <p>JSON response containing matching concepts with concept_id and label fields.</p> Notes <p>Propagates :class:<code>requests.HTTPError</code> when the API responds with a non-success status code.</p> Source code in <code>src/search_client/client.py</code> <pre><code>def concepts(self, q: str, limit: int = 50) -&gt; JsonValue:\n    \"\"\"Retrieve graph concepts that match the provided query string.\n\n    Queries the knowledge graph for concepts matching the query string.\n    Returns concept IDs and labels.\n\n    Parameters\n    ----------\n    q : str\n        Query string to match against concept labels (case-insensitive).\n    limit : int, optional\n        Maximum number of concepts to return. Defaults to 50.\n\n    Returns\n    -------\n    JsonValue\n        JSON response containing matching concepts with concept_id and label\n        fields.\n\n    Notes\n    -----\n    Propagates :class:`requests.HTTPError` when the API responds with a\n    non-success status code.\n    \"\"\"\n    body: dict[str, JsonValue] = {\"q\": q, \"limit\": limit}\n    response = self._http.post(\n        f\"{self.base_url}/graph/concepts\",\n        json=body,\n        headers=self._headers(),\n        timeout=self.timeout,\n    )\n    response.raise_for_status()\n    return response.json()\n</code></pre>"},{"location":"modules/search_client.client/#search_client.client.KGFoundryClient.healthz","title":"<code>healthz()</code>","text":"<p>Fetch the service health endpoint.</p> <p>Queries the /healthz endpoint to check service availability and component status.</p> <p>Returns:</p> Type Description <code>JsonValue</code> <p>JSON payload describing service health, including component availability status.</p> Notes <p>Propagates :class:<code>requests.HTTPError</code> when the API responds with a non-success status code.</p> Source code in <code>src/search_client/client.py</code> <pre><code>def healthz(self) -&gt; JsonValue:\n    \"\"\"Fetch the service health endpoint.\n\n    Queries the /healthz endpoint to check service availability and\n    component status.\n\n    Returns\n    -------\n    JsonValue\n        JSON payload describing service health, including component\n        availability status.\n\n    Notes\n    -----\n    Propagates :class:`requests.HTTPError` when the API responds with a\n    non-success status code.\n    \"\"\"\n    response = self._http.get(f\"{self.base_url}/healthz\", timeout=self.timeout)\n    response.raise_for_status()\n    return response.json()\n</code></pre>"},{"location":"modules/search_client.client/#search_client.client.KGFoundryClient.search","title":"<code>search(query, k=10, filters=None, *, explain=False)</code>","text":"<p>Execute a semantic search request.</p> <p>Performs a hybrid search query combining dense (FAISS), sparse (BM25/SPLADE), and knowledge graph signals. Returns ranked results with optional explanation metadata.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query text.</p> required <code>k</code> <code>int</code> <p>Maximum number of results to return. Defaults to 10.</p> <code>10</code> <code>filters</code> <code>dict[str, JsonValue] | None</code> <p>Optional facet filters for narrowing search results. Defaults to None.</p> <code>None</code> <code>explain</code> <code>bool</code> <p>Whether to include explanation metadata in results. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>JsonValue</code> <p>JSON response containing the ranked search results with metadata.</p> Notes <p>Propagates :class:<code>requests.HTTPError</code> when the API responds with a non-success status code.</p> Source code in <code>src/search_client/client.py</code> <pre><code>def search(\n    self,\n    query: str,\n    k: int = 10,\n    filters: dict[str, JsonValue] | None = None,\n    *,\n    explain: bool = False,\n) -&gt; JsonValue:\n    \"\"\"Execute a semantic search request.\n\n    Performs a hybrid search query combining dense (FAISS), sparse (BM25/SPLADE),\n    and knowledge graph signals. Returns ranked results with optional explanation\n    metadata.\n\n    Parameters\n    ----------\n    query : str\n        Search query text.\n    k : int, optional\n        Maximum number of results to return. Defaults to 10.\n    filters : dict[str, JsonValue] | None, optional\n        Optional facet filters for narrowing search results. Defaults to None.\n    explain : bool, optional\n        Whether to include explanation metadata in results. Defaults to False.\n\n    Returns\n    -------\n    JsonValue\n        JSON response containing the ranked search results with metadata.\n\n    Notes\n    -----\n    Propagates :class:`requests.HTTPError` when the API responds with a\n    non-success status code.\n    \"\"\"\n    filters_payload: dict[str, JsonValue] = filters.copy() if filters is not None else {}\n    payload: dict[str, JsonValue] = {\n        \"query\": query,\n        \"k\": k,\n        \"filters\": filters_payload,\n        \"explain\": explain,\n    }\n    response = self._http.post(\n        f\"{self.base_url}/search\",\n        json=payload,\n        headers=self._headers(),\n        timeout=self.timeout,\n    )\n    response.raise_for_status()\n    return response.json()\n</code></pre>"},{"location":"modules/search_client.client/#search_clientclientrequestshttp","title":"search_client.client.RequestsHttp","text":"<p>Bases: SupportsHttp</p>"},{"location":"modules/search_client.client/#search_client.client.RequestsHttp","title":"<code>search_client.client.RequestsHttp</code>","text":"<p>               Bases: <code>SupportsHttp</code></p> <p>HTTP adapter that delegates HTTP verbs to :mod:<code>requests</code>.</p> <p>Thin wrapper around the <code>requests</code> library that implements the SupportsHttp protocol. This adapter exists to make the high-level client easy to test by swapping in alternative transports.</p> Notes <p>This thin wrapper exists to make the high-level client easy to test by swapping in alternative transports.</p> Source code in <code>src/search_client/client.py</code> <pre><code>class RequestsHttp(SupportsHttp):\n    \"\"\"HTTP adapter that delegates HTTP verbs to :mod:`requests`.\n\n    Thin wrapper around the `requests` library that implements the SupportsHttp\n    protocol. This adapter exists to make the high-level client easy to test\n    by swapping in alternative transports.\n\n    Notes\n    -----\n    This thin wrapper exists to make the high-level client easy to test by swapping\n    in alternative transports.\n    \"\"\"\n\n    def __init__(self, session: requests.Session | None = None) -&gt; None:\n        \"\"\"Initialize search client.\n\n        Parameters\n        ----------\n        session : requests.Session | None, optional\n            HTTP session to use. Creates new session if None.\n            Defaults to None.\n        \"\"\"\n        self._session = session or requests.Session()\n\n    def get(\n        self,\n        url: str,\n        *,\n        timeout: float | tuple[float | None, float | None] | None = None,\n        headers: Mapping[str, str] | None = None,\n    ) -&gt; SupportsResponse:\n        \"\"\"Send a ``GET`` request using :func:`requests.get`.\n\n        Delegates to the underlying requests.Session.get() method.\n\n        Parameters\n        ----------\n        url : str\n            Target URL for the GET request.\n        timeout : float | tuple[float | None, float | None] | None, optional\n            Request timeout in seconds or (connect, read) tuple. Defaults to None\n            (no timeout).\n        headers : Mapping[str, str] | None, optional\n            HTTP headers to include with the request. Defaults to None.\n\n        Returns\n        -------\n        SupportsResponse\n            Response returned by :mod:`requests`.\n        \"\"\"\n        response = self._session.get(url, timeout=timeout, headers=headers)\n        return cast(\"SupportsResponse\", response)\n\n    def post(\n        self,\n        url: str,\n        *,\n        json: JsonValue | None = None,\n        headers: Mapping[str, str] | None = None,\n        timeout: float | tuple[float | None, float | None] | None = None,\n    ) -&gt; SupportsResponse:\n        \"\"\"Send a ``POST`` request using :func:`requests.post`.\n\n        Delegates to the underlying requests.Session.post() method.\n\n        Parameters\n        ----------\n        url : str\n            Target URL for the POST request.\n        json : JsonValue | None, optional\n            JSON body to send with the request. Defaults to None.\n        headers : Mapping[str, str] | None, optional\n            HTTP headers to include with the request. Defaults to None.\n        timeout : float | tuple[float | None, float | None] | None, optional\n            Request timeout in seconds or (connect, read) tuple. Defaults to None\n            (no timeout).\n\n        Returns\n        -------\n        SupportsResponse\n            Response returned by :mod:`requests`.\n        \"\"\"\n        response = self._session.post(url, json=json, headers=headers, timeout=timeout)\n        return cast(\"SupportsResponse\", response)\n</code></pre>"},{"location":"modules/search_client.client/#search_client.client.RequestsHttp.__init__","title":"<code>__init__(session=None)</code>","text":"<p>Initialize search client.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>Session | None</code> <p>HTTP session to use. Creates new session if None. Defaults to None.</p> <code>None</code> Source code in <code>src/search_client/client.py</code> <pre><code>def __init__(self, session: requests.Session | None = None) -&gt; None:\n    \"\"\"Initialize search client.\n\n    Parameters\n    ----------\n    session : requests.Session | None, optional\n        HTTP session to use. Creates new session if None.\n        Defaults to None.\n    \"\"\"\n    self._session = session or requests.Session()\n</code></pre>"},{"location":"modules/search_client.client/#search_client.client.RequestsHttp.get","title":"<code>get(url, *, timeout=None, headers=None)</code>","text":"<p>Send a <code>GET</code> request using :func:<code>requests.get</code>.</p> <p>Delegates to the underlying requests.Session.get() method.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target URL for the GET request.</p> required <code>timeout</code> <code>float | tuple[float | None, float | None] | None</code> <p>Request timeout in seconds or (connect, read) tuple. Defaults to None (no timeout).</p> <code>None</code> <code>headers</code> <code>Mapping[str, str] | None</code> <p>HTTP headers to include with the request. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>SupportsResponse</code> <p>Response returned by :mod:<code>requests</code>.</p> Source code in <code>src/search_client/client.py</code> <pre><code>def get(\n    self,\n    url: str,\n    *,\n    timeout: float | tuple[float | None, float | None] | None = None,\n    headers: Mapping[str, str] | None = None,\n) -&gt; SupportsResponse:\n    \"\"\"Send a ``GET`` request using :func:`requests.get`.\n\n    Delegates to the underlying requests.Session.get() method.\n\n    Parameters\n    ----------\n    url : str\n        Target URL for the GET request.\n    timeout : float | tuple[float | None, float | None] | None, optional\n        Request timeout in seconds or (connect, read) tuple. Defaults to None\n        (no timeout).\n    headers : Mapping[str, str] | None, optional\n        HTTP headers to include with the request. Defaults to None.\n\n    Returns\n    -------\n    SupportsResponse\n        Response returned by :mod:`requests`.\n    \"\"\"\n    response = self._session.get(url, timeout=timeout, headers=headers)\n    return cast(\"SupportsResponse\", response)\n</code></pre>"},{"location":"modules/search_client.client/#search_client.client.RequestsHttp.post","title":"<code>post(url, *, json=None, headers=None, timeout=None)</code>","text":"<p>Send a <code>POST</code> request using :func:<code>requests.post</code>.</p> <p>Delegates to the underlying requests.Session.post() method.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target URL for the POST request.</p> required <code>json</code> <code>JsonValue | None</code> <p>JSON body to send with the request. Defaults to None.</p> <code>None</code> <code>headers</code> <code>Mapping[str, str] | None</code> <p>HTTP headers to include with the request. Defaults to None.</p> <code>None</code> <code>timeout</code> <code>float | tuple[float | None, float | None] | None</code> <p>Request timeout in seconds or (connect, read) tuple. Defaults to None (no timeout).</p> <code>None</code> <p>Returns:</p> Type Description <code>SupportsResponse</code> <p>Response returned by :mod:<code>requests</code>.</p> Source code in <code>src/search_client/client.py</code> <pre><code>def post(\n    self,\n    url: str,\n    *,\n    json: JsonValue | None = None,\n    headers: Mapping[str, str] | None = None,\n    timeout: float | tuple[float | None, float | None] | None = None,\n) -&gt; SupportsResponse:\n    \"\"\"Send a ``POST`` request using :func:`requests.post`.\n\n    Delegates to the underlying requests.Session.post() method.\n\n    Parameters\n    ----------\n    url : str\n        Target URL for the POST request.\n    json : JsonValue | None, optional\n        JSON body to send with the request. Defaults to None.\n    headers : Mapping[str, str] | None, optional\n        HTTP headers to include with the request. Defaults to None.\n    timeout : float | tuple[float | None, float | None] | None, optional\n        Request timeout in seconds or (connect, read) tuple. Defaults to None\n        (no timeout).\n\n    Returns\n    -------\n    SupportsResponse\n        Response returned by :mod:`requests`.\n    \"\"\"\n    response = self._session.post(url, json=json, headers=headers, timeout=timeout)\n    return cast(\"SupportsResponse\", response)\n</code></pre>"},{"location":"modules/search_client.client/#search_clientclientsupportshttp","title":"search_client.client.SupportsHttp","text":"<p>Bases: Protocol</p>"},{"location":"modules/search_client.client/#search_client.client.SupportsHttp","title":"<code>search_client.client.SupportsHttp</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol describing the HTTP verbs required by :class:<code>KGFoundryClient</code>.</p> <p>This protocol defines the minimal HTTP interface required by KGFoundryClient. Implementations only need to provide <code>get</code> and <code>post</code> methods that mirror the behavior of the <code>requests</code> library.</p> Notes <p>Implementations only need to provide <code>get</code> and <code>post</code> methods that mirror the behaviour of :mod:<code>requests</code>.</p> Source code in <code>src/search_client/client.py</code> <pre><code>class SupportsHttp(Protocol):\n    \"\"\"Protocol describing the HTTP verbs required by :class:`KGFoundryClient`.\n\n    This protocol defines the minimal HTTP interface required by KGFoundryClient.\n    Implementations only need to provide `get` and `post` methods that mirror\n    the behavior of the `requests` library.\n\n    Notes\n    -----\n    Implementations only need to provide ``get`` and ``post`` methods that mirror the\n    behaviour of :mod:`requests`.\n    \"\"\"\n\n    def get(\n        self,\n        url: str,\n        *,\n        timeout: float | tuple[float | None, float | None] | None = None,\n        headers: Mapping[str, str] | None = None,\n    ) -&gt; SupportsResponse:\n        \"\"\"Issue an HTTP ``GET`` request.\n\n        Sends a GET request to the specified URL with optional timeout and headers.\n\n        Parameters\n        ----------\n        url : str\n            Target URL for the GET request.\n        timeout : float | tuple[float | None, float | None] | None, optional\n            Request timeout in seconds or (connect, read) tuple. Defaults to None\n            (no timeout).\n        headers : Mapping[str, str] | None, optional\n            HTTP headers to include with the request. Defaults to None.\n\n        Returns\n        -------\n        SupportsResponse\n            Response wrapper produced by the HTTP implementation.\n        \"\"\"\n        ...\n\n    def post(\n        self,\n        url: str,\n        *,\n        json: JsonValue | None = None,\n        headers: Mapping[str, str] | None = None,\n        timeout: float | tuple[float | None, float | None] | None = None,\n    ) -&gt; SupportsResponse:\n        \"\"\"Issue an HTTP ``POST`` request.\n\n        Sends a POST request to the specified URL with optional JSON payload,\n        headers, and timeout.\n\n        Parameters\n        ----------\n        url : str\n            Target URL for the POST request.\n        json : JsonValue | None, optional\n            JSON payload to include in the request body. Defaults to None.\n        headers : Mapping[str, str] | None, optional\n            HTTP headers to include with the request. Defaults to None.\n        timeout : float | tuple[float | None, float | None] | None, optional\n            Request timeout in seconds or (connect, read) tuple. Defaults to None\n            (no timeout).\n\n        Returns\n        -------\n        SupportsResponse\n            Response wrapper produced by the HTTP implementation.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/search_client.client/#search_client.client.SupportsHttp.get","title":"<code>get(url, *, timeout=None, headers=None)</code>","text":"<p>Issue an HTTP <code>GET</code> request.</p> <p>Sends a GET request to the specified URL with optional timeout and headers.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target URL for the GET request.</p> required <code>timeout</code> <code>float | tuple[float | None, float | None] | None</code> <p>Request timeout in seconds or (connect, read) tuple. Defaults to None (no timeout).</p> <code>None</code> <code>headers</code> <code>Mapping[str, str] | None</code> <p>HTTP headers to include with the request. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>SupportsResponse</code> <p>Response wrapper produced by the HTTP implementation.</p> Source code in <code>src/search_client/client.py</code> <pre><code>def get(\n    self,\n    url: str,\n    *,\n    timeout: float | tuple[float | None, float | None] | None = None,\n    headers: Mapping[str, str] | None = None,\n) -&gt; SupportsResponse:\n    \"\"\"Issue an HTTP ``GET`` request.\n\n    Sends a GET request to the specified URL with optional timeout and headers.\n\n    Parameters\n    ----------\n    url : str\n        Target URL for the GET request.\n    timeout : float | tuple[float | None, float | None] | None, optional\n        Request timeout in seconds or (connect, read) tuple. Defaults to None\n        (no timeout).\n    headers : Mapping[str, str] | None, optional\n        HTTP headers to include with the request. Defaults to None.\n\n    Returns\n    -------\n    SupportsResponse\n        Response wrapper produced by the HTTP implementation.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/search_client.client/#search_client.client.SupportsHttp.post","title":"<code>post(url, *, json=None, headers=None, timeout=None)</code>","text":"<p>Issue an HTTP <code>POST</code> request.</p> <p>Sends a POST request to the specified URL with optional JSON payload, headers, and timeout.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Target URL for the POST request.</p> required <code>json</code> <code>JsonValue | None</code> <p>JSON payload to include in the request body. Defaults to None.</p> <code>None</code> <code>headers</code> <code>Mapping[str, str] | None</code> <p>HTTP headers to include with the request. Defaults to None.</p> <code>None</code> <code>timeout</code> <code>float | tuple[float | None, float | None] | None</code> <p>Request timeout in seconds or (connect, read) tuple. Defaults to None (no timeout).</p> <code>None</code> <p>Returns:</p> Type Description <code>SupportsResponse</code> <p>Response wrapper produced by the HTTP implementation.</p> Source code in <code>src/search_client/client.py</code> <pre><code>def post(\n    self,\n    url: str,\n    *,\n    json: JsonValue | None = None,\n    headers: Mapping[str, str] | None = None,\n    timeout: float | tuple[float | None, float | None] | None = None,\n) -&gt; SupportsResponse:\n    \"\"\"Issue an HTTP ``POST`` request.\n\n    Sends a POST request to the specified URL with optional JSON payload,\n    headers, and timeout.\n\n    Parameters\n    ----------\n    url : str\n        Target URL for the POST request.\n    json : JsonValue | None, optional\n        JSON payload to include in the request body. Defaults to None.\n    headers : Mapping[str, str] | None, optional\n        HTTP headers to include with the request. Defaults to None.\n    timeout : float | tuple[float | None, float | None] | None, optional\n        Request timeout in seconds or (connect, read) tuple. Defaults to None\n        (no timeout).\n\n    Returns\n    -------\n    SupportsResponse\n        Response wrapper produced by the HTTP implementation.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/search_client.client/#search_clientclientsupportsresponse","title":"search_client.client.SupportsResponse","text":"<p>Bases: Protocol</p>"},{"location":"modules/search_client.client/#search_client.client.SupportsResponse","title":"<code>search_client.client.SupportsResponse</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol describing the minimal HTTP response surface used by the client.</p> <p>This protocol defines the minimal interface required for HTTP responses used by KGFoundryClient. Implementations should mirror the behavior of <code>requests.Response</code> for the provided methods.</p> Notes <p>Implementations are expected to mirror :class:<code>requests.Response</code> for the provided methods so callers can work with a small shared interface.</p> Source code in <code>src/search_client/client.py</code> <pre><code>class SupportsResponse(Protocol):\n    \"\"\"Protocol describing the minimal HTTP response surface used by the client.\n\n    This protocol defines the minimal interface required for HTTP responses\n    used by KGFoundryClient. Implementations should mirror the behavior of\n    `requests.Response` for the provided methods.\n\n    Notes\n    -----\n    Implementations are expected to mirror :class:`requests.Response` for the provided\n    methods so callers can work with a small shared interface.\n    \"\"\"\n\n    def raise_for_status(self) -&gt; None:\n        \"\"\"Raise an HTTP error if the response indicates failure.\n\n        Raises an exception if the HTTP status code indicates an error (4xx or 5xx). Should mirror\n        the behavior of `requests.Response.raise_for_status()`.\n        \"\"\"\n\n    def json(self) -&gt; JsonValue:\n        \"\"\"Return the response payload as JSON.\n\n        Parses the response body as JSON and returns the decoded value.\n        Should mirror the behavior of `requests.Response.json()`.\n\n        Returns\n        -------\n        JsonValue\n            Decoded JSON body returned by the HTTP service. Can be a dict, list,\n            str, int, float, bool, or None.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"modules/search_client.client/#search_client.client.SupportsResponse.json","title":"<code>json()</code>","text":"<p>Return the response payload as JSON.</p> <p>Parses the response body as JSON and returns the decoded value. Should mirror the behavior of <code>requests.Response.json()</code>.</p> <p>Returns:</p> Type Description <code>JsonValue</code> <p>Decoded JSON body returned by the HTTP service. Can be a dict, list, str, int, float, bool, or None.</p> Source code in <code>src/search_client/client.py</code> <pre><code>def json(self) -&gt; JsonValue:\n    \"\"\"Return the response payload as JSON.\n\n    Parses the response body as JSON and returns the decoded value.\n    Should mirror the behavior of `requests.Response.json()`.\n\n    Returns\n    -------\n    JsonValue\n        Decoded JSON body returned by the HTTP service. Can be a dict, list,\n        str, int, float, bool, or None.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"modules/search_client.client/#search_client.client.SupportsResponse.raise_for_status","title":"<code>raise_for_status()</code>","text":"<p>Raise an HTTP error if the response indicates failure.</p> <p>Raises an exception if the HTTP status code indicates an error (4xx or 5xx). Should mirror the behavior of <code>requests.Response.raise_for_status()</code>.</p> Source code in <code>src/search_client/client.py</code> <pre><code>def raise_for_status(self) -&gt; None:\n    \"\"\"Raise an HTTP error if the response indicates failure.\n\n    Raises an exception if the HTTP status code indicates an error (4xx or 5xx). Should mirror\n    the behavior of `requests.Response.raise_for_status()`.\n    \"\"\"\n</code></pre>"},{"location":"modules/search_client/","title":"search_client","text":""},{"location":"modules/search_client/#search_client","title":"search_client","text":"<p>Client abstractions for calling the kgfoundry Search API</p> <p>:material-source-repository: View source</p>"},{"location":"modules/search_client/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"search_client__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.navmap_types.NavMapsearch_client.client.KGFoundryClientsearch_client code <p>See the full diagram: search_client</p>"},{"location":"modules/search_client/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.navmap_types.NavMap</code>, <code>search_client.client.KGFoundryClient</code></p>"},{"location":"modules/vectorstore_faiss.gpu/","title":"vectorstore_faiss.gpu","text":""},{"location":"modules/vectorstore_faiss.gpu/#vectorstore_faissgpu","title":"vectorstore_faiss.gpu","text":"<p>GPU-aware FAISS index helpers backed by the shared search API facade.</p> <p>:material-source-repository: View source</p>"},{"location":"modules/vectorstore_faiss.gpu/#inheritance","title":"Inheritance","text":"<pre><code>classDiagram\n    class FaissGpuIndex\n</code></pre>"},{"location":"modules/vectorstore_faiss.gpu/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"vectorstore_faiss.gpu__future__.annotationscollections.abc.Sequencedataclasses.dataclasskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.numpy_typing.FloatMatrixkgfoundry_common.numpy_typing.FloatVectorkgfoundry_common.numpy_typing.IntVectorkgfoundry_common.numpy_typing.normalize_l2loggingnumpynumpy.typingsearch_api.faiss_gpu.GpuContextsearch_api.faiss_gpu.clone_index_to_gpusearch_api.faiss_gpu.configure_search_parameterssearch_api.faiss_gpu.detect_gpu_contextsearch_api.types.FaissIndexProtocolsearch_api.types.FaissModuleProtocoltyping.TYPE_CHECKINGtyping.castvectorstore_faiss.gpu code <p>See the full diagram: vectorstore_faiss.gpu</p>"},{"location":"modules/vectorstore_faiss.gpu/#autorefs-examples","title":"Autorefs Examples","text":"<ul> <li>vectorstore_faiss.gpu.FaissGpuIndex</li> </ul>"},{"location":"modules/vectorstore_faiss.gpu/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>collections.abc.Sequence</code>, <code>dataclasses.dataclass</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.numpy_typing.FloatMatrix</code>, <code>kgfoundry_common.numpy_typing.FloatVector</code>, <code>kgfoundry_common.numpy_typing.IntVector</code>, <code>kgfoundry_common.numpy_typing.normalize_l2</code>, <code>logging</code>, <code>numpy</code>, <code>numpy.typing</code>, <code>search_api.faiss_gpu.GpuContext</code>, <code>search_api.faiss_gpu.clone_index_to_gpu</code>, <code>search_api.faiss_gpu.configure_search_parameters</code>, <code>search_api.faiss_gpu.detect_gpu_context</code>, <code>search_api.types.FaissIndexProtocol</code>, <code>search_api.types.FaissModuleProtocol</code>, <code>typing.TYPE_CHECKING</code>, <code>typing.cast</code></p>"},{"location":"modules/vectorstore_faiss.gpu/#contents","title":"Contents","text":""},{"location":"modules/vectorstore_faiss.gpu/#vectorstore_faissgpufaissgpuindex","title":"vectorstore_faiss.gpu.FaissGpuIndex","text":""},{"location":"modules/vectorstore_faiss.gpu/#vectorstore_faiss.gpu.FaissGpuIndex","title":"<code>vectorstore_faiss.gpu.FaissGpuIndex</code>  <code>dataclass</code>","text":"<p>Small GPU-aware facade that delegates to :mod:<code>search_api.faiss_gpu</code>.</p> <p>The facade keeps GPU initialisation idempotent by caching the detected context. If GPUs or cuVS helpers are unavailable, the CPU index is returned unchanged, ensuring safe fallbacks without caller intervention.</p> Source code in <code>src/vectorstore_faiss/gpu.py</code> <pre><code>@dataclass(slots=True)\n# [nav:anchor FaissGpuIndex]\nclass FaissGpuIndex:\n    \"\"\"Small GPU-aware facade that delegates to :mod:`search_api.faiss_gpu`.\n\n    The facade keeps GPU initialisation idempotent by caching the detected context. If GPUs or cuVS\n    helpers are unavailable, the CPU index is returned unchanged, ensuring safe fallbacks without\n    caller intervention.\n    \"\"\"\n\n    faiss_module: FaissModuleProtocol\n    factory: str\n    metric: str\n    nprobe: int = 64\n    use_gpu: bool = True\n    use_cuvs: bool = True\n    devices: Sequence[int] = (0,)\n\n    _context: GpuContext | None = None\n    _index: FaissIndexProtocol | None = None\n\n    def prepare(self, trained_index: FaissIndexProtocol) -&gt; FaissIndexProtocol:\n        \"\"\"Clone ``trained_index`` to GPU when possible and set search parameters.\n\n        The method is safe to call repeatedly; once a GPU index has been prepared it is reused on\n        subsequent invocations. Any failures during cloning or configuration are logged and the CPU\n        index is returned.\n\n        Parameters\n        ----------\n        trained_index : FaissIndexProtocol\n            Trained CPU index to prepare.\n\n        Returns\n        -------\n        FaissIndexProtocol\n            GPU index if available, otherwise CPU index.\n        \"\"\"\n        if not self.use_gpu:\n            logger.debug(\"GPU acceleration disabled; using CPU index only\")\n            self._index = trained_index\n            return trained_index\n\n        context = detect_gpu_context(\n            self.faiss_module,\n            use_cuvs=self.use_cuvs,\n            device_ids=self.devices,\n        )\n        if context is None:\n            logger.debug(\"GPU helpers missing; falling back to CPU index\")\n            self._index = trained_index\n            return trained_index\n\n        gpu_index = clone_index_to_gpu(trained_index, context)\n        configure_search_parameters(\n            self.faiss_module, gpu_index, nprobe=self.nprobe, gpu_enabled=True\n        )\n        self._context = context\n        self._index = gpu_index\n        return gpu_index\n\n    def search(self, query: FloatVector, k: int) -&gt; list[tuple[int, float]]:\n        \"\"\"Execute a search against the prepared index returning ``(id, score)`` pairs.\n\n        Parameters\n        ----------\n        query : FloatVector\n            Query vector to search with.\n        k : int\n            Number of results to return.\n\n        Returns\n        -------\n        list[tuple[int, float]]\n            List of (id, score) pairs.\n\n        Raises\n        ------\n        RuntimeError\n            If index has not been prepared.\n        \"\"\"\n        if self._index is None:\n            msg = \"FAISS GPU index not prepared\"\n            raise RuntimeError(msg)\n\n        query_vector = np.asarray(query, dtype=np.float32).reshape(1, -1)\n        normalized = normalize_l2(query_vector, axis=1)\n        score_matrix, index_matrix = self._index.search(normalized, k)\n        score_matrix_typed: FloatMatrix = np.asarray(score_matrix, dtype=np.float32)\n        index_matrix_typed: IntVector = np.asarray(index_matrix, dtype=np.int64)\n        score_vector: FloatVector = score_matrix_typed[0]\n        index_vector: IntVector = index_matrix_typed[0]\n        top_scores = cast(\"list[float]\", score_vector.astype(np.float32, copy=False).tolist())\n        top_indices = cast(\"list[int]\", index_vector.astype(np.int64, copy=False).tolist())\n        return list(zip(top_indices, top_scores, strict=False))\n</code></pre>"},{"location":"modules/vectorstore_faiss.gpu/#vectorstore_faiss.gpu.FaissGpuIndex.prepare","title":"<code>prepare(trained_index)</code>","text":"<p>Clone <code>trained_index</code> to GPU when possible and set search parameters.</p> <p>The method is safe to call repeatedly; once a GPU index has been prepared it is reused on subsequent invocations. Any failures during cloning or configuration are logged and the CPU index is returned.</p> <p>Parameters:</p> Name Type Description Default <code>trained_index</code> <code>FaissIndexProtocol</code> <p>Trained CPU index to prepare.</p> required <p>Returns:</p> Type Description <code>FaissIndexProtocol</code> <p>GPU index if available, otherwise CPU index.</p> Source code in <code>src/vectorstore_faiss/gpu.py</code> <pre><code>def prepare(self, trained_index: FaissIndexProtocol) -&gt; FaissIndexProtocol:\n    \"\"\"Clone ``trained_index`` to GPU when possible and set search parameters.\n\n    The method is safe to call repeatedly; once a GPU index has been prepared it is reused on\n    subsequent invocations. Any failures during cloning or configuration are logged and the CPU\n    index is returned.\n\n    Parameters\n    ----------\n    trained_index : FaissIndexProtocol\n        Trained CPU index to prepare.\n\n    Returns\n    -------\n    FaissIndexProtocol\n        GPU index if available, otherwise CPU index.\n    \"\"\"\n    if not self.use_gpu:\n        logger.debug(\"GPU acceleration disabled; using CPU index only\")\n        self._index = trained_index\n        return trained_index\n\n    context = detect_gpu_context(\n        self.faiss_module,\n        use_cuvs=self.use_cuvs,\n        device_ids=self.devices,\n    )\n    if context is None:\n        logger.debug(\"GPU helpers missing; falling back to CPU index\")\n        self._index = trained_index\n        return trained_index\n\n    gpu_index = clone_index_to_gpu(trained_index, context)\n    configure_search_parameters(\n        self.faiss_module, gpu_index, nprobe=self.nprobe, gpu_enabled=True\n    )\n    self._context = context\n    self._index = gpu_index\n    return gpu_index\n</code></pre>"},{"location":"modules/vectorstore_faiss.gpu/#vectorstore_faiss.gpu.FaissGpuIndex.search","title":"<code>search(query, k)</code>","text":"<p>Execute a search against the prepared index returning <code>(id, score)</code> pairs.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>FloatVector</code> <p>Query vector to search with.</p> required <code>k</code> <code>int</code> <p>Number of results to return.</p> required <p>Returns:</p> Type Description <code>list[tuple[int, float]]</code> <p>List of (id, score) pairs.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If index has not been prepared.</p> Source code in <code>src/vectorstore_faiss/gpu.py</code> <pre><code>def search(self, query: FloatVector, k: int) -&gt; list[tuple[int, float]]:\n    \"\"\"Execute a search against the prepared index returning ``(id, score)`` pairs.\n\n    Parameters\n    ----------\n    query : FloatVector\n        Query vector to search with.\n    k : int\n        Number of results to return.\n\n    Returns\n    -------\n    list[tuple[int, float]]\n        List of (id, score) pairs.\n\n    Raises\n    ------\n    RuntimeError\n        If index has not been prepared.\n    \"\"\"\n    if self._index is None:\n        msg = \"FAISS GPU index not prepared\"\n        raise RuntimeError(msg)\n\n    query_vector = np.asarray(query, dtype=np.float32).reshape(1, -1)\n    normalized = normalize_l2(query_vector, axis=1)\n    score_matrix, index_matrix = self._index.search(normalized, k)\n    score_matrix_typed: FloatMatrix = np.asarray(score_matrix, dtype=np.float32)\n    index_matrix_typed: IntVector = np.asarray(index_matrix, dtype=np.int64)\n    score_vector: FloatVector = score_matrix_typed[0]\n    index_vector: IntVector = index_matrix_typed[0]\n    top_scores = cast(\"list[float]\", score_vector.astype(np.float32, copy=False).tolist())\n    top_indices = cast(\"list[int]\", index_vector.astype(np.int64, copy=False).tolist())\n    return list(zip(top_indices, top_scores, strict=False))\n</code></pre>"},{"location":"modules/vectorstore_faiss/","title":"vectorstore_faiss","text":""},{"location":"modules/vectorstore_faiss/#vectorstore_faiss","title":"vectorstore_faiss","text":"<p>FAISS GPU vector store wrappers</p> <p>:material-source-repository: View source</p>"},{"location":"modules/vectorstore_faiss/#dependencies-at-a-glance","title":"Dependencies at a Glance","text":"vectorstore_faiss__future__.annotationskgfoundry_common.navmap_loader.load_nav_metadatakgfoundry_common.navmap_types.NavMapvectorstore_faiss code <p>See the full diagram: vectorstore_faiss</p>"},{"location":"modules/vectorstore_faiss/#relationships","title":"Relationships","text":"<p>Imports: <code>__future__.annotations</code>, <code>kgfoundry_common.navmap_loader.load_nav_metadata</code>, <code>kgfoundry_common.navmap_types.NavMap</code></p>"}]}