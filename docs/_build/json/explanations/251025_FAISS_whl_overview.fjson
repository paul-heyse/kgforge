{"parents": [{"link": "../", "title": "Explanations"}], "prev": {"link": "../251025_HighLevelArchitecture/", "title": "Implementation-Grade Architecture Overview"}, "next": {"link": "../../autoapi/", "title": "API Reference"}, "title": "Updated cuVS Addendum", "meta": {"wordcount": {"words": 2629, "minutes": 13}}, "body": "<section id=\"updated-cuvs-addendum\">\n<h1>Updated cuVS Addendum<a class=\"headerlink\" href=\"#updated-cuvs-addendum\" title=\"Link to this heading\">#</a></h1>\n<p>Below is an <strong>updated, implementation\u2011grade addendum</strong> that reflects your <strong>new FAISS wheel</strong> with <strong>cuVS integration compiled for</strong>: <strong>Flat</strong>, <strong>IVF\u2011Flat</strong>, <strong>IVF\u2011PQ</strong>, <strong>Graph CAGRA</strong>, and <strong>Binary\u2011CAGRA</strong>, as indicated by the build artifacts:</p>\n<div class=\"highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">CuvsFlatIndex</span><span class=\"o\">.</span><span class=\"n\">cu</span><span class=\"o\">.</span><span class=\"n\">o</span>\n<span class=\"n\">CuvsIVFFlat</span><span class=\"o\">.</span><span class=\"n\">cu</span><span class=\"o\">.</span><span class=\"n\">o</span>\n<span class=\"n\">CuvsIVFPQ</span><span class=\"o\">.</span><span class=\"n\">cu</span><span class=\"o\">.</span><span class=\"n\">o</span>\n<span class=\"n\">CuvsCagra</span><span class=\"o\">.</span><span class=\"n\">cu</span><span class=\"o\">.</span><span class=\"n\">o</span>\n<span class=\"n\">BinaryCuvsCagra</span><span class=\"o\">.</span><span class=\"n\">cu</span><span class=\"o\">.</span><span class=\"n\">o</span>\n<span class=\"n\">utils</span><span class=\"o\">/</span><span class=\"n\">CuvsFilterConvert</span><span class=\"o\">.</span><span class=\"n\">cu</span><span class=\"o\">.</span><span class=\"n\">o</span>\n<span class=\"n\">utils</span><span class=\"o\">/</span><span class=\"n\">CuvsUtils</span><span class=\"o\">.</span><span class=\"n\">cu</span><span class=\"o\">.</span><span class=\"n\">o</span>\n</pre></div>\n</div>\n<blockquote>\n<div><p><strong>Key consequence:</strong> In this wheel, <strong>FAISS GPU indexes can dispatch to cuVS kernels</strong> for the families above when you <strong>enable cuVS</strong> at construction/cloning time and the <strong>cuVS/RAPIDS libraries are present</strong> in the process. The runtime loader &amp; resource rules for cuVS remain the same (preload <code class=\"docutils literal notranslate\"><span class=\"pre\">libcuvs</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">librmm</span></code>, logging; use a shared <code class=\"docutils literal notranslate\"><span class=\"pre\">Resources</span></code> handle if calling cuVS directly).</p>\n</div></blockquote>\n<hr class=\"docutils\" />\n<section id=\"revised-capability-matrix-this-wheel\">\n<h2>1) Revised capability matrix (this wheel)<a class=\"headerlink\" href=\"#revised-capability-matrix-this-wheel\" title=\"Link to this heading\">#</a></h2>\n<div class=\"pst-scrollable-table-container\"><table class=\"table\">\n<thead>\n<tr class=\"row-odd\"><th class=\"head\"><p>Family / class</p></th>\n<th class=\"head text-right\"><p>CPU</p></th>\n<th class=\"head text-right\"><p>GPU (FAISS kernels)</p></th>\n<th class=\"head text-right\"><p><strong>cuVS through FAISS (this wheel)</strong></p></th>\n<th class=\"head text-right\"><p><strong>cuVS direct (Python)</strong></p></th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"row-even\"><td><p><strong>Flat (exact)</strong></p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexFlat{L2,IP}</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexFlat{L2,IP}</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 via <strong>index\u2011level cuVS</strong> (<code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexFlat{L2,IP}</span></code> with <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code>) and via <strong>bfKNN</strong> (<code class=\"docutils literal notranslate\"><span class=\"pre\">knn_gpu/bfKnn</span></code> with <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code>)</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.neighbors.brute_force</span></code></p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><strong>IVF\u2011Flat</strong></p></td>\n<td class=\"text-right\"><p>\u2705</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexIVFFlat</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 <strong>index\u2011level cuVS</strong> (<code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexIVFFlat</span></code> with <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code>)</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.neighbors.ivf_flat</span></code></p></td>\n</tr>\n<tr class=\"row-even\"><td><p><strong>IVF\u2011PQ</strong></p></td>\n<td class=\"text-right\"><p>\u2705</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexIVFPQ</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 <strong>index\u2011level cuVS</strong> (<code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexIVFPQ</span></code> with <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code>)</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.neighbors.ivf_pq</span></code></p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><strong>IVF\u2011SQ</strong></p></td>\n<td class=\"text-right\"><p>\u2705</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexIVFScalarQuantizer</span></code></p></td>\n<td class=\"text-right\"><p>\u2013 (no cuVS kernel here)</p></td>\n<td class=\"text-right\"><p>\u2013</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><strong>Graph (HNSW)</strong></p></td>\n<td class=\"text-right\"><p>\u2705</p></td>\n<td class=\"text-right\"><p>\u2013</p></td>\n<td class=\"text-right\"><p>\u2013</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.neighbors.hnsw</span></code></p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><strong>Graph (CAGRA)</strong></p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexHNSWCagra</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexCagra</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 <strong>index\u2011level cuVS</strong> (<code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexCagra</span></code> with <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code>)</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.neighbors.cagra</span></code> (+ multi\u2011GPU)</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><strong>Binary</strong></p></td>\n<td class=\"text-right\"><p>\u2705</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexBinaryFlat</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexBinaryCagra</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 <strong>Binary\u2011CAGRA</strong> via <strong>index\u2011level cuVS</strong> (<code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexBinaryCagra</span></code>)</p></td>\n<td class=\"text-right\"><p>\u2013</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><strong>Direct bfKNN</strong></p></td>\n<td class=\"text-right\"><p>\u2013</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">bfKnn(...)</span></code> / <code class=\"docutils literal notranslate\"><span class=\"pre\">knn_gpu(...)</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 <strong>set <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code></strong> (guard with <code class=\"docutils literal notranslate\"><span class=\"pre\">should_use_cuvs(...)</span></code>)</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.distance</span></code> / brute_force</p></td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>What changed:</strong> In earlier guidance, IVF\u2011Flat/IVF\u2011PQ/CAGRA/Binary\u2011CAGRA were marked \u201cnot via FAISS route\u201d. In <strong>this</strong> wheel, those families <strong>are</strong> cuVS\u2011enabled inside FAISS when you opt in via the <strong>index configs</strong> or <strong>GPU cloner options</strong> described below (and cuVS libs are present). The bfKNN cuVS path remains available. The cuVS loader &amp; environment remain as documented.</p>\n</section>\n<hr class=\"docutils\" />\n<section id=\"how-to-enable-cuvs-reliable-patterns\">\n<h2>2) How to enable cuVS (reliable patterns)<a class=\"headerlink\" href=\"#how-to-enable-cuvs-reliable-patterns\" title=\"Link to this heading\">#</a></h2>\n<section id=\"oneline-preload-cuvs-rapids-libs\">\n<h3>2.1. One\u2011line preload (cuVS/RAPIDS libs)<a class=\"headerlink\" href=\"#oneline-preload-cuvs-rapids-libs\" title=\"Link to this heading\">#</a></h3>\n<p>Call this <strong>before</strong> importing/initializing FAISS to ensure the shared libraries are resident:</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">libcuvs</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">load_library</span>\n<span class=\"n\">load_library</span><span class=\"p\">()</span>  <span class=\"c1\"># loads libcuvs, librmm, rapids_logger; idempotent</span>\n</pre></div>\n</div>\n<p>This follows the integration guidance in your loader reference and prevents <code class=\"docutils literal notranslate\"><span class=\"pre\">OSError:</span> <span class=\"pre\">libcuvs_c.so</span> <span class=\"pre\">not</span> <span class=\"pre\">found</span></code> surprises.</p>\n</section>\n<hr class=\"docutils\" />\n<section id=\"enabling-cuvs-via-gpu-cloner-options-recommended\">\n<h3>2.2. Enabling cuVS via <strong>GPU Cloner Options</strong> (recommended)<a class=\"headerlink\" href=\"#enabling-cuvs-via-gpu-cloner-options-recommended\" title=\"Link to this heading\">#</a></h3>\n<p>The simplest and most portable way to engage cuVS for <strong>Flat / IVF\u2011Flat / IVF\u2011PQ / CAGRA / Binary\u2011CAGRA</strong> is to <strong>build the index on CPU</strong>, then <strong>clone to GPU</strong> with a cuVS\u2011aware cloner:</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">faiss</span>\n\n<span class=\"c1\"># 1) Build a CPU index (examples below)</span>\n<span class=\"n\">cpu_index</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_factory</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"s2\">&quot;OPQ64,IVF8192,PQ64&quot;</span><span class=\"p\">,</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">)</span>\n<span class=\"n\">cpu_index</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">train_vectors</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 2) Prepare GPU resources</span>\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">StandardGpuResources</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># 3) Clone with cuVS enabled (guarded)</span>\n<span class=\"n\">co</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuClonerOptions</span><span class=\"p\">()</span>\n<span class=\"n\">co</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>  <span class=\"c1\"># ask for cuVS kernels if available</span>\n\n<span class=\"k\">try</span><span class=\"p\">:</span>\n    <span class=\"n\">gpu_index</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">cpu_index</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">)</span>\n<span class=\"k\">except</span> <span class=\"ne\">RuntimeError</span><span class=\"p\">:</span>\n    <span class=\"c1\"># Fallback if cuVS cannot be used for this combo</span>\n    <span class=\"n\">co</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n    <span class=\"n\">gpu_index</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">cpu_index</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<ul class=\"simple\">\n<li><p><code class=\"docutils literal notranslate\"><span class=\"pre\">GpuClonerOptions.use_cuvs</span></code> is exposed in this wheel and directs FAISS to build the <strong>cuVS\u2011backed</strong> GPU index when possible.</p></li>\n<li><p>This pattern works uniformly across Flat / IVF\u2011Flat / IVF\u2011PQ and also covers <strong>CAGRA</strong> if cloning from <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexHNSWCagra</span></code> to <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexCagra</span></code> is desired. (You can also build <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexCagra</span></code> directly; see 2.3.)</p></li>\n<li><p>Keep your <strong>existing memory tuning</strong> (<code class=\"docutils literal notranslate\"><span class=\"pre\">setTempMemory</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">setPinnedMemory</span></code>) for throughput.</p></li>\n</ul>\n<blockquote>\n<div><p>You can also probe <code class=\"docutils literal notranslate\"><span class=\"pre\">faiss.should_use_cuvs(...)</span></code> before setting the flag; however, the <strong>try/except</strong> is the most robust guard when combining drivers, cards, and dims.</p>\n</div></blockquote>\n</section>\n<hr class=\"docutils\" />\n<section id=\"enabling-cuvs-via-index-configs-direct-gpu-constructors\">\n<h3>2.3. Enabling cuVS via <strong>index configs</strong> (direct GPU constructors)<a class=\"headerlink\" href=\"#enabling-cuvs-via-index-configs-direct-gpu-constructors\" title=\"Link to this heading\">#</a></h3>\n<p>When you <strong>construct GPU indexes directly</strong>, pass a config whose base type is <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexConfig</span></code> and set <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code> there (the property is inherited by specific configs):</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"c1\"># Flat</span>\n<span class=\"n\">flat_cfg</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexFlatConfig</span><span class=\"p\">()</span>\n<span class=\"n\">flat_cfg</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"n\">gpu_flat</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexFlatIP</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"n\">flat_cfg</span><span class=\"p\">)</span>  <span class=\"c1\"># or GpuIndexFlatL2</span>\n\n<span class=\"c1\"># IVF-FLAT / IVF-PQ</span>\n<span class=\"n\">ivf_cfg</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexIVFConfig</span><span class=\"p\">()</span>\n<span class=\"n\">ivf_cfg</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"c1\"># ... pass ivf_cfg to the appropriate GpuIndexIVF* constructor</span>\n\n<span class=\"c1\"># CAGRA</span>\n<span class=\"n\">cagra_cfg</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexCagraConfig</span><span class=\"p\">()</span>\n<span class=\"n\">cagra_cfg</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"n\">gpu_cagra</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexCagra</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"n\">cagra_cfg</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Binary-CAGRA (if you build it directly)</span>\n<span class=\"c1\"># (config class may not be separate in the API; prefer the cloner path if unsure)</span>\n</pre></div>\n</div>\n<p>These configs inherit <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code> through <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexConfig</span></code> in this wheel. Use the cloner option (2.2) when you want one code path that works across all index types.</p>\n</section>\n<hr class=\"docutils\" />\n<section id=\"enabling-cuvs-for-direct-gpu-bruteforce-knn\">\n<h3>2.4. Enabling cuVS for <strong>direct GPU brute\u2011force kNN</strong><a class=\"headerlink\" href=\"#enabling-cuvs-for-direct-gpu-bruteforce-knn\" title=\"Link to this heading\">#</a></h3>\n<p>The <strong>bfKNN</strong> path can independently dispatch to cuVS kernels:</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">faiss</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">StandardGpuResources</span><span class=\"p\">,</span> <span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">,</span> <span class=\"n\">GpuDistanceParams</span><span class=\"p\">,</span> <span class=\"n\">knn_gpu</span>\n\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">StandardGpuResources</span><span class=\"p\">()</span>\n<span class=\"n\">params</span> <span class=\"o\">=</span> <span class=\"n\">GpuDistanceParams</span><span class=\"p\">();</span> <span class=\"n\">params</span><span class=\"o\">.</span><span class=\"n\">metric</span> <span class=\"o\">=</span> <span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">;</span> <span class=\"n\">params</span><span class=\"o\">.</span><span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"mi\">10</span><span class=\"p\">;</span> <span class=\"n\">params</span><span class=\"o\">.</span><span class=\"n\">dims</span> <span class=\"o\">=</span> <span class=\"n\">d</span>\n\n<span class=\"c1\"># guard with should_use_cuvs; fallback is automatic inside knn_gpu if you pass False</span>\n<span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>  <span class=\"c1\"># or: bool(faiss.should_use_cuvs(params))</span>\n<span class=\"n\">D</span><span class=\"p\">,</span> <span class=\"n\">I</span> <span class=\"o\">=</span> <span class=\"n\">knn_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">xq</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">),</span> <span class=\"n\">xb</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">),</span>\n               <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">,</span> <span class=\"n\">use_cuvs</span><span class=\"o\">=</span><span class=\"n\">use_cuvs</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p>This remains a great baseline even when your main serving index is IVF\u2011PQ/CAGRA.</p>\n</section>\n</section>\n<hr class=\"docutils\" />\n<section id=\"minimal-correct-by-construction-recipes-per-family\">\n<h2>3) Minimal \u201ccorrect by construction\u201d recipes per family<a class=\"headerlink\" href=\"#minimal-correct-by-construction-recipes-per-family\" title=\"Link to this heading\">#</a></h2>\n<blockquote>\n<div><p>These patterns <strong>train on CPU</strong> (deterministic), then <strong>clone to GPU with cuVS</strong>. You can switch to direct GPU construction later; the recall/latency behavior is identical once cuVS is engaged.</p>\n</div></blockquote>\n<section id=\"ivfpq-opq64-ivf8192-pq64-with-cuvs\">\n<h3>3.1. <strong>IVF\u2011PQ (OPQ64,IVF8192,PQ64)</strong> with cuVS<a class=\"headerlink\" href=\"#ivfpq-opq64-ivf8192-pq64-with-cuvs\" title=\"Link to this heading\">#</a></h3>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">faiss</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"nn\">numpy</span><span class=\"w\"> </span><span class=\"k\">as</span><span class=\"w\"> </span><span class=\"nn\">np</span>\n\n<span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"mi\">2560</span>\n<span class=\"n\">cpu</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_factory</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"s2\">&quot;OPQ64,IVF8192,PQ64&quot;</span><span class=\"p\">,</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">)</span>\n\n<span class=\"n\">train</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">10_000_000</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">normalize_L2</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">)</span>\n<span class=\"n\">cpu</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">)</span>\n\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">StandardGpuResources</span><span class=\"p\">()</span>\n<span class=\"n\">co</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuClonerOptions</span><span class=\"p\">();</span> <span class=\"n\">co</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"n\">gpu</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">cpu</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">)</span>  <span class=\"c1\"># cuVS-backed IVFPQ</span>\n\n<span class=\"c1\"># add/search as usual</span>\n</pre></div>\n</div>\n<ul class=\"simple\">\n<li><p>Keeps your default \u201cbest\u2011in\u2011class\u201d factory and determinism.</p></li>\n<li><p>The <strong>cloner</strong> chooses the cuVS implementation for the data path compiled in this wheel.</p></li>\n</ul>\n</section>\n<section id=\"ivfflat-with-cuvs\">\n<h3>3.2. <strong>IVF\u2011Flat</strong> with cuVS<a class=\"headerlink\" href=\"#ivfflat-with-cuvs\" title=\"Link to this heading\">#</a></h3>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">cpu</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_factory</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"s2\">&quot;IVF8192,Flat&quot;</span><span class=\"p\">,</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">)</span>\n<span class=\"n\">cpu</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">)</span>\n\n<span class=\"n\">co</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuClonerOptions</span><span class=\"p\">();</span> <span class=\"n\">co</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"n\">gpu</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">cpu</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">)</span>  <span class=\"c1\"># cuVS-backed IVFFlat</span>\n</pre></div>\n</div>\n</section>\n<section id=\"flat-exact-with-cuvs\">\n<h3>3.3. <strong>Flat (exact)</strong> with cuVS<a class=\"headerlink\" href=\"#flat-exact-with-cuvs\" title=\"Link to this heading\">#</a></h3>\n<ul class=\"simple\">\n<li><p><strong>Index route:</strong> <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexFlat{L2,IP}</span></code> with <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexFlatConfig.use_cuvs</span> <span class=\"pre\">=</span> <span class=\"pre\">True</span></code>.</p></li>\n<li><p><strong>Direct KNN:</strong> <code class=\"docutils literal notranslate\"><span class=\"pre\">knn_gpu(...,</span> <span class=\"pre\">use_cuvs=True)</span></code> (guarded).</p></li>\n</ul>\n</section>\n<section id=\"cagra-with-cuvs\">\n<h3>3.4. <strong>CAGRA</strong> with cuVS<a class=\"headerlink\" href=\"#cagra-with-cuvs\" title=\"Link to this heading\">#</a></h3>\n<ul>\n<li><p><strong>Direct GPU build</strong> (graph lives on GPU):</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">cfg</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexCagraConfig</span><span class=\"p\">();</span> <span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"n\">gpu_cagra</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexCagra</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"n\">cfg</span><span class=\"p\">)</span>\n<span class=\"c1\"># gpu_cagra.add(n, xb) builds the graph; search as usual</span>\n</pre></div>\n</div>\n</li>\n<li><p><strong>CPU\u2194GPU interop:</strong> <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexHNSWCagra</span></code> exists on CPU for moving graph structure if needed (e.g., copy base level). Keep primary serving on GPU to avoid host &lt;-&gt; device hops.</p></li>\n</ul>\n</section>\n<section id=\"binarycagra-with-cuvs\">\n<h3>3.5. <strong>Binary\u2011CAGRA</strong> with cuVS<a class=\"headerlink\" href=\"#binarycagra-with-cuvs\" title=\"Link to this heading\">#</a></h3>\n<ul class=\"simple\">\n<li><p>Prefer the <strong>cloner path</strong> when coming from CPU binary indexes; if you instantiate <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexBinaryCagra</span></code> directly, keep the same principle: construct with a config that enables cuVS (or clone with <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuClonerOptions.use_cuvs=True</span></code>) and fall back on error.</p></li>\n</ul>\n</section>\n</section>\n<hr class=\"docutils\" />\n<section id=\"filters-selectors-what-those-cuvsfilter-objects-mean-for-you\">\n<h2>4) Filters &amp; selectors (what those <code class=\"docutils literal notranslate\"><span class=\"pre\">CuvsFilter*</span></code> objects mean for you)<a class=\"headerlink\" href=\"#filters-selectors-what-those-cuvsfilter-objects-mean-for-you\" title=\"Link to this heading\">#</a></h2>\n<p>The presence of <code class=\"docutils literal notranslate\"><span class=\"pre\">utils/CuvsFilterConvert.cu.o</span></code> indicates FAISS performs <strong>selector/bitset conversion</strong> into cuVS\u2011compatible filter representations when a filter is passed at search time (e.g., via <code class=\"docutils literal notranslate\"><span class=\"pre\">SearchParametersIVF.sel</span></code> / ID selectors). You do not need to change your Python calls:</p>\n<ul class=\"simple\">\n<li><p>Keep using FAISS\u2019 <strong>search parameters</strong> (e.g., <code class=\"docutils literal notranslate\"><span class=\"pre\">SearchParametersIVF</span></code>\u2019s selector).</p></li>\n<li><p>When the index was constructed/cloned with <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code></strong>, the FAISS runtime converts the filter to cuVS\u2019 internal format and applies it during list scans.</p></li>\n</ul>\n<p>This is transparent but worth noting for <strong>filtered search</strong> scenarios. (The general cuVS run\u2011time and loader expectations remain exactly as previously documented.)</p>\n</section>\n<hr class=\"docutils\" />\n<section id=\"operational-reminders-unchanged-but-critical\">\n<h2>5) Operational reminders (unchanged but critical)<a class=\"headerlink\" href=\"#operational-reminders-unchanged-but-critical\" title=\"Link to this heading\">#</a></h2>\n<ul class=\"simple\">\n<li><p><strong>Preload cuVS</strong> once per process (<code class=\"docutils literal notranslate\"><span class=\"pre\">libcuvs.load_library()</span></code>), so <strong>RMM</strong> and logging are initialized and all <code class=\"docutils literal notranslate\"><span class=\"pre\">.so</span></code> dependencies are resident.</p></li>\n<li><p>Stick to <strong>row\u2011major <code class=\"docutils literal notranslate\"><span class=\"pre\">float32</span></code></strong> contiguous arrays for FAISS; normalize vectors for cosine (IP).</p></li>\n<li><p>Keep GPU working set <strong>\u2264 ~80% VRAM</strong>; pre\u2011allocate <strong>temp</strong> and <strong>pinned</strong> memory on <code class=\"docutils literal notranslate\"><span class=\"pre\">StandardGpuResources</span></code>.</p></li>\n<li><p>For <strong>cuVS direct</strong> experimentation (IVF\u2011PQ, IVF\u2011Flat, CAGRA, HNSW, multi\u2011GPU), continue to use the Python surfaces under <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.neighbors.*</span></code> with a shared <code class=\"docutils literal notranslate\"><span class=\"pre\">Resources</span></code> handle and device arrays, as documented in your cuVS reference.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"quick-am-i-using-cuvs-right-now-probes\">\n<h2>6) Quick \u201cam I using cuVS right now?\u201d probes<a class=\"headerlink\" href=\"#quick-am-i-using-cuvs-right-now-probes\" title=\"Link to this heading\">#</a></h2>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"c1\"># After calling libcuvs.load_library() and constructing your GPU index:</span>\n\n<span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">faiss</span>\n\n<span class=\"c1\"># 1) For bfKNN:</span>\n<span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuDistanceParams</span><span class=\"p\">();</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">;</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">dims</span><span class=\"o\">=</span><span class=\"n\">d</span><span class=\"p\">;</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&quot;bfKNN should_use_cuvs:&quot;</span><span class=\"p\">,</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">should_use_cuvs</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">))</span>  <span class=\"c1\"># True \u2192 bfKNN will route to cuVS</span>\n\n<span class=\"c1\"># 2) For an index you plan to build:</span>\n<span class=\"n\">cfg</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexIVFConfig</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&quot;Index should_use_cuvs:&quot;</span><span class=\"p\">,</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">should_use_cuvs</span><span class=\"p\">(</span><span class=\"n\">cfg</span><span class=\"p\">))</span>  <span class=\"c1\"># True \u2192 set cfg/co.use_cuvs = True</span>\n</pre></div>\n</div>\n<ul class=\"simple\">\n<li><p>If you skip <code class=\"docutils literal notranslate\"><span class=\"pre\">should_use_cuvs</span></code>, simply <strong>set <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code></strong> and <strong>catch</strong> a <code class=\"docutils literal notranslate\"><span class=\"pre\">RuntimeError</span></code> on construction; re\u2011try with <code class=\"docutils literal notranslate\"><span class=\"pre\">False</span></code>. This keeps your code robust across environments while <strong>preferring cuVS</strong> whenever available.</p></li>\n</ul>\n<hr class=\"docutils\" />\n<section id=\"pointers-unchanged\">\n<h3>Pointers (unchanged)<a class=\"headerlink\" href=\"#pointers-unchanged\" title=\"Link to this heading\">#</a></h3>\n<ul class=\"simple\">\n<li><p><strong>cuVS API &amp; usage</strong> (neighbors, distance, resources, device arrays) \u2014 your cuVS reference.</p></li>\n<li><p><strong>cuVS loader &amp; environment</strong> (preload order, env vars, system vs wheel libs) \u2014 libcuvs loader reference.</p></li>\n<li><p><strong>System architecture &amp; defaults</strong> (2560\u2011d, OPQ64/IVF8192/PQ64, persistence, observability) \u2014 high\u2011level architecture.</p></li>\n</ul>\n</section>\n</section>\n<hr class=\"docutils\" />\n<section id=\"bottom-line-what-to-change-in-your-code\">\n<h2>7) Bottom line (what to change in your code)<a class=\"headerlink\" href=\"#bottom-line-what-to-change-in-your-code\" title=\"Link to this heading\">#</a></h2>\n<ol class=\"arabic simple\">\n<li><p><strong>Call</strong> <code class=\"docutils literal notranslate\"><span class=\"pre\">load_library()</span></code> <strong>once at startup</strong>.</p></li>\n<li><p><strong>When cloning</strong> CPU\u2192GPU, set <code class=\"docutils literal notranslate\"><span class=\"pre\">co.use_cuvs</span> <span class=\"pre\">=</span> <span class=\"pre\">True</span></code> and <strong>fall back</strong> on error. This now enables cuVS for <strong>Flat</strong>, <strong>IVF\u2011Flat</strong>, <strong>IVF\u2011PQ</strong>, <strong>CAGRA</strong>, and <strong>Binary\u2011CAGRA</strong> in this build.</p></li>\n<li><p><strong>When constructing GPU indexes directly</strong>, set <code class=\"docutils literal notranslate\"><span class=\"pre\">cfg.use_cuvs</span> <span class=\"pre\">=</span> <span class=\"pre\">True</span></code> on the appropriate <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndex*Config</span></code></strong> (or use the cloner).</p></li>\n<li><p>For <strong>bfKNN</strong>, pass <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code> (or guard with <code class=\"docutils literal notranslate\"><span class=\"pre\">should_use_cuvs</span></code>).</p></li>\n<li><p>Keep the rest of the pipeline (factory string, normalization, memory planning, multi\u2011GPU strategy, persistence) <strong>unchanged</strong>.</p></li>\n</ol>\n</section>\n</section>\n<section id=\"addendum-base-content-on-faiss-gpu-library\">\n<h1>addendum, base content on faiss gpu library<a class=\"headerlink\" href=\"#addendum-base-content-on-faiss-gpu-library\" title=\"Link to this heading\">#</a></h1>\n<section id=\"what-changed-vs-the-prior-wheel-and-how-to-think-about-it\">\n<h2>0) What changed vs. the prior wheel (and how to think about it)<a class=\"headerlink\" href=\"#what-changed-vs-the-prior-wheel-and-how-to-think-about-it\" title=\"Link to this heading\">#</a></h2>\n<p><strong>Hardware/ABI</strong></p>\n<ul class=\"simple\">\n<li><p>CUDA runtime linked: <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">libcudart.so.13</span></code></strong> \u2192 the wheel targets <strong>CUDA\u202f13</strong> (Blackwell\u2011ready).</p></li>\n<li><p>GPU arch: <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">sm_120</span></code> SASS + PTX</strong> (\u201c<strong><code class=\"docutils literal notranslate\"><span class=\"pre\">sm_120\u2011virtual</span></code></strong>\u201d) for forward compatibility\u2014native kernels when they match, PTX JIT otherwise.</p></li>\n</ul>\n<p><strong>cuVS inside FAISS (this wheel)</strong></p>\n<ul class=\"simple\">\n<li><p>The GPU SWIG layer exports <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code> gates on index configs and cloner options</strong> and dynamically links against cuVS/RAPIDS libs. With cuVS libraries <strong>preloaded</strong>, FAISS GPU indexes can route to <strong>cuVS kernels</strong> for <strong>Flat, IVF\u2011Flat, IVF\u2011PQ, CAGRA, Binary\u2011CAGRA</strong>; otherwise FAISS falls back to its own kernels.</p></li>\n</ul>\n<blockquote>\n<div><p><strong>Reminder</strong>: the kernels themselves live in the <strong>cuVS</strong> shared libraries; the FAISS wheel holds <strong>dispatch hooks</strong> and dynamic links. Ensure the cuVS loader is invoked at process start.</p>\n</div></blockquote>\n</section>\n<hr class=\"docutils\" />\n<section id=\"cpu-vs-gpu-vs-cuvs-updated-capability-map-this-wheel\">\n<h2>1) CPU vs GPU vs cuVS \u2014 updated capability map (this wheel)<a class=\"headerlink\" href=\"#cpu-vs-gpu-vs-cuvs-updated-capability-map-this-wheel\" title=\"Link to this heading\">#</a></h2>\n<div class=\"pst-scrollable-table-container\"><table class=\"table\">\n<thead>\n<tr class=\"row-odd\"><th class=\"head\"><p>Family / class</p></th>\n<th class=\"head text-right\"><p>CPU</p></th>\n<th class=\"head text-right\"><p>GPU (FAISS kernels)</p></th>\n<th class=\"head text-right\"><p><strong>cuVS through FAISS</strong> (this wheel)</p></th>\n<th class=\"head text-right\"><p><strong>cuVS direct (Python)</strong></p></th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"row-even\"><td><p><strong>Flat (exact)</strong></p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexFlat{L2,IP}</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexFlat{L2,IP}</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 via <strong>index\u2011level <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code></strong> on <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexFlat*</span></code> and via <strong>bfKNN</strong> (<code class=\"docutils literal notranslate\"><span class=\"pre\">knn_gpu/bfKnn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code>)</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.neighbors.brute_force</span></code></p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><strong>IVF\u2011Flat</strong></p></td>\n<td class=\"text-right\"><p>\u2705</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexIVFFlat</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 via <strong>index\u2011level <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code></strong> / GPU cloner</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.neighbors.ivf_flat</span></code></p></td>\n</tr>\n<tr class=\"row-even\"><td><p><strong>IVF\u2011PQ</strong></p></td>\n<td class=\"text-right\"><p>\u2705</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexIVFPQ</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 via <strong>index\u2011level <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code></strong> / GPU cloner</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.neighbors.ivf_pq</span></code></p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><strong>IVF\u2011SQ</strong></p></td>\n<td class=\"text-right\"><p>\u2705</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexIVFScalarQuantizer</span></code></p></td>\n<td class=\"text-right\"><p>\u2013 (no cuVS path)</p></td>\n<td class=\"text-right\"><p>\u2013</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><strong>Graph (HNSW)</strong></p></td>\n<td class=\"text-right\"><p>\u2705</p></td>\n<td class=\"text-right\"><p>\u2013</p></td>\n<td class=\"text-right\"><p>\u2013</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.neighbors.hnsw</span></code></p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><strong>Graph (CAGRA)</strong></p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexHNSWCagra</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexCagra</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 via <strong>index\u2011level <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code></strong></p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.neighbors.cagra</span></code> (+ multi\u2011GPU)</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><strong>Binary</strong></p></td>\n<td class=\"text-right\"><p>\u2705</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexBinaryFlat</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexBinaryCagra</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 <strong>Binary\u2011CAGRA</strong> via index\u2011level <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code></p></td>\n<td class=\"text-right\"><p>\u2013</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><strong>Direct bfKNN</strong></p></td>\n<td class=\"text-right\"><p>\u2013</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">bfKnn(...)</span></code> / <code class=\"docutils literal notranslate\"><span class=\"pre\">knn_gpu(...)</span></code></p></td>\n<td class=\"text-right\"><p>\u2705 <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code></strong> (guard with <code class=\"docutils literal notranslate\"><span class=\"pre\">should_use_cuvs</span></code>)</p></td>\n<td class=\"text-right\"><p>\u2705 <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.distance</span></code> / brute_force</p></td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>Filters &amp; selectors:</strong> your build includes <code class=\"docutils literal notranslate\"><span class=\"pre\">CuvsFilterConvert.cu.o</span></code>; FAISS will convert FAISS selectors/bitsets into cuVS\u2019 filter format automatically when the index was created with <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code>. You keep using standard FAISS search params at the Python layer.</p>\n</section>\n<hr class=\"docutils\" />\n<section id=\"blackwell-rtx-5090-support-sass-sm-120-ptx-sm-120virtual\">\n<h2>2) Blackwell (RTX\u202f5090) support: SASS <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">sm_120</span></code></strong> + PTX <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">sm_120\u2011virtual</span></code></strong><a class=\"headerlink\" href=\"#blackwell-rtx-5090-support-sass-sm-120-ptx-sm-120virtual\" title=\"Link to this heading\">#</a></h2>\n<ul class=\"simple\">\n<li><p><strong>Why it matters</strong>: perfect performance when SASS matches; <strong>PTX fallback</strong> when driver/toolkit moves ahead (no \u201cno kernel image\u201d errors).</p></li>\n<li><p><strong>Ops tips</strong>: leave <code class=\"docutils literal notranslate\"><span class=\"pre\">CUDA_CACHE_MAXSIZE</span></code> roomy to avoid first\u2011run JIT thrash; never force JIT in production.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"cuvs-enablement-model-final-patterns\">\n<h2>3) cuVS enablement model (final patterns)<a class=\"headerlink\" href=\"#cuvs-enablement-model-final-patterns\" title=\"Link to this heading\">#</a></h2>\n<p><strong>Always preload cuVS/RAPIDS libs before FAISS</strong>:</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">libcuvs</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">load_library</span>\n<span class=\"n\">load_library</span><span class=\"p\">()</span>  <span class=\"c1\"># loads libcuvs, librmm, rapids_logger; idempotent. :contentReference[oaicite:12]{index=12}</span>\n</pre></div>\n</div>\n<p><strong>A) Index\u2011level enablement (recommended)</strong>\nSet <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code></strong> on the GPU cloner or GPU index config; <strong>catch &amp; fallback</strong>:</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">faiss</span>\n\n<span class=\"c1\"># Clone CPU \u2192 GPU (works uniformly for Flat / IVF-Flat / IVF-PQ / CAGRA / Binary-CAGRA)</span>\n<span class=\"n\">co</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuClonerOptions</span><span class=\"p\">();</span> <span class=\"n\">co</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"k\">try</span><span class=\"p\">:</span>\n    <span class=\"n\">gpu_index</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">cpu_index</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">)</span>\n<span class=\"k\">except</span> <span class=\"ne\">RuntimeError</span><span class=\"p\">:</span>\n    <span class=\"n\">co</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n    <span class=\"n\">gpu_index</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">cpu_index</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p>Or <strong>construct GPU indexes directly</strong> with a config inheriting <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexConfig.use_cuvs</span></code>:</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">flat_cfg</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexFlatConfig</span><span class=\"p\">();</span> <span class=\"n\">flat_cfg</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"n\">gpu_flat</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexFlatIP</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"n\">flat_cfg</span><span class=\"p\">)</span>\n\n<span class=\"n\">ivf_cfg</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexIVFConfig</span><span class=\"p\">();</span> <span class=\"n\">ivf_cfg</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"c1\"># pass ivf_cfg into the appropriate GpuIndexIVF* constructor</span>\n\n<span class=\"n\">cagra_cfg</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexCagraConfig</span><span class=\"p\">();</span> <span class=\"n\">cagra_cfg</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"n\">gpu_cagra</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexCagra</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"n\">cagra_cfg</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><strong>B) Brute\u2011force KNN path</strong>\nGuard <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code></strong> with the central probe (falls back if not viable):</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">params</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuDistanceParams</span><span class=\"p\">();</span> <span class=\"n\">params</span><span class=\"o\">.</span><span class=\"n\">dims</span><span class=\"o\">=</span><span class=\"n\">d</span><span class=\"p\">;</span> <span class=\"n\">params</span><span class=\"o\">.</span><span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">;</span> <span class=\"n\">params</span><span class=\"o\">.</span><span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span>\n<span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"nb\">bool</span><span class=\"p\">(</span><span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">should_use_cuvs</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">))</span>  <span class=\"c1\"># detects viability at runtime. :contentReference[oaicite:13]{index=13}</span>\n<span class=\"n\">D</span><span class=\"p\">,</span> <span class=\"n\">I</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">knn_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">xq</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">),</span> <span class=\"n\">xb</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">),</span> <span class=\"mi\">10</span><span class=\"p\">,</span>\n                     <span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">,</span> <span class=\"n\">use_cuvs</span><span class=\"o\">=</span><span class=\"n\">use_cuvs</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><strong>C) Direct cuVS ANN (optional)</strong>\nUse cuVS Python APIs for IVF\u2011Flat/IVF\u2011PQ/CAGRA/HNSW (especially when you want multi\u2011GPU <code class=\"docutils literal notranslate\"><span class=\"pre\">mg.*</span></code> variants): <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.neighbors.{ivf_flat,</span> <span class=\"pre\">ivf_pq,</span> <span class=\"pre\">cagra,</span> <span class=\"pre\">hnsw}</span></code> with <code class=\"docutils literal notranslate\"><span class=\"pre\">Resources</span></code> handle and device arrays.</p>\n</section>\n<hr class=\"docutils\" />\n<section id=\"bestinclass-faiss-build-on-rtx-5090-cosine-2560d-now-with-cuvs-toggles\">\n<h2>4) \u201cBest\u2011in\u2011class\u201d FAISS build on RTX\u202f5090 (cosine, 2560\u2011d) \u2014 <strong>now with cuVS toggles</strong><a class=\"headerlink\" href=\"#bestinclass-faiss-build-on-rtx-5090-cosine-2560d-now-with-cuvs-toggles\" title=\"Link to this heading\">#</a></h2>\n<p><strong>Index choice</strong>: <code class=\"docutils literal notranslate\"><span class=\"pre\">OPQ64,IVF8192,PQ64</span></code> (cosine via L2 normalization + IP). <strong>Train</strong> on up to <strong>10\u202fM</strong> samples (seed=42). <strong>Search</strong> with <code class=\"docutils literal notranslate\"><span class=\"pre\">nprobe=64</span></code>.</p>\n<p><strong>GPU clone with cuVS</strong> (preferred path):</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">faiss</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"nn\">numpy</span><span class=\"w\"> </span><span class=\"k\">as</span><span class=\"w\"> </span><span class=\"nn\">np</span>\n\n<span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"mi\">2560</span>\n<span class=\"n\">cpu</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_factory</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"s2\">&quot;OPQ64,IVF8192,PQ64&quot;</span><span class=\"p\">,</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">)</span>\n<span class=\"n\">train</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">10_000_000</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">);</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">normalize_L2</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">)</span>\n<span class=\"n\">cpu</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">)</span>\n\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">StandardGpuResources</span><span class=\"p\">()</span>\n<span class=\"n\">res</span><span class=\"o\">.</span><span class=\"n\">setTempMemory</span><span class=\"p\">(</span><span class=\"mi\">1_200_000_000</span><span class=\"p\">);</span> <span class=\"n\">res</span><span class=\"o\">.</span><span class=\"n\">setPinnedMemory</span><span class=\"p\">(</span><span class=\"mi\">512_000_000</span><span class=\"p\">)</span>\n\n<span class=\"n\">co</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuClonerOptions</span><span class=\"p\">();</span> <span class=\"n\">co</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"k\">try</span><span class=\"p\">:</span>\n    <span class=\"n\">gpu</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">cpu</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">)</span>  <span class=\"c1\"># cuVS-backed IVFPQ in this build</span>\n<span class=\"k\">except</span> <span class=\"ne\">RuntimeError</span><span class=\"p\">:</span>\n    <span class=\"n\">co</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n    <span class=\"n\">gpu</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">cpu</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># add / search as usual</span>\n</pre></div>\n</div>\n<p><strong>Notes &amp; knobs</strong></p>\n<ul class=\"simple\">\n<li><p>Precompute lookup tables on GPU if your PQ config benefits (via cloner/options); keep working set \u2264 <strong>80%</strong> VRAM; reuse pinned host buffers for larger transfers.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"when-to-call-cuvs-directly-and-when-faiss-cuvs-is-enough\">\n<h2>5) When to call cuVS directly (and when FAISS+cuVS is enough)<a class=\"headerlink\" href=\"#when-to-call-cuvs-directly-and-when-faiss-cuvs-is-enough\" title=\"Link to this heading\">#</a></h2>\n<ul class=\"simple\">\n<li><p><strong>Stay inside FAISS</strong> (with <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code>) for: <strong>Flat, IVF\u2011Flat, IVF\u2011PQ, CAGRA, Binary\u2011CAGRA</strong>; you get FAISS\u2019 ergonomics and cuVS performance.</p></li>\n<li><p><strong>Call cuVS directly</strong> when you need: <strong>multi\u2011GPU <code class=\"docutils literal notranslate\"><span class=\"pre\">mg.*</span></code></strong> pipelines, algorithm\u2011specific parameters not exposed by FAISS\u2019 wrappers, or you want to co\u2011locate with other RAFT pipelines with explicit stream choreography.</p></li>\n</ul>\n<p><strong>Direct IVF\u2011PQ example (unchanged)</strong> \u2014 device arrays + <code class=\"docutils literal notranslate\"><span class=\"pre\">Resources</span></code>:</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">cuvs.common</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">Resources</span>\n<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">cuvs.neighbors</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">ivf_pq</span>\n<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">pylibraft.common</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">device_ndarray</span>\n<span class=\"c1\"># build/search as in your prior example \u2026 :contentReference[oaicite:18]{index=18}</span>\n</pre></div>\n</div>\n</section>\n<hr class=\"docutils\" />\n<section id=\"quick-api-map-what-youll-call-most-often\">\n<h2>6) Quick API map \u2014 <strong>what you\u2019ll call most often</strong><a class=\"headerlink\" href=\"#quick-api-map-what-youll-call-most-often\" title=\"Link to this heading\">#</a></h2>\n<p><strong>CPU</strong>\n<code class=\"docutils literal notranslate\"><span class=\"pre\">IndexFlat{L2,IP}</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexIVFFlat</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexIVFPQ</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexIVFScalarQuantizer</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexHNSW*</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexHNSWCagra</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexBinary*</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexPreTransform</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">OPQMatrix</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">PCAMatrix</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexRefineFlat</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexShards</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexReplicas</span></code>.</p>\n<p><strong>GPU (FAISS)</strong>\n<code class=\"docutils literal notranslate\"><span class=\"pre\">StandardGpuResources</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexFlat{L2,IP}</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexIVFFlat</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexIVFPQ</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexIVFScalarQuantizer</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexCagra</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexBinaryFlat</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndexBinaryCagra</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">index_cpu_to_gpu[_multiple]</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">index_gpu_to_cpu</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuClonerOptions</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuParameterSpace</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">knn_gpu(...)</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">bfKnn(...)</span></code>.</p>\n<p><strong>cuVS hooks inside FAISS</strong>\n<code class=\"docutils literal notranslate\"><span class=\"pre\">GpuClonerOptions.use_cuvs</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndex*Config.use_cuvs</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">should_use_cuvs(...)</span></code> (for bfKNN probe), <code class=\"docutils literal notranslate\"><span class=\"pre\">knn_gpu(...,</span> <span class=\"pre\">use_cuvs=...)</span></code>.</p>\n<p><strong>cuVS (direct)</strong>\n<code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.neighbors.{ivf_flat,</span> <span class=\"pre\">ivf_pq,</span> <span class=\"pre\">cagra,</span> <span class=\"pre\">hnsw,</span> <span class=\"pre\">brute_force,</span> <span class=\"pre\">mg.*}</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.cluster.kmeans</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.distance.pairwise_distance</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.common.Resources</span></code>.</p>\n</section>\n<hr class=\"docutils\" />\n<section id=\"validation-checklist-runtime\">\n<h2>7) Validation checklist (runtime)<a class=\"headerlink\" href=\"#validation-checklist-runtime\" title=\"Link to this heading\">#</a></h2>\n<ol class=\"arabic simple\">\n<li><p><strong>Preload check</strong> (did we load the libraries?):</p></li>\n</ol>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">libcuvs</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">load_library</span>\n<span class=\"nb\">print</span><span class=\"p\">([</span><span class=\"n\">h</span><span class=\"o\">.</span><span class=\"n\">_name</span> <span class=\"k\">for</span> <span class=\"n\">h</span> <span class=\"ow\">in</span> <span class=\"n\">load_library</span><span class=\"p\">()])</span>  <span class=\"c1\"># expect libcuvs*, librmm, rapids_logger. :contentReference[oaicite:21]{index=21}</span>\n</pre></div>\n</div>\n<ol class=\"arabic simple\" start=\"2\">\n<li><p><strong>Index\u2011level cuVS</strong> (construction guard):</p></li>\n</ol>\n<ul class=\"simple\">\n<li><p>Clone/construct with <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code>. If it <strong>raises</strong>, retry with <code class=\"docutils literal notranslate\"><span class=\"pre\">False</span></code>. Log the final <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code> state per index.</p></li>\n</ul>\n<ol class=\"arabic simple\" start=\"3\">\n<li><p><strong>bfKNN cuVS probe</strong> (fast sanity):</p></li>\n</ol>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">faiss</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">GpuDistanceParams</span><span class=\"p\">,</span> <span class=\"n\">should_use_cuvs</span><span class=\"p\">,</span> <span class=\"n\">METRIC_INNER_PRODUCT</span>\n<span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"n\">GpuDistanceParams</span><span class=\"p\">();</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">metric</span> <span class=\"o\">=</span> <span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">;</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">dims</span> <span class=\"o\">=</span> <span class=\"mi\">2560</span><span class=\"p\">;</span> <span class=\"n\">p</span><span class=\"o\">.</span><span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&quot;bfKNN should_use_cuvs:&quot;</span><span class=\"p\">,</span> <span class=\"n\">should_use_cuvs</span><span class=\"p\">(</span><span class=\"n\">p</span><span class=\"p\">))</span>  <span class=\"c1\"># True =&gt; bfKNN will route to cuVS. :contentReference[oaicite:22]{index=22}</span>\n</pre></div>\n</div>\n<ol class=\"arabic simple\" start=\"4\">\n<li><p><strong>Direct cuVS smoke</strong> (IVF\u2011PQ or brute\u2011force) with device arrays + <code class=\"docutils literal notranslate\"><span class=\"pre\">Resources</span></code>.</p></li>\n</ol>\n</section>\n<hr class=\"docutils\" />\n<section id=\"operational-guidance-unchanged-principles-cuvsaware\">\n<h2>8) Operational guidance (unchanged principles, cuVS\u2011aware)<a class=\"headerlink\" href=\"#operational-guidance-unchanged-principles-cuvsaware\" title=\"Link to this heading\">#</a></h2>\n<ul class=\"simple\">\n<li><p><strong>Loader order</strong>: preload RAPIDS/cuVS first; then import FAISS.</p></li>\n<li><p><strong>Memory</strong>: size <code class=\"docutils literal notranslate\"><span class=\"pre\">setTempMemory</span></code>/<code class=\"docutils literal notranslate\"><span class=\"pre\">setPinnedMemory</span></code> once; keep VRAM headroom ~<strong>20%</strong>; batch adds to avoid OOM; precompute tables where helpful.</p></li>\n<li><p><strong>Streams</strong>: cuVS direct calls accept a <code class=\"docutils literal notranslate\"><span class=\"pre\">Resources</span></code> handle (shared stream) and only sync when you call <code class=\"docutils literal notranslate\"><span class=\"pre\">handle.sync()</span></code>. FAISS tends to sync at call boundaries; overlap I/O with compute using pinned buffers.</p></li>\n<li><p><strong>Indexes at rest</strong>: save <strong>CPU</strong> index (<code class=\"docutils literal notranslate\"><span class=\"pre\">.faiss</span></code>) + <code class=\"docutils literal notranslate\"><span class=\"pre\">.ids</span></code>; rebuild GPU clones at startup (set <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs</span></code> again when cloning).</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"readytopaste-helpers-with-cuvs-autoengage\">\n<h2>9) Ready\u2011to\u2011paste helpers (with cuVS auto\u2011engage)<a class=\"headerlink\" href=\"#readytopaste-helpers-with-cuvs-autoengage\" title=\"Link to this heading\">#</a></h2>\n<p><strong>A. GPU clone (cuVS\u2011first, safe fallback)</strong></p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">to_gpu_cuvs_first</span><span class=\"p\">(</span><span class=\"n\">cpu_index</span><span class=\"p\">,</span> <span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">):</span>\n    <span class=\"n\">co</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuClonerOptions</span><span class=\"p\">();</span> <span class=\"n\">co</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n    <span class=\"k\">try</span><span class=\"p\">:</span>\n        <span class=\"k\">return</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">cpu_index</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">),</span> <span class=\"kc\">True</span>\n    <span class=\"k\">except</span> <span class=\"ne\">RuntimeError</span><span class=\"p\">:</span>\n        <span class=\"n\">co</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n        <span class=\"k\">return</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">,</span> <span class=\"n\">cpu_index</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">),</span> <span class=\"kc\">False</span>\n</pre></div>\n</div>\n<p><strong>B. bfKNN with automatic cuVS</strong></p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">knn_gpu_auto</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">xq_f32</span><span class=\"p\">,</span> <span class=\"n\">xb_f32</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">):</span>\n    <span class=\"n\">params</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuDistanceParams</span><span class=\"p\">()</span>\n    <span class=\"n\">params</span><span class=\"o\">.</span><span class=\"n\">metric</span> <span class=\"o\">=</span> <span class=\"n\">metric</span><span class=\"p\">;</span> <span class=\"n\">params</span><span class=\"o\">.</span><span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"n\">k</span><span class=\"p\">;</span> <span class=\"n\">params</span><span class=\"o\">.</span><span class=\"n\">dims</span> <span class=\"o\">=</span> <span class=\"n\">xq_f32</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n    <span class=\"n\">use</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">should_use_cuvs</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">)</span>  <span class=\"c1\"># True when viable. :contentReference[oaicite:28]{index=28}</span>\n    <span class=\"k\">return</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">knn_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">xq_f32</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">,</span> <span class=\"n\">copy</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">),</span>\n                         <span class=\"n\">xb_f32</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">,</span> <span class=\"n\">copy</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">),</span>\n                         <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"n\">metric</span><span class=\"p\">,</span> <span class=\"n\">use_cuvs</span><span class=\"o\">=</span><span class=\"n\">use</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><strong>C. Direct cuVS IVF\u2011PQ (device arrays)</strong> \u2014 unchanged.</p>\n</section>\n<hr class=\"docutils\" />\n<section id=\"bottom-line\">\n<h2>10) Bottom line<a class=\"headerlink\" href=\"#bottom-line\" title=\"Link to this heading\">#</a></h2>\n<ul class=\"simple\">\n<li><p><strong>This wheel</strong>: Blackwell\u2011ready (<strong><code class=\"docutils literal notranslate\"><span class=\"pre\">sm_120</span></code> + PTX</strong>), CUDA\u201113, and <strong>cuVS\u2011enabled</strong> inside FAISS for <strong>Flat, IVF\u2011Flat, IVF\u2011PQ, CAGRA, Binary\u2011CAGRA</strong>.</p></li>\n<li><p><strong>Your code</strong>: preload cuVS; set <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code></strong> on GPU clones/constructors; guard with try/except; use <code class=\"docutils literal notranslate\"><span class=\"pre\">should_use_cuvs(...)</span></code> for bfKNN.</p></li>\n<li><p><strong>Architecture &amp; defaults</strong> (factory, training, persistence, multi\u2011GPU) remain per plan; you simply get <strong>cuVS speed paths</strong> where available without changing the higher\u2011level design.</p></li>\n</ul>\n</section>\n</section>\n<hr class=\"docutils\" />\n<section id=\"addendum-agentoriented-details-updated-to-match-the-new-cuvs-coverage\">\n<h1>Addendum \u2014 Agent\u2011oriented details (updated to match the new cuVS coverage)<a class=\"headerlink\" href=\"#addendum-agentoriented-details-updated-to-match-the-new-cuvs-coverage\" title=\"Link to this heading\">#</a></h1>\n<p>These sections expand the \u201chow\u201d with concrete interfaces, schemas, and runbooks across the stack and already assume <strong>FAISS can route to cuVS</strong> for the families above.</p>\n<section id=\"a1-process-bootstrap-deterministic-cuvsready\">\n<h2>A1. Process bootstrap (deterministic &amp; cuVS\u2011ready)<a class=\"headerlink\" href=\"#a1-process-bootstrap-deterministic-cuvsready\" title=\"Link to this heading\">#</a></h2>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">libcuvs</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">load_library</span><span class=\"p\">;</span> <span class=\"n\">load_library</span><span class=\"p\">()</span>   <span class=\"c1\"># ensures libcuvs/librmm/logging are loaded. :contentReference[oaicite:31]{index=31}</span>\n<span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">faiss</span>\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">StandardGpuResources</span><span class=\"p\">()</span>\n<span class=\"n\">res</span><span class=\"o\">.</span><span class=\"n\">setTempMemory</span><span class=\"p\">(</span><span class=\"mi\">1_200_000_000</span><span class=\"p\">);</span> <span class=\"n\">res</span><span class=\"o\">.</span><span class=\"n\">setPinnedMemory</span><span class=\"p\">(</span><span class=\"mi\">512_000_000</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p>Keep a single <code class=\"docutils literal notranslate\"><span class=\"pre\">StandardGpuResources</span></code> per device for the process lifetime and configure it once.</p>\n</section>\n<section id=\"a2-zerocopy-interop-faiss-cuvs\">\n<h2>A2. Zero\u2011copy interop (FAISS \u2194 cuVS)<a class=\"headerlink\" href=\"#a2-zerocopy-interop-faiss-cuvs\" title=\"Link to this heading\">#</a></h2>\n<p>Use RAFT <code class=\"docutils literal notranslate\"><span class=\"pre\">Resources</span></code> and device arrays when calling cuVS directly; prefer pinned host arenas + contiguous <code class=\"docutils literal notranslate\"><span class=\"pre\">float32</span></code> for FAISS inputs to minimize hidden copies.</p>\n</section>\n<section id=\"a3-multigpu-replicas-and-shards-unchanged\">\n<h2>A3. Multi\u2011GPU: replicas and shards (unchanged)<a class=\"headerlink\" href=\"#a3-multigpu-replicas-and-shards-unchanged\" title=\"Link to this heading\">#</a></h2>\n<p>Use <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexReplicas</span></code> (QPS) or <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexShards</span></code> (capacity). When cloning to multiple GPUs, set <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code> on the cloner options once; FAISS will apply it per device (fallback per GPU on error).</p>\n</section>\n<section id=\"a4-memory-planning-batching\">\n<h2>A4. Memory planning &amp; batching<a class=\"headerlink\" href=\"#a4-memory-planning-batching\" title=\"Link to this heading\">#</a></h2>\n<p>Budget <strong>scratch + PQ tables + codes + ids + batch</strong> \u2264 <strong>80%</strong> VRAM. Tune batch add/search sizes empirically; precompute lookup tables where it helps latency.</p>\n</section>\n<section id=\"a5-persistence-registry\">\n<h2>A5. Persistence &amp; registry<a class=\"headerlink\" href=\"#a5-persistence-registry\" title=\"Link to this heading\">#</a></h2>\n<p>Persist <strong>CPU</strong> index (<code class=\"docutils literal notranslate\"><span class=\"pre\">.faiss</span></code>) + <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">.ids</span></code></strong>; rebuild GPU clones at service start using <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code>. Record the final <strong>applied</strong> state (<code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs=true/false</span></code>) in your registry\u2019s <code class=\"docutils literal notranslate\"><span class=\"pre\">faiss_indexes</span></code> rows for observability.</p>\n</section>\n<section id=\"a6-observability-probes\">\n<h2>A6. Observability &amp; probes<a class=\"headerlink\" href=\"#a6-observability-probes\" title=\"Link to this heading\">#</a></h2>\n<ul class=\"simple\">\n<li><p>Log <code class=\"docutils literal notranslate\"><span class=\"pre\">{gpu_id,</span> <span class=\"pre\">nlist,</span> <span class=\"pre\">m,</span> <span class=\"pre\">nprobe,</span> <span class=\"pre\">k,</span> <span class=\"pre\">batch,</span> <span class=\"pre\">temp_mem,</span> <span class=\"pre\">pinned_mem,</span> <span class=\"pre\">use_cuvs}</span></code> for each search; expose p50/p95/p99 histograms.</p></li>\n<li><p>Quick \u201care the libs loaded?\u201d probe: <code class=\"docutils literal notranslate\"><span class=\"pre\">list(h._name</span> <span class=\"pre\">for</span> <span class=\"pre\">h</span> <span class=\"pre\">in</span> <span class=\"pre\">load_library())</span></code>.</p></li>\n<li><p>Quick \u201cwill bfKNN use cuVS?\u201d probe: <code class=\"docutils literal notranslate\"><span class=\"pre\">should_use_cuvs(GpuDistanceParams(...))</span></code>.</p></li>\n</ul>\n</section>\n<section id=\"a7-failure-taxonomy-fallbacks-gpu-paths\">\n<h2>A7. Failure taxonomy &amp; fallbacks (GPU paths)<a class=\"headerlink\" href=\"#a7-failure-taxonomy-fallbacks-gpu-paths\" title=\"Link to this heading\">#</a></h2>\n<ul class=\"simple\">\n<li><p><strong>Missing libs</strong> \u2192 run <code class=\"docutils literal notranslate\"><span class=\"pre\">load_library()</span></code> first (or fix <code class=\"docutils literal notranslate\"><span class=\"pre\">LD_LIBRARY_PATH</span></code>); <strong>resume</strong> with FAISS kernels if cuVS fails to initialize.</p></li>\n<li><p><strong>OOM</strong> \u2192 halve batch; lower <code class=\"docutils literal notranslate\"><span class=\"pre\">setTempMemory</span></code>; retry twice; then quarantine batch.</p></li>\n</ul>\n</section>\n<section id=\"a8-direct-cuvs-catalog-unchanged-surfaces\">\n<h2>A8. Direct cuVS catalog (unchanged surfaces)<a class=\"headerlink\" href=\"#a8-direct-cuvs-catalog-unchanged-surfaces\" title=\"Link to this heading\">#</a></h2>\n<p><code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.neighbors.{ivf_flat,</span> <span class=\"pre\">ivf_pq,</span> <span class=\"pre\">cagra,</span> <span class=\"pre\">hnsw,</span> <span class=\"pre\">brute_force,</span> <span class=\"pre\">mg.*}</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.cluster.kmeans</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.distance.pairwise_distance</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">cuvs.common.Resources</span></code> \u2014 consistent <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexParams</span></code>/<code class=\"docutils literal notranslate\"><span class=\"pre\">SearchParams</span></code>/<code class=\"docutils literal notranslate\"><span class=\"pre\">build</span></code>/<code class=\"docutils literal notranslate\"><span class=\"pre\">extend</span></code>/<code class=\"docutils literal notranslate\"><span class=\"pre\">save</span></code>/<code class=\"docutils literal notranslate\"><span class=\"pre\">load</span></code> patterns.</p>\n</section>\n<section id=\"a9-architecture-defaults-for-the-broader-system\">\n<h2>A9. Architecture defaults (for the broader system)<a class=\"headerlink\" href=\"#a9-architecture-defaults-for-the-broader-system\" title=\"Link to this heading\">#</a></h2>\n<p>Keep the <strong>2560\u2011d</strong> embedder, chunking settings, Parquet schemas, DuckDB catalog/migrations, and hybrid retrieval pipeline exactly as specified in your architecture doc; nothing about the cuVS enablement changes those contracts.</p>\n<hr class=\"docutils\" />\n<p>If you\u2019d like, I can also output a <strong>drop\u2011in <code class=\"docutils literal notranslate\"><span class=\"pre\">vectorstore_faiss</span></code> module</strong> (Python package) that wraps the <strong>train/add/search/persist</strong> flow with <strong>cuVS\u2011first</strong> cloning and automatic bfKNN fallback, plus a tiny <strong>validator</strong> script that prints library load locations, shows <code class=\"docutils literal notranslate\"><span class=\"pre\">should_use_cuvs(...)</span></code>, and runs a 10k\u2011vector bfKNN smoke test on the RTX\u202f5090.</p>\n<p>Below is a <strong>comprehensive, example\u2011driven reference</strong> that fills in the remaining FAISS and cuVS Python surfaces we hadn\u2019t previously shown with code. It\u2019s organized so an agent can copy/paste snippets and understand shapes, params, edge\u2011cases, and performance notes. Where relevant, I point to the cuVS and loader docs you provided.</p>\n</section>\n<hr class=\"docutils\" />\n<section id=\"a-faiss-cpuside-classes-utilities-with-examples\">\n<h2>A) FAISS \u2014 CPU\u2011side classes &amp; utilities (with examples)<a class=\"headerlink\" href=\"#a-faiss-cpuside-classes-utilities-with-examples\" title=\"Link to this heading\">#</a></h2>\n<section id=\"a1-indexidmap-indexidmap2-stable-ids-around-any-index\">\n<h3>A1) <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexIDMap</span></code> / <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexIDMap2</span></code> \u2014 stable IDs around any index<a class=\"headerlink\" href=\"#a1-indexidmap-indexidmap2-stable-ids-around-any-index\" title=\"Link to this heading\">#</a></h3>\n<p><strong>Why:</strong> FAISS stores integer IDs; these wrappers let you control them.</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">faiss</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"nn\">numpy</span><span class=\"w\"> </span><span class=\"k\">as</span><span class=\"w\"> </span><span class=\"nn\">np</span>\n\n<span class=\"c1\"># Base ANN index (any type works)</span>\n<span class=\"n\">d</span> <span class=\"o\">=</span> <span class=\"mi\">2560</span>\n<span class=\"n\">base</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_factory</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"s2\">&quot;IVF8192,PQ64&quot;</span><span class=\"p\">,</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Wrap with an ID map so we add our own 64-bit IDs</span>\n<span class=\"n\">idmap</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">IndexIDMap2</span><span class=\"p\">(</span><span class=\"n\">base</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Train as usual (on base)</span>\n<span class=\"n\">train</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">1_000_000</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">);</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">normalize_L2</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">)</span>\n<span class=\"n\">idmap</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Add vectors with application-specific IDs</span>\n<span class=\"n\">xb</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">500_000</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">);</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">normalize_L2</span><span class=\"p\">(</span><span class=\"n\">xb</span><span class=\"p\">)</span>\n<span class=\"n\">ids</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">100_000</span><span class=\"p\">,</span> <span class=\"mi\">100_000</span> <span class=\"o\">+</span> <span class=\"n\">xb</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s1\">&#39;int64&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">idmap</span><span class=\"o\">.</span><span class=\"n\">add_with_ids</span><span class=\"p\">(</span><span class=\"n\">xb</span><span class=\"p\">,</span> <span class=\"n\">ids</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Search returns your IDs</span>\n<span class=\"n\">xq</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">);</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">normalize_L2</span><span class=\"p\">(</span><span class=\"n\">xq</span><span class=\"p\">)</span>\n<span class=\"n\">D</span><span class=\"p\">,</span> <span class=\"n\">I</span> <span class=\"o\">=</span> <span class=\"n\">idmap</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">xq</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>Use <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexIDMap2</span></code> (64\u2011bit IDs) for large corpora.</p></li>\n<li><p>Persist <strong>CPU</strong> form (see A6) and keep a parallel <code class=\"docutils literal notranslate\"><span class=\"pre\">.ids</span></code> copy if you ever unwrap the map.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"a2-indexrefineflat-refine-ann-hits-with-exact-scoring\">\n<h3>A2) <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexRefineFlat</span></code> \u2014 refine ANN hits with exact scoring<a class=\"headerlink\" href=\"#a2-indexrefineflat-refine-ann-hits-with-exact-scoring\" title=\"Link to this heading\">#</a></h3>\n<p><strong>Why:</strong> Get IVF/graph latency with exact cosine/IP re\u2011ranking.</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"c1\"># Build a fast coarse index (e.g., IVF,PQ) then refine with Flat</span>\n<span class=\"n\">coarse</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_factory</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"s2\">&quot;IVF8192,PQ64&quot;</span><span class=\"p\">,</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">)</span>\n<span class=\"n\">coarse</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">);</span> <span class=\"n\">coarse</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">xb</span><span class=\"p\">)</span>\n\n<span class=\"n\">refined</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">IndexRefineFlat</span><span class=\"p\">(</span><span class=\"n\">coarse</span><span class=\"p\">)</span>   <span class=\"c1\"># wraps the coarse index with an exact refiner</span>\n<span class=\"n\">refined</span><span class=\"o\">.</span><span class=\"n\">kfactor</span> <span class=\"o\">=</span> <span class=\"mf\">2.0</span>                     <span class=\"c1\"># search 2\u00d7k in coarse stage, re-rank down to k</span>\n\n<span class=\"n\">D</span><span class=\"p\">,</span> <span class=\"n\">I</span> <span class=\"o\">=</span> <span class=\"n\">refined</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">xq</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>On GPU you\u2019ll typically run the coarse stage on device, then refine on device or CPU depending on memory; the wrapper manages the sequence.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"a3-indexpretransform-transforms-opqmatrix-pcamatrix\">\n<h3>A3) <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexPreTransform</span></code> + transforms (<code class=\"docutils literal notranslate\"><span class=\"pre\">OPQMatrix</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">PCAMatrix</span></code>)<a class=\"headerlink\" href=\"#a3-indexpretransform-transforms-opqmatrix-pcamatrix\" title=\"Link to this heading\">#</a></h3>\n<p><strong>Why:</strong> Pre\u2011rotate or reduce dimension <strong>inside</strong> the index for better PQ fit.</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"c1\"># 1) Build transforms: PCA (optional) then OPQ</span>\n<span class=\"n\">pca</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">PCAMatrix</span><span class=\"p\">(</span><span class=\"n\">d_in</span><span class=\"o\">=</span><span class=\"mi\">2560</span><span class=\"p\">,</span> <span class=\"n\">d_out</span><span class=\"o\">=</span><span class=\"mi\">1024</span><span class=\"p\">,</span> <span class=\"n\">eigen_power</span><span class=\"o\">=-</span><span class=\"mf\">0.5</span><span class=\"p\">)</span>  <span class=\"c1\"># example PCA step</span>\n<span class=\"n\">opq</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">OPQMatrix</span><span class=\"p\">(</span><span class=\"n\">d_out</span><span class=\"o\">=</span><span class=\"mi\">1024</span><span class=\"p\">,</span> <span class=\"n\">m</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">)</span>  <span class=\"c1\"># OPQ with 64 subquantizers</span>\n\n<span class=\"c1\"># 2) Chain transforms in a vector</span>\n<span class=\"n\">vt</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">VectorTransformChain</span><span class=\"p\">()</span>\n<span class=\"n\">vt</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">pca</span><span class=\"p\">)</span>\n<span class=\"n\">vt</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">opq</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 3) Base index AFTER transforms (note d=1024 now)</span>\n<span class=\"n\">base</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_factory</span><span class=\"p\">(</span><span class=\"mi\">1024</span><span class=\"p\">,</span> <span class=\"s2\">&quot;IVF8192,PQ64&quot;</span><span class=\"p\">,</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 4) Wrap into IndexPreTransform</span>\n<span class=\"n\">pre</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">IndexPreTransform</span><span class=\"p\">(</span><span class=\"n\">vt</span><span class=\"p\">,</span> <span class=\"n\">base</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 5) Train on original-dim data; transform is applied internally</span>\n<span class=\"n\">pre</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">)</span>       <span class=\"c1\"># &#39;train&#39; runs PCA/OPQ fitting + IVF/PQ training</span>\n<span class=\"n\">pre</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">xb</span><span class=\"p\">)</span>\n<span class=\"n\">D</span><span class=\"p\">,</span> <span class=\"n\">I</span> <span class=\"o\">=</span> <span class=\"n\">pre</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">xq</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>For our default blueprint we already use OPQ64; <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexPreTransform</span></code> is the explicit form of that pipeline. Keep cosine/IP consistency: <strong>normalize</strong> before train/add/query.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"a4-clustering-kmeans-build-coarse-quantizers-explicitly\">\n<h3>A4) <code class=\"docutils literal notranslate\"><span class=\"pre\">Clustering</span></code> (K\u2011means) \u2014 build coarse quantizers explicitly<a class=\"headerlink\" href=\"#a4-clustering-kmeans-build-coarse-quantizers-explicitly\" title=\"Link to this heading\">#</a></h3>\n<p><strong>Why:</strong> Manual control when you don\u2019t use <code class=\"docutils literal notranslate\"><span class=\"pre\">index_factory()</span></code>.</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"c1\"># Train IVF coarse quantizer centroids explicitly with K-means</span>\n<span class=\"n\">nlist</span> <span class=\"o\">=</span> <span class=\"mi\">8192</span>\n<span class=\"n\">kmeans</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">Clustering</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"n\">nlist</span><span class=\"p\">)</span>\n<span class=\"n\">kmeans</span><span class=\"o\">.</span><span class=\"n\">niter</span> <span class=\"o\">=</span> <span class=\"mi\">25</span><span class=\"p\">;</span> <span class=\"n\">kmeans</span><span class=\"o\">.</span><span class=\"n\">verbose</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n\n<span class=\"n\">quantizer</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">IndexFlatIP</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">)</span>        <span class=\"c1\"># cosine via normalization + IP</span>\n<span class=\"n\">kmeans</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">,</span> <span class=\"n\">quantizer</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Use trained quantizer to build IVF, then attach PQ</span>\n<span class=\"n\">ivf</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">IndexIVFFlat</span><span class=\"p\">(</span><span class=\"n\">quantizer</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"n\">nlist</span><span class=\"p\">,</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">)</span>\n<span class=\"n\">ivf</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">)</span>\n<span class=\"n\">ivf</span><span class=\"o\">.</span><span class=\"n\">add</span><span class=\"p\">(</span><span class=\"n\">xb</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p><code class=\"docutils literal notranslate\"><span class=\"pre\">index_factory()</span></code> automates this, but direct <code class=\"docutils literal notranslate\"><span class=\"pre\">Clustering</span></code> is useful for specialized training schedules.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"a5-parameterspace-gpuparameterspace-named-tuning-knobs\">\n<h3>A5) <code class=\"docutils literal notranslate\"><span class=\"pre\">ParameterSpace</span></code> / <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuParameterSpace</span></code> \u2014 named tuning knobs<a class=\"headerlink\" href=\"#a5-parameterspace-gpuparameterspace-named-tuning-knobs\" title=\"Link to this heading\">#</a></h3>\n<p><strong>Why:</strong> Set parameters (e.g., <code class=\"docutils literal notranslate\"><span class=\"pre\">nprobe</span></code>) by <strong>name</strong>, works across families.</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"c1\"># CPU</span>\n<span class=\"n\">ps</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">ParameterSpace</span><span class=\"p\">()</span>\n<span class=\"n\">ps</span><span class=\"o\">.</span><span class=\"n\">set_index_parameter</span><span class=\"p\">(</span><span class=\"n\">base</span><span class=\"p\">,</span> <span class=\"s2\">&quot;nprobe&quot;</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># GPU</span>\n<span class=\"n\">gps</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuParameterSpace</span><span class=\"p\">();</span> <span class=\"n\">gps</span><span class=\"o\">.</span><span class=\"n\">initialize</span><span class=\"p\">(</span><span class=\"n\">gpu_index</span><span class=\"p\">)</span>\n<span class=\"n\">gps</span><span class=\"o\">.</span><span class=\"n\">set_index_parameter</span><span class=\"p\">(</span><span class=\"n\">gpu_index</span><span class=\"p\">,</span> <span class=\"s2\">&quot;nprobe&quot;</span><span class=\"p\">,</span> <span class=\"mi\">64</span><span class=\"p\">)</span>   <span class=\"c1\"># same name on GPU</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>Prefer these over ad\u2011hoc setters; helps keep code index\u2011agnostic.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"a6-persistence-write-index-read-index\">\n<h3>A6) Persistence \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">write_index</span></code> / <code class=\"docutils literal notranslate\"><span class=\"pre\">read_index</span></code><a class=\"headerlink\" href=\"#a6-persistence-write-index-read-index\" title=\"Link to this heading\">#</a></h3>\n<p><strong>Why:</strong> Save CPU index for fast reload; re\u2011clone to GPU at runtime.</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">write_index</span><span class=\"p\">(</span><span class=\"n\">idmap</span><span class=\"p\">,</span> <span class=\"s2\">&quot;/data/faiss/shard_000.idx&quot;</span><span class=\"p\">)</span>          <span class=\"c1\"># save CPU index (any type)</span>\n<span class=\"n\">idmap2</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">read_index</span><span class=\"p\">(</span><span class=\"s2\">&quot;/data/faiss/shard_000.idx&quot;</span><span class=\"p\">)</span>         <span class=\"c1\"># load CPU index</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>Don\u2019t save GPU indexes; reconstruct by cloning the CPU index on startup. Track paths and config in DuckDB (<code class=\"docutils literal notranslate\"><span class=\"pre\">faiss_indexes</span></code>).</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"a7-range-search-range-search-a-k-a-radius-search\">\n<h3>A7) Range search \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">range_search</span></code> (a.k.a. radius search)<a class=\"headerlink\" href=\"#a7-range-search-range-search-a-k-a-radius-search\" title=\"Link to this heading\">#</a></h3>\n<p><strong>Why:</strong> Get all neighbors within a distance threshold instead of top\u2011K.</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">radius</span> <span class=\"o\">=</span> <span class=\"mf\">0.1</span>  <span class=\"c1\"># for cosine/IP, pick meaningful threshold on normalized vectors</span>\n<span class=\"n\">rs</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">RangeSearchResult</span><span class=\"p\">(</span><span class=\"n\">xq</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span>\n<span class=\"n\">idmap</span><span class=\"o\">.</span><span class=\"n\">range_search</span><span class=\"p\">(</span><span class=\"n\">xq</span><span class=\"p\">,</span> <span class=\"n\">radius</span><span class=\"p\">,</span> <span class=\"n\">rs</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Extract result per query</span>\n<span class=\"n\">lims</span><span class=\"p\">,</span> <span class=\"n\">D</span><span class=\"p\">,</span> <span class=\"n\">I</span> <span class=\"o\">=</span> <span class=\"n\">rs</span><span class=\"o\">.</span><span class=\"n\">lims</span><span class=\"p\">,</span> <span class=\"n\">rs</span><span class=\"o\">.</span><span class=\"n\">distances</span><span class=\"p\">,</span> <span class=\"n\">rs</span><span class=\"o\">.</span><span class=\"n\">labels</span>\n<span class=\"k\">for</span> <span class=\"n\">qi</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">xq</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]):</span>\n    <span class=\"n\">begin</span><span class=\"p\">,</span> <span class=\"n\">end</span> <span class=\"o\">=</span> <span class=\"n\">lims</span><span class=\"p\">[</span><span class=\"n\">qi</span><span class=\"p\">],</span> <span class=\"n\">lims</span><span class=\"p\">[</span><span class=\"n\">qi</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n    <span class=\"n\">neigh_ids</span> <span class=\"o\">=</span> <span class=\"n\">I</span><span class=\"p\">[</span><span class=\"n\">begin</span><span class=\"p\">:</span><span class=\"n\">end</span><span class=\"p\">]</span>\n    <span class=\"n\">neigh_dist</span> <span class=\"o\">=</span> <span class=\"n\">D</span><span class=\"p\">[</span><span class=\"n\">begin</span><span class=\"p\">:</span><span class=\"n\">end</span><span class=\"p\">]</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>Range search is less common for large\u2011scale serving, but handy for thresholded neighbor graphs.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"a8-filtered-search-idselector-searchparametersivf\">\n<h3>A8) Filtered search \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">IDSelector*</span></code> + <code class=\"docutils literal notranslate\"><span class=\"pre\">SearchParametersIVF</span></code><a class=\"headerlink\" href=\"#a8-filtered-search-idselector-searchparametersivf\" title=\"Link to this heading\">#</a></h3>\n<p><strong>Why:</strong> Exclude/allow subsets of IDs at <strong>query time</strong>.</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"c1\"># Build a selector (ids in [lo, hi))</span>\n<span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">IDSelectorRange</span><span class=\"p\">(</span><span class=\"n\">lo</span><span class=\"o\">=</span><span class=\"mi\">100_000</span><span class=\"p\">,</span> <span class=\"n\">hi</span><span class=\"o\">=</span><span class=\"mi\">150_000</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Tie selector to IVF search params</span>\n<span class=\"n\">sp</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">SearchParametersIVF</span><span class=\"p\">()</span>\n<span class=\"n\">sp</span><span class=\"o\">.</span><span class=\"n\">nprobe</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>\n<span class=\"n\">sp</span><span class=\"o\">.</span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">sel</span>\n\n<span class=\"c1\"># Call the 3-arg search to pass params</span>\n<span class=\"n\">D</span><span class=\"p\">,</span> <span class=\"n\">I</span> <span class=\"o\">=</span> <span class=\"n\">idmap</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">xq</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">params</span><span class=\"o\">=</span><span class=\"n\">sp</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>With cuVS\u2011backed GPU indexes enabled (<code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code> when cloning/constructing), FAISS converts these selectors into cuVS filters under the hood (your build includes the converter).</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"a9-deletions-remove-ids\">\n<h3>A9) Deletions \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">remove_ids</span></code><a class=\"headerlink\" href=\"#a9-deletions-remove-ids\" title=\"Link to this heading\">#</a></h3>\n<p><strong>Why:</strong> Remove a set of IDs (e.g., retractions, updates).</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">to_remove</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">IDSelectorRange</span><span class=\"p\">(</span><span class=\"mi\">200_000</span><span class=\"p\">,</span> <span class=\"mi\">210_000</span><span class=\"p\">)</span>  <span class=\"c1\"># OR IDSelectorBatch([...])</span>\n<span class=\"n\">n_removed</span> <span class=\"o\">=</span> <span class=\"n\">idmap</span><span class=\"o\">.</span><span class=\"n\">remove_ids</span><span class=\"p\">(</span><span class=\"n\">to_remove</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>IVF/PQ structures become \u201choley\u201d over time; periodic rebuilds (or re\u2011add to a fresh shard) keep performance consistent.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"a10-reconstruction-reconstruct-reconstruct-n\">\n<h3>A10) Reconstruction \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">reconstruct</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">reconstruct_n</span></code><a class=\"headerlink\" href=\"#a10-reconstruction-reconstruct-reconstruct-n\" title=\"Link to this heading\">#</a></h3>\n<p><strong>Why:</strong> Retrieve vector approximations (exact for Flat/HNSW; approximate for PQ).</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">vec</span> <span class=\"o\">=</span> <span class=\"n\">idmap</span><span class=\"o\">.</span><span class=\"n\">reconstruct</span><span class=\"p\">(</span><span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"n\">I</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"mi\">0</span><span class=\"p\">]))</span>\n<span class=\"n\">mat</span> <span class=\"o\">=</span> <span class=\"n\">idmap</span><span class=\"o\">.</span><span class=\"n\">reconstruct_n</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">100</span><span class=\"p\">)</span>   <span class=\"c1\"># first 100 vectors</span>\n</pre></div>\n</div>\n</section>\n<hr class=\"docutils\" />\n<section id=\"a11-cpu-parallelism-omp-set-num-threads\">\n<h3>A11) CPU parallelism \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">omp_set_num_threads</span></code><a class=\"headerlink\" href=\"#a11-cpu-parallelism-omp-set-num-threads\" title=\"Link to this heading\">#</a></h3>\n<p><strong>Why:</strong> Pin thread count for CPU add/search/training.</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">omp_set_num_threads</span><span class=\"p\">(</span><span class=\"mi\">14</span><span class=\"p\">)</span>  <span class=\"c1\"># match your server threads</span>\n</pre></div>\n</div>\n</section>\n</section>\n<hr class=\"docutils\" />\n<section id=\"b-faiss-gpu-multigpu-functions-deeper-with-cuvs-enablement\">\n<h2>B) FAISS \u2014 GPU &amp; multi\u2011GPU functions (deeper, with cuVS enablement)<a class=\"headerlink\" href=\"#b-faiss-gpu-multigpu-functions-deeper-with-cuvs-enablement\" title=\"Link to this heading\">#</a></h2>\n<blockquote>\n<div><p><strong>Reminder</strong>: In your wheel, FAISS GPU indexes can dispatch to <strong>cuVS</strong> for <strong>Flat, IVF\u2011Flat, IVF\u2011PQ, CAGRA, Binary\u2011CAGRA</strong> when you set <code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code> on the <strong>GPU cloner</strong> or the <strong>GPU index config</strong>, and the cuVS libraries are preloaded.</p>\n</div></blockquote>\n<section id=\"b1-cpugpu-cloning-single-multigpu\">\n<h3>B1) CPU\u2192GPU cloning (single &amp; multi\u2011GPU)<a class=\"headerlink\" href=\"#b1-cpugpu-cloning-single-multigpu\" title=\"Link to this heading\">#</a></h3>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">faiss</span>\n\n<span class=\"c1\"># 1) Single GPU (cuVS-first, safe fallback)</span>\n<span class=\"n\">co</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuClonerOptions</span><span class=\"p\">();</span> <span class=\"n\">co</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"k\">try</span><span class=\"p\">:</span>\n    <span class=\"n\">gpu_index</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">idmap</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">)</span>\n<span class=\"k\">except</span> <span class=\"ne\">RuntimeError</span><span class=\"p\">:</span>\n    <span class=\"n\">co</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">False</span>\n    <span class=\"n\">gpu_index</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">idmap</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># 2) Replicated (QPS-scale)</span>\n<span class=\"n\">ngpu</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">get_num_gpus</span><span class=\"p\">()</span>\n<span class=\"n\">resources</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">StandardGpuResources</span><span class=\"p\">()</span> <span class=\"k\">for</span> <span class=\"n\">_</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">ngpu</span><span class=\"p\">)]</span>\n<span class=\"n\">replicas</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">IndexReplicas</span><span class=\"p\">()</span>\n<span class=\"k\">for</span> <span class=\"n\">dev</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">ngpu</span><span class=\"p\">):</span>\n    <span class=\"n\">replicas</span><span class=\"o\">.</span><span class=\"n\">addIndex</span><span class=\"p\">(</span><span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">resources</span><span class=\"p\">[</span><span class=\"n\">dev</span><span class=\"p\">],</span> <span class=\"n\">dev</span><span class=\"p\">,</span> <span class=\"n\">idmap</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">))</span>\n\n<span class=\"c1\"># 3) Sharded (capacity-scale)</span>\n<span class=\"n\">shards</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">IndexShards</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"n\">threaded</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">successive_ids</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n<span class=\"c1\"># Build per-shard CPU indexes first, then clone each with co.use_cuvs=True and add to &#39;shards&#39;</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>Replicas improve QPS; shards expand capacity; wrap both under one logical index in your registry and fan\u2011out search.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"b2-direct-gpu-constructors-with-gpuindex-config-use-cuvs\">\n<h3>B2) Direct GPU constructors with <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndex*Config.use_cuvs</span></code><a class=\"headerlink\" href=\"#b2-direct-gpu-constructors-with-gpuindex-config-use-cuvs\" title=\"Link to this heading\">#</a></h3>\n<p><strong>Flat</strong></p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">cfg</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexFlatConfig</span><span class=\"p\">();</span> <span class=\"n\">cfg</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"n\">gpu_flat</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexFlatIP</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"n\">cfg</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><strong>IVF\u2011Flat / IVF\u2011PQ</strong></p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">ivf_cfg</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuIndexIVFConfig</span><span class=\"p\">();</span> <span class=\"n\">ivf_cfg</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"kc\">True</span>\n<span class=\"c1\"># Pass ivf_cfg to the appropriate GpuIndexIVF* constructor for your metric/quantizer</span>\n</pre></div>\n</div>\n<p><strong>CAGRA</strong> (graph ANN)</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"c1\"># Prefer CPU\u2192GPU cloning unless you need specific GPU-only build options.</span>\n<span class=\"c1\"># If constructing directly, set the config that inherits GpuIndexConfig:</span>\n<span class=\"c1\"># cagra_cfg = faiss.GpuIndexCagraConfig(); cagra_cfg.use_cuvs = True</span>\n<span class=\"c1\"># gpu_cagra = faiss.GpuIndexCagra(res, d, cagra_cfg)</span>\n</pre></div>\n</div>\n<p><strong>Binary\u2011CAGRA</strong></p>\n<ul class=\"simple\">\n<li><p>Use the <strong>cloner</strong> (<code class=\"docutils literal notranslate\"><span class=\"pre\">GpuClonerOptions.use_cuvs=True</span></code>) when moving from CPU binary graph indexes to GPU.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"b3-gpu-distance-primitives-bfknn-knn-gpu-bfknn\">\n<h3>B3) GPU distance primitives \u2014 bfKNN (<code class=\"docutils literal notranslate\"><span class=\"pre\">knn_gpu</span></code>/<code class=\"docutils literal notranslate\"><span class=\"pre\">bfKnn</span></code>)<a class=\"headerlink\" href=\"#b3-gpu-distance-primitives-bfknn-knn-gpu-bfknn\" title=\"Link to this heading\">#</a></h3>\n<p><strong>Exact GPU kNN</strong> (cuVS\u2011aware):</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"n\">params</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuDistanceParams</span><span class=\"p\">();</span> <span class=\"n\">params</span><span class=\"o\">.</span><span class=\"n\">metric</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span>\n<span class=\"n\">params</span><span class=\"o\">.</span><span class=\"n\">k</span> <span class=\"o\">=</span> <span class=\"mi\">10</span><span class=\"p\">;</span> <span class=\"n\">params</span><span class=\"o\">.</span><span class=\"n\">dims</span> <span class=\"o\">=</span> <span class=\"n\">d</span>\n<span class=\"n\">use_cuvs</span> <span class=\"o\">=</span> <span class=\"nb\">bool</span><span class=\"p\">(</span><span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">should_use_cuvs</span><span class=\"p\">(</span><span class=\"n\">params</span><span class=\"p\">))</span>     <span class=\"c1\"># central probe, then:</span>\n\n<span class=\"n\">D</span><span class=\"p\">,</span> <span class=\"n\">I</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">knn_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"n\">xq</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">),</span> <span class=\"n\">xb</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">),</span>\n                     <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">,</span> <span class=\"n\">use_cuvs</span><span class=\"o\">=</span><span class=\"n\">use_cuvs</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>Your build routes bfKNN to cuVS when possible; otherwise FAISS kernels are used. Preload cuVS so the probe can return True when viable.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"b4-gpu-tuning-knobs-gpuparameterspace-configs\">\n<h3>B4) GPU tuning knobs \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuParameterSpace</span></code> &amp; configs<a class=\"headerlink\" href=\"#b4-gpu-tuning-knobs-gpuparameterspace-configs\" title=\"Link to this heading\">#</a></h3>\n<ul class=\"simple\">\n<li><p><code class=\"docutils literal notranslate\"><span class=\"pre\">GpuParameterSpace.set_index_parameter(gpu_index,</span> <span class=\"pre\">&quot;nprobe&quot;,</span> <span class=\"pre\">64)</span></code> \u2014 uniform way to set IVF probes.</p></li>\n<li><p>IVFPQ config highlights:</p>\n<ul>\n<li><p><code class=\"docutils literal notranslate\"><span class=\"pre\">usePrecomputedTables</span></code> \u2014 faster scans at higher memory.</p></li>\n<li><p><code class=\"docutils literal notranslate\"><span class=\"pre\">useFloat16LookupTables</span></code> \u2014 lower memory, slight precision trade\u2011off; useful for large <code class=\"docutils literal notranslate\"><span class=\"pre\">m</span></code> or tight VRAM budgets.</p></li>\n</ul>\n</li>\n</ul>\n</section>\n</section>\n<hr class=\"docutils\" />\n<section id=\"c-faiss-contrib-helpers-youll-likely-use\">\n<h2>C) FAISS contrib helpers you\u2019ll likely use<a class=\"headerlink\" href=\"#c-faiss-contrib-helpers-youll-likely-use\" title=\"Link to this heading\">#</a></h2>\n<p><em>(These ship in the python package and are handy for pipelines.)</em></p>\n<ul class=\"simple\">\n<li><p><strong><code class=\"docutils literal notranslate\"><span class=\"pre\">contrib.factory_tools</span></code></strong> \u2014 convenience builders &amp; validators for factory strings.</p></li>\n<li><p><strong><code class=\"docutils literal notranslate\"><span class=\"pre\">contrib.ivf_tools</span></code></strong> \u2014 IVF diagnostics, centroid utilities.</p></li>\n<li><p><strong><code class=\"docutils literal notranslate\"><span class=\"pre\">contrib.big_batch_search</span></code></strong> \u2014 large\u2011batch search helpers to pipeline host\u2194device copies.</p></li>\n<li><p><strong><code class=\"docutils literal notranslate\"><span class=\"pre\">contrib.ondisk</span></code></strong> \u2014 on\u2011disk inverted lists for huge CPU\u2011side corpora.</p></li>\n</ul>\n<p>Use them to simplify scripts; your production path should still keep <strong>CPU index persisted + GPU clone</strong> at runtime as the source of truth.</p>\n</section>\n<hr class=\"docutils\" />\n<section id=\"d-cuvs-functions-modules-we-hadnt-exemplified-now-with-code\">\n<h2>D) cuVS \u2014 functions &amp; modules we hadn\u2019t exemplified (now with code)<a class=\"headerlink\" href=\"#d-cuvs-functions-modules-we-hadnt-exemplified-now-with-code\" title=\"Link to this heading\">#</a></h2>\n<blockquote>\n<div><p>cuVS runs <strong>entirely on GPU</strong> with a consistent <code class=\"docutils literal notranslate\"><span class=\"pre\">build</span> <span class=\"pre\">/</span> <span class=\"pre\">extend</span> <span class=\"pre\">/</span> <span class=\"pre\">search</span> <span class=\"pre\">/</span> <span class=\"pre\">save</span> <span class=\"pre\">/</span> <span class=\"pre\">load</span></code> shape per algorithm. Provide a <code class=\"docutils literal notranslate\"><span class=\"pre\">Resources</span></code> handle to share a stream and avoid implicit syncs; pass <strong>device arrays</strong> for best performance.</p>\n</div></blockquote>\n<section id=\"d1-neighbors-brute-force-exact-knn-baseline-qa\">\n<h3>D1) <code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.brute_force</span></code> \u2014 exact kNN (baseline &amp; QA)<a class=\"headerlink\" href=\"#d1-neighbors-brute-force-exact-knn-baseline-qa\" title=\"Link to this heading\">#</a></h3>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">numpy</span><span class=\"w\"> </span><span class=\"k\">as</span><span class=\"w\"> </span><span class=\"nn\">np</span>\n<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">cuvs.common</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">Resources</span>\n<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">cuvs.neighbors</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">brute_force</span>\n<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">pylibraft.common</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">device_ndarray</span>\n\n<span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">Resources</span><span class=\"p\">()</span>\n<span class=\"n\">xb</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">1_000_000</span><span class=\"p\">,</span> <span class=\"mi\">2560</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>\n<span class=\"n\">xq</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">10_000</span><span class=\"p\">,</span>    <span class=\"mi\">2560</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>\n\n<span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"n\">brute_force</span><span class=\"o\">.</span><span class=\"n\">build</span><span class=\"p\">(</span><span class=\"n\">brute_force</span><span class=\"o\">.</span><span class=\"n\">IndexParams</span><span class=\"p\">(</span><span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"s2\">&quot;sqeuclidean&quot;</span><span class=\"p\">),</span> <span class=\"n\">xb</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n\n<span class=\"n\">D</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">xq</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>\n<span class=\"n\">I</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">xq</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">int64</span><span class=\"p\">))</span>\n<span class=\"n\">brute_force</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">brute_force</span><span class=\"o\">.</span><span class=\"n\">SearchParams</span><span class=\"p\">(</span><span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"s2\">&quot;sqeuclidean&quot;</span><span class=\"p\">),</span>\n                   <span class=\"n\">index</span><span class=\"p\">,</span> <span class=\"n\">xq</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">distances</span><span class=\"o\">=</span><span class=\"n\">D</span><span class=\"p\">,</span> <span class=\"n\">neighbors</span><span class=\"o\">=</span><span class=\"n\">I</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Incremental ingest</span>\n<span class=\"n\">xb2</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">200_000</span><span class=\"p\">,</span> <span class=\"mi\">2560</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>\n<span class=\"n\">brute_force</span><span class=\"o\">.</span><span class=\"n\">extend</span><span class=\"p\">(</span><span class=\"n\">index</span><span class=\"p\">,</span> <span class=\"n\">xb2</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Persistence</span>\n<span class=\"n\">brute_force</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"n\">index</span><span class=\"p\">,</span> <span class=\"s2\">&quot;/tmp/cuvs_bruteforce.idx&quot;</span><span class=\"p\">)</span>\n<span class=\"n\">index</span> <span class=\"o\">=</span> <span class=\"n\">brute_force</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s2\">&quot;/tmp/cuvs_bruteforce.idx&quot;</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n<span class=\"n\">h</span><span class=\"o\">.</span><span class=\"n\">sync</span><span class=\"p\">()</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>Good for <strong>ground truth</strong> during tuning and for small datasets.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"d2-neighbors-ivf-flat-faisslike-ivf-on-gpu\">\n<h3>D2) <code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.ivf_flat</span></code> \u2014 FAISS\u2011like IVF on GPU<a class=\"headerlink\" href=\"#d2-neighbors-ivf-flat-faisslike-ivf-on-gpu\" title=\"Link to this heading\">#</a></h3>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">cuvs.neighbors</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">ivf_flat</span>\n\n<span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">Resources</span><span class=\"p\">()</span>\n<span class=\"n\">xb</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">10_000</span><span class=\"p\">,</span> <span class=\"mi\">2560</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>\n<span class=\"n\">xq</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">1_000</span><span class=\"p\">,</span>  <span class=\"mi\">2560</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>\n\n<span class=\"n\">idx</span> <span class=\"o\">=</span> <span class=\"n\">ivf_flat</span><span class=\"o\">.</span><span class=\"n\">build</span><span class=\"p\">(</span><span class=\"n\">ivf_flat</span><span class=\"o\">.</span><span class=\"n\">IndexParams</span><span class=\"p\">(</span><span class=\"n\">n_lists</span><span class=\"o\">=</span><span class=\"mi\">8192</span><span class=\"p\">,</span> <span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"s2\">&quot;sqeuclidean&quot;</span><span class=\"p\">),</span> <span class=\"n\">xb</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n\n<span class=\"n\">D</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">xq</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>\n<span class=\"n\">I</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">xq</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">int64</span><span class=\"p\">))</span>\n<span class=\"n\">ivf_flat</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">ivf_flat</span><span class=\"o\">.</span><span class=\"n\">SearchParams</span><span class=\"p\">(</span><span class=\"n\">n_probes</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">),</span> <span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"n\">xq</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span>\n                <span class=\"n\">distances</span><span class=\"o\">=</span><span class=\"n\">D</span><span class=\"p\">,</span> <span class=\"n\">neighbors</span><span class=\"o\">=</span><span class=\"n\">I</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Add more</span>\n<span class=\"n\">ivf_flat</span><span class=\"o\">.</span><span class=\"n\">extend</span><span class=\"p\">(</span><span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">5_000</span><span class=\"p\">,</span> <span class=\"mi\">2560</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)),</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Save / load</span>\n<span class=\"n\">ivf_flat</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"s2\">&quot;/tmp/cuvs_ivfflat.idx&quot;</span><span class=\"p\">)</span>\n<span class=\"n\">idx2</span> <span class=\"o\">=</span> <span class=\"n\">ivf_flat</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s2\">&quot;/tmp/cuvs_ivfflat.idx&quot;</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n<span class=\"n\">h</span><span class=\"o\">.</span><span class=\"n\">sync</span><span class=\"p\">()</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>Parameter names mirror FAISS concepts: <code class=\"docutils literal notranslate\"><span class=\"pre\">n_lists</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">n_probes</span></code>, metric.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"d3-neighbors-ivf-pq-ivf-with-product-quantization\">\n<h3>D3) <code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.ivf_pq</span></code> \u2014 IVF with Product Quantization<a class=\"headerlink\" href=\"#d3-neighbors-ivf-pq-ivf-with-product-quantization\" title=\"Link to this heading\">#</a></h3>\n<p><em>(We\u2019d shown build/search before; here\u2019s <code class=\"docutils literal notranslate\"><span class=\"pre\">extend/save/load</span></code> and host output conversion.)</em></p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">cuvs.neighbors</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">ivf_pq</span>\n\n<span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">Resources</span><span class=\"p\">()</span>\n<span class=\"n\">idx</span> <span class=\"o\">=</span> <span class=\"n\">ivf_pq</span><span class=\"o\">.</span><span class=\"n\">build</span><span class=\"p\">(</span><span class=\"n\">ivf_pq</span><span class=\"o\">.</span><span class=\"n\">IndexParams</span><span class=\"p\">(</span><span class=\"n\">n_lists</span><span class=\"o\">=</span><span class=\"mi\">8192</span><span class=\"p\">,</span> <span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"s2\">&quot;sqeuclidean&quot;</span><span class=\"p\">,</span> <span class=\"n\">pq_bits</span><span class=\"o\">=</span><span class=\"mi\">8</span><span class=\"p\">),</span>\n                   <span class=\"n\">xb</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Extend incrementally</span>\n<span class=\"n\">ivf_pq</span><span class=\"o\">.</span><span class=\"n\">extend</span><span class=\"p\">(</span><span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">20_000</span><span class=\"p\">,</span> <span class=\"mi\">2560</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)),</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Search to host arrays (optional)</span>\n<span class=\"n\">D_dev</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">xq</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>\n<span class=\"n\">I_dev</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">xq</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">int64</span><span class=\"p\">))</span>\n<span class=\"n\">ivf_pq</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">ivf_pq</span><span class=\"o\">.</span><span class=\"n\">SearchParams</span><span class=\"p\">(</span><span class=\"n\">n_probes</span><span class=\"o\">=</span><span class=\"mi\">64</span><span class=\"p\">),</span> <span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"n\">xq</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">distances</span><span class=\"o\">=</span><span class=\"n\">D_dev</span><span class=\"p\">,</span> <span class=\"n\">neighbors</span><span class=\"o\">=</span><span class=\"n\">I_dev</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n<span class=\"n\">D_host</span><span class=\"p\">,</span> <span class=\"n\">I_host</span> <span class=\"o\">=</span> <span class=\"n\">D_dev</span><span class=\"o\">.</span><span class=\"n\">copy_to_host</span><span class=\"p\">(),</span> <span class=\"n\">I_dev</span><span class=\"o\">.</span><span class=\"n\">copy_to_host</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># Save / load</span>\n<span class=\"n\">ivf_pq</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"s2\">&quot;/tmp/cuvs_ivfpq.idx&quot;</span><span class=\"p\">)</span>\n<span class=\"n\">idx</span> <span class=\"o\">=</span> <span class=\"n\">ivf_pq</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s2\">&quot;/tmp/cuvs_ivfpq.idx&quot;</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n<span class=\"n\">h</span><span class=\"o\">.</span><span class=\"n\">sync</span><span class=\"p\">()</span>\n</pre></div>\n</div>\n</section>\n<hr class=\"docutils\" />\n<section id=\"d4-neighbors-cagra-highrecall-graph-ann\">\n<h3>D4) <code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.cagra</span></code> \u2014 high\u2011recall graph ANN<a class=\"headerlink\" href=\"#d4-neighbors-cagra-highrecall-graph-ann\" title=\"Link to this heading\">#</a></h3>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">cuvs.neighbors</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">cagra</span>\n\n<span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">Resources</span><span class=\"p\">()</span>\n<span class=\"n\">xb</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">2_000_000</span><span class=\"p\">,</span> <span class=\"mi\">2560</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>\n<span class=\"n\">xq</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">20_000</span><span class=\"p\">,</span>    <span class=\"mi\">2560</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>\n\n<span class=\"n\">idx</span> <span class=\"o\">=</span> <span class=\"n\">cagra</span><span class=\"o\">.</span><span class=\"n\">build</span><span class=\"p\">(</span><span class=\"n\">cagra</span><span class=\"o\">.</span><span class=\"n\">IndexParams</span><span class=\"p\">(</span><span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"s2\">&quot;sqeuclidean&quot;</span><span class=\"p\">),</span> <span class=\"n\">xb</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n\n<span class=\"n\">D</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">xq</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">))</span>\n<span class=\"n\">I</span> <span class=\"o\">=</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">empty</span><span class=\"p\">((</span><span class=\"n\">xq</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">int64</span><span class=\"p\">))</span>\n<span class=\"n\">cagra</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">cagra</span><span class=\"o\">.</span><span class=\"n\">SearchParams</span><span class=\"p\">(),</span> <span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"n\">xq</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">distances</span><span class=\"o\">=</span><span class=\"n\">D</span><span class=\"p\">,</span> <span class=\"n\">neighbors</span><span class=\"o\">=</span><span class=\"n\">I</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Extend / persist</span>\n<span class=\"n\">cagra</span><span class=\"o\">.</span><span class=\"n\">extend</span><span class=\"p\">(</span><span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"n\">device_ndarray</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">rand</span><span class=\"p\">(</span><span class=\"mi\">100_000</span><span class=\"p\">,</span> <span class=\"mi\">2560</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">)),</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n<span class=\"n\">cagra</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"s2\">&quot;/tmp/cuvs_cagra.idx&quot;</span><span class=\"p\">)</span>\n<span class=\"n\">idx</span> <span class=\"o\">=</span> <span class=\"n\">cagra</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"s2\">&quot;/tmp/cuvs_cagra.idx&quot;</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n<span class=\"n\">h</span><span class=\"o\">.</span><span class=\"n\">sync</span><span class=\"p\">()</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>CAGRA is excellent for tight latency at high recall; memory\u2011heavier than PQ. Use it for premium tiers.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"d5-neighbors-hnsw\">\n<h3>D5) <code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.hnsw</span></code><a class=\"headerlink\" href=\"#d5-neighbors-hnsw\" title=\"Link to this heading\">#</a></h3>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">cuvs.neighbors</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">hnsw</span>\n\n<span class=\"n\">h</span> <span class=\"o\">=</span> <span class=\"n\">Resources</span><span class=\"p\">()</span>\n<span class=\"n\">idx</span> <span class=\"o\">=</span> <span class=\"n\">hnsw</span><span class=\"o\">.</span><span class=\"n\">build</span><span class=\"p\">(</span><span class=\"n\">hnsw</span><span class=\"o\">.</span><span class=\"n\">IndexParams</span><span class=\"p\">(</span><span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"s2\">&quot;sqeuclidean&quot;</span><span class=\"p\">),</span> <span class=\"n\">xb</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n<span class=\"n\">hnsw</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">hnsw</span><span class=\"o\">.</span><span class=\"n\">SearchParams</span><span class=\"p\">(),</span> <span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"n\">xq</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span>\n            <span class=\"n\">distances</span><span class=\"o\">=</span><span class=\"n\">D</span><span class=\"p\">,</span> <span class=\"n\">neighbors</span><span class=\"o\">=</span><span class=\"n\">I</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n<span class=\"n\">hnsw</span><span class=\"o\">.</span><span class=\"n\">save</span><span class=\"p\">(</span><span class=\"n\">idx</span><span class=\"p\">,</span> <span class=\"s2\">&quot;/tmp/cuvs_hnsw.idx&quot;</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>A familiar graph ANN baseline on GPU. Pick either <strong>CAGRA</strong> (higher perf) or <strong>HNSW</strong> depending on constraints.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"d6-filters-refine-tiered-indexes-highlevel-patterns\">\n<h3>D6) Filters, refine, tiered indexes (high\u2011level patterns)<a class=\"headerlink\" href=\"#d6-filters-refine-tiered-indexes-highlevel-patterns\" title=\"Link to this heading\">#</a></h3>\n<ul class=\"simple\">\n<li><p><strong>Filters</strong> \u2014 apply post\u2011search restrictions or pre\u2011filter candidates with <code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.filters</span></code> utilities (e.g., by ID set). Use them for <strong>policy constraints</strong> or <strong>tenancy</strong>.</p></li>\n<li><p><strong>Refine</strong> \u2014 re\u2011score ANN candidates with an exact step (<code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.refine</span></code>) for <strong>accuracy boosts</strong>. Good when you need Flat re\u2011ranking on a subset.</p></li>\n<li><p><strong>Tiered index</strong> \u2014 orchestrate multi\u2011stage pipelines (e.g., IVF\u2011PQ \u2192 refine) using <code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.tiered_index</span></code> helpers.</p></li>\n</ul>\n<p><em>(Function names follow the <code class=\"docutils literal notranslate\"><span class=\"pre\">build/search/extend/save/load</span></code> theme; wire them like the examples above.)</em></p>\n</section>\n<hr class=\"docutils\" />\n<section id=\"d7-multigpu-neighbors-mg-distributed-ivfpq-ivfflat-cagra\">\n<h3>D7) Multi\u2011GPU (<code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.mg</span></code>) \u2014 <strong>distributed IVF\u2011PQ / IVF\u2011Flat / CAGRA</strong><a class=\"headerlink\" href=\"#d7-multigpu-neighbors-mg-distributed-ivfpq-ivfflat-cagra\" title=\"Link to this heading\">#</a></h3>\n<p><strong>Conceptual usage</strong> (keep the same <code class=\"docutils literal notranslate\"><span class=\"pre\">Resources</span></code> concept per device and use NCCL):</p>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">cuvs.neighbors.mg</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">ivf_pq</span> <span class=\"k\">as</span> <span class=\"n\">mg_ivfpq</span>\n<span class=\"c1\"># Build: mg_ivfpq.build(mg_ivfpq.IndexParams(...), dataset_per_gpu, resources=handles_per_gpu)</span>\n<span class=\"c1\"># Search: mg_ivfpq.search(..., k=..., resources=handles_per_gpu)</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>Requires NCCL. Use this path when one GPU\u2019s memory is insufficient or you need cluster\u2011like throughput while staying on a single multi\u2011GPU box.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"d8-distance-pairwise-distance-gpu-distance-matrix\">\n<h3>D8) <code class=\"docutils literal notranslate\"><span class=\"pre\">distance.pairwise_distance</span></code> \u2014 GPU distance matrix<a class=\"headerlink\" href=\"#d8-distance-pairwise-distance-gpu-distance-matrix\" title=\"Link to this heading\">#</a></h3>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">cuvs</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">distance</span>\n<span class=\"n\">Dx</span> <span class=\"o\">=</span> <span class=\"n\">distance</span><span class=\"o\">.</span><span class=\"n\">pairwise_distance</span><span class=\"p\">(</span><span class=\"n\">xq</span><span class=\"p\">,</span> <span class=\"n\">xb</span><span class=\"p\">,</span> <span class=\"n\">metric</span><span class=\"o\">=</span><span class=\"s2\">&quot;sqeuclidean&quot;</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>  <span class=\"c1\"># Dx on device by default</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>Handy for diagnostics, unit tests, or custom scoring layers.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"d9-cluster-kmeans-gpu-kmeans-centers-predict-cost\">\n<h3>D9) <code class=\"docutils literal notranslate\"><span class=\"pre\">cluster.kmeans</span></code> \u2014 GPU KMeans (centers, predict, cost)<a class=\"headerlink\" href=\"#d9-cluster-kmeans-gpu-kmeans-centers-predict-cost\" title=\"Link to this heading\">#</a></h3>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">cuvs.cluster</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">kmeans</span>\n\n<span class=\"n\">centers</span><span class=\"p\">,</span> <span class=\"n\">inertia</span><span class=\"p\">,</span> <span class=\"n\">n_iters</span> <span class=\"o\">=</span> <span class=\"n\">kmeans</span><span class=\"o\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">kmeans</span><span class=\"o\">.</span><span class=\"n\">KMeansParams</span><span class=\"p\">(</span><span class=\"n\">n_clusters</span><span class=\"o\">=</span><span class=\"mi\">8192</span><span class=\"p\">),</span> <span class=\"n\">xb</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n<span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">kmeans</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">xb</span><span class=\"p\">,</span> <span class=\"n\">centers</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n<span class=\"n\">cost</span> <span class=\"o\">=</span> <span class=\"n\">kmeans</span><span class=\"o\">.</span><span class=\"n\">cluster_cost</span><span class=\"p\">(</span><span class=\"n\">xb</span><span class=\"p\">,</span> <span class=\"n\">centers</span><span class=\"p\">,</span> <span class=\"n\">resources</span><span class=\"o\">=</span><span class=\"n\">h</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>Use for <strong>custom IVF training</strong> or other clustering tasks; interoperates with device arrays.</p></li>\n</ul>\n</section>\n</section>\n<hr class=\"docutils\" />\n<section id=\"e-libcuvs-loader-functions-env-youll-use-in-code\">\n<h2>E) libcuvs loader \u2014 functions &amp; env you\u2019ll use in code<a class=\"headerlink\" href=\"#e-libcuvs-loader-functions-env-youll-use-in-code\" title=\"Link to this heading\">#</a></h2>\n<blockquote>\n<div><p>Preload cuVS and RAPIDS libs <strong>once per process</strong> before any FAISS/cuVS calls to guarantee symbol resolution and allocator setup.</p>\n</div></blockquote>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">libcuvs</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">load_library</span>\n<span class=\"n\">handles</span> <span class=\"o\">=</span> <span class=\"n\">load_library</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s2\">&quot;Loaded:&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">h</span><span class=\"o\">.</span><span class=\"n\">_name</span> <span class=\"k\">for</span> <span class=\"n\">h</span> <span class=\"ow\">in</span> <span class=\"n\">handles</span><span class=\"p\">])</span>  <span class=\"c1\"># libcuvs.so, libcuvs_c.so, librmm.so, rapids_logger.so</span>\n</pre></div>\n</div>\n<p><strong>Environment knobs</strong> (optional):</p>\n<ul class=\"simple\">\n<li><p><code class=\"docutils literal notranslate\"><span class=\"pre\">RAPIDS_LIBCUVS_PREFER_SYSTEM_LIBRARY=true</span></code> \u2192 prefer system libs over wheel\u2011bundled copies.</p></li>\n<li><p>HybridSearch\u2019s <code class=\"docutils literal notranslate\"><span class=\"pre\">_ensure_cuvs_loader_path()</span></code> adds all <code class=\"docutils literal notranslate\"><span class=\"pre\">lib64/</span></code> dirs to <code class=\"docutils literal notranslate\"><span class=\"pre\">LD_LIBRARY_PATH</span></code> for child processes (inheritance is useful for workers).</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"f-endtoend-patterns-that-combine-the-above\">\n<h2>F) End\u2011to\u2011end patterns that combine the above<a class=\"headerlink\" href=\"#f-endtoend-patterns-that-combine-the-above\" title=\"Link to this heading\">#</a></h2>\n<section id=\"f1-filtered-refined-ivfpq-on-gpu-with-cuvs\">\n<h3>F1) <strong>Filtered, refined IVF\u2011PQ</strong> on GPU with cuVS<a class=\"headerlink\" href=\"#f1-filtered-refined-ivfpq-on-gpu-with-cuvs\" title=\"Link to this heading\">#</a></h3>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"c1\"># 0) Preload cuVS (once)</span>\n<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">libcuvs</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">load_library</span><span class=\"p\">;</span> <span class=\"n\">load_library</span><span class=\"p\">()</span>                               <span class=\"c1\"># loader. :contentReference[oaicite:25]{index=25}</span>\n<span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">faiss</span><span class=\"o\">,</span><span class=\"w\"> </span><span class=\"nn\">numpy</span><span class=\"w\"> </span><span class=\"k\">as</span><span class=\"w\"> </span><span class=\"nn\">np</span>\n\n<span class=\"n\">d</span><span class=\"o\">=</span><span class=\"mi\">2560</span>\n<span class=\"n\">cpu</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_factory</span><span class=\"p\">(</span><span class=\"n\">d</span><span class=\"p\">,</span> <span class=\"s2\">&quot;OPQ64,IVF8192,PQ64&quot;</span><span class=\"p\">,</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">METRIC_INNER_PRODUCT</span><span class=\"p\">)</span>\n<span class=\"n\">train</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">10_000_000</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">);</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">normalize_L2</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">)</span>\n<span class=\"n\">cpu</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"p\">(</span><span class=\"n\">train</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># ID map to carry your IDs</span>\n<span class=\"n\">idmap</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">IndexIDMap2</span><span class=\"p\">(</span><span class=\"n\">cpu</span><span class=\"p\">)</span>\n<span class=\"n\">xb</span>  <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">20_000_000</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">);</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">normalize_L2</span><span class=\"p\">(</span><span class=\"n\">xb</span><span class=\"p\">)</span>\n<span class=\"n\">ids</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">1</span><span class=\"o\">+</span><span class=\"n\">xb</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s1\">&#39;int64&#39;</span><span class=\"p\">)</span>\n<span class=\"n\">idmap</span><span class=\"o\">.</span><span class=\"n\">add_with_ids</span><span class=\"p\">(</span><span class=\"n\">xb</span><span class=\"p\">,</span> <span class=\"n\">ids</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Clone to GPU with cuVS enabled (fallback safe)</span>\n<span class=\"n\">res</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">StandardGpuResources</span><span class=\"p\">();</span> <span class=\"n\">res</span><span class=\"o\">.</span><span class=\"n\">setTempMemory</span><span class=\"p\">(</span><span class=\"mi\">1_200_000_000</span><span class=\"p\">);</span> <span class=\"n\">res</span><span class=\"o\">.</span><span class=\"n\">setPinnedMemory</span><span class=\"p\">(</span><span class=\"mi\">512_000_000</span><span class=\"p\">)</span>\n<span class=\"n\">co</span>  <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">GpuClonerOptions</span><span class=\"p\">();</span> <span class=\"n\">co</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span><span class=\"o\">=</span><span class=\"kc\">True</span>\n<span class=\"k\">try</span><span class=\"p\">:</span> <span class=\"n\">gpu</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">idmap</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">)</span>\n<span class=\"k\">except</span> <span class=\"ne\">RuntimeError</span><span class=\"p\">:</span>\n    <span class=\"n\">co</span><span class=\"o\">.</span><span class=\"n\">use_cuvs</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">;</span> <span class=\"n\">gpu</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">index_cpu_to_gpu</span><span class=\"p\">(</span><span class=\"n\">res</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">idmap</span><span class=\"p\">,</span> <span class=\"n\">co</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Filter: only IDs in a range, then search &amp; refine</span>\n<span class=\"n\">sp</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">SearchParametersIVF</span><span class=\"p\">();</span> <span class=\"n\">sp</span><span class=\"o\">.</span><span class=\"n\">nprobe</span> <span class=\"o\">=</span> <span class=\"mi\">64</span><span class=\"p\">;</span> <span class=\"n\">sp</span><span class=\"o\">.</span><span class=\"n\">sel</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">IDSelectorRange</span><span class=\"p\">(</span><span class=\"mi\">100_000</span><span class=\"p\">,</span> <span class=\"mi\">500_000</span><span class=\"p\">)</span>\n<span class=\"n\">refiner</span> <span class=\"o\">=</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">IndexRefineFlat</span><span class=\"p\">(</span><span class=\"n\">gpu</span><span class=\"p\">);</span> <span class=\"n\">refiner</span><span class=\"o\">.</span><span class=\"n\">kfactor</span> <span class=\"o\">=</span> <span class=\"mf\">2.0</span>\n\n<span class=\"n\">xq</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"mi\">1000</span><span class=\"p\">,</span> <span class=\"n\">d</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">astype</span><span class=\"p\">(</span><span class=\"s1\">&#39;float32&#39;</span><span class=\"p\">);</span> <span class=\"n\">faiss</span><span class=\"o\">.</span><span class=\"n\">normalize_L2</span><span class=\"p\">(</span><span class=\"n\">xq</span><span class=\"p\">)</span>\n<span class=\"n\">D</span><span class=\"p\">,</span> <span class=\"n\">I</span> <span class=\"o\">=</span> <span class=\"n\">refiner</span><span class=\"o\">.</span><span class=\"n\">search</span><span class=\"p\">(</span><span class=\"n\">xq</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">params</span><span class=\"o\">=</span><span class=\"n\">sp</span><span class=\"p\">)</span>\n</pre></div>\n</div>\n<p><strong>Why this works well for you</strong></p>\n<ul class=\"simple\">\n<li><p>Cosine via normalization + IP (2560\u2011d per architecture).</p></li>\n<li><p>cuVS path engaged for IVF\u2011PQ when available; otherwise FAISS kernels.</p></li>\n<li><p>Filter converted to cuVS filter internally in your build.</p></li>\n</ul>\n</section>\n<hr class=\"docutils\" />\n<section id=\"f2-direct-cuvs-multigpu-ivfpq-outline\">\n<h3>F2) <strong>Direct cuVS</strong> multi\u2011GPU IVF\u2011PQ (outline)<a class=\"headerlink\" href=\"#f2-direct-cuvs-multigpu-ivfpq-outline\" title=\"Link to this heading\">#</a></h3>\n<div class=\"highlight-python notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"c1\"># Pseudocode outline (patterns match single-GPU examples; use mg.ivf_pq)</span>\n<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">cuvs.neighbors.mg</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">ivf_pq</span> <span class=\"k\">as</span> <span class=\"n\">mg_ivfpq</span>\n<span class=\"c1\"># handles = [Resources() per GPU]; datasets split per GPU as device arrays</span>\n<span class=\"c1\"># idx = mg_ivfpq.build(mg_ivfpq.IndexParams(n_lists=8192, metric=&quot;sqeuclidean&quot;, pq_bits=8),</span>\n<span class=\"c1\">#                      datasets, resources=handles)</span>\n<span class=\"c1\"># mg_ivfpq.search(mg_ivfpq.SearchParams(n_probes=64), idx, queries, k=10,</span>\n<span class=\"c1\">#                 distances=..., neighbors=..., resources=handles)</span>\n</pre></div>\n</div>\n<p><strong>Notes</strong></p>\n<ul class=\"simple\">\n<li><p>Reach for multi\u2011GPU cuVS when a single GPU\u2019s VRAM is the bottleneck.</p></li>\n</ul>\n</section>\n</section>\n<hr class=\"docutils\" />\n<section id=\"g-quick-checklist-for-agents-so-you-dont-miss-a-function-again\">\n<h2>G) Quick checklist for agents (so you don\u2019t miss a function again)<a class=\"headerlink\" href=\"#g-quick-checklist-for-agents-so-you-dont-miss-a-function-again\" title=\"Link to this heading\">#</a></h2>\n<ul class=\"simple\">\n<li><p><strong>Always normalize</strong> embeddings for cosine/IP.</p></li>\n<li><p>Use <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">IndexIDMap2</span></code></strong> to own IDs; <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">IndexRefineFlat</span></code></strong> when you need exact re\u2011ranking.</p></li>\n<li><p>Set knobs with <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">ParameterSpace</span></code> / <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuParameterSpace</span></code></strong>.</p></li>\n<li><p>For <strong>filters</strong>, use <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">IDSelector*</span></code></strong> + <code class=\"docutils literal notranslate\"><span class=\"pre\">SearchParametersIVF</span></code>; your build converts to cuVS automatically when cuVS is enabled.</p></li>\n<li><p>Persist <strong>CPU</strong> index with <code class=\"docutils literal notranslate\"><span class=\"pre\">write_index</span></code>; <strong>re\u2011clone</strong> to GPU on startup.</p></li>\n<li><p>Preload cuVS (<code class=\"docutils literal notranslate\"><span class=\"pre\">libcuvs.load_library()</span></code>), then set <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">use_cuvs=True</span></code></strong> on <strong>cloner/config</strong> for <strong>Flat, IVF\u2011Flat, IVF\u2011PQ, CAGRA, Binary\u2011CAGRA</strong>; guard with try/except or <code class=\"docutils literal notranslate\"><span class=\"pre\">should_use_cuvs</span></code> for <strong>bfKNN</strong>.</p></li>\n<li><p>For <strong>direct cuVS</strong>: use <code class=\"docutils literal notranslate\"><span class=\"pre\">build/extend/search/save/load</span></code> in <code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.{ivf_flat,</span> <span class=\"pre\">ivf_pq,</span> <span class=\"pre\">cagra,</span> <span class=\"pre\">hnsw,</span> <span class=\"pre\">brute_force}</span></code> with <strong>device arrays</strong> and a shared <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">Resources</span></code></strong> handle.</p></li>\n<li><p>Keep defaults from the architecture doc (2560\u2011d, <code class=\"docutils literal notranslate\"><span class=\"pre\">OPQ64,IVF8192,PQ64</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">nprobe=64</span></code>, shards \u226410\u202fM vectors).</p></li>\n</ul>\n<hr class=\"docutils\" />\n<p>If you want, I can also package these into a <strong>reference Jupyter notebook</strong> that runs each snippet end\u2011to\u2011end (with small synthetic data) and prints sanity checks (dimensions, top\u2011K shapes, cuVS enabled flags).</p>\n</section>\n</section>\n", "metatags": "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n", "rellinks": [["genindex", "General Index", "I", "index"], ["py-modindex", "Python Module Index", "", "modules"], ["autoapi/index", "API Reference", "N", "next"], ["explanations/251025_HighLevelArchitecture", "Implementation-Grade Architecture Overview", "P", "previous"]], "sourcename": "explanations/251025_FAISS_whl_overview.md.txt", "toc": "<ul>\n<li><a class=\"reference internal\" href=\"#\">Updated cuVS Addendum</a><ul>\n<li><a class=\"reference internal\" href=\"#revised-capability-matrix-this-wheel\">1) Revised capability matrix (this wheel)</a></li>\n<li><a class=\"reference internal\" href=\"#how-to-enable-cuvs-reliable-patterns\">2) How to enable cuVS (reliable patterns)</a><ul>\n<li><a class=\"reference internal\" href=\"#oneline-preload-cuvs-rapids-libs\">2.1. One\u2011line preload (cuVS/RAPIDS libs)</a></li>\n<li><a class=\"reference internal\" href=\"#enabling-cuvs-via-gpu-cloner-options-recommended\">2.2. Enabling cuVS via <strong>GPU Cloner Options</strong> (recommended)</a></li>\n<li><a class=\"reference internal\" href=\"#enabling-cuvs-via-index-configs-direct-gpu-constructors\">2.3. Enabling cuVS via <strong>index configs</strong> (direct GPU constructors)</a></li>\n<li><a class=\"reference internal\" href=\"#enabling-cuvs-for-direct-gpu-bruteforce-knn\">2.4. Enabling cuVS for <strong>direct GPU brute\u2011force kNN</strong></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#minimal-correct-by-construction-recipes-per-family\">3) Minimal \u201ccorrect by construction\u201d recipes per family</a><ul>\n<li><a class=\"reference internal\" href=\"#ivfpq-opq64-ivf8192-pq64-with-cuvs\">3.1. <strong>IVF\u2011PQ (OPQ64,IVF8192,PQ64)</strong> with cuVS</a></li>\n<li><a class=\"reference internal\" href=\"#ivfflat-with-cuvs\">3.2. <strong>IVF\u2011Flat</strong> with cuVS</a></li>\n<li><a class=\"reference internal\" href=\"#flat-exact-with-cuvs\">3.3. <strong>Flat (exact)</strong> with cuVS</a></li>\n<li><a class=\"reference internal\" href=\"#cagra-with-cuvs\">3.4. <strong>CAGRA</strong> with cuVS</a></li>\n<li><a class=\"reference internal\" href=\"#binarycagra-with-cuvs\">3.5. <strong>Binary\u2011CAGRA</strong> with cuVS</a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#filters-selectors-what-those-cuvsfilter-objects-mean-for-you\">4) Filters &amp; selectors (what those <code class=\"docutils literal notranslate\"><span class=\"pre\">CuvsFilter*</span></code> objects mean for you)</a></li>\n<li><a class=\"reference internal\" href=\"#operational-reminders-unchanged-but-critical\">5) Operational reminders (unchanged but critical)</a></li>\n<li><a class=\"reference internal\" href=\"#quick-am-i-using-cuvs-right-now-probes\">6) Quick \u201cam I using cuVS right now?\u201d probes</a><ul>\n<li><a class=\"reference internal\" href=\"#pointers-unchanged\">Pointers (unchanged)</a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#bottom-line-what-to-change-in-your-code\">7) Bottom line (what to change in your code)</a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#addendum-base-content-on-faiss-gpu-library\">addendum, base content on faiss gpu library</a><ul>\n<li><a class=\"reference internal\" href=\"#what-changed-vs-the-prior-wheel-and-how-to-think-about-it\">0) What changed vs. the prior wheel (and how to think about it)</a></li>\n<li><a class=\"reference internal\" href=\"#cpu-vs-gpu-vs-cuvs-updated-capability-map-this-wheel\">1) CPU vs GPU vs cuVS \u2014 updated capability map (this wheel)</a></li>\n<li><a class=\"reference internal\" href=\"#blackwell-rtx-5090-support-sass-sm-120-ptx-sm-120virtual\">2) Blackwell (RTX\u202f5090) support: SASS <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">sm_120</span></code></strong> + PTX <strong><code class=\"docutils literal notranslate\"><span class=\"pre\">sm_120\u2011virtual</span></code></strong></a></li>\n<li><a class=\"reference internal\" href=\"#cuvs-enablement-model-final-patterns\">3) cuVS enablement model (final patterns)</a></li>\n<li><a class=\"reference internal\" href=\"#bestinclass-faiss-build-on-rtx-5090-cosine-2560d-now-with-cuvs-toggles\">4) \u201cBest\u2011in\u2011class\u201d FAISS build on RTX\u202f5090 (cosine, 2560\u2011d) \u2014 <strong>now with cuVS toggles</strong></a></li>\n<li><a class=\"reference internal\" href=\"#when-to-call-cuvs-directly-and-when-faiss-cuvs-is-enough\">5) When to call cuVS directly (and when FAISS+cuVS is enough)</a></li>\n<li><a class=\"reference internal\" href=\"#quick-api-map-what-youll-call-most-often\">6) Quick API map \u2014 <strong>what you\u2019ll call most often</strong></a></li>\n<li><a class=\"reference internal\" href=\"#validation-checklist-runtime\">7) Validation checklist (runtime)</a></li>\n<li><a class=\"reference internal\" href=\"#operational-guidance-unchanged-principles-cuvsaware\">8) Operational guidance (unchanged principles, cuVS\u2011aware)</a></li>\n<li><a class=\"reference internal\" href=\"#readytopaste-helpers-with-cuvs-autoengage\">9) Ready\u2011to\u2011paste helpers (with cuVS auto\u2011engage)</a></li>\n<li><a class=\"reference internal\" href=\"#bottom-line\">10) Bottom line</a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#addendum-agentoriented-details-updated-to-match-the-new-cuvs-coverage\">Addendum \u2014 Agent\u2011oriented details (updated to match the new cuVS coverage)</a><ul>\n<li><a class=\"reference internal\" href=\"#a1-process-bootstrap-deterministic-cuvsready\">A1. Process bootstrap (deterministic &amp; cuVS\u2011ready)</a></li>\n<li><a class=\"reference internal\" href=\"#a2-zerocopy-interop-faiss-cuvs\">A2. Zero\u2011copy interop (FAISS \u2194 cuVS)</a></li>\n<li><a class=\"reference internal\" href=\"#a3-multigpu-replicas-and-shards-unchanged\">A3. Multi\u2011GPU: replicas and shards (unchanged)</a></li>\n<li><a class=\"reference internal\" href=\"#a4-memory-planning-batching\">A4. Memory planning &amp; batching</a></li>\n<li><a class=\"reference internal\" href=\"#a5-persistence-registry\">A5. Persistence &amp; registry</a></li>\n<li><a class=\"reference internal\" href=\"#a6-observability-probes\">A6. Observability &amp; probes</a></li>\n<li><a class=\"reference internal\" href=\"#a7-failure-taxonomy-fallbacks-gpu-paths\">A7. Failure taxonomy &amp; fallbacks (GPU paths)</a></li>\n<li><a class=\"reference internal\" href=\"#a8-direct-cuvs-catalog-unchanged-surfaces\">A8. Direct cuVS catalog (unchanged surfaces)</a></li>\n<li><a class=\"reference internal\" href=\"#a9-architecture-defaults-for-the-broader-system\">A9. Architecture defaults (for the broader system)</a></li>\n<li><a class=\"reference internal\" href=\"#a-faiss-cpuside-classes-utilities-with-examples\">A) FAISS \u2014 CPU\u2011side classes &amp; utilities (with examples)</a><ul>\n<li><a class=\"reference internal\" href=\"#a1-indexidmap-indexidmap2-stable-ids-around-any-index\">A1) <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexIDMap</span></code> / <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexIDMap2</span></code> \u2014 stable IDs around any index</a></li>\n<li><a class=\"reference internal\" href=\"#a2-indexrefineflat-refine-ann-hits-with-exact-scoring\">A2) <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexRefineFlat</span></code> \u2014 refine ANN hits with exact scoring</a></li>\n<li><a class=\"reference internal\" href=\"#a3-indexpretransform-transforms-opqmatrix-pcamatrix\">A3) <code class=\"docutils literal notranslate\"><span class=\"pre\">IndexPreTransform</span></code> + transforms (<code class=\"docutils literal notranslate\"><span class=\"pre\">OPQMatrix</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">PCAMatrix</span></code>)</a></li>\n<li><a class=\"reference internal\" href=\"#a4-clustering-kmeans-build-coarse-quantizers-explicitly\">A4) <code class=\"docutils literal notranslate\"><span class=\"pre\">Clustering</span></code> (K\u2011means) \u2014 build coarse quantizers explicitly</a></li>\n<li><a class=\"reference internal\" href=\"#a5-parameterspace-gpuparameterspace-named-tuning-knobs\">A5) <code class=\"docutils literal notranslate\"><span class=\"pre\">ParameterSpace</span></code> / <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuParameterSpace</span></code> \u2014 named tuning knobs</a></li>\n<li><a class=\"reference internal\" href=\"#a6-persistence-write-index-read-index\">A6) Persistence \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">write_index</span></code> / <code class=\"docutils literal notranslate\"><span class=\"pre\">read_index</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#a7-range-search-range-search-a-k-a-radius-search\">A7) Range search \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">range_search</span></code> (a.k.a. radius search)</a></li>\n<li><a class=\"reference internal\" href=\"#a8-filtered-search-idselector-searchparametersivf\">A8) Filtered search \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">IDSelector*</span></code> + <code class=\"docutils literal notranslate\"><span class=\"pre\">SearchParametersIVF</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#a9-deletions-remove-ids\">A9) Deletions \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">remove_ids</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#a10-reconstruction-reconstruct-reconstruct-n\">A10) Reconstruction \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">reconstruct</span></code>, <code class=\"docutils literal notranslate\"><span class=\"pre\">reconstruct_n</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#a11-cpu-parallelism-omp-set-num-threads\">A11) CPU parallelism \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">omp_set_num_threads</span></code></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#b-faiss-gpu-multigpu-functions-deeper-with-cuvs-enablement\">B) FAISS \u2014 GPU &amp; multi\u2011GPU functions (deeper, with cuVS enablement)</a><ul>\n<li><a class=\"reference internal\" href=\"#b1-cpugpu-cloning-single-multigpu\">B1) CPU\u2192GPU cloning (single &amp; multi\u2011GPU)</a></li>\n<li><a class=\"reference internal\" href=\"#b2-direct-gpu-constructors-with-gpuindex-config-use-cuvs\">B2) Direct GPU constructors with <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuIndex*Config.use_cuvs</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#b3-gpu-distance-primitives-bfknn-knn-gpu-bfknn\">B3) GPU distance primitives \u2014 bfKNN (<code class=\"docutils literal notranslate\"><span class=\"pre\">knn_gpu</span></code>/<code class=\"docutils literal notranslate\"><span class=\"pre\">bfKnn</span></code>)</a></li>\n<li><a class=\"reference internal\" href=\"#b4-gpu-tuning-knobs-gpuparameterspace-configs\">B4) GPU tuning knobs \u2014 <code class=\"docutils literal notranslate\"><span class=\"pre\">GpuParameterSpace</span></code> &amp; configs</a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#c-faiss-contrib-helpers-youll-likely-use\">C) FAISS contrib helpers you\u2019ll likely use</a></li>\n<li><a class=\"reference internal\" href=\"#d-cuvs-functions-modules-we-hadnt-exemplified-now-with-code\">D) cuVS \u2014 functions &amp; modules we hadn\u2019t exemplified (now with code)</a><ul>\n<li><a class=\"reference internal\" href=\"#d1-neighbors-brute-force-exact-knn-baseline-qa\">D1) <code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.brute_force</span></code> \u2014 exact kNN (baseline &amp; QA)</a></li>\n<li><a class=\"reference internal\" href=\"#d2-neighbors-ivf-flat-faisslike-ivf-on-gpu\">D2) <code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.ivf_flat</span></code> \u2014 FAISS\u2011like IVF on GPU</a></li>\n<li><a class=\"reference internal\" href=\"#d3-neighbors-ivf-pq-ivf-with-product-quantization\">D3) <code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.ivf_pq</span></code> \u2014 IVF with Product Quantization</a></li>\n<li><a class=\"reference internal\" href=\"#d4-neighbors-cagra-highrecall-graph-ann\">D4) <code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.cagra</span></code> \u2014 high\u2011recall graph ANN</a></li>\n<li><a class=\"reference internal\" href=\"#d5-neighbors-hnsw\">D5) <code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.hnsw</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#d6-filters-refine-tiered-indexes-highlevel-patterns\">D6) Filters, refine, tiered indexes (high\u2011level patterns)</a></li>\n<li><a class=\"reference internal\" href=\"#d7-multigpu-neighbors-mg-distributed-ivfpq-ivfflat-cagra\">D7) Multi\u2011GPU (<code class=\"docutils literal notranslate\"><span class=\"pre\">neighbors.mg</span></code>) \u2014 <strong>distributed IVF\u2011PQ / IVF\u2011Flat / CAGRA</strong></a></li>\n<li><a class=\"reference internal\" href=\"#d8-distance-pairwise-distance-gpu-distance-matrix\">D8) <code class=\"docutils literal notranslate\"><span class=\"pre\">distance.pairwise_distance</span></code> \u2014 GPU distance matrix</a></li>\n<li><a class=\"reference internal\" href=\"#d9-cluster-kmeans-gpu-kmeans-centers-predict-cost\">D9) <code class=\"docutils literal notranslate\"><span class=\"pre\">cluster.kmeans</span></code> \u2014 GPU KMeans (centers, predict, cost)</a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#e-libcuvs-loader-functions-env-youll-use-in-code\">E) libcuvs loader \u2014 functions &amp; env you\u2019ll use in code</a></li>\n<li><a class=\"reference internal\" href=\"#f-endtoend-patterns-that-combine-the-above\">F) End\u2011to\u2011end patterns that combine the above</a><ul>\n<li><a class=\"reference internal\" href=\"#f1-filtered-refined-ivfpq-on-gpu-with-cuvs\">F1) <strong>Filtered, refined IVF\u2011PQ</strong> on GPU with cuVS</a></li>\n<li><a class=\"reference internal\" href=\"#f2-direct-cuvs-multigpu-ivfpq-outline\">F2) <strong>Direct cuVS</strong> multi\u2011GPU IVF\u2011PQ (outline)</a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#g-quick-checklist-for-agents-so-you-dont-miss-a-function-again\">G) Quick checklist for agents (so you don\u2019t miss a function again)</a></li>\n</ul>\n</li>\n</ul>\n", "display_toc": true, "page_source_suffix": ".md", "has_maths_elements": false, "current_page_name": "explanations/251025_FAISS_whl_overview", "sidebars": ["sidebar-nav-bs.html"], "alabaster_version": "0.7.16", "alabaster_version_info": [0, 7, 16], "theme_show_toc_level": 1, "generate_toctree_html": "<functools._lru_cache_wrapper object at 0x790abb112350>", "generate_toc_html": "<functools._lru_cache_wrapper object at 0x790abb110f60>", "theme_version": "0.16.1", "theme_logo": {"image_relative": {}}}