"""Configuration settings using msgspec for fast, validated config.

NO Pydantic - using msgspec.Struct for performance-critical settings.
All configuration loaded from environment variables with sensible defaults.
"""

from __future__ import annotations

import os
from pathlib import Path

import msgspec


class VLLMConfig(msgspec.Struct, frozen=True):
    """vLLM embedding service configuration.

    Configuration for connecting to a vLLM embedding service that provides
    OpenAI-compatible embeddings API. This is used for generating vector embeddings
    of code chunks during indexing and for query embeddings during semantic search.

    The vLLM service runs separately (typically on a GPU-enabled machine) and
    provides fast batch embedding generation. The configuration includes connection
    details, model selection, and performance tuning parameters.

    Attributes
    ----------
    base_url : str
        Base URL for the vLLM embeddings API endpoint. Should point to the /v1
        endpoint of a running vLLM server. Defaults to localhost:8001.
    model : str
        Model identifier for embeddings. This should match a model that the
        vLLM server has loaded. Defaults to "nomic-ai/nomic-embed-code" which
        is a code-specific embedding model with 2560 dimensions.
    batch_size : int
        Number of texts to embed in a single batch request. Larger batches improve
        throughput but increase memory usage. Defaults to 64, which is a good
        balance for most GPU setups.
    timeout_s : float
        HTTP request timeout in seconds. Embedding requests can take time for
        large batches, so this should be set appropriately. Defaults to 120 seconds.
    """

    base_url: str = "http://127.0.0.1:8001/v1"
    model: str = "nomic-ai/nomic-embed-code"
    batch_size: int = 64
    timeout_s: float = 120.0


class PathsConfig(msgspec.Struct, frozen=True):
    """File system paths configuration.

    Centralized configuration for all file system paths used by the code intelligence
    system. This includes paths for data storage, indexes, and source code locations.
    All paths can be relative (to repo_root) or absolute.

    The paths are organized hierarchically: data_dir contains subdirectories for
    different types of data (vectors, indexes, etc.). This structure makes it easy
    to manage and back up the entire index state.

    Attributes
    ----------
    repo_root : str
        Absolute path to the repository root directory. This is the base directory
        for all source code indexing and is used to resolve relative file paths
        from SCIP indexes. Required - no default.
    data_dir : str
        Base directory for all data storage (indexes, vectors, databases). Defaults
        to "data" relative to repo_root. This directory will contain subdirectories
        for vectors, FAISS indexes, Lucene indexes, etc.
    vectors_dir : str
        Directory containing Parquet files with vector embeddings. Each Parquet file
        stores chunks with their embeddings in Arrow FixedSizeList format for
        efficient zero-copy access. Defaults to "data/vectors".
    faiss_index : str
        Path to the FAISS IVF-PQ index file (CPU version). This is the persisted
        index that can be loaded and cloned to GPU. Defaults to
        "data/faiss/code.ivfpq.faiss".
    lucene_dir : str
        Directory for Lucene/BM25 indexes. Used for sparse retrieval methods like
        BM25 keyword search. Defaults to "data/lucene".
    splade_dir : str
        Directory for SPLADE (Sparse Lexical and Dense) impact indexes. SPLADE
        provides learned sparse representations that combine benefits of keyword
        and dense search. Defaults to "data/splade".
    duckdb_path : str
        Path to the DuckDB catalog database file. DuckDB provides SQL views over
        Parquet files, enabling fast queries for chunk metadata, filtering, and
        joins. Defaults to "data/catalog.duckdb".
    scip_index : str
        Path to the SCIP index file (either protobuf .scip or JSON .scip.json).
        This is the source of truth for symbol definitions and is generated by
        the SCIP Python indexer. Defaults to "index.scip" in repo_root.
    """

    repo_root: str
    data_dir: str = "data"
    vectors_dir: str = "data/vectors"
    faiss_index: str = "data/faiss/code.ivfpq.faiss"
    lucene_dir: str = "data/lucene"
    splade_dir: str = "data/splade"
    duckdb_path: str = "data/catalog.duckdb"
    scip_index: str = "index.scip"


class IndexConfig(msgspec.Struct, frozen=True):
    """Indexing and search configuration.

    Configuration parameters for the indexing pipeline and search algorithms.
    This includes settings for chunking, vector dimensions, FAISS index structure,
    BM25 parameters, and hybrid retrieval fusion.

    The configuration balances search quality (recall/precision) with performance
    (index size, search speed). The defaults are tuned for code search workloads
    with typical repository sizes (thousands to millions of chunks).

    Attributes
    ----------
    vec_dim : int
        Dimensionality of embedding vectors. Must match the embedding model's
        output dimension. Defaults to 2560 for nomic-embed-code model. Changing
        this requires re-indexing with a different model.
    chunk_budget : int
        Target chunk size in characters. The cAST chunker tries to pack symbols
        up to this size before splitting. Larger chunks provide more context but
        may reduce precision. Defaults to 2200 characters, which is optimal for
        code search (roughly 50-100 lines depending on code style).
    faiss_nlist : int
        Number of IVF (Inverted File) centroids/clusters. More centroids improve
        recall but increase index size and training time. Defaults to 8192, which
        provides good recall for millions of vectors. For smaller datasets (<100k),
        consider 4096; for very large (>10M), consider 16384.
    faiss_nprobe : int
        Number of IVF cells to probe during search. Higher values improve recall
        but slow down search. Defaults to 128, which probes ~1.5% of cells for
        nlist=8192. For higher recall, increase to 256 or 512; for faster search,
        decrease to 64.
    bm25_k1 : float
        BM25 term frequency saturation parameter. Controls how quickly term
        frequency saturates. Higher values (1.0-2.0) give more weight to
        repeated terms. Defaults to 0.9, which is standard for code search.
    bm25_b : float
        BM25 length normalization parameter. Controls how much document length
        affects scoring (0 = no normalization, 1 = full normalization).
        Defaults to 0.4, which provides moderate length normalization suitable
        for code where length varies significantly.
    rrf_k : int
        Reciprocal Rank Fusion (RRF) K parameter. Used to fuse results from
        multiple retrieval systems (FAISS, BM25, SPLADE). Higher K values give
        more weight to lower-ranked results. Defaults to 60, which is standard
        for hybrid search. Lower values (30-40) favor top results; higher (80-100)
        give more weight to consensus across systems.
    use_cuvs : bool
        Enable cuVS (CUDA Vector Search) acceleration for FAISS GPU operations.
        cuVS provides optimized GPU kernels that can be 2-3x faster than standard
        FAISS GPU. Requires libcuvs-cu13 package. Defaults to True. Set to False
        if cuVS is unavailable or causes issues.
    faiss_preload : bool
        Pre-load FAISS index during application startup (eager loading). When True,
        the FAISS index is loaded immediately at startup, eliminating first-request
        latency. When False (default), the index is loaded lazily on first semantic
        search request. Set to True in production for consistent response times;
        keep False in development for faster startup iteration.
    """

    vec_dim: int = 2560
    chunk_budget: int = 2200
    faiss_nlist: int = 8192
    faiss_nprobe: int = 128
    bm25_k1: float = 0.9
    bm25_b: float = 0.4
    rrf_k: int = 60
    use_cuvs: bool = True
    faiss_preload: bool = False


class ServerLimits(msgspec.Struct, frozen=True):
    """Server resource limits and rate limiting configuration.

    Configuration for protecting the server from resource exhaustion and ensuring
    fair usage. These limits prevent individual queries from consuming excessive
    resources and provide basic rate limiting for API access.

    The defaults are conservative and suitable for production deployments. Adjust
    based on your hardware capabilities and expected load patterns.

    Attributes
    ----------
    max_results : int
        Maximum number of results to return per query. This prevents queries from
        returning excessively large result sets that could cause memory issues or
        slow response times. Defaults to 1000 results, which is typically more
        than needed for most use cases. For interactive search, 50-100 is usually
        sufficient.
    query_timeout_s : float
        Maximum time in seconds that a query is allowed to run before timing out.
        This protects against slow queries (e.g., very large FAISS searches) that
        could block the server. Defaults to 30 seconds, which should be sufficient
        for most semantic searches even on large indexes. For very large indexes
        (>10M vectors), consider increasing to 60 seconds.
    rate_limit_qps : float
        Queries per second (QPS) rate limit. This is the sustained rate at which
        queries are allowed. Defaults to 10 QPS, which is reasonable for a single
        server instance. For production deployments behind a load balancer, this
        should be set per-instance (total QPS = instances * rate_limit_qps).
    rate_limit_burst : int
        Burst capacity for the rate limiter. This allows short bursts above the
        QPS limit to handle traffic spikes. Defaults to 20 queries, which allows
        a 2-second burst at 10 QPS. Set higher (40-60) if you expect more variable
        traffic patterns.
    """

    max_results: int = 1000
    query_timeout_s: float = 30.0
    rate_limit_qps: float = 10.0
    rate_limit_burst: int = 20


class Settings(msgspec.Struct, frozen=True):
    """Global settings container for the entire code intelligence system.

    This is the root configuration object that aggregates all subsystem
    configurations. It's loaded once at application startup from environment
    variables and remains immutable throughout the application lifetime.

    The Settings object is frozen (immutable) to prevent accidental modification
    and ensure thread-safe access. All configuration is validated at load time
    through msgspec's type system.

    Attributes
    ----------
    vllm : VLLMConfig
        Configuration for the vLLM embedding service. Includes connection details,
        model selection, and batching parameters for generating code embeddings.
    paths : PathsConfig
        File system path configuration. Defines where indexes, vectors, databases,
        and source code are stored. All paths are resolved relative to repo_root.
    index : IndexConfig
        Indexing and search algorithm configuration. Includes chunking parameters,
        FAISS index structure, BM25 settings, and hybrid retrieval fusion parameters.
    limits : ServerLimits
        Server resource limits and rate limiting configuration. Protects against
        resource exhaustion and provides basic API rate limiting.
    """

    vllm: VLLMConfig
    paths: PathsConfig
    index: IndexConfig
    limits: ServerLimits


def load_settings() -> Settings:
    """Load settings from environment variables with sensible defaults.

    This function reads configuration from environment variables and constructs
    a Settings object with all subsystem configurations. Environment variables
    follow a hierarchical naming scheme: subsystem name in uppercase, then
    the parameter name.

    All environment variables are optional - sensible defaults are provided for
    development and testing. For production deployments, you should set at minimum:
    REPO_ROOT, VLLM_URL, and any paths that differ from defaults.

    The function validates types (converting strings to int/float/bool as needed)
    and ensures required fields (like repo_root) have values. If REPO_ROOT is
    not set, it defaults to the current working directory.

    Returns
    -------
    Settings
        Fully configured Settings instance with all subsystems initialized.
        The Settings object is frozen (immutable) and can be safely shared across
        threads.

    See Also
    --------
    The following environment variables can be used to configure the settings:
    ---------------------
    VLLM_URL : str, optional
        vLLM service base URL (default: "http://127.0.0.1:8001/v1").
    VLLM_MODEL : str, optional
        Embedding model identifier (default: "nomic-ai/nomic-embed-code").
    VLLM_BATCH_SIZE : int, optional
        Batch size for embedding requests (default: 64).
    VLLM_TIMEOUT_S : float, optional
        HTTP timeout for vLLM requests in seconds (default: 120.0).
    REPO_ROOT : str, optional
        Repository root directory path (default: current working directory).
    DATA_DIR : str, optional
        Base data directory (default: "data").
    VECTORS_DIR : str, optional
        Vector storage directory (default: "data/vectors").
    FAISS_INDEX : str, optional
        FAISS index file path (default: "data/faiss/code.ivfpq.faiss").
    LUCENE_DIR : str, optional
        Lucene index directory (default: "data/lucene").
    SPLADE_DIR : str, optional
        SPLADE index directory (default: "data/splade").
    DUCKDB_PATH : str, optional
        DuckDB catalog database path (default: "data/catalog.duckdb").
    SCIP_INDEX : str, optional
        SCIP index file path (default: "index.scip").
    VEC_DIM : int, optional
        Embedding vector dimension (default: 2560).
    CHUNK_BUDGET : int, optional
        Target chunk size in characters (default: 2200).
    FAISS_NLIST : int, optional
        Number of IVF centroids (default: 8192).
    FAISS_NPROBE : int, optional
        Number of IVF cells to probe during search (default: 128).
    BM25_K1 : float, optional
        BM25 k1 parameter (default: 0.9).
    BM25_B : float, optional
        BM25 b parameter (default: 0.4).
    RRF_K : int, optional
        RRF fusion K parameter (default: 60).
    USE_CUVS : str, optional
        Enable cuVS acceleration: "1", "true", or "yes" (default: "1").
    FAISS_PRELOAD : str, optional
        Pre-load FAISS index at startup: "1", "true", or "yes" (default: "0").
        When enabled, startup takes 2-10 seconds longer but first request is faster.
    MAX_RESULTS : int, optional
        Maximum results per query (default: 1000).
    QUERY_TIMEOUT_S : float, optional
        Query timeout in seconds (default: 30.0).
    RATE_LIMIT_QPS : float, optional
        Rate limit queries per second (default: 10.0).
    RATE_LIMIT_BURST : int, optional
        Rate limit burst capacity (default: 20).
    """
    repo_root = os.environ.get("REPO_ROOT", str(Path.cwd()))

    vllm = VLLMConfig(
        base_url=os.environ.get("VLLM_URL", "http://127.0.0.1:8001/v1"),
        model=os.environ.get("VLLM_MODEL", "nomic-ai/nomic-embed-code"),
        batch_size=int(os.environ.get("VLLM_BATCH_SIZE", "64")),
        timeout_s=float(os.environ.get("VLLM_TIMEOUT_S", "120.0")),
    )

    paths = PathsConfig(
        repo_root=repo_root,
        data_dir=os.environ.get("DATA_DIR", "data"),
        vectors_dir=os.environ.get("VECTORS_DIR", "data/vectors"),
        faiss_index=os.environ.get("FAISS_INDEX", "data/faiss/code.ivfpq.faiss"),
        lucene_dir=os.environ.get("LUCENE_DIR", "data/lucene"),
        splade_dir=os.environ.get("SPLADE_DIR", "data/splade"),
        duckdb_path=os.environ.get("DUCKDB_PATH", "data/catalog.duckdb"),
        scip_index=os.environ.get("SCIP_INDEX", "index.scip"),
    )

    index = IndexConfig(
        vec_dim=int(os.environ.get("VEC_DIM", "2560")),
        chunk_budget=int(os.environ.get("CHUNK_BUDGET", "2200")),
        faiss_nlist=int(os.environ.get("FAISS_NLIST", "8192")),
        faiss_nprobe=int(os.environ.get("FAISS_NPROBE", "128")),
        bm25_k1=float(os.environ.get("BM25_K1", "0.9")),
        bm25_b=float(os.environ.get("BM25_B", "0.4")),
        rrf_k=int(os.environ.get("RRF_K", "60")),
        use_cuvs=os.environ.get("USE_CUVS", "1").lower() in {"1", "true", "yes"},
        faiss_preload=os.environ.get("FAISS_PRELOAD", "0").lower() in {"1", "true", "yes"},
    )

    limits = ServerLimits(
        max_results=int(os.environ.get("MAX_RESULTS", "1000")),
        query_timeout_s=float(os.environ.get("QUERY_TIMEOUT_S", "30.0")),
        rate_limit_qps=float(os.environ.get("RATE_LIMIT_QPS", "10.0")),
        rate_limit_burst=int(os.environ.get("RATE_LIMIT_BURST", "20")),
    )

    return Settings(vllm=vllm, paths=paths, index=index, limits=limits)


__all__ = [
    "IndexConfig",
    "PathsConfig",
    "ServerLimits",
    "Settings",
    "VLLMConfig",
    "load_settings",
]
