src.kgfoundry_common.parquet_io
===============================

.. py:module:: src.kgfoundry_common.parquet_io

.. autoapi-nested-parse::

   Module for kgfoundry_common.parquet_io.

   NavMap:
   - NavMap: Structure describing a module navmap.
   - ParquetVectorWriter: Persist embedding vectors into partitioned Parquet datasets.
   - ParquetChunkWriter: Persist chunk metadata and text into Parquet files.





Module Contents
---------------

.. py:class:: ParquetVectorWriter(root)

   Persist embedding vectors into partitioned Parquet datasets.


   .. py:method:: dense_schema(dim)
      :staticmethod:


      Return the schema used for dense embedding Parquet files.

      :param dim: Number of dimensions in each dense vector.
      :type dim: int

      :returns: Arrow schema describing the dense vector rows.
      :rtype: pa.schema



   .. py:attribute:: root


   .. py:method:: write_dense(model, run_id, dim, records, shard = 0)

      Write dense embedding vectors to a Parquet shard.

      :param model: Identifier for the embedding model.
      :type model: str
      :param run_id: Identifier for the batch or run that produced the embeddings.
      :type run_id: str
      :param dim: Number of dimensions in the embedding vectors.
      :type dim: int
      :param records: Sequence of ``(chunk_id, vector, l2_norm)`` rows.
      :type records: Iterable[tuple[str, list[float], float]]
      :param shard: Shard partition to write, defaults to ``0``.
      :type shard: int, optional

      :returns: Root directory path as a string.
      :rtype: str



   .. py:method:: splade_schema()
      :staticmethod:


      Return the schema used for SPLADE sparse vector Parquet files.

      :returns: Arrow schema describing sparse vocab ids and weights.
      :rtype: pa.schema



   .. py:method:: write_splade(model, run_id, records, shard = 0)

      Write SPLADE sparse vector data to a Parquet shard.

      :param model: Identifier for the sparse embedding model.
      :type model: str
      :param run_id: Identifier for the batch or run that produced the embeddings.
      :type run_id: str
      :param records: Sequence of ``(chunk_id, vocab_ids, weights)`` rows.
      :type records: Iterable[tuple[str, list[int], list[float]]]
      :param shard: Shard partition to write, defaults to ``0``.
      :type shard: int, optional

      :returns: Root directory path as a string.
      :rtype: str



.. py:class:: ParquetChunkWriter(root, model = 'docling_hybrid', run_id = 'dev')

   Persist chunk metadata and text into Parquet files.


   .. py:method:: chunk_schema()
      :staticmethod:


      Return the schema describing chunk metadata rows.

      :returns: Arrow schema describing chunk metadata and text columns.
      :rtype: pa.schema



   .. py:attribute:: root


   .. py:method:: write(rows)

      Write chunk rows to Parquet and return the run directory.

      :param rows: Sequence of dictionaries matching :meth:`chunk_schema`.
      :type rows: Iterable[dict[str, Any]]

      :returns: Path (as string) to the containing run directory.
      :rtype: str



