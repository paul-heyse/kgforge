
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>Updated cuVS Addendum - KGForge</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.84d31ad4.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#updated-cuvs-addendum" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="KGForge" class="md-header__button md-logo" aria-label="KGForge" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            KGForge
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Updated cuVS Addendum
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="KGForge" class="md-nav__button md-logo" aria-label="KGForge" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    KGForge
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
          
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../how-to/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Guides
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Getting Started
    
  </span>
  

      </a>
    </li>
  

              
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Explanations
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Architecture
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    API
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-revised-capability-matrix-this-wheel" class="md-nav__link">
    <span class="md-ellipsis">
      1) Revised capability matrix (this wheel)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-how-to-enable-cuvs-reliable-patterns" class="md-nav__link">
    <span class="md-ellipsis">
      2) How to enable cuVS (reliable patterns)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2) How to enable cuVS (reliable patterns)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-oneline-preload-cuvsrapids-libs" class="md-nav__link">
    <span class="md-ellipsis">
      2.1. One‑line preload (cuVS/RAPIDS libs)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-enabling-cuvs-via-gpu-cloner-options-recommended" class="md-nav__link">
    <span class="md-ellipsis">
      2.2. Enabling cuVS via GPU Cloner Options (recommended)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-enabling-cuvs-via-index-configs-direct-gpu-constructors" class="md-nav__link">
    <span class="md-ellipsis">
      2.3. Enabling cuVS via index configs (direct GPU constructors)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24-enabling-cuvs-for-direct-gpu-bruteforce-knn" class="md-nav__link">
    <span class="md-ellipsis">
      2.4. Enabling cuVS for direct GPU brute‑force kNN
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-minimal-correct-by-construction-recipes-per-family" class="md-nav__link">
    <span class="md-ellipsis">
      3) Minimal “correct by construction” recipes per family
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3) Minimal “correct by construction” recipes per family">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-ivfpq-opq64ivf8192pq64-with-cuvs" class="md-nav__link">
    <span class="md-ellipsis">
      3.1. IVF‑PQ (OPQ64,IVF8192,PQ64) with cuVS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-ivfflat-with-cuvs" class="md-nav__link">
    <span class="md-ellipsis">
      3.2. IVF‑Flat with cuVS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-flat-exact-with-cuvs" class="md-nav__link">
    <span class="md-ellipsis">
      3.3. Flat (exact) with cuVS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-cagra-with-cuvs" class="md-nav__link">
    <span class="md-ellipsis">
      3.4. CAGRA with cuVS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-binarycagra-with-cuvs" class="md-nav__link">
    <span class="md-ellipsis">
      3.5. Binary‑CAGRA with cuVS
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-filters-selectors-what-those-cuvsfilter-objects-mean-for-you" class="md-nav__link">
    <span class="md-ellipsis">
      4) Filters &amp; selectors (what those CuvsFilter* objects mean for you)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-operational-reminders-unchanged-but-critical" class="md-nav__link">
    <span class="md-ellipsis">
      5) Operational reminders (unchanged but critical)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-quick-am-i-using-cuvs-right-now-probes" class="md-nav__link">
    <span class="md-ellipsis">
      6) Quick “am I using cuVS right now?” probes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6) Quick “am I using cuVS right now?” probes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pointers-unchanged" class="md-nav__link">
    <span class="md-ellipsis">
      Pointers (unchanged)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-bottom-line-what-to-change-in-your-code" class="md-nav__link">
    <span class="md-ellipsis">
      7) Bottom line (what to change in your code)
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="updated-cuvs-addendum">Updated cuVS Addendum</h1>
<p>Below is an <strong>updated, implementation‑grade addendum</strong> that reflects your <strong>new FAISS wheel</strong> with <strong>cuVS integration compiled for</strong>: <strong>Flat</strong>, <strong>IVF‑Flat</strong>, <strong>IVF‑PQ</strong>, <strong>Graph CAGRA</strong>, and <strong>Binary‑CAGRA</strong>, as indicated by the build artifacts:</p>
<pre><code>CuvsFlatIndex.cu.o
CuvsIVFFlat.cu.o
CuvsIVFPQ.cu.o
CuvsCagra.cu.o
BinaryCuvsCagra.cu.o
utils/CuvsFilterConvert.cu.o
utils/CuvsUtils.cu.o
</code></pre>
<blockquote>
<p><strong>Key consequence:</strong> In this wheel, <strong>FAISS GPU indexes can dispatch to cuVS kernels</strong> for the families above when you <strong>enable cuVS</strong> at construction/cloning time and the <strong>cuVS/RAPIDS libraries are present</strong> in the process. The runtime loader &amp; resource rules for cuVS remain the same (preload <code>libcuvs</code>, <code>librmm</code>, logging; use a shared <code>Resources</code> handle if calling cuVS directly).  </p>
</blockquote>
<hr />
<h2 id="1-revised-capability-matrix-this-wheel">1) Revised capability matrix (this wheel)</h2>
<table>
<thead>
<tr>
<th>Family / class</th>
<th style="text-align: right;">CPU</th>
<th style="text-align: right;">GPU (FAISS kernels)</th>
<th style="text-align: right;"><strong>cuVS through FAISS (this wheel)</strong></th>
<th style="text-align: right;"><strong>cuVS direct (Python)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Flat (exact)</strong></td>
<td style="text-align: right;">✅ <code>IndexFlat{L2,IP}</code></td>
<td style="text-align: right;">✅ <code>GpuIndexFlat{L2,IP}</code></td>
<td style="text-align: right;">✅ via <strong>index‑level cuVS</strong> (<code>GpuIndexFlat{L2,IP}</code> with <code>use_cuvs</code>) and via <strong>bfKNN</strong> (<code>knn_gpu/bfKnn</code> with <code>use_cuvs</code>)</td>
<td style="text-align: right;">✅ <code>cuvs.neighbors.brute_force</code></td>
</tr>
<tr>
<td><strong>IVF‑Flat</strong></td>
<td style="text-align: right;">✅</td>
<td style="text-align: right;">✅ <code>GpuIndexIVFFlat</code></td>
<td style="text-align: right;">✅ <strong>index‑level cuVS</strong> (<code>GpuIndexIVFFlat</code> with <code>use_cuvs</code>)</td>
<td style="text-align: right;">✅ <code>cuvs.neighbors.ivf_flat</code></td>
</tr>
<tr>
<td><strong>IVF‑PQ</strong></td>
<td style="text-align: right;">✅</td>
<td style="text-align: right;">✅ <code>GpuIndexIVFPQ</code></td>
<td style="text-align: right;">✅ <strong>index‑level cuVS</strong> (<code>GpuIndexIVFPQ</code> with <code>use_cuvs</code>)</td>
<td style="text-align: right;">✅ <code>cuvs.neighbors.ivf_pq</code></td>
</tr>
<tr>
<td><strong>IVF‑SQ</strong></td>
<td style="text-align: right;">✅</td>
<td style="text-align: right;">✅ <code>GpuIndexIVFScalarQuantizer</code></td>
<td style="text-align: right;">– (no cuVS kernel here)</td>
<td style="text-align: right;">–</td>
</tr>
<tr>
<td><strong>Graph (HNSW)</strong></td>
<td style="text-align: right;">✅</td>
<td style="text-align: right;">–</td>
<td style="text-align: right;">–</td>
<td style="text-align: right;">✅ <code>cuvs.neighbors.hnsw</code></td>
</tr>
<tr>
<td><strong>Graph (CAGRA)</strong></td>
<td style="text-align: right;">✅ <code>IndexHNSWCagra</code></td>
<td style="text-align: right;">✅ <code>GpuIndexCagra</code></td>
<td style="text-align: right;">✅ <strong>index‑level cuVS</strong> (<code>GpuIndexCagra</code> with <code>use_cuvs</code>)</td>
<td style="text-align: right;">✅ <code>cuvs.neighbors.cagra</code> (+ multi‑GPU)</td>
</tr>
<tr>
<td><strong>Binary</strong></td>
<td style="text-align: right;">✅</td>
<td style="text-align: right;">✅ <code>GpuIndexBinaryFlat</code>, <code>GpuIndexBinaryCagra</code></td>
<td style="text-align: right;">✅ <strong>Binary‑CAGRA</strong> via <strong>index‑level cuVS</strong> (<code>GpuIndexBinaryCagra</code>)</td>
<td style="text-align: right;">–</td>
</tr>
<tr>
<td><strong>Direct bfKNN</strong></td>
<td style="text-align: right;">–</td>
<td style="text-align: right;">✅ <code>bfKnn(...)</code> / <code>knn_gpu(...)</code></td>
<td style="text-align: right;">✅ <strong>set <code>use_cuvs=True</code></strong> (guard with <code>should_use_cuvs(...)</code>)</td>
<td style="text-align: right;">✅ <code>cuvs.distance</code> / brute_force</td>
</tr>
</tbody>
</table>
<p><strong>What changed:</strong> In earlier guidance, IVF‑Flat/IVF‑PQ/CAGRA/Binary‑CAGRA were marked “not via FAISS route”. In <strong>this</strong> wheel, those families <strong>are</strong> cuVS‑enabled inside FAISS when you opt in via the <strong>index configs</strong> or <strong>GPU cloner options</strong> described below (and cuVS libs are present). The bfKNN cuVS path remains available. The cuVS loader &amp; environment remain as documented. </p>
<hr />
<h2 id="2-how-to-enable-cuvs-reliable-patterns">2) How to enable cuVS (reliable patterns)</h2>
<h3 id="21-oneline-preload-cuvsrapids-libs">2.1. One‑line preload (cuVS/RAPIDS libs)</h3>
<p>Call this <strong>before</strong> importing/initializing FAISS to ensure the shared libraries are resident:</p>
<pre><code class="language-python">from libcuvs import load_library
load_library()  # loads libcuvs, librmm, rapids_logger; idempotent
</code></pre>
<p>This follows the integration guidance in your loader reference and prevents <code>OSError: libcuvs_c.so not found</code> surprises. </p>
<hr />
<h3 id="22-enabling-cuvs-via-gpu-cloner-options-recommended">2.2. Enabling cuVS via <strong>GPU Cloner Options</strong> (recommended)</h3>
<p>The simplest and most portable way to engage cuVS for <strong>Flat / IVF‑Flat / IVF‑PQ / CAGRA / Binary‑CAGRA</strong> is to <strong>build the index on CPU</strong>, then <strong>clone to GPU</strong> with a cuVS‑aware cloner:</p>
<pre><code class="language-python">import faiss

# 1) Build a CPU index (examples below)
cpu_index = faiss.index_factory(d, &quot;OPQ64,IVF8192,PQ64&quot;, faiss.METRIC_INNER_PRODUCT)
cpu_index.train(train_vectors)

# 2) Prepare GPU resources
res = faiss.StandardGpuResources()

# 3) Clone with cuVS enabled (guarded)
co = faiss.GpuClonerOptions()
co.use_cuvs = True  # ask for cuVS kernels if available

try:
    gpu_index = faiss.index_cpu_to_gpu(res, 0, cpu_index, co)
except RuntimeError:
    # Fallback if cuVS cannot be used for this combo
    co.use_cuvs = False
    gpu_index = faiss.index_cpu_to_gpu(res, 0, cpu_index, co)
</code></pre>
<ul>
<li><code>GpuClonerOptions.use_cuvs</code> is exposed in this wheel and directs FAISS to build the <strong>cuVS‑backed</strong> GPU index when possible. </li>
<li>This pattern works uniformly across Flat / IVF‑Flat / IVF‑PQ and also covers <strong>CAGRA</strong> if cloning from <code>IndexHNSWCagra</code> to <code>GpuIndexCagra</code> is desired. (You can also build <code>GpuIndexCagra</code> directly; see 2.3.)</li>
<li>Keep your <strong>existing memory tuning</strong> (<code>setTempMemory</code>, <code>setPinnedMemory</code>) for throughput.</li>
</ul>
<blockquote>
<p>You can also probe <code>faiss.should_use_cuvs(...)</code> before setting the flag; however, the <strong>try/except</strong> is the most robust guard when combining drivers, cards, and dims. </p>
</blockquote>
<hr />
<h3 id="23-enabling-cuvs-via-index-configs-direct-gpu-constructors">2.3. Enabling cuVS via <strong>index configs</strong> (direct GPU constructors)</h3>
<p>When you <strong>construct GPU indexes directly</strong>, pass a config whose base type is <code>GpuIndexConfig</code> and set <code>use_cuvs</code> there (the property is inherited by specific configs):</p>
<pre><code class="language-python"># Flat
flat_cfg = faiss.GpuIndexFlatConfig()
flat_cfg.use_cuvs = True
gpu_flat = faiss.GpuIndexFlatIP(res, d, flat_cfg)  # or GpuIndexFlatL2

# IVF-FLAT / IVF-PQ
ivf_cfg = faiss.GpuIndexIVFConfig()
ivf_cfg.use_cuvs = True
# ... pass ivf_cfg to the appropriate GpuIndexIVF* constructor

# CAGRA
cagra_cfg = faiss.GpuIndexCagraConfig()
cagra_cfg.use_cuvs = True
gpu_cagra = faiss.GpuIndexCagra(res, d, cagra_cfg)

# Binary-CAGRA (if you build it directly)
# (config class may not be separate in the API; prefer the cloner path if unsure)
</code></pre>
<p>These configs inherit <code>use_cuvs</code> through <code>GpuIndexConfig</code> in this wheel. Use the cloner option (2.2) when you want one code path that works across all index types. </p>
<hr />
<h3 id="24-enabling-cuvs-for-direct-gpu-bruteforce-knn">2.4. Enabling cuVS for <strong>direct GPU brute‑force kNN</strong></h3>
<p>The <strong>bfKNN</strong> path can independently dispatch to cuVS kernels:</p>
<pre><code class="language-python">from faiss import StandardGpuResources, METRIC_INNER_PRODUCT, GpuDistanceParams, knn_gpu

res = StandardGpuResources()
params = GpuDistanceParams(); params.metric = METRIC_INNER_PRODUCT; params.k = 10; params.dims = d

# guard with should_use_cuvs; fallback is automatic inside knn_gpu if you pass False
use_cuvs = True  # or: bool(faiss.should_use_cuvs(params))
D, I = knn_gpu(res, xq.astype('float32'), xb.astype('float32'),
               k=10, metric=METRIC_INNER_PRODUCT, use_cuvs=use_cuvs)
</code></pre>
<p>This remains a great baseline even when your main serving index is IVF‑PQ/CAGRA. </p>
<hr />
<h2 id="3-minimal-correct-by-construction-recipes-per-family">3) Minimal “correct by construction” recipes per family</h2>
<blockquote>
<p>These patterns <strong>train on CPU</strong> (deterministic), then <strong>clone to GPU with cuVS</strong>. You can switch to direct GPU construction later; the recall/latency behavior is identical once cuVS is engaged.</p>
</blockquote>
<h3 id="31-ivfpq-opq64ivf8192pq64-with-cuvs">3.1. <strong>IVF‑PQ (OPQ64,IVF8192,PQ64)</strong> with cuVS</h3>
<pre><code class="language-python">import faiss, numpy as np

d = 2560
cpu = faiss.index_factory(d, &quot;OPQ64,IVF8192,PQ64&quot;, faiss.METRIC_INNER_PRODUCT)

train = np.random.randn(10_000_000, d).astype('float32')
faiss.normalize_L2(train)
cpu.train(train)

res = faiss.StandardGpuResources()
co = faiss.GpuClonerOptions(); co.use_cuvs = True
gpu = faiss.index_cpu_to_gpu(res, 0, cpu, co)  # cuVS-backed IVFPQ

# add/search as usual
</code></pre>
<ul>
<li>Keeps your default “best‑in‑class” factory and determinism.</li>
<li>The <strong>cloner</strong> chooses the cuVS implementation for the data path compiled in this wheel. </li>
</ul>
<h3 id="32-ivfflat-with-cuvs">3.2. <strong>IVF‑Flat</strong> with cuVS</h3>
<pre><code class="language-python">cpu = faiss.index_factory(d, &quot;IVF8192,Flat&quot;, faiss.METRIC_INNER_PRODUCT)
cpu.train(train)

co = faiss.GpuClonerOptions(); co.use_cuvs = True
gpu = faiss.index_cpu_to_gpu(res, 0, cpu, co)  # cuVS-backed IVFFlat
</code></pre>
<h3 id="33-flat-exact-with-cuvs">3.3. <strong>Flat (exact)</strong> with cuVS</h3>
<ul>
<li><strong>Index route:</strong> <code>GpuIndexFlat{L2,IP}</code> with <code>GpuIndexFlatConfig.use_cuvs = True</code>.</li>
<li><strong>Direct KNN:</strong> <code>knn_gpu(..., use_cuvs=True)</code> (guarded). </li>
</ul>
<h3 id="34-cagra-with-cuvs">3.4. <strong>CAGRA</strong> with cuVS</h3>
<ul>
<li><strong>Direct GPU build</strong> (graph lives on GPU):</li>
</ul>
<p><code>python
  cfg = faiss.GpuIndexCagraConfig(); cfg.use_cuvs = True
  gpu_cagra = faiss.GpuIndexCagra(res, d, cfg)
  # gpu_cagra.add(n, xb) builds the graph; search as usual</code></p>
<ul>
<li><strong>CPU↔GPU interop:</strong> <code>IndexHNSWCagra</code> exists on CPU for moving graph structure if needed (e.g., copy base level). Keep primary serving on GPU to avoid host &lt;-&gt; device hops.</li>
</ul>
<h3 id="35-binarycagra-with-cuvs">3.5. <strong>Binary‑CAGRA</strong> with cuVS</h3>
<ul>
<li>Prefer the <strong>cloner path</strong> when coming from CPU binary indexes; if you instantiate <code>GpuIndexBinaryCagra</code> directly, keep the same principle: construct with a config that enables cuVS (or clone with <code>GpuClonerOptions.use_cuvs=True</code>) and fall back on error.</li>
</ul>
<hr />
<h2 id="4-filters-selectors-what-those-cuvsfilter-objects-mean-for-you">4) Filters &amp; selectors (what those <code>CuvsFilter*</code> objects mean for you)</h2>
<p>The presence of <code>utils/CuvsFilterConvert.cu.o</code> indicates FAISS performs <strong>selector/bitset conversion</strong> into cuVS‑compatible filter representations when a filter is passed at search time (e.g., via <code>SearchParametersIVF.sel</code> / ID selectors). You do not need to change your Python calls:</p>
<ul>
<li>Keep using FAISS’ <strong>search parameters</strong> (e.g., <code>SearchParametersIVF</code>’s selector).</li>
<li>When the index was constructed/cloned with <strong><code>use_cuvs=True</code></strong>, the FAISS runtime converts the filter to cuVS’ internal format and applies it during list scans.</li>
</ul>
<p>This is transparent but worth noting for <strong>filtered search</strong> scenarios. (The general cuVS run‑time and loader expectations remain exactly as previously documented.) </p>
<hr />
<h2 id="5-operational-reminders-unchanged-but-critical">5) Operational reminders (unchanged but critical)</h2>
<ul>
<li><strong>Preload cuVS</strong> once per process (<code>libcuvs.load_library()</code>), so <strong>RMM</strong> and logging are initialized and all <code>.so</code> dependencies are resident. </li>
<li>Stick to <strong>row‑major <code>float32</code></strong> contiguous arrays for FAISS; normalize vectors for cosine (IP).</li>
<li>Keep GPU working set <strong>≤ ~80% VRAM</strong>; pre‑allocate <strong>temp</strong> and <strong>pinned</strong> memory on <code>StandardGpuResources</code>.</li>
<li>For <strong>cuVS direct</strong> experimentation (IVF‑PQ, IVF‑Flat, CAGRA, HNSW, multi‑GPU), continue to use the Python surfaces under <code>cuvs.neighbors.*</code> with a shared <code>Resources</code> handle and device arrays, as documented in your cuVS reference. </li>
</ul>
<hr />
<h2 id="6-quick-am-i-using-cuvs-right-now-probes">6) Quick “am I using cuVS right now?” probes</h2>
<pre><code class="language-python"># After calling libcuvs.load_library() and constructing your GPU index:

import faiss

# 1) For bfKNN:
p = faiss.GpuDistanceParams(); p.k=10; p.dims=d; p.metric=faiss.METRIC_INNER_PRODUCT
print(&quot;bfKNN should_use_cuvs:&quot;, faiss.should_use_cuvs(p))  # True → bfKNN will route to cuVS

# 2) For an index you plan to build:
cfg = faiss.GpuIndexIVFConfig()
print(&quot;Index should_use_cuvs:&quot;, faiss.should_use_cuvs(cfg))  # True → set cfg/co.use_cuvs = True
</code></pre>
<ul>
<li>If you skip <code>should_use_cuvs</code>, simply <strong>set <code>use_cuvs=True</code></strong> and <strong>catch</strong> a <code>RuntimeError</code> on construction; re‑try with <code>False</code>. This keeps your code robust across environments while <strong>preferring cuVS</strong> whenever available. </li>
</ul>
<hr />
<h3 id="pointers-unchanged">Pointers (unchanged)</h3>
<ul>
<li><strong>cuVS API &amp; usage</strong> (neighbors, distance, resources, device arrays) — your cuVS reference. </li>
<li><strong>cuVS loader &amp; environment</strong> (preload order, env vars, system vs wheel libs) — libcuvs loader reference. </li>
<li><strong>System architecture &amp; defaults</strong> (2560‑d, OPQ64/IVF8192/PQ64, persistence, observability) — high‑level architecture. </li>
</ul>
<hr />
<h2 id="7-bottom-line-what-to-change-in-your-code">7) Bottom line (what to change in your code)</h2>
<ol>
<li><strong>Call</strong> <code>load_library()</code> <strong>once at startup</strong>. </li>
<li><strong>When cloning</strong> CPU→GPU, set <code>co.use_cuvs = True</code> and <strong>fall back</strong> on error. This now enables cuVS for <strong>Flat</strong>, <strong>IVF‑Flat</strong>, <strong>IVF‑PQ</strong>, <strong>CAGRA</strong>, and <strong>Binary‑CAGRA</strong> in this build.</li>
<li><strong>When constructing GPU indexes directly</strong>, set <code>cfg.use_cuvs = True</code> on the appropriate <strong><code>GpuIndex*Config</code></strong> (or use the cloner).</li>
<li>For <strong>bfKNN</strong>, pass <code>use_cuvs=True</code> (or guard with <code>should_use_cuvs</code>). </li>
<li>Keep the rest of the pipeline (factory string, normalization, memory planning, multi‑GPU strategy, persistence) <strong>unchanged</strong>. </li>
</ol>
<h1 id="addendum-base-content-on-faiss-gpu-library">addendum, base content on faiss gpu library</h1>
<hr />
<h2 id="0-what-changed-vs-the-prior-wheel-and-how-to-think-about-it">0) What changed vs. the prior wheel (and how to think about it)</h2>
<p><strong>Hardware/ABI</strong></p>
<ul>
<li>CUDA runtime linked: <strong><code>libcudart.so.13</code></strong> → the wheel targets <strong>CUDA 13</strong> (Blackwell‑ready).</li>
<li>GPU arch: <strong><code>sm_120</code> SASS + PTX</strong> (“<strong><code>sm_120‑virtual</code></strong>”) for forward compatibility—native kernels when they match, PTX JIT otherwise.</li>
</ul>
<p><strong>cuVS inside FAISS (this wheel)</strong></p>
<ul>
<li>The GPU SWIG layer exports <strong><code>use_cuvs</code> gates on index configs and cloner options</strong> and dynamically links against cuVS/RAPIDS libs. With cuVS libraries <strong>preloaded</strong>, FAISS GPU indexes can route to <strong>cuVS kernels</strong> for <strong>Flat, IVF‑Flat, IVF‑PQ, CAGRA, Binary‑CAGRA</strong>; otherwise FAISS falls back to its own kernels. </li>
</ul>
<blockquote>
<p><strong>Reminder</strong>: the kernels themselves live in the <strong>cuVS</strong> shared libraries; the FAISS wheel holds <strong>dispatch hooks</strong> and dynamic links. Ensure the cuVS loader is invoked at process start. </p>
</blockquote>
<hr />
<h2 id="1-cpu-vs-gpu-vs-cuvs-updated-capability-map-this-wheel">1) CPU vs GPU vs cuVS — updated capability map (this wheel)</h2>
<table>
<thead>
<tr>
<th>Family / class</th>
<th style="text-align: right;">CPU</th>
<th style="text-align: right;">GPU (FAISS kernels)</th>
<th style="text-align: right;"><strong>cuVS through FAISS</strong> (this wheel)</th>
<th style="text-align: right;"><strong>cuVS direct (Python)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Flat (exact)</strong></td>
<td style="text-align: right;">✅ <code>IndexFlat{L2,IP}</code></td>
<td style="text-align: right;">✅ <code>GpuIndexFlat{L2,IP}</code></td>
<td style="text-align: right;">✅ via <strong>index‑level <code>use_cuvs</code></strong> on <code>GpuIndexFlat*</code> and via <strong>bfKNN</strong> (<code>knn_gpu/bfKnn</code> <code>use_cuvs</code>)</td>
<td style="text-align: right;">✅ <code>cuvs.neighbors.brute_force</code></td>
</tr>
<tr>
<td><strong>IVF‑Flat</strong></td>
<td style="text-align: right;">✅</td>
<td style="text-align: right;">✅ <code>GpuIndexIVFFlat</code></td>
<td style="text-align: right;">✅ via <strong>index‑level <code>use_cuvs</code></strong> / GPU cloner</td>
<td style="text-align: right;">✅ <code>cuvs.neighbors.ivf_flat</code></td>
</tr>
<tr>
<td><strong>IVF‑PQ</strong></td>
<td style="text-align: right;">✅</td>
<td style="text-align: right;">✅ <code>GpuIndexIVFPQ</code></td>
<td style="text-align: right;">✅ via <strong>index‑level <code>use_cuvs</code></strong> / GPU cloner</td>
<td style="text-align: right;">✅ <code>cuvs.neighbors.ivf_pq</code></td>
</tr>
<tr>
<td><strong>IVF‑SQ</strong></td>
<td style="text-align: right;">✅</td>
<td style="text-align: right;">✅ <code>GpuIndexIVFScalarQuantizer</code></td>
<td style="text-align: right;">– (no cuVS path)</td>
<td style="text-align: right;">–</td>
</tr>
<tr>
<td><strong>Graph (HNSW)</strong></td>
<td style="text-align: right;">✅</td>
<td style="text-align: right;">–</td>
<td style="text-align: right;">–</td>
<td style="text-align: right;">✅ <code>cuvs.neighbors.hnsw</code></td>
</tr>
<tr>
<td><strong>Graph (CAGRA)</strong></td>
<td style="text-align: right;">✅ <code>IndexHNSWCagra</code></td>
<td style="text-align: right;">✅ <code>GpuIndexCagra</code></td>
<td style="text-align: right;">✅ via <strong>index‑level <code>use_cuvs</code></strong></td>
<td style="text-align: right;">✅ <code>cuvs.neighbors.cagra</code> (+ multi‑GPU)</td>
</tr>
<tr>
<td><strong>Binary</strong></td>
<td style="text-align: right;">✅</td>
<td style="text-align: right;">✅ <code>GpuIndexBinaryFlat</code>, <code>GpuIndexBinaryCagra</code></td>
<td style="text-align: right;">✅ <strong>Binary‑CAGRA</strong> via index‑level <code>use_cuvs</code></td>
<td style="text-align: right;">–</td>
</tr>
<tr>
<td><strong>Direct bfKNN</strong></td>
<td style="text-align: right;">–</td>
<td style="text-align: right;">✅ <code>bfKnn(...)</code> / <code>knn_gpu(...)</code></td>
<td style="text-align: right;">✅ <strong><code>use_cuvs=True</code></strong> (guard with <code>should_use_cuvs</code>)</td>
<td style="text-align: right;">✅ <code>cuvs.distance</code> / brute_force</td>
</tr>
</tbody>
</table>
<p><strong>Filters &amp; selectors:</strong> your build includes <code>CuvsFilterConvert.cu.o</code>; FAISS will convert FAISS selectors/bitsets into cuVS’ filter format automatically when the index was created with <code>use_cuvs=True</code>. You keep using standard FAISS search params at the Python layer. </p>
<hr />
<h2 id="2-blackwell-rtx-5090-support-sass-sm_120-ptx-sm_120virtual">2) Blackwell (RTX 5090) support: SASS <strong><code>sm_120</code></strong> + PTX <strong><code>sm_120‑virtual</code></strong></h2>
<ul>
<li><strong>Why it matters</strong>: perfect performance when SASS matches; <strong>PTX fallback</strong> when driver/toolkit moves ahead (no “no kernel image” errors).</li>
<li><strong>Ops tips</strong>: leave <code>CUDA_CACHE_MAXSIZE</code> roomy to avoid first‑run JIT thrash; never force JIT in production.</li>
</ul>
<hr />
<h2 id="3-cuvs-enablement-model-final-patterns">3) cuVS enablement model (final patterns)</h2>
<p><strong>Always preload cuVS/RAPIDS libs before FAISS</strong>:</p>
<pre><code class="language-python">from libcuvs import load_library
load_library()  # loads libcuvs, librmm, rapids_logger; idempotent. :contentReference[oaicite:12]{index=12}
</code></pre>
<p><strong>A) Index‑level enablement (recommended)</strong>
Set <strong><code>use_cuvs=True</code></strong> on the GPU cloner or GPU index config; <strong>catch &amp; fallback</strong>:</p>
<pre><code class="language-python">import faiss

# Clone CPU → GPU (works uniformly for Flat / IVF-Flat / IVF-PQ / CAGRA / Binary-CAGRA)
co = faiss.GpuClonerOptions(); co.use_cuvs = True
try:
    gpu_index = faiss.index_cpu_to_gpu(res, 0, cpu_index, co)
except RuntimeError:
    co.use_cuvs = False
    gpu_index = faiss.index_cpu_to_gpu(res, 0, cpu_index, co)
</code></pre>
<p>Or <strong>construct GPU indexes directly</strong> with a config inheriting <code>GpuIndexConfig.use_cuvs</code>:</p>
<pre><code class="language-python">flat_cfg = faiss.GpuIndexFlatConfig(); flat_cfg.use_cuvs = True
gpu_flat = faiss.GpuIndexFlatIP(res, d, flat_cfg)

ivf_cfg = faiss.GpuIndexIVFConfig(); ivf_cfg.use_cuvs = True
# pass ivf_cfg into the appropriate GpuIndexIVF* constructor

cagra_cfg = faiss.GpuIndexCagraConfig(); cagra_cfg.use_cuvs = True
gpu_cagra = faiss.GpuIndexCagra(res, d, cagra_cfg)
</code></pre>
<p><strong>B) Brute‑force KNN path</strong>
Guard <strong><code>use_cuvs</code></strong> with the central probe (falls back if not viable):</p>
<pre><code class="language-python">params = faiss.GpuDistanceParams(); params.dims=d; params.k=10; params.metric=faiss.METRIC_INNER_PRODUCT
use_cuvs = bool(faiss.should_use_cuvs(params))  # detects viability at runtime. :contentReference[oaicite:13]{index=13}
D, I = faiss.knn_gpu(res, xq.astype('float32'), xb.astype('float32'), 10,
                     metric=faiss.METRIC_INNER_PRODUCT, use_cuvs=use_cuvs)
</code></pre>
<p><strong>C) Direct cuVS ANN (optional)</strong>
Use cuVS Python APIs for IVF‑Flat/IVF‑PQ/CAGRA/HNSW (especially when you want multi‑GPU <code>mg.*</code> variants): <code>cuvs.neighbors.{ivf_flat, ivf_pq, cagra, hnsw}</code> with <code>Resources</code> handle and device arrays. </p>
<hr />
<h2 id="4-bestinclass-faiss-build-on-rtx-5090-cosine-2560d-now-with-cuvs-toggles">4) “Best‑in‑class” FAISS build on RTX 5090 (cosine, 2560‑d) — <strong>now with cuVS toggles</strong></h2>
<p><strong>Index choice</strong>: <code>OPQ64,IVF8192,PQ64</code> (cosine via L2 normalization + IP). <strong>Train</strong> on up to <strong>10 M</strong> samples (seed=42). <strong>Search</strong> with <code>nprobe=64</code>. </p>
<p><strong>GPU clone with cuVS</strong> (preferred path):</p>
<pre><code class="language-python">import faiss, numpy as np

d = 2560
cpu = faiss.index_factory(d, &quot;OPQ64,IVF8192,PQ64&quot;, faiss.METRIC_INNER_PRODUCT)
train = np.random.randn(10_000_000, d).astype('float32'); faiss.normalize_L2(train)
cpu.train(train)

res = faiss.StandardGpuResources()
res.setTempMemory(1_200_000_000); res.setPinnedMemory(512_000_000)

co = faiss.GpuClonerOptions(); co.use_cuvs = True
try:
    gpu = faiss.index_cpu_to_gpu(res, 0, cpu, co)  # cuVS-backed IVFPQ in this build
except RuntimeError:
    co.use_cuvs = False
    gpu = faiss.index_cpu_to_gpu(res, 0, cpu, co)

# add / search as usual
</code></pre>
<p><strong>Notes &amp; knobs</strong></p>
<ul>
<li>Precompute lookup tables on GPU if your PQ config benefits (via cloner/options); keep working set ≤ <strong>80%</strong> VRAM; reuse pinned host buffers for larger transfers. </li>
</ul>
<hr />
<h2 id="5-when-to-call-cuvs-directly-and-when-faisscuvs-is-enough">5) When to call cuVS directly (and when FAISS+cuVS is enough)</h2>
<ul>
<li><strong>Stay inside FAISS</strong> (with <code>use_cuvs=True</code>) for: <strong>Flat, IVF‑Flat, IVF‑PQ, CAGRA, Binary‑CAGRA</strong>; you get FAISS’ ergonomics and cuVS performance.</li>
<li><strong>Call cuVS directly</strong> when you need: <strong>multi‑GPU <code>mg.*</code></strong> pipelines, algorithm‑specific parameters not exposed by FAISS’ wrappers, or you want to co‑locate with other RAFT pipelines with explicit stream choreography. </li>
</ul>
<p><strong>Direct IVF‑PQ example (unchanged)</strong> — device arrays + <code>Resources</code>:</p>
<pre><code class="language-python">from cuvs.common import Resources
from cuvs.neighbors import ivf_pq
from pylibraft.common import device_ndarray
# build/search as in your prior example … :contentReference[oaicite:18]{index=18}
</code></pre>
<hr />
<h2 id="6-quick-api-map-what-youll-call-most-often">6) Quick API map — <strong>what you’ll call most often</strong></h2>
<p><strong>CPU</strong>
<code>IndexFlat{L2,IP}</code>, <code>IndexIVFFlat</code>, <code>IndexIVFPQ</code>, <code>IndexIVFScalarQuantizer</code>, <code>IndexHNSW*</code>, <code>IndexHNSWCagra</code>, <code>IndexBinary*</code>, <code>IndexPreTransform</code>, <code>OPQMatrix</code>, <code>PCAMatrix</code>, <code>IndexRefineFlat</code>, <code>IndexShards</code>, <code>IndexReplicas</code>.</p>
<p><strong>GPU (FAISS)</strong>
<code>StandardGpuResources</code>, <code>GpuIndexFlat{L2,IP}</code>, <code>GpuIndexIVFFlat</code>, <code>GpuIndexIVFPQ</code>, <code>GpuIndexIVFScalarQuantizer</code>, <code>GpuIndexCagra</code>, <code>GpuIndexBinaryFlat</code>, <code>GpuIndexBinaryCagra</code>, <code>index_cpu_to_gpu[_multiple]</code>, <code>index_gpu_to_cpu</code>, <code>GpuClonerOptions</code>, <code>GpuParameterSpace</code>, <code>knn_gpu(...)</code>, <code>bfKnn(...)</code>.</p>
<p><strong>cuVS hooks inside FAISS</strong>
<code>GpuClonerOptions.use_cuvs</code>, <code>GpuIndex*Config.use_cuvs</code>, <code>should_use_cuvs(...)</code> (for bfKNN probe), <code>knn_gpu(..., use_cuvs=...)</code>. </p>
<p><strong>cuVS (direct)</strong>
<code>cuvs.neighbors.{ivf_flat, ivf_pq, cagra, hnsw, brute_force, mg.*}</code>, <code>cuvs.cluster.kmeans</code>, <code>cuvs.distance.pairwise_distance</code>, <code>cuvs.common.Resources</code>. </p>
<hr />
<h2 id="7-validation-checklist-runtime">7) Validation checklist (runtime)</h2>
<ol>
<li><strong>Preload check</strong> (did we load the libraries?):</li>
</ol>
<pre><code class="language-python">from libcuvs import load_library
print([h._name for h in load_library()])  # expect libcuvs*, librmm, rapids_logger. :contentReference[oaicite:21]{index=21}
</code></pre>
<ol>
<li>
<p><strong>Index‑level cuVS</strong> (construction guard):</p>
</li>
<li>
<p>Clone/construct with <code>use_cuvs=True</code>. If it <strong>raises</strong>, retry with <code>False</code>. Log the final <code>use_cuvs</code> state per index.</p>
</li>
<li>
<p><strong>bfKNN cuVS probe</strong> (fast sanity):</p>
</li>
</ol>
<pre><code class="language-python">from faiss import GpuDistanceParams, should_use_cuvs, METRIC_INNER_PRODUCT
p = GpuDistanceParams(); p.metric = METRIC_INNER_PRODUCT; p.dims = 2560; p.k = 10
print(&quot;bfKNN should_use_cuvs:&quot;, should_use_cuvs(p))  # True =&gt; bfKNN will route to cuVS. :contentReference[oaicite:22]{index=22}
</code></pre>
<ol>
<li><strong>Direct cuVS smoke</strong> (IVF‑PQ or brute‑force) with device arrays + <code>Resources</code>. </li>
</ol>
<hr />
<h2 id="8-operational-guidance-unchanged-principles-cuvsaware">8) Operational guidance (unchanged principles, cuVS‑aware)</h2>
<ul>
<li><strong>Loader order</strong>: preload RAPIDS/cuVS first; then import FAISS. </li>
<li><strong>Memory</strong>: size <code>setTempMemory</code>/<code>setPinnedMemory</code> once; keep VRAM headroom ~<strong>20%</strong>; batch adds to avoid OOM; precompute tables where helpful. </li>
<li><strong>Streams</strong>: cuVS direct calls accept a <code>Resources</code> handle (shared stream) and only sync when you call <code>handle.sync()</code>. FAISS tends to sync at call boundaries; overlap I/O with compute using pinned buffers. </li>
<li><strong>Indexes at rest</strong>: save <strong>CPU</strong> index (<code>.faiss</code>) + <code>.ids</code>; rebuild GPU clones at startup (set <code>use_cuvs</code> again when cloning). </li>
</ul>
<hr />
<h2 id="9-readytopaste-helpers-with-cuvs-autoengage">9) Ready‑to‑paste helpers (with cuVS auto‑engage)</h2>
<p><strong>A. GPU clone (cuVS‑first, safe fallback)</strong></p>
<pre><code class="language-python">def to_gpu_cuvs_first(cpu_index, res, device=0):
    co = faiss.GpuClonerOptions(); co.use_cuvs = True
    try:
        return faiss.index_cpu_to_gpu(res, device, cpu_index, co), True
    except RuntimeError:
        co.use_cuvs = False
        return faiss.index_cpu_to_gpu(res, device, cpu_index, co), False
</code></pre>
<p><strong>B. bfKNN with automatic cuVS</strong></p>
<pre><code class="language-python">def knn_gpu_auto(res, xq_f32, xb_f32, k=10, metric=faiss.METRIC_INNER_PRODUCT):
    params = faiss.GpuDistanceParams()
    params.metric = metric; params.k = k; params.dims = xq_f32.shape[1]
    use = faiss.should_use_cuvs(params)  # True when viable. :contentReference[oaicite:28]{index=28}
    return faiss.knn_gpu(res, xq_f32.astype('float32', copy=False),
                         xb_f32.astype('float32', copy=False),
                         k, metric=metric, use_cuvs=use)
</code></pre>
<p><strong>C. Direct cuVS IVF‑PQ (device arrays)</strong> — unchanged. </p>
<hr />
<h2 id="10-bottom-line">10) Bottom line</h2>
<ul>
<li><strong>This wheel</strong>: Blackwell‑ready (<strong><code>sm_120</code> + PTX</strong>), CUDA‑13, and <strong>cuVS‑enabled</strong> inside FAISS for <strong>Flat, IVF‑Flat, IVF‑PQ, CAGRA, Binary‑CAGRA</strong>.</li>
<li><strong>Your code</strong>: preload cuVS; set <strong><code>use_cuvs=True</code></strong> on GPU clones/constructors; guard with try/except; use <code>should_use_cuvs(...)</code> for bfKNN.</li>
<li><strong>Architecture &amp; defaults</strong> (factory, training, persistence, multi‑GPU) remain per plan; you simply get <strong>cuVS speed paths</strong> where available without changing the higher‑level design. </li>
</ul>
<hr />
<h1 id="addendum-agentoriented-details-updated-to-match-the-new-cuvs-coverage">Addendum — Agent‑oriented details (updated to match the new cuVS coverage)</h1>
<p>These sections expand the “how” with concrete interfaces, schemas, and runbooks across the stack and already assume <strong>FAISS can route to cuVS</strong> for the families above.</p>
<h3 id="a1-process-bootstrap-deterministic-cuvsready">A1. Process bootstrap (deterministic &amp; cuVS‑ready)</h3>
<pre><code class="language-python">from libcuvs import load_library; load_library()   # ensures libcuvs/librmm/logging are loaded. :contentReference[oaicite:31]{index=31}
import faiss
res = faiss.StandardGpuResources()
res.setTempMemory(1_200_000_000); res.setPinnedMemory(512_000_000)
</code></pre>
<p>Keep a single <code>StandardGpuResources</code> per device for the process lifetime and configure it once. </p>
<h3 id="a2-zerocopy-interop-faiss-cuvs">A2. Zero‑copy interop (FAISS ↔ cuVS)</h3>
<p>Use RAFT <code>Resources</code> and device arrays when calling cuVS directly; prefer pinned host arenas + contiguous <code>float32</code> for FAISS inputs to minimize hidden copies. </p>
<h3 id="a3-multigpu-replicas-and-shards-unchanged">A3. Multi‑GPU: replicas and shards (unchanged)</h3>
<p>Use <code>IndexReplicas</code> (QPS) or <code>IndexShards</code> (capacity). When cloning to multiple GPUs, set <code>use_cuvs=True</code> on the cloner options once; FAISS will apply it per device (fallback per GPU on error). </p>
<h3 id="a4-memory-planning-batching">A4. Memory planning &amp; batching</h3>
<p>Budget <strong>scratch + PQ tables + codes + ids + batch</strong> ≤ <strong>80%</strong> VRAM. Tune batch add/search sizes empirically; precompute lookup tables where it helps latency. </p>
<h3 id="a5-persistence-registry">A5. Persistence &amp; registry</h3>
<p>Persist <strong>CPU</strong> index (<code>.faiss</code>) + <strong><code>.ids</code></strong>; rebuild GPU clones at service start using <code>use_cuvs=True</code>. Record the final <strong>applied</strong> state (<code>cuvs=true/false</code>) in your registry’s <code>faiss_indexes</code> rows for observability. </p>
<h3 id="a6-observability-probes">A6. Observability &amp; probes</h3>
<ul>
<li>Log <code>{gpu_id, nlist, m, nprobe, k, batch, temp_mem, pinned_mem, use_cuvs}</code> for each search; expose p50/p95/p99 histograms. </li>
<li>Quick “are the libs loaded?” probe: <code>list(h._name for h in load_library())</code>. </li>
<li>Quick “will bfKNN use cuVS?” probe: <code>should_use_cuvs(GpuDistanceParams(...))</code>. </li>
</ul>
<h3 id="a7-failure-taxonomy-fallbacks-gpu-paths">A7. Failure taxonomy &amp; fallbacks (GPU paths)</h3>
<ul>
<li><strong>Missing libs</strong> → run <code>load_library()</code> first (or fix <code>LD_LIBRARY_PATH</code>); <strong>resume</strong> with FAISS kernels if cuVS fails to initialize. </li>
<li><strong>OOM</strong> → halve batch; lower <code>setTempMemory</code>; retry twice; then quarantine batch. </li>
</ul>
<h3 id="a8-direct-cuvs-catalog-unchanged-surfaces">A8. Direct cuVS catalog (unchanged surfaces)</h3>
<p><code>cuvs.neighbors.{ivf_flat, ivf_pq, cagra, hnsw, brute_force, mg.*}</code>, <code>cuvs.cluster.kmeans</code>, <code>cuvs.distance.pairwise_distance</code>, <code>cuvs.common.Resources</code> — consistent <code>IndexParams</code>/<code>SearchParams</code>/<code>build</code>/<code>extend</code>/<code>save</code>/<code>load</code> patterns. </p>
<h3 id="a9-architecture-defaults-for-the-broader-system">A9. Architecture defaults (for the broader system)</h3>
<p>Keep the <strong>2560‑d</strong> embedder, chunking settings, Parquet schemas, DuckDB catalog/migrations, and hybrid retrieval pipeline exactly as specified in your architecture doc; nothing about the cuVS enablement changes those contracts. </p>
<hr />
<p>If you’d like, I can also output a <strong>drop‑in <code>vectorstore_faiss</code> module</strong> (Python package) that wraps the <strong>train/add/search/persist</strong> flow with <strong>cuVS‑first</strong> cloning and automatic bfKNN fallback, plus a tiny <strong>validator</strong> script that prints library load locations, shows <code>should_use_cuvs(...)</code>, and runs a 10k‑vector bfKNN smoke test on the RTX 5090.</p>
<p>Below is a <strong>comprehensive, example‑driven reference</strong> that fills in the remaining FAISS and cuVS Python surfaces we hadn’t previously shown with code. It’s organized so an agent can copy/paste snippets and understand shapes, params, edge‑cases, and performance notes. Where relevant, I point to the cuVS and loader docs you provided.   </p>
<hr />
<h2 id="a-faiss-cpuside-classes-utilities-with-examples">A) FAISS — CPU‑side classes &amp; utilities (with examples)</h2>
<h3 id="a1-indexidmap-indexidmap2-stable-ids-around-any-index">A1) <code>IndexIDMap</code> / <code>IndexIDMap2</code> — stable IDs around any index</h3>
<p><strong>Why:</strong> FAISS stores integer IDs; these wrappers let you control them.</p>
<pre><code class="language-python">import faiss, numpy as np

# Base ANN index (any type works)
d = 2560
base = faiss.index_factory(d, &quot;IVF8192,PQ64&quot;, faiss.METRIC_INNER_PRODUCT)

# Wrap with an ID map so we add our own 64-bit IDs
idmap = faiss.IndexIDMap2(base)

# Train as usual (on base)
train = np.random.randn(1_000_000, d).astype('float32'); faiss.normalize_L2(train)
idmap.train(train)

# Add vectors with application-specific IDs
xb = np.random.randn(500_000, d).astype('float32'); faiss.normalize_L2(xb)
ids = np.arange(100_000, 100_000 + xb.shape[0], dtype='int64')
idmap.add_with_ids(xb, ids)

# Search returns your IDs
xq = np.random.randn(1000, d).astype('float32'); faiss.normalize_L2(xq)
D, I = idmap.search(xq, k=10)
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>Use <code>IndexIDMap2</code> (64‑bit IDs) for large corpora.</li>
<li>Persist <strong>CPU</strong> form (see A6) and keep a parallel <code>.ids</code> copy if you ever unwrap the map. </li>
</ul>
<hr />
<h3 id="a2-indexrefineflat-refine-ann-hits-with-exact-scoring">A2) <code>IndexRefineFlat</code> — refine ANN hits with exact scoring</h3>
<p><strong>Why:</strong> Get IVF/graph latency with exact cosine/IP re‑ranking.</p>
<pre><code class="language-python"># Build a fast coarse index (e.g., IVF,PQ) then refine with Flat
coarse = faiss.index_factory(d, &quot;IVF8192,PQ64&quot;, faiss.METRIC_INNER_PRODUCT)
coarse.train(train); coarse.add(xb)

refined = faiss.IndexRefineFlat(coarse)   # wraps the coarse index with an exact refiner
refined.kfactor = 2.0                     # search 2×k in coarse stage, re-rank down to k

D, I = refined.search(xq, k=10)
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>On GPU you’ll typically run the coarse stage on device, then refine on device or CPU depending on memory; the wrapper manages the sequence.</li>
</ul>
<hr />
<h3 id="a3-indexpretransform-transforms-opqmatrix-pcamatrix">A3) <code>IndexPreTransform</code> + transforms (<code>OPQMatrix</code>, <code>PCAMatrix</code>)</h3>
<p><strong>Why:</strong> Pre‑rotate or reduce dimension <strong>inside</strong> the index for better PQ fit.</p>
<pre><code class="language-python"># 1) Build transforms: PCA (optional) then OPQ
pca = faiss.PCAMatrix(d_in=2560, d_out=1024, eigen_power=-0.5)  # example PCA step
opq = faiss.OPQMatrix(d_out=1024, m=64)  # OPQ with 64 subquantizers

# 2) Chain transforms in a vector
vt = faiss.VectorTransformChain()
vt.append(pca)
vt.append(opq)

# 3) Base index AFTER transforms (note d=1024 now)
base = faiss.index_factory(1024, &quot;IVF8192,PQ64&quot;, faiss.METRIC_INNER_PRODUCT)

# 4) Wrap into IndexPreTransform
pre = faiss.IndexPreTransform(vt, base)

# 5) Train on original-dim data; transform is applied internally
pre.train(train)       # 'train' runs PCA/OPQ fitting + IVF/PQ training
pre.add(xb)
D, I = pre.search(xq, 10)
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>For our default blueprint we already use OPQ64; <code>IndexPreTransform</code> is the explicit form of that pipeline. Keep cosine/IP consistency: <strong>normalize</strong> before train/add/query. </li>
</ul>
<hr />
<h3 id="a4-clustering-kmeans-build-coarse-quantizers-explicitly">A4) <code>Clustering</code> (K‑means) — build coarse quantizers explicitly</h3>
<p><strong>Why:</strong> Manual control when you don’t use <code>index_factory()</code>.</p>
<pre><code class="language-python"># Train IVF coarse quantizer centroids explicitly with K-means
nlist = 8192
kmeans = faiss.Clustering(d, nlist)
kmeans.niter = 25; kmeans.verbose = True

quantizer = faiss.IndexFlatIP(d)        # cosine via normalization + IP
kmeans.train(train, quantizer)

# Use trained quantizer to build IVF, then attach PQ
ivf = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_INNER_PRODUCT)
ivf.train(train)
ivf.add(xb)
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li><code>index_factory()</code> automates this, but direct <code>Clustering</code> is useful for specialized training schedules.</li>
</ul>
<hr />
<h3 id="a5-parameterspace-gpuparameterspace-named-tuning-knobs">A5) <code>ParameterSpace</code> / <code>GpuParameterSpace</code> — named tuning knobs</h3>
<p><strong>Why:</strong> Set parameters (e.g., <code>nprobe</code>) by <strong>name</strong>, works across families.</p>
<pre><code class="language-python"># CPU
ps = faiss.ParameterSpace()
ps.set_index_parameter(base, &quot;nprobe&quot;, 64)

# GPU
gps = faiss.GpuParameterSpace(); gps.initialize(gpu_index)
gps.set_index_parameter(gpu_index, &quot;nprobe&quot;, 64)   # same name on GPU
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>Prefer these over ad‑hoc setters; helps keep code index‑agnostic.</li>
</ul>
<hr />
<h3 id="a6-persistence-write_index-read_index">A6) Persistence — <code>write_index</code> / <code>read_index</code></h3>
<p><strong>Why:</strong> Save CPU index for fast reload; re‑clone to GPU at runtime.</p>
<pre><code class="language-python">faiss.write_index(idmap, &quot;/data/faiss/shard_000.idx&quot;)          # save CPU index (any type)
idmap2 = faiss.read_index(&quot;/data/faiss/shard_000.idx&quot;)         # load CPU index
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>Don’t save GPU indexes; reconstruct by cloning the CPU index on startup. Track paths and config in DuckDB (<code>faiss_indexes</code>). </li>
</ul>
<hr />
<h3 id="a7-range-search-range_search-aka-radius-search">A7) Range search — <code>range_search</code> (a.k.a. radius search)</h3>
<p><strong>Why:</strong> Get all neighbors within a distance threshold instead of top‑K.</p>
<pre><code class="language-python">radius = 0.1  # for cosine/IP, pick meaningful threshold on normalized vectors
rs = faiss.RangeSearchResult(xq.shape[0])
idmap.range_search(xq, radius, rs)

# Extract result per query
lims, D, I = rs.lims, rs.distances, rs.labels
for qi in range(xq.shape[0]):
    begin, end = lims[qi], lims[qi+1]
    neigh_ids = I[begin:end]
    neigh_dist = D[begin:end]
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>Range search is less common for large‑scale serving, but handy for thresholded neighbor graphs.</li>
</ul>
<hr />
<h3 id="a8-filtered-search-idselector-searchparametersivf">A8) Filtered search — <code>IDSelector*</code> + <code>SearchParametersIVF</code></h3>
<p><strong>Why:</strong> Exclude/allow subsets of IDs at <strong>query time</strong>.</p>
<pre><code class="language-python"># Build a selector (ids in [lo, hi))
sel = faiss.IDSelectorRange(lo=100_000, hi=150_000)

# Tie selector to IVF search params
sp = faiss.SearchParametersIVF()
sp.nprobe = 64
sp.sel = sel

# Call the 3-arg search to pass params
D, I = idmap.search(xq, 10, params=sp)
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>With cuVS‑backed GPU indexes enabled (<code>use_cuvs=True</code> when cloning/constructing), FAISS converts these selectors into cuVS filters under the hood (your build includes the converter). </li>
</ul>
<hr />
<h3 id="a9-deletions-remove_ids">A9) Deletions — <code>remove_ids</code></h3>
<p><strong>Why:</strong> Remove a set of IDs (e.g., retractions, updates).</p>
<pre><code class="language-python">to_remove = faiss.IDSelectorRange(200_000, 210_000)  # OR IDSelectorBatch([...])
n_removed = idmap.remove_ids(to_remove)
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>IVF/PQ structures become “holey” over time; periodic rebuilds (or re‑add to a fresh shard) keep performance consistent.</li>
</ul>
<hr />
<h3 id="a10-reconstruction-reconstruct-reconstruct_n">A10) Reconstruction — <code>reconstruct</code>, <code>reconstruct_n</code></h3>
<p><strong>Why:</strong> Retrieve vector approximations (exact for Flat/HNSW; approximate for PQ).</p>
<pre><code class="language-python">vec = idmap.reconstruct(int(I[0,0]))
mat = idmap.reconstruct_n(0, 100)   # first 100 vectors
</code></pre>
<hr />
<h3 id="a11-cpu-parallelism-omp_set_num_threads">A11) CPU parallelism — <code>omp_set_num_threads</code></h3>
<p><strong>Why:</strong> Pin thread count for CPU add/search/training.</p>
<pre><code class="language-python">faiss.omp_set_num_threads(14)  # match your server threads
</code></pre>
<hr />
<h2 id="b-faiss-gpu-multigpu-functions-deeper-with-cuvs-enablement">B) FAISS — GPU &amp; multi‑GPU functions (deeper, with cuVS enablement)</h2>
<blockquote>
<p><strong>Reminder</strong>: In your wheel, FAISS GPU indexes can dispatch to <strong>cuVS</strong> for <strong>Flat, IVF‑Flat, IVF‑PQ, CAGRA, Binary‑CAGRA</strong> when you set <code>use_cuvs=True</code> on the <strong>GPU cloner</strong> or the <strong>GPU index config</strong>, and the cuVS libraries are preloaded. </p>
</blockquote>
<h3 id="b1-cpugpu-cloning-single-multigpu">B1) CPU→GPU cloning (single &amp; multi‑GPU)</h3>
<pre><code class="language-python">import faiss

# 1) Single GPU (cuVS-first, safe fallback)
co = faiss.GpuClonerOptions(); co.use_cuvs = True
try:
    gpu_index = faiss.index_cpu_to_gpu(res, 0, idmap, co)
except RuntimeError:
    co.use_cuvs = False
    gpu_index = faiss.index_cpu_to_gpu(res, 0, idmap, co)

# 2) Replicated (QPS-scale)
ngpu = faiss.get_num_gpus()
resources = [faiss.StandardGpuResources() for _ in range(ngpu)]
replicas = faiss.IndexReplicas()
for dev in range(ngpu):
    replicas.addIndex(faiss.index_cpu_to_gpu(resources[dev], dev, idmap, co))

# 3) Sharded (capacity-scale)
shards = faiss.IndexShards(d, threaded=True, successive_ids=False)
# Build per-shard CPU indexes first, then clone each with co.use_cuvs=True and add to 'shards'
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>Replicas improve QPS; shards expand capacity; wrap both under one logical index in your registry and fan‑out search. </li>
</ul>
<hr />
<h3 id="b2-direct-gpu-constructors-with-gpuindexconfiguse_cuvs">B2) Direct GPU constructors with <code>GpuIndex*Config.use_cuvs</code></h3>
<p><strong>Flat</strong></p>
<pre><code class="language-python">cfg = faiss.GpuIndexFlatConfig(); cfg.use_cuvs = True
gpu_flat = faiss.GpuIndexFlatIP(res, d, cfg)
</code></pre>
<p><strong>IVF‑Flat / IVF‑PQ</strong></p>
<pre><code class="language-python">ivf_cfg = faiss.GpuIndexIVFConfig(); ivf_cfg.use_cuvs = True
# Pass ivf_cfg to the appropriate GpuIndexIVF* constructor for your metric/quantizer
</code></pre>
<p><strong>CAGRA</strong> (graph ANN)</p>
<pre><code class="language-python"># Prefer CPU→GPU cloning unless you need specific GPU-only build options.
# If constructing directly, set the config that inherits GpuIndexConfig:
# cagra_cfg = faiss.GpuIndexCagraConfig(); cagra_cfg.use_cuvs = True
# gpu_cagra = faiss.GpuIndexCagra(res, d, cagra_cfg)
</code></pre>
<p><strong>Binary‑CAGRA</strong></p>
<ul>
<li>Use the <strong>cloner</strong> (<code>GpuClonerOptions.use_cuvs=True</code>) when moving from CPU binary graph indexes to GPU.</li>
</ul>
<hr />
<h3 id="b3-gpu-distance-primitives-bfknn-knn_gpubfknn">B3) GPU distance primitives — bfKNN (<code>knn_gpu</code>/<code>bfKnn</code>)</h3>
<p><strong>Exact GPU kNN</strong> (cuVS‑aware):</p>
<pre><code class="language-python">params = faiss.GpuDistanceParams(); params.metric = faiss.METRIC_INNER_PRODUCT
params.k = 10; params.dims = d
use_cuvs = bool(faiss.should_use_cuvs(params))     # central probe, then:

D, I = faiss.knn_gpu(res, xq.astype('float32'), xb.astype('float32'),
                     k=10, metric=faiss.METRIC_INNER_PRODUCT, use_cuvs=use_cuvs)
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>Your build routes bfKNN to cuVS when possible; otherwise FAISS kernels are used. Preload cuVS so the probe can return True when viable. </li>
</ul>
<hr />
<h3 id="b4-gpu-tuning-knobs-gpuparameterspace-configs">B4) GPU tuning knobs — <code>GpuParameterSpace</code> &amp; configs</h3>
<ul>
<li><code>GpuParameterSpace.set_index_parameter(gpu_index, "nprobe", 64)</code> — uniform way to set IVF probes.</li>
<li>
<p>IVFPQ config highlights:</p>
</li>
<li>
<p><code>usePrecomputedTables</code> — faster scans at higher memory.</p>
</li>
<li><code>useFloat16LookupTables</code> — lower memory, slight precision trade‑off; useful for large <code>m</code> or tight VRAM budgets.</li>
</ul>
<hr />
<h2 id="c-faiss-contrib-helpers-youll-likely-use">C) FAISS contrib helpers you’ll likely use</h2>
<p><em>(These ship in the python package and are handy for pipelines.)</em></p>
<ul>
<li><strong><code>contrib.factory_tools</code></strong> — convenience builders &amp; validators for factory strings.</li>
<li><strong><code>contrib.ivf_tools</code></strong> — IVF diagnostics, centroid utilities.</li>
<li><strong><code>contrib.big_batch_search</code></strong> — large‑batch search helpers to pipeline host↔device copies.</li>
<li><strong><code>contrib.ondisk</code></strong> — on‑disk inverted lists for huge CPU‑side corpora.</li>
</ul>
<p>Use them to simplify scripts; your production path should still keep <strong>CPU index persisted + GPU clone</strong> at runtime as the source of truth. </p>
<hr />
<h2 id="d-cuvs-functions-modules-we-hadnt-exemplified-now-with-code">D) cuVS — functions &amp; modules we hadn’t exemplified (now with code)</h2>
<blockquote>
<p>cuVS runs <strong>entirely on GPU</strong> with a consistent <code>build / extend / search / save / load</code> shape per algorithm. Provide a <code>Resources</code> handle to share a stream and avoid implicit syncs; pass <strong>device arrays</strong> for best performance. </p>
</blockquote>
<h3 id="d1-neighborsbrute_force-exact-knn-baseline-qa">D1) <code>neighbors.brute_force</code> — exact kNN (baseline &amp; QA)</h3>
<pre><code class="language-python">import numpy as np
from cuvs.common import Resources
from cuvs.neighbors import brute_force
from pylibraft.common import device_ndarray

h = Resources()
xb = device_ndarray(np.random.rand(1_000_000, 2560).astype(np.float32))
xq = device_ndarray(np.random.rand(10_000,    2560).astype(np.float32))

index = brute_force.build(brute_force.IndexParams(metric=&quot;sqeuclidean&quot;), xb, resources=h)

D = device_ndarray(np.empty((xq.shape[0], 10), np.float32))
I = device_ndarray(np.empty((xq.shape[0], 10), np.int64))
brute_force.search(brute_force.SearchParams(metric=&quot;sqeuclidean&quot;),
                   index, xq, k=10, distances=D, neighbors=I, resources=h)

# Incremental ingest
xb2 = device_ndarray(np.random.rand(200_000, 2560).astype(np.float32))
brute_force.extend(index, xb2, resources=h)

# Persistence
brute_force.save(index, &quot;/tmp/cuvs_bruteforce.idx&quot;)
index = brute_force.load(&quot;/tmp/cuvs_bruteforce.idx&quot;, resources=h)
h.sync()
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>Good for <strong>ground truth</strong> during tuning and for small datasets. </li>
</ul>
<hr />
<h3 id="d2-neighborsivf_flat-faisslike-ivf-on-gpu">D2) <code>neighbors.ivf_flat</code> — FAISS‑like IVF on GPU</h3>
<pre><code class="language-python">from cuvs.neighbors import ivf_flat

h = Resources()
xb = device_ndarray(np.random.rand(10_000, 2560).astype(np.float32))
xq = device_ndarray(np.random.rand(1_000,  2560).astype(np.float32))

idx = ivf_flat.build(ivf_flat.IndexParams(n_lists=8192, metric=&quot;sqeuclidean&quot;), xb, resources=h)

D = device_ndarray(np.empty((xq.shape[0], 10), np.float32))
I = device_ndarray(np.empty((xq.shape[0], 10), np.int64))
ivf_flat.search(ivf_flat.SearchParams(n_probes=64), idx, xq, k=10,
                distances=D, neighbors=I, resources=h)

# Add more
ivf_flat.extend(idx, device_ndarray(np.random.rand(5_000, 2560).astype(np.float32)), resources=h)

# Save / load
ivf_flat.save(idx, &quot;/tmp/cuvs_ivfflat.idx&quot;)
idx2 = ivf_flat.load(&quot;/tmp/cuvs_ivfflat.idx&quot;, resources=h)
h.sync()
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>Parameter names mirror FAISS concepts: <code>n_lists</code>, <code>n_probes</code>, metric. </li>
</ul>
<hr />
<h3 id="d3-neighborsivf_pq-ivf-with-product-quantization">D3) <code>neighbors.ivf_pq</code> — IVF with Product Quantization</h3>
<p><em>(We’d shown build/search before; here’s <code>extend/save/load</code> and host output conversion.)</em> </p>
<pre><code class="language-python">from cuvs.neighbors import ivf_pq

h = Resources()
idx = ivf_pq.build(ivf_pq.IndexParams(n_lists=8192, metric=&quot;sqeuclidean&quot;, pq_bits=8),
                   xb, resources=h)

# Extend incrementally
ivf_pq.extend(idx, device_ndarray(np.random.rand(20_000, 2560).astype(np.float32)), resources=h)

# Search to host arrays (optional)
D_dev = device_ndarray(np.empty((xq.shape[0], 10), np.float32))
I_dev = device_ndarray(np.empty((xq.shape[0], 10), np.int64))
ivf_pq.search(ivf_pq.SearchParams(n_probes=64), idx, xq, k=10, distances=D_dev, neighbors=I_dev, resources=h)
D_host, I_host = D_dev.copy_to_host(), I_dev.copy_to_host()

# Save / load
ivf_pq.save(idx, &quot;/tmp/cuvs_ivfpq.idx&quot;)
idx = ivf_pq.load(&quot;/tmp/cuvs_ivfpq.idx&quot;, resources=h)
h.sync()
</code></pre>
<hr />
<h3 id="d4-neighborscagra-highrecall-graph-ann">D4) <code>neighbors.cagra</code> — high‑recall graph ANN</h3>
<pre><code class="language-python">from cuvs.neighbors import cagra

h = Resources()
xb = device_ndarray(np.random.rand(2_000_000, 2560).astype(np.float32))
xq = device_ndarray(np.random.rand(20_000,    2560).astype(np.float32))

idx = cagra.build(cagra.IndexParams(metric=&quot;sqeuclidean&quot;), xb, resources=h)

D = device_ndarray(np.empty((xq.shape[0], 10), np.float32))
I = device_ndarray(np.empty((xq.shape[0], 10), np.int64))
cagra.search(cagra.SearchParams(), idx, xq, k=10, distances=D, neighbors=I, resources=h)

# Extend / persist
cagra.extend(idx, device_ndarray(np.random.rand(100_000, 2560).astype(np.float32)), resources=h)
cagra.save(idx, &quot;/tmp/cuvs_cagra.idx&quot;)
idx = cagra.load(&quot;/tmp/cuvs_cagra.idx&quot;, resources=h)
h.sync()
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>CAGRA is excellent for tight latency at high recall; memory‑heavier than PQ. Use it for premium tiers. </li>
</ul>
<hr />
<h3 id="d5-neighborshnsw">D5) <code>neighbors.hnsw</code></h3>
<pre><code class="language-python">from cuvs.neighbors import hnsw

h = Resources()
idx = hnsw.build(hnsw.IndexParams(metric=&quot;sqeuclidean&quot;), xb, resources=h)
hnsw.search(hnsw.SearchParams(), idx, xq, k=10,
            distances=D, neighbors=I, resources=h)
hnsw.save(idx, &quot;/tmp/cuvs_hnsw.idx&quot;)
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>A familiar graph ANN baseline on GPU. Pick either <strong>CAGRA</strong> (higher perf) or <strong>HNSW</strong> depending on constraints. </li>
</ul>
<hr />
<h3 id="d6-filters-refine-tiered-indexes-highlevel-patterns">D6) Filters, refine, tiered indexes (high‑level patterns)</h3>
<ul>
<li><strong>Filters</strong> — apply post‑search restrictions or pre‑filter candidates with <code>neighbors.filters</code> utilities (e.g., by ID set). Use them for <strong>policy constraints</strong> or <strong>tenancy</strong>. </li>
<li><strong>Refine</strong> — re‑score ANN candidates with an exact step (<code>neighbors.refine</code>) for <strong>accuracy boosts</strong>. Good when you need Flat re‑ranking on a subset. </li>
<li><strong>Tiered index</strong> — orchestrate multi‑stage pipelines (e.g., IVF‑PQ → refine) using <code>neighbors.tiered_index</code> helpers. </li>
</ul>
<p><em>(Function names follow the <code>build/search/extend/save/load</code> theme; wire them like the examples above.)</em></p>
<hr />
<h3 id="d7-multigpu-neighborsmg-distributed-ivfpq-ivfflat-cagra">D7) Multi‑GPU (<code>neighbors.mg</code>) — <strong>distributed IVF‑PQ / IVF‑Flat / CAGRA</strong></h3>
<p><strong>Conceptual usage</strong> (keep the same <code>Resources</code> concept per device and use NCCL):</p>
<pre><code class="language-python">from cuvs.neighbors.mg import ivf_pq as mg_ivfpq
# Build: mg_ivfpq.build(mg_ivfpq.IndexParams(...), dataset_per_gpu, resources=handles_per_gpu)
# Search: mg_ivfpq.search(..., k=..., resources=handles_per_gpu)
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>Requires NCCL. Use this path when one GPU’s memory is insufficient or you need cluster‑like throughput while staying on a single multi‑GPU box. </li>
</ul>
<hr />
<h3 id="d8-distancepairwise_distance-gpu-distance-matrix">D8) <code>distance.pairwise_distance</code> — GPU distance matrix</h3>
<pre><code class="language-python">from cuvs import distance
Dx = distance.pairwise_distance(xq, xb, metric=&quot;sqeuclidean&quot;, resources=h)  # Dx on device by default
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>Handy for diagnostics, unit tests, or custom scoring layers. </li>
</ul>
<hr />
<h3 id="d9-clusterkmeans-gpu-kmeans-centers-predict-cost">D9) <code>cluster.kmeans</code> — GPU KMeans (centers, predict, cost)</h3>
<pre><code class="language-python">from cuvs.cluster import kmeans

centers, inertia, n_iters = kmeans.fit(kmeans.KMeansParams(n_clusters=8192), xb, resources=h)
labels = kmeans.predict(xb, centers, resources=h)
cost = kmeans.cluster_cost(xb, centers, resources=h)
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>Use for <strong>custom IVF training</strong> or other clustering tasks; interoperates with device arrays. </li>
</ul>
<hr />
<h2 id="e-libcuvs-loader-functions-env-youll-use-in-code">E) libcuvs loader — functions &amp; env you’ll use in code</h2>
<blockquote>
<p>Preload cuVS and RAPIDS libs <strong>once per process</strong> before any FAISS/cuVS calls to guarantee symbol resolution and allocator setup. </p>
</blockquote>
<pre><code class="language-python">from libcuvs import load_library
handles = load_library()
print(&quot;Loaded:&quot;, [h._name for h in handles])  # libcuvs.so, libcuvs_c.so, librmm.so, rapids_logger.so
</code></pre>
<p><strong>Environment knobs</strong> (optional):</p>
<ul>
<li><code>RAPIDS_LIBCUVS_PREFER_SYSTEM_LIBRARY=true</code> → prefer system libs over wheel‑bundled copies.</li>
<li>HybridSearch’s <code>_ensure_cuvs_loader_path()</code> adds all <code>lib64/</code> dirs to <code>LD_LIBRARY_PATH</code> for child processes (inheritance is useful for workers). </li>
</ul>
<hr />
<h2 id="f-endtoend-patterns-that-combine-the-above">F) End‑to‑end patterns that combine the above</h2>
<h3 id="f1-filtered-refined-ivfpq-on-gpu-with-cuvs">F1) <strong>Filtered, refined IVF‑PQ</strong> on GPU with cuVS</h3>
<pre><code class="language-python"># 0) Preload cuVS (once)
from libcuvs import load_library; load_library()                               # loader. :contentReference[oaicite:25]{index=25}
import faiss, numpy as np

d=2560
cpu = faiss.index_factory(d, &quot;OPQ64,IVF8192,PQ64&quot;, faiss.METRIC_INNER_PRODUCT)
train = np.random.randn(10_000_000, d).astype('float32'); faiss.normalize_L2(train)
cpu.train(train)

# ID map to carry your IDs
idmap = faiss.IndexIDMap2(cpu)
xb  = np.random.randn(20_000_000, d).astype('float32'); faiss.normalize_L2(xb)
ids = np.arange(1, 1+xb.shape[0], dtype='int64')
idmap.add_with_ids(xb, ids)

# Clone to GPU with cuVS enabled (fallback safe)
res = faiss.StandardGpuResources(); res.setTempMemory(1_200_000_000); res.setPinnedMemory(512_000_000)
co  = faiss.GpuClonerOptions(); co.use_cuvs=True
try: gpu = faiss.index_cpu_to_gpu(res, 0, idmap, co)
except RuntimeError:
    co.use_cuvs=False; gpu = faiss.index_cpu_to_gpu(res, 0, idmap, co)

# Filter: only IDs in a range, then search &amp; refine
sp = faiss.SearchParametersIVF(); sp.nprobe = 64; sp.sel = faiss.IDSelectorRange(100_000, 500_000)
refiner = faiss.IndexRefineFlat(gpu); refiner.kfactor = 2.0

xq = np.random.randn(1000, d).astype('float32'); faiss.normalize_L2(xq)
D, I = refiner.search(xq, 10, params=sp)
</code></pre>
<p><strong>Why this works well for you</strong></p>
<ul>
<li>Cosine via normalization + IP (2560‑d per architecture). </li>
<li>cuVS path engaged for IVF‑PQ when available; otherwise FAISS kernels. </li>
<li>Filter converted to cuVS filter internally in your build. </li>
</ul>
<hr />
<h3 id="f2-direct-cuvs-multigpu-ivfpq-outline">F2) <strong>Direct cuVS</strong> multi‑GPU IVF‑PQ (outline)</h3>
<pre><code class="language-python"># Pseudocode outline (patterns match single-GPU examples; use mg.ivf_pq)
from cuvs.neighbors.mg import ivf_pq as mg_ivfpq
# handles = [Resources() per GPU]; datasets split per GPU as device arrays
# idx = mg_ivfpq.build(mg_ivfpq.IndexParams(n_lists=8192, metric=&quot;sqeuclidean&quot;, pq_bits=8),
#                      datasets, resources=handles)
# mg_ivfpq.search(mg_ivfpq.SearchParams(n_probes=64), idx, queries, k=10,
#                 distances=..., neighbors=..., resources=handles)
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li>Reach for multi‑GPU cuVS when a single GPU’s VRAM is the bottleneck. </li>
</ul>
<hr />
<h2 id="g-quick-checklist-for-agents-so-you-dont-miss-a-function-again">G) Quick checklist for agents (so you don’t miss a function again)</h2>
<ul>
<li><strong>Always normalize</strong> embeddings for cosine/IP.</li>
<li>Use <strong><code>IndexIDMap2</code></strong> to own IDs; <strong><code>IndexRefineFlat</code></strong> when you need exact re‑ranking.</li>
<li>Set knobs with <strong><code>ParameterSpace</code> / <code>GpuParameterSpace</code></strong>.</li>
<li>For <strong>filters</strong>, use <strong><code>IDSelector*</code></strong> + <code>SearchParametersIVF</code>; your build converts to cuVS automatically when cuVS is enabled. </li>
<li>Persist <strong>CPU</strong> index with <code>write_index</code>; <strong>re‑clone</strong> to GPU on startup.</li>
<li>Preload cuVS (<code>libcuvs.load_library()</code>), then set <strong><code>use_cuvs=True</code></strong> on <strong>cloner/config</strong> for <strong>Flat, IVF‑Flat, IVF‑PQ, CAGRA, Binary‑CAGRA</strong>; guard with try/except or <code>should_use_cuvs</code> for <strong>bfKNN</strong>. </li>
<li>For <strong>direct cuVS</strong>: use <code>build/extend/search/save/load</code> in <code>neighbors.{ivf_flat, ivf_pq, cagra, hnsw, brute_force}</code> with <strong>device arrays</strong> and a shared <strong><code>Resources</code></strong> handle. </li>
<li>Keep defaults from the architecture doc (2560‑d, <code>OPQ64,IVF8192,PQ64</code>, <code>nprobe=64</code>, shards ≤10 M vectors). </li>
</ul>
<hr />
<p>If you want, I can also package these into a <strong>reference Jupyter notebook</strong> that runs each snippet end‑to‑end (with small synthetic data) and prints sanity checks (dimensions, top‑K shapes, cuVS enabled flags).</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.indexes"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>